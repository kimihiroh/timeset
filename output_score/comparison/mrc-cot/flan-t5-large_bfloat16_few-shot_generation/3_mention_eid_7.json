{
    "args": {
        "batch_size": 4,
        "dataset_name": "ctf-mrc-cot",
        "device": "cuda",
        "dirpath_log": "log",
        "dirpath_model": null,
        "dirpath_output": "output/comparison",
        "dirpath_output_score": "output_score/comparison",
        "filepath_test": "data/preprocessed/ctf-sample/test.json",
        "filepath_dev": "data/preprocessed/ctf-sample/dev.json",
        "inference_type": "few-shot",
        "local_rank": 0,
        "marker": "eid",
        "max_new_tokens": 512,
        "model_id": "google/flan-t5-large",
        "num_demonstration": 3,
        "num_gpu": 1,
        "num_cpu": 4,
        "peft_model_path": null,
        "precision_type": "bfloat16",
        "representation": "mention",
        "seed": 7,
        "temperature": 0.0,
        "dirpath_model_cache": "/data/tir/projects/tir6/general/kimihiro/.cache/huggingface/transformers"
    },
    "average": {
        "document-and-pair-wise-scores": {
            "range": {
                "min": 0.12196235144891383,
                "median": 0.1628239333858256,
                "max": 0.288479311968065
            },
            "individual": {
                "hint_cot": 0.288479311968065,
                "note_events_cot": 0.14314933682672062,
                "refer_events_cot": 0.27617054114016676,
                "careful_cot": 0.1628239333858256,
                "simple_cot": 0.12196235144891383
            }
        }
    },
    "individuals": {
        "document-and-pair-wise-scores": {
            "hint_cot": {
                "government_and_politics_riots_4": {
                    "AFTER": {
                        "precision": 0.125,
                        "recall": 0.25,
                        "f1-score": 0.16666666666666666,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.6666666666666666,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.4444444444444444,
                        "support": 12.0
                    },
                    "COEX": {
                        "precision": 0.5,
                        "recall": 0.25,
                        "f1-score": 0.3333333333333333,
                        "support": 12.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2857142857142857,
                    "macro avg": {
                        "precision": 0.32291666666666663,
                        "recall": 0.20833333333333331,
                        "f1-score": 0.2361111111111111,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.5178571428571429,
                        "recall": 0.2857142857142857,
                        "f1-score": 0.35714285714285715,
                        "support": 28.0
                    }
                },
                "rail_transport_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "BEFORE": {
                        "precision": 0.875,
                        "recall": 0.20588235294117646,
                        "f1-score": 0.33333333333333337,
                        "support": 34.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.19444444444444445,
                    "macro avg": {
                        "precision": 0.21875,
                        "recall": 0.051470588235294115,
                        "f1-score": 0.08333333333333334,
                        "support": 36.0
                    },
                    "weighted avg": {
                        "precision": 0.8263888888888888,
                        "recall": 0.19444444444444445,
                        "f1-score": 0.3148148148148148,
                        "support": 36.0
                    }
                },
                "politics_and_conflicts_policy_change_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.25,
                        "recall": 0.5,
                        "f1-score": 0.3333333333333333,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.16666666666666666,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.16666666666666666,
                        "support": 6.0
                    },
                    "macro avg": {
                        "precision": 0.0625,
                        "recall": 0.125,
                        "f1-score": 0.08333333333333333,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.08333333333333333,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.1111111111111111,
                        "support": 6.0
                    }
                },
                "politics_and_conflicts_drones_1": {
                    "AFTER": {
                        "precision": 0.2857142857142857,
                        "recall": 0.18181818181818182,
                        "f1-score": 0.2222222222222222,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.2,
                        "recall": 0.125,
                        "f1-score": 0.15384615384615385,
                        "support": 8.0
                    },
                    "COEX": {
                        "precision": 0.25,
                        "recall": 0.5,
                        "f1-score": 0.3333333333333333,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.19047619047619047,
                    "macro avg": {
                        "precision": 0.18392857142857144,
                        "recall": 0.20170454545454547,
                        "f1-score": 0.17735042735042733,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.24965986394557824,
                        "recall": 0.19047619047619047,
                        "f1-score": 0.20675620675620673,
                        "support": 21.0
                    }
                },
                "disasters_and_accidents_road_crash_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "BEFORE": {
                        "precision": 0.75,
                        "recall": 0.2727272727272727,
                        "f1-score": 0.39999999999999997,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 10.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.14285714285714285,
                    "macro avg": {
                        "precision": 0.1875,
                        "recall": 0.06818181818181818,
                        "f1-score": 0.09999999999999999,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.39285714285714285,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.2095238095238095,
                        "support": 21.0
                    }
                },
                "crime_and_law_accuse_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.5,
                        "f1-score": 0.6666666666666666,
                        "support": 6.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.3,
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.125,
                        "f1-score": 0.16666666666666666,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.6,
                        "recall": 0.3,
                        "f1-score": 0.4,
                        "support": 10.0
                    }
                },
                "government_and_politics_protests_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.625,
                        "recall": 0.25,
                        "f1-score": 0.35714285714285715,
                        "support": 20.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.17857142857142858,
                    "macro avg": {
                        "precision": 0.15625,
                        "recall": 0.0625,
                        "f1-score": 0.08928571428571429,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.44642857142857145,
                        "recall": 0.17857142857142858,
                        "f1-score": 0.25510204081632654,
                        "support": 28.0
                    }
                },
                "politics_and_conflicts_elections_2": {
                    "AFTER": {
                        "precision": 0.2857142857142857,
                        "recall": 0.09090909090909091,
                        "f1-score": 0.13793103448275862,
                        "support": 22.0
                    },
                    "BEFORE": {
                        "precision": 0.13333333333333333,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.1379310344827586,
                        "support": 14.0
                    },
                    "COEX": {
                        "precision": 0.14285714285714285,
                        "recall": 0.1111111111111111,
                        "f1-score": 0.125,
                        "support": 9.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.1111111111111111,
                    "macro avg": {
                        "precision": 0.14047619047619048,
                        "recall": 0.08621933621933622,
                        "f1-score": 0.10021551724137931,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.2097354497354497,
                        "recall": 0.1111111111111111,
                        "f1-score": 0.1353448275862069,
                        "support": 45.0
                    }
                },
                "environment_2": {
                    "AFTER": {
                        "precision": 0.375,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.20689655172413796,
                        "support": 21.0
                    },
                    "BEFORE": {
                        "precision": 0.6363636363636364,
                        "recall": 0.30434782608695654,
                        "f1-score": 0.411764705882353,
                        "support": 23.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2222222222222222,
                    "macro avg": {
                        "precision": 0.25284090909090906,
                        "recall": 0.11180124223602485,
                        "f1-score": 0.15466531440162273,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.5002525252525253,
                        "recall": 0.2222222222222222,
                        "f1-score": 0.3070092404778003,
                        "support": 45.0
                    }
                },
                "weather_floods_3": {
                    "AFTER": {
                        "precision": 0.14285714285714285,
                        "recall": 0.25,
                        "f1-score": 0.18181818181818182,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.6666666666666666,
                        "recall": 0.2857142857142857,
                        "f1-score": 0.4,
                        "support": 7.0
                    },
                    "COEX": {
                        "precision": 0.25,
                        "recall": 0.25,
                        "f1-score": 0.25,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.26666666666666666,
                    "macro avg": {
                        "precision": 0.2648809523809524,
                        "recall": 0.19642857142857142,
                        "f1-score": 0.20795454545454545,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.41587301587301584,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.3018181818181818,
                        "support": 15.0
                    }
                },
                "sports_1": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.5,
                        "f1-score": 0.6666666666666666,
                        "support": 2.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 3.0
                    },
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.125,
                        "f1-score": 0.16666666666666666,
                        "support": 3.0
                    },
                    "weighted avg": {
                        "precision": 0.6666666666666666,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.4444444444444444,
                        "support": 3.0
                    }
                },
                "health_4": {
                    "AFTER": {
                        "precision": 0.16666666666666666,
                        "recall": 0.1111111111111111,
                        "f1-score": 0.13333333333333333,
                        "support": 9.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 8.0
                    },
                    "COEX": {
                        "precision": 0.25,
                        "recall": 0.25,
                        "f1-score": 0.25,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.09523809523809523,
                    "macro avg": {
                        "precision": 0.10416666666666666,
                        "recall": 0.09027777777777778,
                        "f1-score": 0.09583333333333333,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.11904761904761904,
                        "recall": 0.09523809523809523,
                        "f1-score": 0.10476190476190476,
                        "support": 21.0
                    }
                },
                "weather_earthquakes_1": {
                    "AFTER": {
                        "precision": 0.25,
                        "recall": 0.5,
                        "f1-score": 0.3333333333333333,
                        "support": 6.0
                    },
                    "BEFORE": {
                        "precision": 0.7,
                        "recall": 0.21875,
                        "f1-score": 0.3333333333333333,
                        "support": 32.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 7.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2222222222222222,
                    "macro avg": {
                        "precision": 0.2375,
                        "recall": 0.1796875,
                        "f1-score": 0.16666666666666666,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.5311111111111111,
                        "recall": 0.2222222222222222,
                        "f1-score": 0.28148148148148144,
                        "support": 45.0
                    }
                },
                "space_4": {
                    "AFTER": {
                        "precision": 0.3333333333333333,
                        "recall": 0.2727272727272727,
                        "f1-score": 0.3,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.3478260869565218,
                        "support": 15.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.25,
                    "macro avg": {
                        "precision": 0.20833333333333331,
                        "recall": 0.13484848484848483,
                        "f1-score": 0.16195652173913044,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.3988095238095238,
                        "recall": 0.25,
                        "f1-score": 0.304192546583851,
                        "support": 28.0
                    }
                },
                "economy_and_business_strikes_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.25,
                        "f1-score": 0.3333333333333333,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.16666666666666666,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.16666666666666666,
                        "support": 6.0
                    },
                    "macro avg": {
                        "precision": 0.125,
                        "recall": 0.0625,
                        "f1-score": 0.08333333333333333,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.2222222222222222,
                        "support": 6.0
                    }
                },
                "politics_and_conflicts_armed_conflict_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.18181818181818182,
                        "f1-score": 0.26666666666666666,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.14285714285714285,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.2,
                        "support": 3.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.2,
                        "recall": 0.2,
                        "f1-score": 0.20000000000000004,
                        "support": 15.0
                    },
                    "macro avg": {
                        "precision": 0.1607142857142857,
                        "recall": 0.12878787878787878,
                        "f1-score": 0.11666666666666667,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.3952380952380953,
                        "recall": 0.2,
                        "f1-score": 0.23555555555555555,
                        "support": 15.0
                    }
                },
                "infectious_disease_4": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.25,
                        "f1-score": 0.25,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    }
                },
                "health_1": {
                    "AFTER": {
                        "precision": 0.6,
                        "recall": 0.5,
                        "f1-score": 0.5454545454545454,
                        "support": 6.0
                    },
                    "BEFORE": {
                        "precision": 0.6666666666666666,
                        "recall": 0.6666666666666666,
                        "f1-score": 0.6666666666666666,
                        "support": 3.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.5,
                        "recall": 0.5,
                        "f1-score": 0.5,
                        "support": 10.0
                    },
                    "macro avg": {
                        "precision": 0.31666666666666665,
                        "recall": 0.29166666666666663,
                        "f1-score": 0.303030303030303,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.5599999999999999,
                        "recall": 0.5,
                        "f1-score": 0.5272727272727272,
                        "support": 10.0
                    }
                },
                "disasters_and_accidents_shipwreck_2": {
                    "AFTER": {
                        "precision": 0.2,
                        "recall": 0.09090909090909091,
                        "f1-score": 0.12500000000000003,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.16666666666666666,
                        "recall": 0.1111111111111111,
                        "f1-score": 0.13333333333333333,
                        "support": 9.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.09523809523809523,
                    "macro avg": {
                        "precision": 0.09166666666666667,
                        "recall": 0.050505050505050504,
                        "f1-score": 0.06458333333333334,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.1761904761904762,
                        "recall": 0.09523809523809523,
                        "f1-score": 0.12261904761904763,
                        "support": 21.0
                    }
                },
                "rail_transport_3": {
                    "AFTER": {
                        "precision": 0.3333333333333333,
                        "recall": 0.4,
                        "f1-score": 0.3636363636363636,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.4,
                        "recall": 0.2,
                        "f1-score": 0.26666666666666666,
                        "support": 10.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.26666666666666666,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.26666666666666666,
                        "support": 15.0
                    },
                    "macro avg": {
                        "precision": 0.18333333333333335,
                        "recall": 0.15000000000000002,
                        "f1-score": 0.15757575757575756,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.3777777777777777,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.298989898989899,
                        "support": 15.0
                    }
                },
                "weather_storms_1_extra": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    }
                },
                "health_1_extra": {
                    "AFTER": {
                        "precision": 0.2,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.1818181818181818,
                        "support": 12.0
                    },
                    "BEFORE": {
                        "precision": 0.5833333333333334,
                        "recall": 0.25,
                        "f1-score": 0.35000000000000003,
                        "support": 28.0
                    },
                    "COEX": {
                        "precision": 0.6666666666666666,
                        "recall": 0.4,
                        "f1-score": 0.5,
                        "support": 15.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2727272727272727,
                    "macro avg": {
                        "precision": 0.36250000000000004,
                        "recall": 0.20416666666666666,
                        "f1-score": 0.25795454545454544,
                        "support": 55.0
                    },
                    "weighted avg": {
                        "precision": 0.5224242424242425,
                        "recall": 0.2727272727272727,
                        "f1-score": 0.3542148760330579,
                        "support": 55.0
                    }
                },
                "weather_floods_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.4,
                        "support": 24.0
                    },
                    "COEX": {
                        "precision": 0.125,
                        "recall": 0.03571428571428571,
                        "f1-score": 0.05555555555555556,
                        "support": 28.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.16363636363636364,
                    "macro avg": {
                        "precision": 0.15625,
                        "recall": 0.09226190476190475,
                        "f1-score": 0.1138888888888889,
                        "support": 55.0
                    },
                    "weighted avg": {
                        "precision": 0.2818181818181818,
                        "recall": 0.16363636363636364,
                        "f1-score": 0.20282828282828286,
                        "support": 55.0
                    }
                },
                "mining_4": {
                    "AFTER": {
                        "precision": 0.14285714285714285,
                        "recall": 0.09090909090909091,
                        "f1-score": 0.1111111111111111,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.6153846153846154,
                        "recall": 0.32,
                        "f1-score": 0.4210526315789474,
                        "support": 25.0
                    },
                    "COEX": {
                        "precision": 0.2,
                        "recall": 0.1111111111111111,
                        "f1-score": 0.14285714285714285,
                        "support": 9.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2222222222222222,
                    "macro avg": {
                        "precision": 0.23956043956043954,
                        "recall": 0.1305050505050505,
                        "f1-score": 0.16875522138680032,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.41680097680097683,
                        "recall": 0.2222222222222222,
                        "f1-score": 0.2896500510535598,
                        "support": 45.0
                    }
                },
                "disasters_and_accidents_volcanoes_4": {
                    "AFTER": {
                        "precision": 0.2,
                        "recall": 0.1,
                        "f1-score": 0.13333333333333333,
                        "support": 20.0
                    },
                    "BEFORE": {
                        "precision": 0.2,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.16666666666666666,
                        "support": 14.0
                    },
                    "COEX": {
                        "precision": 0.14285714285714285,
                        "recall": 0.5,
                        "f1-score": 0.22222222222222224,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.1388888888888889,
                    "macro avg": {
                        "precision": 0.13571428571428573,
                        "recall": 0.18571428571428572,
                        "f1-score": 0.13055555555555556,
                        "support": 36.0
                    },
                    "weighted avg": {
                        "precision": 0.19682539682539685,
                        "recall": 0.1388888888888889,
                        "f1-score": 0.15123456790123457,
                        "support": 36.0
                    }
                },
                "politics_and_conflicts_elections_3": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.6,
                        "f1-score": 0.5454545454545454,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.25,
                        "f1-score": 0.3333333333333333,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.75,
                        "recall": 0.5,
                        "f1-score": 0.6,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.4666666666666667,
                    "macro avg": {
                        "precision": 0.4375,
                        "recall": 0.3375,
                        "f1-score": 0.36969696969696964,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.6,
                        "recall": 0.4666666666666667,
                        "f1-score": 0.5107070707070707,
                        "support": 15.0
                    }
                },
                "economy_and_business_strikes_3": {
                    "AFTER": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3,
                        "f1-score": 0.3157894736842105,
                        "support": 10.0
                    },
                    "BEFORE": {
                        "precision": 0.14285714285714285,
                        "recall": 0.09090909090909091,
                        "f1-score": 0.1111111111111111,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.42857142857142855,
                        "recall": 0.42857142857142855,
                        "f1-score": 0.42857142857142855,
                        "support": 7.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.25,
                    "macro avg": {
                        "precision": 0.22619047619047616,
                        "recall": 0.20487012987012987,
                        "f1-score": 0.21386800334168754,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.282312925170068,
                        "recall": 0.25,
                        "f1-score": 0.26357560568086885,
                        "support": 28.0
                    }
                },
                "space_2": {
                    "AFTER": {
                        "precision": 0.5384615384615384,
                        "recall": 0.14,
                        "f1-score": 0.2222222222222222,
                        "support": 100.0
                    },
                    "BEFORE": {
                        "precision": 0.34782608695652173,
                        "recall": 0.1568627450980392,
                        "f1-score": 0.21621621621621623,
                        "support": 51.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.1437908496732026,
                    "macro avg": {
                        "precision": 0.22157190635451504,
                        "recall": 0.0742156862745098,
                        "f1-score": 0.10960960960960961,
                        "support": 153.0
                    },
                    "weighted avg": {
                        "precision": 0.4678776750388004,
                        "recall": 0.1437908496732026,
                        "f1-score": 0.2173153545702565,
                        "support": 153.0
                    }
                },
                "politics_and_conflicts_resign_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    }
                },
                "environment_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.5714285714285714,
                        "recall": 0.8,
                        "f1-score": 0.6666666666666666,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 1.0,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.5,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.4,
                    "macro avg": {
                        "precision": 0.39285714285714285,
                        "recall": 0.2833333333333333,
                        "f1-score": 0.29166666666666663,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.5904761904761905,
                        "recall": 0.4,
                        "f1-score": 0.4222222222222222,
                        "support": 15.0
                    }
                },
                "space_1_extra": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 1.0,
                        "f1-score": 0.6666666666666666,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.4,
                        "f1-score": 0.5714285714285715,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.5,
                        "recall": 0.5,
                        "f1-score": 0.5,
                        "support": 6.0
                    },
                    "macro avg": {
                        "precision": 0.375,
                        "recall": 0.35,
                        "f1-score": 0.30952380952380953,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.9166666666666666,
                        "recall": 0.5,
                        "f1-score": 0.5873015873015873,
                        "support": 6.0
                    }
                },
                "health_3": {
                    "AFTER": {
                        "precision": 0.3333333333333333,
                        "recall": 0.125,
                        "f1-score": 0.18181818181818182,
                        "support": 8.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.06666666666666667,
                    "macro avg": {
                        "precision": 0.08333333333333333,
                        "recall": 0.03125,
                        "f1-score": 0.045454545454545456,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.17777777777777776,
                        "recall": 0.06666666666666667,
                        "f1-score": 0.09696969696969697,
                        "support": 15.0
                    }
                },
                "environment_3": {
                    "AFTER": {
                        "precision": 0.6666666666666666,
                        "recall": 0.36363636363636365,
                        "f1-score": 0.4705882352941177,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.26666666666666666,
                    "macro avg": {
                        "precision": 0.16666666666666666,
                        "recall": 0.09090909090909091,
                        "f1-score": 0.11764705882352942,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.4888888888888889,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.34509803921568627,
                        "support": 15.0
                    }
                },
                "government_and_politics_protests_3": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.5,
                        "f1-score": 0.6666666666666666,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 6.0
                    },
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.125,
                        "f1-score": 0.16666666666666666,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.6666666666666666,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.4444444444444444,
                        "support": 6.0
                    }
                },
                "economy_and_business_financial_crisis_4": {
                    "AFTER": {
                        "precision": 0.42857142857142855,
                        "recall": 0.25,
                        "f1-score": 0.3157894736842105,
                        "support": 12.0
                    },
                    "BEFORE": {
                        "precision": 0.14285714285714285,
                        "recall": 0.2,
                        "f1-score": 0.16666666666666666,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.2,
                        "recall": 0.25,
                        "f1-score": 0.22222222222222224,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.23809523809523808,
                    "macro avg": {
                        "precision": 0.19285714285714284,
                        "recall": 0.175,
                        "f1-score": 0.17616959064327484,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.3170068027210884,
                        "recall": 0.23809523809523808,
                        "f1-score": 0.2624617098301309,
                        "support": 21.0
                    }
                },
                "computers_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    }
                },
                "crime_and_law_accuse_4": {
                    "AFTER": {
                        "precision": 0.75,
                        "recall": 0.6,
                        "f1-score": 0.6666666666666665,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.4,
                        "f1-score": 0.4444444444444445,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.5,
                        "recall": 0.5,
                        "f1-score": 0.5,
                        "support": 10.0
                    },
                    "macro avg": {
                        "precision": 0.3125,
                        "recall": 0.25,
                        "f1-score": 0.27777777777777773,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.625,
                        "recall": 0.5,
                        "f1-score": 0.5555555555555556,
                        "support": 10.0
                    }
                },
                "culture_and_entertainment_1": {
                    "AFTER": {
                        "precision": 0.25,
                        "recall": 0.5,
                        "f1-score": 0.3333333333333333,
                        "support": 2.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.16666666666666666,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.16666666666666666,
                        "support": 6.0
                    },
                    "macro avg": {
                        "precision": 0.0625,
                        "recall": 0.125,
                        "f1-score": 0.08333333333333333,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.08333333333333333,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.1111111111111111,
                        "support": 6.0
                    }
                },
                "internet_2": {
                    "AFTER": {
                        "precision": 0.25,
                        "recall": 0.2,
                        "f1-score": 0.22222222222222224,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 0.25,
                        "f1-score": 0.28571428571428575,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2,
                    "macro avg": {
                        "precision": 0.14583333333333331,
                        "recall": 0.1125,
                        "f1-score": 0.126984126984127,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.2583333333333333,
                        "recall": 0.2,
                        "f1-score": 0.2253968253968254,
                        "support": 10.0
                    }
                },
                "culture_and_entertainment_3": {
                    "AFTER": {
                        "precision": 0.25,
                        "recall": 0.2,
                        "f1-score": 0.22222222222222224,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.25,
                        "recall": 0.25,
                        "f1-score": 0.25,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.6,
                        "recall": 0.5,
                        "f1-score": 0.5454545454545454,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.3333333333333333,
                    "macro avg": {
                        "precision": 0.275,
                        "recall": 0.2375,
                        "f1-score": 0.25441919191919193,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.38999999999999996,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3589225589225589,
                        "support": 15.0
                    }
                }
            },
            "note_events_cot": {
                "government_and_politics_riots_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.2857142857142857,
                        "support": 12.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 12.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.07142857142857142,
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.041666666666666664,
                        "f1-score": 0.07142857142857142,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.42857142857142855,
                        "recall": 0.07142857142857142,
                        "f1-score": 0.12244897959183673,
                        "support": 28.0
                    }
                },
                "rail_transport_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.058823529411764705,
                        "f1-score": 0.1111111111111111,
                        "support": 34.0
                    },
                    "COEX": {
                        "precision": 0.3333333333333333,
                        "recall": 1.0,
                        "f1-score": 0.5,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.1111111111111111,
                    "macro avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.2647058823529412,
                        "f1-score": 0.1527777777777778,
                        "support": 36.0
                    },
                    "weighted avg": {
                        "precision": 0.9629629629629629,
                        "recall": 0.1111111111111111,
                        "f1-score": 0.13271604938271606,
                        "support": 36.0
                    }
                },
                "politics_and_conflicts_policy_change_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.0,
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    }
                },
                "politics_and_conflicts_drones_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 0.125,
                        "f1-score": 0.18181818181818182,
                        "support": 8.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.047619047619047616,
                    "macro avg": {
                        "precision": 0.08333333333333333,
                        "recall": 0.03125,
                        "f1-score": 0.045454545454545456,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.12698412698412698,
                        "recall": 0.047619047619047616,
                        "f1-score": 0.06926406926406926,
                        "support": 21.0
                    }
                },
                "disasters_and_accidents_road_crash_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.09090909090909091,
                        "f1-score": 0.16666666666666669,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 10.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.047619047619047616,
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.022727272727272728,
                        "f1-score": 0.04166666666666667,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.5238095238095238,
                        "recall": 0.047619047619047616,
                        "f1-score": 0.08730158730158731,
                        "support": 21.0
                    }
                },
                "crime_and_law_accuse_3": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.25,
                        "f1-score": 0.3333333333333333,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.1,
                    "macro avg": {
                        "precision": 0.125,
                        "recall": 0.0625,
                        "f1-score": 0.08333333333333333,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.2,
                        "recall": 0.1,
                        "f1-score": 0.13333333333333333,
                        "support": 10.0
                    }
                },
                "government_and_politics_protests_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 20.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.0,
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 28.0
                    }
                },
                "politics_and_conflicts_elections_2": {
                    "AFTER": {
                        "precision": 0.2,
                        "recall": 0.045454545454545456,
                        "f1-score": 0.07407407407407407,
                        "support": 22.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 14.0
                    },
                    "COEX": {
                        "precision": 0.25,
                        "recall": 0.2222222222222222,
                        "f1-score": 0.23529411764705882,
                        "support": 9.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.06666666666666667,
                    "macro avg": {
                        "precision": 0.1125,
                        "recall": 0.06691919191919192,
                        "f1-score": 0.07734204793028322,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.14777777777777779,
                        "recall": 0.06666666666666667,
                        "f1-score": 0.08327281529895908,
                        "support": 45.0
                    }
                },
                "environment_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 21.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 23.0
                    },
                    "COEX": {
                        "precision": 0.16666666666666666,
                        "recall": 1.0,
                        "f1-score": 0.2857142857142857,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.022222222222222223,
                    "macro avg": {
                        "precision": 0.041666666666666664,
                        "recall": 0.25,
                        "f1-score": 0.07142857142857142,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.0037037037037037034,
                        "recall": 0.022222222222222223,
                        "f1-score": 0.006349206349206349,
                        "support": 45.0
                    }
                },
                "weather_floods_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.22222222222222224,
                        "support": 7.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.06666666666666667,
                    "macro avg": {
                        "precision": 0.125,
                        "recall": 0.03571428571428571,
                        "f1-score": 0.05555555555555556,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.23333333333333334,
                        "recall": 0.06666666666666667,
                        "f1-score": 0.1037037037037037,
                        "support": 15.0
                    }
                },
                "sports_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    }
                },
                "health_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 9.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 8.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.0,
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 21.0
                    }
                },
                "weather_earthquakes_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 32.0
                    },
                    "COEX": {
                        "precision": 0.14285714285714285,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.14285714285714285,
                        "support": 7.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.022222222222222223,
                    "macro avg": {
                        "precision": 0.03571428571428571,
                        "recall": 0.03571428571428571,
                        "f1-score": 0.03571428571428571,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.022222222222222223,
                        "recall": 0.022222222222222223,
                        "f1-score": 0.022222222222222223,
                        "support": 45.0
                    }
                },
                "space_4": {
                    "AFTER": {
                        "precision": 0.25,
                        "recall": 0.18181818181818182,
                        "f1-score": 0.2105263157894737,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 15.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.07142857142857142,
                    "macro avg": {
                        "precision": 0.0625,
                        "recall": 0.045454545454545456,
                        "f1-score": 0.052631578947368425,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.09821428571428571,
                        "recall": 0.07142857142857142,
                        "f1-score": 0.08270676691729324,
                        "support": 28.0
                    }
                },
                "economy_and_business_strikes_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.0,
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    }
                },
                "politics_and_conflicts_armed_conflict_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.0,
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 15.0
                    }
                },
                "infectious_disease_4": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.25,
                        "f1-score": 0.25,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    }
                },
                "health_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.0,
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 10.0
                    }
                },
                "disasters_and_accidents_shipwreck_2": {
                    "AFTER": {
                        "precision": 0.3333333333333333,
                        "recall": 0.09090909090909091,
                        "f1-score": 0.14285714285714288,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 9.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.047619047619047616,
                    "macro avg": {
                        "precision": 0.08333333333333333,
                        "recall": 0.022727272727272728,
                        "f1-score": 0.03571428571428572,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.1746031746031746,
                        "recall": 0.047619047619047616,
                        "f1-score": 0.07482993197278913,
                        "support": 21.0
                    }
                },
                "rail_transport_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 10.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.0,
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 15.0
                    }
                },
                "weather_storms_1_extra": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    }
                },
                "health_1_extra": {
                    "AFTER": {
                        "precision": 0.3333333333333333,
                        "recall": 0.08333333333333333,
                        "f1-score": 0.13333333333333333,
                        "support": 12.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 0.07142857142857142,
                        "f1-score": 0.11764705882352941,
                        "support": 28.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 15.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.05454545454545454,
                    "macro avg": {
                        "precision": 0.16666666666666666,
                        "recall": 0.03869047619047619,
                        "f1-score": 0.06274509803921569,
                        "support": 55.0
                    },
                    "weighted avg": {
                        "precision": 0.2424242424242424,
                        "recall": 0.05454545454545454,
                        "f1-score": 0.08898395721925134,
                        "support": 55.0
                    }
                },
                "weather_floods_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.041666666666666664,
                        "f1-score": 0.07692307692307693,
                        "support": 24.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 28.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.01818181818181818,
                    "macro avg": {
                        "precision": 0.125,
                        "recall": 0.010416666666666666,
                        "f1-score": 0.019230769230769232,
                        "support": 55.0
                    },
                    "weighted avg": {
                        "precision": 0.21818181818181817,
                        "recall": 0.01818181818181818,
                        "f1-score": 0.033566433566433566,
                        "support": 55.0
                    }
                },
                "mining_4": {
                    "AFTER": {
                        "precision": 0.2857142857142857,
                        "recall": 0.18181818181818182,
                        "f1-score": 0.2222222222222222,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 25.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 9.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.044444444444444446,
                    "macro avg": {
                        "precision": 0.07142857142857142,
                        "recall": 0.045454545454545456,
                        "f1-score": 0.05555555555555555,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.06984126984126984,
                        "recall": 0.044444444444444446,
                        "f1-score": 0.05432098765432098,
                        "support": 45.0
                    }
                },
                "disasters_and_accidents_volcanoes_4": {
                    "AFTER": {
                        "precision": 0.6,
                        "recall": 0.3,
                        "f1-score": 0.4,
                        "support": 20.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 14.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.16666666666666666,
                    "macro avg": {
                        "precision": 0.15,
                        "recall": 0.075,
                        "f1-score": 0.1,
                        "support": 36.0
                    },
                    "weighted avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.2222222222222222,
                        "support": 36.0
                    }
                },
                "politics_and_conflicts_elections_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.0,
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 15.0
                    }
                },
                "economy_and_business_strikes_3": {
                    "AFTER": {
                        "precision": 0.3333333333333333,
                        "recall": 0.2,
                        "f1-score": 0.25,
                        "support": 10.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.3333333333333333,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.2,
                        "support": 7.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.10714285714285714,
                    "macro avg": {
                        "precision": 0.16666666666666666,
                        "recall": 0.08571428571428572,
                        "f1-score": 0.1125,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.20238095238095236,
                        "recall": 0.10714285714285714,
                        "f1-score": 0.1392857142857143,
                        "support": 28.0
                    }
                },
                "space_2": {
                    "AFTER": {
                        "precision": 0.2857142857142857,
                        "recall": 0.06,
                        "f1-score": 0.09917355371900825,
                        "support": 100.0
                    },
                    "BEFORE": {
                        "precision": 0.23076923076923078,
                        "recall": 0.058823529411764705,
                        "f1-score": 0.09375,
                        "support": 51.0
                    },
                    "COEX": {
                        "precision": 0.1111111111111111,
                        "recall": 0.5,
                        "f1-score": 0.1818181818181818,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.06535947712418301,
                    "macro avg": {
                        "precision": 0.1568986568986569,
                        "recall": 0.15470588235294117,
                        "f1-score": 0.09368543388429751,
                        "support": 153.0
                    },
                    "weighted avg": {
                        "precision": 0.26511687296001024,
                        "recall": 0.06535947712418301,
                        "f1-score": 0.09844602441527574,
                        "support": 153.0
                    }
                },
                "politics_and_conflicts_resign_1": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.5,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 3.0
                    },
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.08333333333333333,
                        "f1-score": 0.125,
                        "support": 3.0
                    },
                    "weighted avg": {
                        "precision": 1.0,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.5,
                        "support": 3.0
                    }
                },
                "environment_4": {
                    "AFTER": {
                        "precision": 0.3333333333333333,
                        "recall": 0.25,
                        "f1-score": 0.28571428571428575,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.06666666666666667,
                    "macro avg": {
                        "precision": 0.08333333333333333,
                        "recall": 0.0625,
                        "f1-score": 0.07142857142857144,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.08888888888888888,
                        "recall": 0.06666666666666667,
                        "f1-score": 0.0761904761904762,
                        "support": 15.0
                    }
                },
                "space_1_extra": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.2,
                        "f1-score": 0.33333333333333337,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.16666666666666666,
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.05,
                        "f1-score": 0.08333333333333334,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.8333333333333334,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.27777777777777785,
                        "support": 6.0
                    }
                },
                "health_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 8.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.0,
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 15.0
                    }
                },
                "environment_3": {
                    "AFTER": {
                        "precision": 0.8,
                        "recall": 0.36363636363636365,
                        "f1-score": 0.5000000000000001,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.26666666666666666,
                    "macro avg": {
                        "precision": 0.2,
                        "recall": 0.09090909090909091,
                        "f1-score": 0.12500000000000003,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.5866666666666667,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.36666666666666675,
                        "support": 15.0
                    }
                },
                "government_and_politics_protests_3": {
                    "AFTER": {
                        "precision": 0.6666666666666666,
                        "recall": 0.5,
                        "f1-score": 0.5714285714285715,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.3333333333333333,
                    "macro avg": {
                        "precision": 0.16666666666666666,
                        "recall": 0.125,
                        "f1-score": 0.14285714285714288,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.4444444444444444,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.380952380952381,
                        "support": 6.0
                    }
                },
                "economy_and_business_financial_crisis_4": {
                    "AFTER": {
                        "precision": 0.42857142857142855,
                        "recall": 0.25,
                        "f1-score": 0.3157894736842105,
                        "support": 12.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 0.2,
                        "f1-score": 0.25,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.25,
                        "recall": 0.25,
                        "f1-score": 0.25,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.23809523809523808,
                    "macro avg": {
                        "precision": 0.25297619047619047,
                        "recall": 0.175,
                        "f1-score": 0.20394736842105263,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.3718820861678004,
                        "recall": 0.23809523809523808,
                        "f1-score": 0.28759398496240596,
                        "support": 21.0
                    }
                },
                "computers_2": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.25,
                        "f1-score": 0.25,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    }
                },
                "crime_and_law_accuse_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 10.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 10.0
                    }
                },
                "culture_and_entertainment_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.0,
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    }
                },
                "internet_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.0,
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 10.0
                    }
                },
                "culture_and_entertainment_3": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.6,
                        "f1-score": 0.5454545454545454,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.5,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.25,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.26666666666666666,
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.19166666666666665,
                        "f1-score": 0.19886363636363635,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.36666666666666664,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.2818181818181818,
                        "support": 15.0
                    }
                }
            },
            "refer_events_cot": {
                "government_and_politics_riots_4": {
                    "AFTER": {
                        "precision": 0.125,
                        "recall": 0.25,
                        "f1-score": 0.16666666666666666,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.25,
                        "recall": 0.08333333333333333,
                        "f1-score": 0.125,
                        "support": 12.0
                    },
                    "COEX": {
                        "precision": 0.35714285714285715,
                        "recall": 0.4166666666666667,
                        "f1-score": 0.3846153846153846,
                        "support": 12.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.25,
                    "macro avg": {
                        "precision": 0.1830357142857143,
                        "recall": 0.1875,
                        "f1-score": 0.1690705128205128,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.2780612244897959,
                        "recall": 0.25,
                        "f1-score": 0.2422161172161172,
                        "support": 28.0
                    }
                },
                "rail_transport_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "BEFORE": {
                        "precision": 0.8571428571428571,
                        "recall": 0.17647058823529413,
                        "f1-score": 0.29268292682926833,
                        "support": 34.0
                    },
                    "COEX": {
                        "precision": 0.5,
                        "recall": 0.5,
                        "f1-score": 0.5,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.19444444444444445,
                    "macro avg": {
                        "precision": 0.3392857142857143,
                        "recall": 0.16911764705882354,
                        "f1-score": 0.19817073170731708,
                        "support": 36.0
                    },
                    "weighted avg": {
                        "precision": 0.8373015873015873,
                        "recall": 0.19444444444444445,
                        "f1-score": 0.3042005420054201,
                        "support": 36.0
                    }
                },
                "politics_and_conflicts_policy_change_2": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.5,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.16666666666666666,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.16666666666666666,
                        "support": 6.0
                    },
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.08333333333333333,
                        "f1-score": 0.125,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.5,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.25,
                        "support": 6.0
                    }
                },
                "politics_and_conflicts_drones_1": {
                    "AFTER": {
                        "precision": 0.2727272727272727,
                        "recall": 0.2727272727272727,
                        "f1-score": 0.2727272727272727,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.2,
                        "recall": 0.125,
                        "f1-score": 0.15384615384615385,
                        "support": 8.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.19047619047619047,
                    "macro avg": {
                        "precision": 0.11818181818181818,
                        "recall": 0.09943181818181818,
                        "f1-score": 0.10664335664335664,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.21904761904761902,
                        "recall": 0.19047619047619047,
                        "f1-score": 0.20146520146520147,
                        "support": 21.0
                    }
                },
                "disasters_and_accidents_road_crash_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 0.18181818181818182,
                        "f1-score": 0.23529411764705885,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.4,
                        "recall": 0.2,
                        "f1-score": 0.26666666666666666,
                        "support": 10.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.19047619047619047,
                    "macro avg": {
                        "precision": 0.18333333333333335,
                        "recall": 0.09545454545454546,
                        "f1-score": 0.12549019607843137,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.36507936507936506,
                        "recall": 0.19047619047619047,
                        "f1-score": 0.25023342670401494,
                        "support": 21.0
                    }
                },
                "crime_and_law_accuse_3": {
                    "AFTER": {
                        "precision": 0.6666666666666666,
                        "recall": 0.5,
                        "f1-score": 0.5714285714285715,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.6666666666666666,
                        "f1-score": 0.8,
                        "support": 6.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.6,
                    "macro avg": {
                        "precision": 0.41666666666666663,
                        "recall": 0.29166666666666663,
                        "f1-score": 0.34285714285714286,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.8666666666666666,
                        "recall": 0.6,
                        "f1-score": 0.7085714285714287,
                        "support": 10.0
                    }
                },
                "government_and_politics_protests_2": {
                    "AFTER": {
                        "precision": 0.1111111111111111,
                        "recall": 0.2,
                        "f1-score": 0.14285714285714285,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.6666666666666666,
                        "recall": 0.3,
                        "f1-score": 0.41379310344827586,
                        "support": 20.0
                    },
                    "COEX": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 3.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2857142857142857,
                    "macro avg": {
                        "precision": 0.27777777777777773,
                        "recall": 0.20833333333333331,
                        "f1-score": 0.22249589490968802,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.5317460317460317,
                        "recall": 0.2857142857142857,
                        "f1-score": 0.35679099225897254,
                        "support": 28.0
                    }
                },
                "politics_and_conflicts_elections_2": {
                    "AFTER": {
                        "precision": 0.42857142857142855,
                        "recall": 0.13636363636363635,
                        "f1-score": 0.20689655172413793,
                        "support": 22.0
                    },
                    "BEFORE": {
                        "precision": 0.4166666666666667,
                        "recall": 0.35714285714285715,
                        "f1-score": 0.3846153846153846,
                        "support": 14.0
                    },
                    "COEX": {
                        "precision": 0.125,
                        "recall": 0.2222222222222222,
                        "f1-score": 0.16,
                        "support": 9.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2222222222222222,
                    "macro avg": {
                        "precision": 0.2425595238095238,
                        "recall": 0.17893217893217894,
                        "f1-score": 0.18787798408488063,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.3641534391534392,
                        "recall": 0.2222222222222222,
                        "f1-score": 0.25280754494547597,
                        "support": 45.0
                    }
                },
                "environment_2": {
                    "AFTER": {
                        "precision": 0.6923076923076923,
                        "recall": 0.42857142857142855,
                        "f1-score": 0.5294117647058824,
                        "support": 21.0
                    },
                    "BEFORE": {
                        "precision": 0.8,
                        "recall": 0.34782608695652173,
                        "f1-score": 0.48484848484848486,
                        "support": 23.0
                    },
                    "COEX": {
                        "precision": 0.3333333333333333,
                        "recall": 1.0,
                        "f1-score": 0.5,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.4,
                    "macro avg": {
                        "precision": 0.4564102564102564,
                        "recall": 0.4440993788819876,
                        "f1-score": 0.3785650623885918,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.7393732193732194,
                        "recall": 0.4,
                        "f1-score": 0.5059813824519707,
                        "support": 45.0
                    }
                },
                "weather_floods_3": {
                    "AFTER": {
                        "precision": 0.1,
                        "recall": 0.25,
                        "f1-score": 0.14285714285714288,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 7.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.06666666666666667,
                        "recall": 0.06666666666666667,
                        "f1-score": 0.06666666666666667,
                        "support": 15.0
                    },
                    "macro avg": {
                        "precision": 0.025,
                        "recall": 0.0625,
                        "f1-score": 0.03571428571428572,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.02666666666666667,
                        "recall": 0.06666666666666667,
                        "f1-score": 0.0380952380952381,
                        "support": 15.0
                    }
                },
                "sports_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 1.0,
                        "f1-score": 0.6666666666666666,
                        "support": 1.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 3.0
                    },
                    "macro avg": {
                        "precision": 0.125,
                        "recall": 0.25,
                        "f1-score": 0.16666666666666666,
                        "support": 3.0
                    },
                    "weighted avg": {
                        "precision": 0.16666666666666666,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.2222222222222222,
                        "support": 3.0
                    }
                },
                "health_4": {
                    "AFTER": {
                        "precision": 0.4,
                        "recall": 0.2222222222222222,
                        "f1-score": 0.2857142857142857,
                        "support": 9.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.5,
                        "f1-score": 0.5,
                        "support": 8.0
                    },
                    "COEX": {
                        "precision": 0.2,
                        "recall": 0.25,
                        "f1-score": 0.22222222222222224,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.3333333333333333,
                    "macro avg": {
                        "precision": 0.275,
                        "recall": 0.24305555555555555,
                        "f1-score": 0.251984126984127,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.4,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.35525321239606955,
                        "support": 21.0
                    }
                },
                "weather_earthquakes_1": {
                    "AFTER": {
                        "precision": 0.15384615384615385,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.21052631578947367,
                        "support": 6.0
                    },
                    "BEFORE": {
                        "precision": 0.6,
                        "recall": 0.1875,
                        "f1-score": 0.2857142857142857,
                        "support": 32.0
                    },
                    "COEX": {
                        "precision": 0.2,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.16666666666666666,
                        "support": 7.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2,
                    "macro avg": {
                        "precision": 0.23846153846153845,
                        "recall": 0.165922619047619,
                        "f1-score": 0.1657268170426065,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.4782905982905982,
                        "recall": 0.2,
                        "f1-score": 0.25717070453912555,
                        "support": 45.0
                    }
                },
                "space_4": {
                    "AFTER": {
                        "precision": 0.4,
                        "recall": 0.36363636363636365,
                        "f1-score": 0.380952380952381,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.5714285714285714,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.36363636363636365,
                        "support": 15.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2857142857142857,
                    "macro avg": {
                        "precision": 0.24285714285714285,
                        "recall": 0.1575757575757576,
                        "f1-score": 0.18614718614718617,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.463265306122449,
                        "recall": 0.2857142857142857,
                        "f1-score": 0.3444650587507731,
                        "support": 28.0
                    }
                },
                "economy_and_business_strikes_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 0.25,
                        "f1-score": 0.28571428571428575,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.16666666666666666,
                    "macro avg": {
                        "precision": 0.08333333333333333,
                        "recall": 0.0625,
                        "f1-score": 0.07142857142857144,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.2222222222222222,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.1904761904761905,
                        "support": 6.0
                    }
                },
                "politics_and_conflicts_armed_conflict_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.6666666666666666,
                        "recall": 0.36363636363636365,
                        "f1-score": 0.4705882352941177,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.5,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.4,
                        "support": 3.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.3333333333333333,
                    "macro avg": {
                        "precision": 0.29166666666666663,
                        "recall": 0.17424242424242425,
                        "f1-score": 0.21764705882352942,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.5888888888888888,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.4250980392156863,
                        "support": 15.0
                    }
                },
                "infectious_disease_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    }
                },
                "health_1": {
                    "AFTER": {
                        "precision": 0.3333333333333333,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.2222222222222222,
                        "support": 6.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "COEX": {
                        "precision": 0.3333333333333333,
                        "recall": 1.0,
                        "f1-score": 0.5,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2,
                    "macro avg": {
                        "precision": 0.16666666666666666,
                        "recall": 0.2916666666666667,
                        "f1-score": 0.18055555555555555,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.23333333333333334,
                        "recall": 0.2,
                        "f1-score": 0.18333333333333332,
                        "support": 10.0
                    }
                },
                "disasters_and_accidents_shipwreck_2": {
                    "AFTER": {
                        "precision": 0.5714285714285714,
                        "recall": 0.7272727272727273,
                        "f1-score": 0.64,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.25,
                        "recall": 0.1111111111111111,
                        "f1-score": 0.15384615384615383,
                        "support": 9.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.42857142857142855,
                        "recall": 0.42857142857142855,
                        "f1-score": 0.42857142857142855,
                        "support": 21.0
                    },
                    "macro avg": {
                        "precision": 0.20535714285714285,
                        "recall": 0.2095959595959596,
                        "f1-score": 0.19846153846153847,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.40646258503401356,
                        "recall": 0.42857142857142855,
                        "f1-score": 0.40117216117216115,
                        "support": 21.0
                    }
                },
                "rail_transport_3": {
                    "AFTER": {
                        "precision": 0.2857142857142857,
                        "recall": 0.4,
                        "f1-score": 0.3333333333333333,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.2,
                        "f1-score": 0.33333333333333337,
                        "support": 10.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.26666666666666666,
                    "macro avg": {
                        "precision": 0.3214285714285714,
                        "recall": 0.15000000000000002,
                        "f1-score": 0.16666666666666669,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.761904761904762,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.3333333333333333,
                        "support": 15.0
                    }
                },
                "weather_storms_1_extra": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    }
                },
                "health_1_extra": {
                    "AFTER": {
                        "precision": 0.1724137931034483,
                        "recall": 0.4166666666666667,
                        "f1-score": 0.2439024390243903,
                        "support": 12.0
                    },
                    "BEFORE": {
                        "precision": 0.6,
                        "recall": 0.10714285714285714,
                        "f1-score": 0.18181818181818182,
                        "support": 28.0
                    },
                    "COEX": {
                        "precision": 0.42857142857142855,
                        "recall": 0.2,
                        "f1-score": 0.27272727272727276,
                        "support": 15.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2,
                    "macro avg": {
                        "precision": 0.3002463054187192,
                        "recall": 0.18095238095238098,
                        "f1-score": 0.1746119733924612,
                        "support": 55.0
                    },
                    "weighted avg": {
                        "precision": 0.45995521719659654,
                        "recall": 0.2,
                        "f1-score": 0.22015722636565213,
                        "support": 55.0
                    }
                },
                "weather_floods_1": {
                    "AFTER": {
                        "precision": 0.08333333333333333,
                        "recall": 0.6666666666666666,
                        "f1-score": 0.14814814814814814,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.23076923076923078,
                        "recall": 0.125,
                        "f1-score": 0.16216216216216217,
                        "support": 24.0
                    },
                    "COEX": {
                        "precision": 0.4,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.21052631578947364,
                        "support": 28.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.16363636363636364,
                    "macro avg": {
                        "precision": 0.17852564102564103,
                        "recall": 0.23363095238095238,
                        "f1-score": 0.130209156524946,
                        "support": 55.0
                    },
                    "weighted avg": {
                        "precision": 0.3088811188811189,
                        "recall": 0.16363636363636364,
                        "f1-score": 0.18601951233530178,
                        "support": 55.0
                    }
                },
                "mining_4": {
                    "AFTER": {
                        "precision": 0.18181818181818182,
                        "recall": 0.18181818181818182,
                        "f1-score": 0.18181818181818182,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.12,
                        "f1-score": 0.1935483870967742,
                        "support": 25.0
                    },
                    "COEX": {
                        "precision": 0.18181818181818182,
                        "recall": 0.2222222222222222,
                        "f1-score": 0.19999999999999998,
                        "support": 9.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.15555555555555556,
                    "macro avg": {
                        "precision": 0.21590909090909094,
                        "recall": 0.13101010101010102,
                        "f1-score": 0.143841642228739,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.3585858585858586,
                        "recall": 0.15555555555555556,
                        "f1-score": 0.19197132616487456,
                        "support": 45.0
                    }
                },
                "disasters_and_accidents_volcanoes_4": {
                    "AFTER": {
                        "precision": 0.5294117647058824,
                        "recall": 0.45,
                        "f1-score": 0.48648648648648646,
                        "support": 20.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.2,
                        "support": 14.0
                    },
                    "COEX": {
                        "precision": 0.14285714285714285,
                        "recall": 0.5,
                        "f1-score": 0.22222222222222224,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.3333333333333333,
                    "macro avg": {
                        "precision": 0.25140056022408963,
                        "recall": 0.27321428571428574,
                        "f1-score": 0.22717717717717717,
                        "support": 36.0
                    },
                    "weighted avg": {
                        "precision": 0.4316837846249611,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.36039372706039374,
                        "support": 36.0
                    }
                },
                "politics_and_conflicts_elections_3": {
                    "AFTER": {
                        "precision": 0.16666666666666666,
                        "recall": 0.2,
                        "f1-score": 0.1818181818181818,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.25,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.2,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.13333333333333333,
                    "macro avg": {
                        "precision": 0.10416666666666666,
                        "recall": 0.09166666666666667,
                        "f1-score": 0.09545454545454546,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.15555555555555553,
                        "recall": 0.13333333333333333,
                        "f1-score": 0.14060606060606062,
                        "support": 15.0
                    }
                },
                "economy_and_business_strikes_3": {
                    "AFTER": {
                        "precision": 0.47058823529411764,
                        "recall": 0.8,
                        "f1-score": 0.5925925925925927,
                        "support": 10.0
                    },
                    "BEFORE": {
                        "precision": 0.4,
                        "recall": 0.18181818181818182,
                        "f1-score": 0.25000000000000006,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 7.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.35714285714285715,
                    "macro avg": {
                        "precision": 0.21764705882352942,
                        "recall": 0.24545454545454548,
                        "f1-score": 0.2106481481481482,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.32521008403361346,
                        "recall": 0.35714285714285715,
                        "f1-score": 0.3098544973544974,
                        "support": 28.0
                    }
                },
                "space_2": {
                    "AFTER": {
                        "precision": 0.5714285714285714,
                        "recall": 0.16,
                        "f1-score": 0.25,
                        "support": 100.0
                    },
                    "BEFORE": {
                        "precision": 0.4666666666666667,
                        "recall": 0.27450980392156865,
                        "f1-score": 0.34567901234567905,
                        "support": 51.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.19607843137254902,
                    "macro avg": {
                        "precision": 0.2595238095238095,
                        "recall": 0.10862745098039217,
                        "f1-score": 0.14891975308641975,
                        "support": 153.0
                    },
                    "weighted avg": {
                        "precision": 0.5290382819794585,
                        "recall": 0.19607843137254902,
                        "f1-score": 0.2786250302590172,
                        "support": 153.0
                    }
                },
                "politics_and_conflicts_resign_1": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.5,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 3.0
                    },
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.08333333333333333,
                        "f1-score": 0.125,
                        "support": 3.0
                    },
                    "weighted avg": {
                        "precision": 1.0,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.5,
                        "support": 3.0
                    }
                },
                "environment_4": {
                    "AFTER": {
                        "precision": 0.42857142857142855,
                        "recall": 0.75,
                        "f1-score": 0.5454545454545454,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 0.2,
                        "f1-score": 0.25,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.2,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.1818181818181818,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 15.0
                    },
                    "macro avg": {
                        "precision": 0.24047619047619045,
                        "recall": 0.2791666666666667,
                        "f1-score": 0.2443181818181818,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.3053968253968254,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3015151515151515,
                        "support": 15.0
                    }
                },
                "space_1_extra": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.2,
                        "f1-score": 0.33333333333333337,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.16666666666666666,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.16666666666666666,
                        "support": 6.0
                    },
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.05,
                        "f1-score": 0.08333333333333334,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.8333333333333334,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.27777777777777785,
                        "support": 6.0
                    }
                },
                "health_3": {
                    "AFTER": {
                        "precision": 0.6666666666666666,
                        "recall": 0.25,
                        "f1-score": 0.36363636363636365,
                        "support": 8.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.25,
                        "support": 6.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2,
                    "macro avg": {
                        "precision": 0.29166666666666663,
                        "recall": 0.10416666666666666,
                        "f1-score": 0.1534090909090909,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.5555555555555555,
                        "recall": 0.2,
                        "f1-score": 0.29393939393939394,
                        "support": 15.0
                    }
                },
                "environment_3": {
                    "AFTER": {
                        "precision": 0.3333333333333333,
                        "recall": 0.09090909090909091,
                        "f1-score": 0.14285714285714288,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.2222222222222222,
                        "recall": 1.0,
                        "f1-score": 0.3636363636363636,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2,
                    "macro avg": {
                        "precision": 0.1388888888888889,
                        "recall": 0.2727272727272727,
                        "f1-score": 0.1266233766233766,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.274074074074074,
                        "recall": 0.2,
                        "f1-score": 0.15324675324675324,
                        "support": 15.0
                    }
                },
                "government_and_politics_protests_3": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.25,
                        "f1-score": 0.3333333333333333,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 1.0,
                        "f1-score": 0.6666666666666666,
                        "support": 1.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.3333333333333333,
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.3125,
                        "f1-score": 0.25,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.4166666666666667,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 6.0
                    }
                },
                "economy_and_business_financial_crisis_4": {
                    "AFTER": {
                        "precision": 0.625,
                        "recall": 0.4166666666666667,
                        "f1-score": 0.5,
                        "support": 12.0
                    },
                    "BEFORE": {
                        "precision": 0.25,
                        "recall": 0.4,
                        "f1-score": 0.3076923076923077,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.3333333333333333,
                    "macro avg": {
                        "precision": 0.21875,
                        "recall": 0.20416666666666666,
                        "f1-score": 0.20192307692307693,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.4166666666666667,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.358974358974359,
                        "support": 21.0
                    }
                },
                "computers_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    }
                },
                "crime_and_law_accuse_4": {
                    "AFTER": {
                        "precision": 0.25,
                        "recall": 0.2,
                        "f1-score": 0.22222222222222224,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.4,
                        "recall": 0.4,
                        "f1-score": 0.4000000000000001,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.3,
                        "recall": 0.3,
                        "f1-score": 0.3,
                        "support": 10.0
                    },
                    "macro avg": {
                        "precision": 0.1625,
                        "recall": 0.15000000000000002,
                        "f1-score": 0.15555555555555559,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.325,
                        "recall": 0.3,
                        "f1-score": 0.31111111111111117,
                        "support": 10.0
                    }
                },
                "culture_and_entertainment_1": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 1.0,
                        "f1-score": 0.6666666666666666,
                        "support": 2.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.5,
                        "f1-score": 0.6666666666666666,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.5,
                        "recall": 0.5,
                        "f1-score": 0.5,
                        "support": 6.0
                    },
                    "macro avg": {
                        "precision": 0.375,
                        "recall": 0.375,
                        "f1-score": 0.3333333333333333,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.5,
                        "recall": 0.5,
                        "f1-score": 0.4444444444444444,
                        "support": 6.0
                    }
                },
                "internet_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.4,
                        "recall": 0.5,
                        "f1-score": 0.4444444444444445,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2,
                    "macro avg": {
                        "precision": 0.1,
                        "recall": 0.125,
                        "f1-score": 0.11111111111111112,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.16,
                        "recall": 0.2,
                        "f1-score": 0.17777777777777778,
                        "support": 10.0
                    }
                },
                "culture_and_entertainment_3": {
                    "AFTER": {
                        "precision": 0.3333333333333333,
                        "recall": 0.2,
                        "f1-score": 0.25,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.6,
                        "recall": 0.75,
                        "f1-score": 0.6666666666666665,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.2857142857142857,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.30769230769230765,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.4,
                        "recall": 0.4,
                        "f1-score": 0.4000000000000001,
                        "support": 15.0
                    },
                    "macro avg": {
                        "precision": 0.3047619047619048,
                        "recall": 0.3208333333333333,
                        "f1-score": 0.30608974358974356,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.3853968253968254,
                        "recall": 0.4,
                        "f1-score": 0.3841880341880341,
                        "support": 15.0
                    }
                }
            },
            "careful_cot": {
                "government_and_politics_riots_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 12.0
                    },
                    "COEX": {
                        "precision": 0.25,
                        "recall": 0.08333333333333333,
                        "f1-score": 0.125,
                        "support": 12.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.03571428571428571,
                    "macro avg": {
                        "precision": 0.0625,
                        "recall": 0.020833333333333332,
                        "f1-score": 0.03125,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.10714285714285714,
                        "recall": 0.03571428571428571,
                        "f1-score": 0.05357142857142857,
                        "support": 28.0
                    }
                },
                "rail_transport_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.058823529411764705,
                        "f1-score": 0.1111111111111111,
                        "support": 34.0
                    },
                    "COEX": {
                        "precision": 0.14285714285714285,
                        "recall": 0.5,
                        "f1-score": 0.22222222222222224,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.08333333333333333,
                    "macro avg": {
                        "precision": 0.2857142857142857,
                        "recall": 0.13970588235294118,
                        "f1-score": 0.08333333333333334,
                        "support": 36.0
                    },
                    "weighted avg": {
                        "precision": 0.9523809523809523,
                        "recall": 0.08333333333333333,
                        "f1-score": 0.11728395061728396,
                        "support": 36.0
                    }
                },
                "politics_and_conflicts_policy_change_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.0,
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    }
                },
                "politics_and_conflicts_drones_1": {
                    "AFTER": {
                        "precision": 0.3333333333333333,
                        "recall": 0.18181818181818182,
                        "f1-score": 0.23529411764705885,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.125,
                        "f1-score": 0.2,
                        "support": 8.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.14285714285714285,
                    "macro avg": {
                        "precision": 0.20833333333333331,
                        "recall": 0.07670454545454546,
                        "f1-score": 0.10882352941176471,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.36507936507936506,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.19943977591036416,
                        "support": 21.0
                    }
                },
                "disasters_and_accidents_road_crash_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 10.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.0,
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 21.0
                    }
                },
                "crime_and_law_accuse_3": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.25,
                        "f1-score": 0.3333333333333333,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.1,
                        "recall": 0.1,
                        "f1-score": 0.10000000000000002,
                        "support": 10.0
                    },
                    "macro avg": {
                        "precision": 0.125,
                        "recall": 0.0625,
                        "f1-score": 0.08333333333333333,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.2,
                        "recall": 0.1,
                        "f1-score": 0.13333333333333333,
                        "support": 10.0
                    }
                },
                "government_and_politics_protests_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 20.0
                    },
                    "COEX": {
                        "precision": 0.25,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.28571428571428575,
                        "support": 3.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.03571428571428571,
                    "macro avg": {
                        "precision": 0.0625,
                        "recall": 0.08333333333333333,
                        "f1-score": 0.07142857142857144,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.026785714285714284,
                        "recall": 0.03571428571428571,
                        "f1-score": 0.030612244897959186,
                        "support": 28.0
                    }
                },
                "politics_and_conflicts_elections_2": {
                    "AFTER": {
                        "precision": 0.42857142857142855,
                        "recall": 0.13636363636363635,
                        "f1-score": 0.20689655172413793,
                        "support": 22.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 14.0
                    },
                    "COEX": {
                        "precision": 0.5,
                        "recall": 0.1111111111111111,
                        "f1-score": 0.1818181818181818,
                        "support": 9.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.08888888888888889,
                    "macro avg": {
                        "precision": 0.23214285714285715,
                        "recall": 0.061868686868686865,
                        "f1-score": 0.09717868338557993,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.30952380952380953,
                        "recall": 0.08888888888888889,
                        "f1-score": 0.13751306165099267,
                        "support": 45.0
                    }
                },
                "environment_2": {
                    "AFTER": {
                        "precision": 0.2,
                        "recall": 0.047619047619047616,
                        "f1-score": 0.07692307692307693,
                        "support": 21.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 23.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.022222222222222223,
                    "macro avg": {
                        "precision": 0.05,
                        "recall": 0.011904761904761904,
                        "f1-score": 0.019230769230769232,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.09333333333333334,
                        "recall": 0.022222222222222223,
                        "f1-score": 0.035897435897435895,
                        "support": 45.0
                    }
                },
                "weather_floods_3": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.25,
                        "f1-score": 0.3333333333333333,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 7.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.06666666666666667,
                    "macro avg": {
                        "precision": 0.125,
                        "recall": 0.0625,
                        "f1-score": 0.08333333333333333,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.13333333333333333,
                        "recall": 0.06666666666666667,
                        "f1-score": 0.08888888888888888,
                        "support": 15.0
                    }
                },
                "sports_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    }
                },
                "health_4": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.1111111111111111,
                        "f1-score": 0.19999999999999998,
                        "support": 9.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 8.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.047619047619047616,
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.027777777777777776,
                        "f1-score": 0.049999999999999996,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.42857142857142855,
                        "recall": 0.047619047619047616,
                        "f1-score": 0.0857142857142857,
                        "support": 21.0
                    }
                },
                "weather_earthquakes_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.03125,
                        "f1-score": 0.058823529411764705,
                        "support": 32.0
                    },
                    "COEX": {
                        "precision": 0.6,
                        "recall": 0.42857142857142855,
                        "f1-score": 0.5,
                        "support": 7.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.08888888888888889,
                    "macro avg": {
                        "precision": 0.275,
                        "recall": 0.11495535714285714,
                        "f1-score": 0.13970588235294118,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.4488888888888889,
                        "recall": 0.08888888888888889,
                        "f1-score": 0.11960784313725491,
                        "support": 45.0
                    }
                },
                "space_4": {
                    "AFTER": {
                        "precision": 0.25,
                        "recall": 0.18181818181818182,
                        "f1-score": 0.2105263157894737,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.25,
                        "recall": 0.06666666666666667,
                        "f1-score": 0.10526315789473685,
                        "support": 15.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.10714285714285714,
                    "macro avg": {
                        "precision": 0.125,
                        "recall": 0.06212121212121212,
                        "f1-score": 0.07894736842105264,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.23214285714285715,
                        "recall": 0.10714285714285714,
                        "f1-score": 0.13909774436090225,
                        "support": 28.0
                    }
                },
                "economy_and_business_strikes_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.25,
                        "f1-score": 0.3333333333333333,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.16666666666666666,
                    "macro avg": {
                        "precision": 0.125,
                        "recall": 0.0625,
                        "f1-score": 0.08333333333333333,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.2222222222222222,
                        "support": 6.0
                    }
                },
                "politics_and_conflicts_armed_conflict_2": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.09090909090909091,
                        "f1-score": 0.16666666666666669,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 1.0,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.5,
                        "support": 3.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2,
                    "macro avg": {
                        "precision": 0.75,
                        "recall": 0.356060606060606,
                        "f1-score": 0.4166666666666667,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 1.0,
                        "recall": 0.2,
                        "f1-score": 0.2888888888888889,
                        "support": 15.0
                    }
                },
                "infectious_disease_4": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.25,
                        "f1-score": 0.25,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    }
                },
                "health_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.0,
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 10.0
                    }
                },
                "disasters_and_accidents_shipwreck_2": {
                    "AFTER": {
                        "precision": 0.3333333333333333,
                        "recall": 0.09090909090909091,
                        "f1-score": 0.14285714285714288,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 9.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.047619047619047616,
                    "macro avg": {
                        "precision": 0.08333333333333333,
                        "recall": 0.022727272727272728,
                        "f1-score": 0.03571428571428572,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.1746031746031746,
                        "recall": 0.047619047619047616,
                        "f1-score": 0.07482993197278913,
                        "support": 21.0
                    }
                },
                "rail_transport_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 10.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.0,
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 15.0
                    }
                },
                "weather_storms_1_extra": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    }
                },
                "health_1_extra": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 12.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.07142857142857142,
                        "f1-score": 0.125,
                        "support": 28.0
                    },
                    "COEX": {
                        "precision": 0.5,
                        "recall": 0.06666666666666667,
                        "f1-score": 0.11764705882352941,
                        "support": 15.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.05454545454545454,
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.034523809523809526,
                        "f1-score": 0.06066176470588235,
                        "support": 55.0
                    },
                    "weighted avg": {
                        "precision": 0.39090909090909093,
                        "recall": 0.05454545454545454,
                        "f1-score": 0.09572192513368984,
                        "support": 55.0
                    }
                },
                "weather_floods_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 0.041666666666666664,
                        "f1-score": 0.07407407407407407,
                        "support": 24.0
                    },
                    "COEX": {
                        "precision": 0.3333333333333333,
                        "recall": 0.10714285714285714,
                        "f1-score": 0.16216216216216214,
                        "support": 28.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.07272727272727272,
                    "macro avg": {
                        "precision": 0.16666666666666666,
                        "recall": 0.03720238095238095,
                        "f1-score": 0.05905905905905905,
                        "support": 55.0
                    },
                    "weighted avg": {
                        "precision": 0.3151515151515151,
                        "recall": 0.07272727272727272,
                        "f1-score": 0.11487851487851487,
                        "support": 55.0
                    }
                },
                "mining_4": {
                    "AFTER": {
                        "precision": 0.25,
                        "recall": 0.18181818181818182,
                        "f1-score": 0.2105263157894737,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 25.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 9.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.044444444444444446,
                    "macro avg": {
                        "precision": 0.0625,
                        "recall": 0.045454545454545456,
                        "f1-score": 0.052631578947368425,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.06111111111111111,
                        "recall": 0.044444444444444446,
                        "f1-score": 0.05146198830409357,
                        "support": 45.0
                    }
                },
                "disasters_and_accidents_volcanoes_4": {
                    "AFTER": {
                        "precision": 0.75,
                        "recall": 0.3,
                        "f1-score": 0.4285714285714285,
                        "support": 20.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 14.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.16666666666666666,
                    "macro avg": {
                        "precision": 0.1875,
                        "recall": 0.075,
                        "f1-score": 0.10714285714285712,
                        "support": 36.0
                    },
                    "weighted avg": {
                        "precision": 0.4166666666666667,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.23809523809523803,
                        "support": 36.0
                    }
                },
                "politics_and_conflicts_elections_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.5,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.25,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.06666666666666667,
                    "macro avg": {
                        "precision": 0.125,
                        "recall": 0.041666666666666664,
                        "f1-score": 0.0625,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.2,
                        "recall": 0.06666666666666667,
                        "f1-score": 0.1,
                        "support": 15.0
                    }
                },
                "economy_and_business_strikes_3": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.1,
                        "f1-score": 0.16666666666666669,
                        "support": 10.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.09090909090909091,
                        "f1-score": 0.15384615384615385,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.2857142857142857,
                        "recall": 0.2857142857142857,
                        "f1-score": 0.2857142857142857,
                        "support": 7.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.14285714285714285,
                    "macro avg": {
                        "precision": 0.3214285714285714,
                        "recall": 0.11915584415584415,
                        "f1-score": 0.15155677655677657,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.44642857142857145,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.1913919413919414,
                        "support": 28.0
                    }
                },
                "space_2": {
                    "AFTER": {
                        "precision": 0.32,
                        "recall": 0.08,
                        "f1-score": 0.128,
                        "support": 100.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 0.058823529411764705,
                        "f1-score": 0.1,
                        "support": 51.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.0718954248366013,
                    "macro avg": {
                        "precision": 0.16333333333333333,
                        "recall": 0.03470588235294118,
                        "f1-score": 0.057,
                        "support": 153.0
                    },
                    "weighted avg": {
                        "precision": 0.3202614379084967,
                        "recall": 0.0718954248366013,
                        "f1-score": 0.1169934640522876,
                        "support": 153.0
                    }
                },
                "politics_and_conflicts_resign_1": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.5,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 3.0
                    },
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.08333333333333333,
                        "f1-score": 0.125,
                        "support": 3.0
                    },
                    "weighted avg": {
                        "precision": 1.0,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.5,
                        "support": 3.0
                    }
                },
                "environment_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.5,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.25,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.06666666666666667,
                    "macro avg": {
                        "precision": 0.125,
                        "recall": 0.041666666666666664,
                        "f1-score": 0.0625,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.2,
                        "recall": 0.06666666666666667,
                        "f1-score": 0.1,
                        "support": 15.0
                    }
                },
                "space_1_extra": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.6666666666666666,
                        "recall": 0.4,
                        "f1-score": 0.5,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.3333333333333333,
                    "macro avg": {
                        "precision": 0.16666666666666666,
                        "recall": 0.1,
                        "f1-score": 0.125,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.5555555555555555,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.4166666666666667,
                        "support": 6.0
                    }
                },
                "health_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 8.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.0,
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 15.0
                    }
                },
                "environment_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.0,
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 15.0
                    }
                },
                "government_and_politics_protests_3": {
                    "AFTER": {
                        "precision": 0.3333333333333333,
                        "recall": 0.25,
                        "f1-score": 0.28571428571428575,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.16666666666666666,
                    "macro avg": {
                        "precision": 0.08333333333333333,
                        "recall": 0.0625,
                        "f1-score": 0.07142857142857144,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.2222222222222222,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.1904761904761905,
                        "support": 6.0
                    }
                },
                "economy_and_business_financial_crisis_4": {
                    "AFTER": {
                        "precision": 0.25,
                        "recall": 0.08333333333333333,
                        "f1-score": 0.125,
                        "support": 12.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.2,
                        "f1-score": 0.33333333333333337,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.09523809523809523,
                    "macro avg": {
                        "precision": 0.3125,
                        "recall": 0.07083333333333333,
                        "f1-score": 0.11458333333333334,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.38095238095238093,
                        "recall": 0.09523809523809523,
                        "f1-score": 0.1507936507936508,
                        "support": 21.0
                    }
                },
                "computers_2": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.25,
                        "f1-score": 0.25,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    }
                },
                "crime_and_law_accuse_4": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.2,
                        "f1-score": 0.28571428571428575,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.1,
                    "macro avg": {
                        "precision": 0.125,
                        "recall": 0.05,
                        "f1-score": 0.07142857142857144,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.25,
                        "recall": 0.1,
                        "f1-score": 0.14285714285714288,
                        "support": 10.0
                    }
                },
                "culture_and_entertainment_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.0,
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    }
                },
                "internet_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.6666666666666666,
                        "recall": 0.5,
                        "f1-score": 0.5714285714285715,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2,
                    "macro avg": {
                        "precision": 0.16666666666666666,
                        "recall": 0.125,
                        "f1-score": 0.14285714285714288,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.26666666666666666,
                        "recall": 0.2,
                        "f1-score": 0.2285714285714286,
                        "support": 10.0
                    }
                },
                "culture_and_entertainment_3": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.4,
                        "f1-score": 0.4444444444444445,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.13333333333333333,
                    "macro avg": {
                        "precision": 0.125,
                        "recall": 0.1,
                        "f1-score": 0.11111111111111112,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.16666666666666666,
                        "recall": 0.13333333333333333,
                        "f1-score": 0.14814814814814817,
                        "support": 15.0
                    }
                }
            },
            "simple_cot": {
                "government_and_politics_riots_4": {
                    "AFTER": {
                        "precision": 0.2,
                        "recall": 0.25,
                        "f1-score": 0.22222222222222224,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.6666666666666666,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.26666666666666666,
                        "support": 12.0
                    },
                    "COEX": {
                        "precision": 0.3333333333333333,
                        "recall": 0.08333333333333333,
                        "f1-score": 0.13333333333333333,
                        "support": 12.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.14285714285714285,
                    "macro avg": {
                        "precision": 0.3,
                        "recall": 0.12499999999999999,
                        "f1-score": 0.15555555555555556,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.4571428571428572,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.2031746031746032,
                        "support": 28.0
                    }
                },
                "rail_transport_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "BEFORE": {
                        "precision": 0.8,
                        "recall": 0.11764705882352941,
                        "f1-score": 0.20512820512820512,
                        "support": 34.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.1111111111111111,
                    "macro avg": {
                        "precision": 0.2,
                        "recall": 0.029411764705882353,
                        "f1-score": 0.05128205128205128,
                        "support": 36.0
                    },
                    "weighted avg": {
                        "precision": 0.7555555555555556,
                        "recall": 0.1111111111111111,
                        "f1-score": 0.19373219373219375,
                        "support": 36.0
                    }
                },
                "politics_and_conflicts_policy_change_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.0,
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    }
                },
                "politics_and_conflicts_drones_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 8.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.0,
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 21.0
                    }
                },
                "disasters_and_accidents_road_crash_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.09090909090909091,
                        "f1-score": 0.15384615384615385,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.3333333333333333,
                        "recall": 0.2,
                        "f1-score": 0.25,
                        "support": 10.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.14285714285714285,
                    "macro avg": {
                        "precision": 0.20833333333333331,
                        "recall": 0.07272727272727272,
                        "f1-score": 0.10096153846153846,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.4206349206349206,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.19963369963369965,
                        "support": 21.0
                    }
                },
                "crime_and_law_accuse_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.0,
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 10.0
                    }
                },
                "government_and_politics_protests_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 20.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.0,
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 28.0
                    }
                },
                "politics_and_conflicts_elections_2": {
                    "AFTER": {
                        "precision": 0.5555555555555556,
                        "recall": 0.22727272727272727,
                        "f1-score": 0.3225806451612903,
                        "support": 22.0
                    },
                    "BEFORE": {
                        "precision": 0.14285714285714285,
                        "recall": 0.07142857142857142,
                        "f1-score": 0.09523809523809523,
                        "support": 14.0
                    },
                    "COEX": {
                        "precision": 0.2857142857142857,
                        "recall": 0.2222222222222222,
                        "f1-score": 0.25,
                        "support": 9.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.17777777777777778,
                    "macro avg": {
                        "precision": 0.24603174603174602,
                        "recall": 0.13023088023088022,
                        "f1-score": 0.1669546850998464,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.37319223985890654,
                        "recall": 0.17777777777777778,
                        "f1-score": 0.23733572281959378,
                        "support": 45.0
                    }
                },
                "environment_2": {
                    "AFTER": {
                        "precision": 0.75,
                        "recall": 0.2857142857142857,
                        "f1-score": 0.4137931034482759,
                        "support": 21.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 23.0
                    },
                    "COEX": {
                        "precision": 0.125,
                        "recall": 1.0,
                        "f1-score": 0.2222222222222222,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.15555555555555556,
                    "macro avg": {
                        "precision": 0.21875,
                        "recall": 0.3214285714285714,
                        "f1-score": 0.15900383141762453,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.3527777777777778,
                        "recall": 0.15555555555555556,
                        "f1-score": 0.19804171988080033,
                        "support": 45.0
                    }
                },
                "weather_floods_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.25,
                        "support": 7.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.06666666666666667,
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.03571428571428571,
                        "f1-score": 0.0625,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.4666666666666667,
                        "recall": 0.06666666666666667,
                        "f1-score": 0.11666666666666667,
                        "support": 15.0
                    }
                },
                "sports_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    }
                },
                "health_4": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.2222222222222222,
                        "f1-score": 0.30769230769230765,
                        "support": 9.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 8.0
                    },
                    "COEX": {
                        "precision": 0.4,
                        "recall": 0.5,
                        "f1-score": 0.4444444444444445,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.19047619047619047,
                    "macro avg": {
                        "precision": 0.225,
                        "recall": 0.18055555555555555,
                        "f1-score": 0.18803418803418803,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.29047619047619044,
                        "recall": 0.19047619047619047,
                        "f1-score": 0.21652421652421652,
                        "support": 21.0
                    }
                },
                "weather_earthquakes_1": {
                    "AFTER": {
                        "precision": 0.18181818181818182,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.23529411764705885,
                        "support": 6.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 32.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 7.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.044444444444444446,
                    "macro avg": {
                        "precision": 0.045454545454545456,
                        "recall": 0.08333333333333333,
                        "f1-score": 0.05882352941176471,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.02424242424242424,
                        "recall": 0.044444444444444446,
                        "f1-score": 0.03137254901960784,
                        "support": 45.0
                    }
                },
                "space_4": {
                    "AFTER": {
                        "precision": 0.4444444444444444,
                        "recall": 0.36363636363636365,
                        "f1-score": 0.39999999999999997,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 15.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.14285714285714285,
                    "macro avg": {
                        "precision": 0.1111111111111111,
                        "recall": 0.09090909090909091,
                        "f1-score": 0.09999999999999999,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.1746031746031746,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.1571428571428571,
                        "support": 28.0
                    }
                },
                "economy_and_business_strikes_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.25,
                        "f1-score": 0.3333333333333333,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.16666666666666666,
                    "macro avg": {
                        "precision": 0.125,
                        "recall": 0.0625,
                        "f1-score": 0.08333333333333333,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.2222222222222222,
                        "support": 6.0
                    }
                },
                "politics_and_conflicts_armed_conflict_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.25,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.28571428571428575,
                        "support": 3.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.06666666666666667,
                    "macro avg": {
                        "precision": 0.0625,
                        "recall": 0.08333333333333333,
                        "f1-score": 0.07142857142857144,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.05,
                        "recall": 0.06666666666666667,
                        "f1-score": 0.05714285714285715,
                        "support": 15.0
                    }
                },
                "infectious_disease_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    }
                },
                "health_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.0,
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 10.0
                    }
                },
                "disasters_and_accidents_shipwreck_2": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.36363636363636365,
                        "f1-score": 0.4210526315789474,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.2222222222222222,
                        "f1-score": 0.30769230769230765,
                        "support": 9.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2857142857142857,
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.14646464646464646,
                        "f1-score": 0.18218623481781376,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.47619047619047616,
                        "recall": 0.2857142857142857,
                        "f1-score": 0.3524195103142471,
                        "support": 21.0
                    }
                },
                "rail_transport_3": {
                    "AFTER": {
                        "precision": 0.25,
                        "recall": 0.2,
                        "f1-score": 0.22222222222222224,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 0.1,
                        "f1-score": 0.15384615384615383,
                        "support": 10.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.13333333333333333,
                    "macro avg": {
                        "precision": 0.14583333333333331,
                        "recall": 0.07500000000000001,
                        "f1-score": 0.09401709401709402,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.3055555555555555,
                        "recall": 0.13333333333333333,
                        "f1-score": 0.17663817663817663,
                        "support": 15.0
                    }
                },
                "weather_storms_1_extra": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    }
                },
                "health_1_extra": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 12.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.25,
                        "support": 28.0
                    },
                    "COEX": {
                        "precision": 0.2857142857142857,
                        "recall": 0.13333333333333333,
                        "f1-score": 0.18181818181818182,
                        "support": 15.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.10909090909090909,
                    "macro avg": {
                        "precision": 0.3214285714285714,
                        "recall": 0.06904761904761905,
                        "f1-score": 0.10795454545454546,
                        "support": 55.0
                    },
                    "weighted avg": {
                        "precision": 0.587012987012987,
                        "recall": 0.10909090909090909,
                        "f1-score": 0.1768595041322314,
                        "support": 55.0
                    }
                },
                "weather_floods_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.5714285714285714,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.25806451612903225,
                        "support": 24.0
                    },
                    "COEX": {
                        "precision": 0.5,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.22222222222222224,
                        "support": 28.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.14545454545454545,
                    "macro avg": {
                        "precision": 0.26785714285714285,
                        "recall": 0.07738095238095238,
                        "f1-score": 0.12007168458781362,
                        "support": 55.0
                    },
                    "weighted avg": {
                        "precision": 0.503896103896104,
                        "recall": 0.14545454545454545,
                        "f1-score": 0.22574128380579994,
                        "support": 55.0
                    }
                },
                "mining_4": {
                    "AFTER": {
                        "precision": 0.6923076923076923,
                        "recall": 0.8181818181818182,
                        "f1-score": 0.7500000000000001,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 25.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 9.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2,
                    "macro avg": {
                        "precision": 0.17307692307692307,
                        "recall": 0.20454545454545456,
                        "f1-score": 0.18750000000000003,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.1692307692307692,
                        "recall": 0.2,
                        "f1-score": 0.18333333333333338,
                        "support": 45.0
                    }
                },
                "disasters_and_accidents_volcanoes_4": {
                    "AFTER": {
                        "precision": 0.3333333333333333,
                        "recall": 0.1,
                        "f1-score": 0.15384615384615383,
                        "support": 20.0
                    },
                    "BEFORE": {
                        "precision": 0.16666666666666666,
                        "recall": 0.07142857142857142,
                        "f1-score": 0.1,
                        "support": 14.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.08333333333333333,
                    "macro avg": {
                        "precision": 0.125,
                        "recall": 0.04285714285714286,
                        "f1-score": 0.06346153846153846,
                        "support": 36.0
                    },
                    "weighted avg": {
                        "precision": 0.25,
                        "recall": 0.08333333333333333,
                        "f1-score": 0.12435897435897436,
                        "support": 36.0
                    }
                },
                "politics_and_conflicts_elections_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.3333333333333333,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.2222222222222222,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.06666666666666667,
                    "macro avg": {
                        "precision": 0.08333333333333333,
                        "recall": 0.041666666666666664,
                        "f1-score": 0.05555555555555555,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.13333333333333333,
                        "recall": 0.06666666666666667,
                        "f1-score": 0.08888888888888888,
                        "support": 15.0
                    }
                },
                "economy_and_business_strikes_3": {
                    "AFTER": {
                        "precision": 0.125,
                        "recall": 0.1,
                        "f1-score": 0.11111111111111112,
                        "support": 10.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 0.09090909090909091,
                        "f1-score": 0.14285714285714288,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.4,
                        "recall": 0.2857142857142857,
                        "f1-score": 0.3333333333333333,
                        "support": 7.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.14285714285714285,
                    "macro avg": {
                        "precision": 0.21458333333333335,
                        "recall": 0.11915584415584415,
                        "f1-score": 0.14682539682539683,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.2755952380952381,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.17913832199546484,
                        "support": 28.0
                    }
                },
                "space_2": {
                    "AFTER": {
                        "precision": 0.55,
                        "recall": 0.22,
                        "f1-score": 0.3142857142857143,
                        "support": 100.0
                    },
                    "BEFORE": {
                        "precision": 0.1111111111111111,
                        "recall": 0.058823529411764705,
                        "f1-score": 0.07692307692307691,
                        "support": 51.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.16339869281045752,
                    "macro avg": {
                        "precision": 0.1652777777777778,
                        "recall": 0.06970588235294117,
                        "f1-score": 0.0978021978021978,
                        "support": 153.0
                    },
                    "weighted avg": {
                        "precision": 0.3965141612200436,
                        "recall": 0.16339869281045752,
                        "f1-score": 0.23105652517417222,
                        "support": 153.0
                    }
                },
                "politics_and_conflicts_resign_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    }
                },
                "environment_4": {
                    "AFTER": {
                        "precision": 0.3333333333333333,
                        "recall": 0.5,
                        "f1-score": 0.4,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.6666666666666666,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.4444444444444444,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.26666666666666666,
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.20833333333333331,
                        "f1-score": 0.2111111111111111,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.3555555555555555,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.28444444444444444,
                        "support": 15.0
                    }
                },
                "space_1_extra": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.2,
                        "f1-score": 0.33333333333333337,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.16666666666666666,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.16666666666666666,
                        "support": 6.0
                    },
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.05,
                        "f1-score": 0.08333333333333334,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.8333333333333334,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.27777777777777785,
                        "support": 6.0
                    }
                },
                "health_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 8.0
                    },
                    "BEFORE": {
                        "precision": 0.16666666666666666,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.16666666666666666,
                        "support": 6.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.06666666666666667,
                    "macro avg": {
                        "precision": 0.041666666666666664,
                        "recall": 0.041666666666666664,
                        "f1-score": 0.041666666666666664,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.06666666666666667,
                        "recall": 0.06666666666666667,
                        "f1-score": 0.06666666666666667,
                        "support": 15.0
                    }
                },
                "environment_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.0,
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 15.0
                    }
                },
                "government_and_politics_protests_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.0,
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    }
                },
                "economy_and_business_financial_crisis_4": {
                    "AFTER": {
                        "precision": 0.3333333333333333,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.2222222222222222,
                        "support": 12.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.3333333333333333,
                        "recall": 0.25,
                        "f1-score": 0.28571428571428575,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.14285714285714285,
                    "macro avg": {
                        "precision": 0.16666666666666666,
                        "recall": 0.10416666666666666,
                        "f1-score": 0.12698412698412698,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.25396825396825395,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.18140589569160998,
                        "support": 21.0
                    }
                },
                "computers_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    }
                },
                "crime_and_law_accuse_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.0,
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 10.0
                    }
                },
                "culture_and_entertainment_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.3333333333333333,
                        "recall": 0.5,
                        "f1-score": 0.4,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.16666666666666666,
                    "macro avg": {
                        "precision": 0.08333333333333333,
                        "recall": 0.125,
                        "f1-score": 0.1,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.1111111111111111,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.13333333333333333,
                        "support": 6.0
                    }
                },
                "internet_2": {
                    "AFTER": {
                        "precision": 0.25,
                        "recall": 0.2,
                        "f1-score": 0.22222222222222224,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.3333333333333333,
                        "recall": 1.0,
                        "f1-score": 0.5,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2,
                    "macro avg": {
                        "precision": 0.14583333333333331,
                        "recall": 0.3,
                        "f1-score": 0.18055555555555555,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.15833333333333333,
                        "recall": 0.2,
                        "f1-score": 0.16111111111111112,
                        "support": 10.0
                    }
                },
                "culture_and_entertainment_3": {
                    "AFTER": {
                        "precision": 0.375,
                        "recall": 0.6,
                        "f1-score": 0.4615384615384615,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.14285714285714285,
                        "recall": 0.25,
                        "f1-score": 0.18181818181818182,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.26666666666666666,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.26666666666666666,
                        "support": 15.0
                    },
                    "macro avg": {
                        "precision": 0.1294642857142857,
                        "recall": 0.2125,
                        "f1-score": 0.16083916083916083,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.16309523809523807,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.20233100233100235,
                        "support": 15.0
                    }
                }
            }
        }
    }
}

{
    "args": {
        "batch_size": 4,
        "dataset_name": "ctf-mrc-cot",
        "device": "cuda",
        "dirpath_log": "log",
        "dirpath_model": null,
        "dirpath_output": "output/comparison",
        "dirpath_output_score": "output_score/comparison",
        "filepath_test": "data/preprocessed/ctf-sample/test.json",
        "filepath_dev": "data/preprocessed/ctf-sample/dev.json",
        "inference_type": "few-shot",
        "local_rank": 0,
        "marker": "eid",
        "max_new_tokens": 512,
        "model_id": "google/flan-t5-xl",
        "num_demonstration": 0,
        "num_gpu": 1,
        "num_cpu": 4,
        "peft_model_path": null,
        "precision_type": "bfloat16",
        "representation": "mention",
        "seed": 7,
        "temperature": 0.0,
        "dirpath_model_cache": "/data/tir/projects/tir6/general/kimihiro/.cache/huggingface/transformers"
    },
    "average": {
        "document-and-pair-wise-scores": {
            "range": {
                "min": 0.1445021478385185,
                "median": 0.15571735650104515,
                "max": 0.25277324632641457
            },
            "individual": {
                "hint_cot": 0.25277324632641457,
                "note_events_cot": 0.15571735650104515,
                "refer_events_cot": 0.1445021478385185,
                "careful_cot": 0.2176671231395578,
                "simple_cot": 0.1446133890698822
            }
        }
    },
    "individuals": {
        "document-and-pair-wise-scores": {
            "hint_cot": {
                "government_and_politics_riots_4": {
                    "AFTER": {
                        "precision": 0.25,
                        "recall": 0.5,
                        "f1-score": 0.3333333333333333,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.6666666666666666,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.4444444444444444,
                        "support": 12.0
                    },
                    "COEX": {
                        "precision": 0.5,
                        "recall": 0.08333333333333333,
                        "f1-score": 0.14285714285714285,
                        "support": 12.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.25,
                    "macro avg": {
                        "precision": 0.35416666666666663,
                        "recall": 0.22916666666666666,
                        "f1-score": 0.23015873015873012,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.5357142857142857,
                        "recall": 0.25,
                        "f1-score": 0.2993197278911564,
                        "support": 28.0
                    }
                },
                "rail_transport_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.2647058823529412,
                        "f1-score": 0.4186046511627907,
                        "support": 34.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.25,
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.0661764705882353,
                        "f1-score": 0.10465116279069768,
                        "support": 36.0
                    },
                    "weighted avg": {
                        "precision": 0.9444444444444444,
                        "recall": 0.25,
                        "f1-score": 0.39534883720930236,
                        "support": 36.0
                    }
                },
                "politics_and_conflicts_policy_change_2": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.4,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.5,
                        "recall": 0.5,
                        "f1-score": 0.5,
                        "support": 6.0
                    },
                    "macro avg": {
                        "precision": 0.375,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.35,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.5833333333333334,
                        "recall": 0.5,
                        "f1-score": 0.5333333333333333,
                        "support": 6.0
                    }
                },
                "politics_and_conflicts_drones_1": {
                    "AFTER": {
                        "precision": 0.4444444444444444,
                        "recall": 0.36363636363636365,
                        "f1-score": 0.39999999999999997,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 0.25,
                        "f1-score": 0.28571428571428575,
                        "support": 8.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2857142857142857,
                    "macro avg": {
                        "precision": 0.19444444444444442,
                        "recall": 0.1534090909090909,
                        "f1-score": 0.17142857142857143,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.35978835978835977,
                        "recall": 0.2857142857142857,
                        "f1-score": 0.3183673469387755,
                        "support": 21.0
                    }
                },
                "disasters_and_accidents_road_crash_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.09090909090909091,
                        "f1-score": 0.15384615384615385,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.45454545454545453,
                        "recall": 0.5,
                        "f1-score": 0.47619047619047616,
                        "support": 10.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2857142857142857,
                    "macro avg": {
                        "precision": 0.23863636363636365,
                        "recall": 0.14772727272727273,
                        "f1-score": 0.1575091575091575,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.4783549783549783,
                        "recall": 0.2857142857142857,
                        "f1-score": 0.30734345020059306,
                        "support": 21.0
                    }
                },
                "crime_and_law_accuse_3": {
                    "AFTER": {
                        "precision": 0.25,
                        "recall": 0.25,
                        "f1-score": 0.25,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.2222222222222222,
                        "support": 6.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.2,
                        "recall": 0.2,
                        "f1-score": 0.20000000000000004,
                        "support": 10.0
                    },
                    "macro avg": {
                        "precision": 0.14583333333333331,
                        "recall": 0.10416666666666666,
                        "f1-score": 0.11805555555555555,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.3,
                        "recall": 0.2,
                        "f1-score": 0.2333333333333333,
                        "support": 10.0
                    }
                },
                "government_and_politics_protests_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.6666666666666666,
                        "recall": 0.2,
                        "f1-score": 0.30769230769230765,
                        "support": 20.0
                    },
                    "COEX": {
                        "precision": 0.1111111111111111,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.16666666666666666,
                        "support": 3.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.17857142857142858,
                    "macro avg": {
                        "precision": 0.19444444444444442,
                        "recall": 0.13333333333333333,
                        "f1-score": 0.11858974358974358,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.4880952380952381,
                        "recall": 0.17857142857142858,
                        "f1-score": 0.23763736263736263,
                        "support": 28.0
                    }
                },
                "politics_and_conflicts_elections_2": {
                    "AFTER": {
                        "precision": 0.2857142857142857,
                        "recall": 0.09090909090909091,
                        "f1-score": 0.13793103448275862,
                        "support": 22.0
                    },
                    "BEFORE": {
                        "precision": 0.23076923076923078,
                        "recall": 0.21428571428571427,
                        "f1-score": 0.22222222222222224,
                        "support": 14.0
                    },
                    "COEX": {
                        "precision": 0.25,
                        "recall": 0.2222222222222222,
                        "f1-score": 0.23529411764705882,
                        "support": 9.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.15555555555555556,
                    "macro avg": {
                        "precision": 0.1916208791208791,
                        "recall": 0.13185425685425683,
                        "f1-score": 0.1488618435880099,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.2614774114774115,
                        "recall": 0.15555555555555556,
                        "f1-score": 0.18362757619011844,
                        "support": 45.0
                    }
                },
                "environment_2": {
                    "AFTER": {
                        "precision": 0.4444444444444444,
                        "recall": 0.38095238095238093,
                        "f1-score": 0.41025641025641024,
                        "support": 21.0
                    },
                    "BEFORE": {
                        "precision": 0.5384615384615384,
                        "recall": 0.30434782608695654,
                        "f1-score": 0.3888888888888889,
                        "support": 23.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.3333333333333333,
                    "macro avg": {
                        "precision": 0.24572649572649571,
                        "recall": 0.17132505175983437,
                        "f1-score": 0.1997863247863248,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.48262108262108255,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3902184235517569,
                        "support": 45.0
                    }
                },
                "weather_floods_3": {
                    "AFTER": {
                        "precision": 0.16666666666666666,
                        "recall": 0.25,
                        "f1-score": 0.2,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 7.0
                    },
                    "COEX": {
                        "precision": 0.3333333333333333,
                        "recall": 0.5,
                        "f1-score": 0.4,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2,
                    "macro avg": {
                        "precision": 0.125,
                        "recall": 0.1875,
                        "f1-score": 0.15000000000000002,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.13333333333333333,
                        "recall": 0.2,
                        "f1-score": 0.16000000000000003,
                        "support": 15.0
                    }
                },
                "sports_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    }
                },
                "health_4": {
                    "AFTER": {
                        "precision": 0.3333333333333333,
                        "recall": 0.1111111111111111,
                        "f1-score": 0.16666666666666666,
                        "support": 9.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 8.0
                    },
                    "COEX": {
                        "precision": 0.16666666666666666,
                        "recall": 0.5,
                        "f1-score": 0.25,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.14285714285714285,
                    "macro avg": {
                        "precision": 0.125,
                        "recall": 0.1527777777777778,
                        "f1-score": 0.10416666666666666,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.1746031746031746,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.11904761904761904,
                        "support": 21.0
                    }
                },
                "weather_earthquakes_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "BEFORE": {
                        "precision": 0.2727272727272727,
                        "recall": 0.09375,
                        "f1-score": 0.13953488372093023,
                        "support": 32.0
                    },
                    "COEX": {
                        "precision": 0.08,
                        "recall": 0.2857142857142857,
                        "f1-score": 0.125,
                        "support": 7.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.1111111111111111,
                    "macro avg": {
                        "precision": 0.08818181818181818,
                        "recall": 0.09486607142857142,
                        "f1-score": 0.06613372093023256,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.2063838383838384,
                        "recall": 0.1111111111111111,
                        "f1-score": 0.11866925064599483,
                        "support": 45.0
                    }
                },
                "space_4": {
                    "AFTER": {
                        "precision": 0.4,
                        "recall": 0.18181818181818182,
                        "f1-score": 0.25000000000000006,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.2857142857142857,
                        "recall": 0.13333333333333333,
                        "f1-score": 0.18181818181818182,
                        "support": 15.0
                    },
                    "COEX": {
                        "precision": 0.14285714285714285,
                        "recall": 0.5,
                        "f1-score": 0.22222222222222224,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.17857142857142858,
                    "macro avg": {
                        "precision": 0.20714285714285713,
                        "recall": 0.2037878787878788,
                        "f1-score": 0.16351010101010102,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.3204081632653062,
                        "recall": 0.17857142857142858,
                        "f1-score": 0.21148989898989903,
                        "support": 28.0
                    }
                },
                "economy_and_business_strikes_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.25,
                        "f1-score": 0.3333333333333333,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.16666666666666666,
                    "macro avg": {
                        "precision": 0.125,
                        "recall": 0.0625,
                        "f1-score": 0.08333333333333333,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.2222222222222222,
                        "support": 6.0
                    }
                },
                "politics_and_conflicts_armed_conflict_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.18181818181818182,
                        "f1-score": 0.26666666666666666,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.2857142857142857,
                        "recall": 0.6666666666666666,
                        "f1-score": 0.4,
                        "support": 3.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.26666666666666666,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.26666666666666666,
                        "support": 15.0
                    },
                    "macro avg": {
                        "precision": 0.19642857142857142,
                        "recall": 0.2121212121212121,
                        "f1-score": 0.16666666666666669,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.4238095238095238,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.2755555555555555,
                        "support": 15.0
                    }
                },
                "infectious_disease_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    }
                },
                "health_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 10.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 10.0
                    }
                },
                "disasters_and_accidents_shipwreck_2": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.36363636363636365,
                        "f1-score": 0.4210526315789474,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.4,
                        "recall": 0.4444444444444444,
                        "f1-score": 0.4210526315789474,
                        "support": 9.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.38095238095238093,
                        "recall": 0.38095238095238093,
                        "f1-score": 0.38095238095238093,
                        "support": 21.0
                    },
                    "macro avg": {
                        "precision": 0.225,
                        "recall": 0.20202020202020202,
                        "f1-score": 0.2105263157894737,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.4333333333333333,
                        "recall": 0.38095238095238093,
                        "f1-score": 0.40100250626566425,
                        "support": 21.0
                    }
                },
                "rail_transport_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.1,
                        "f1-score": 0.16666666666666669,
                        "support": 10.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.06666666666666667,
                    "macro avg": {
                        "precision": 0.125,
                        "recall": 0.025,
                        "f1-score": 0.04166666666666667,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.06666666666666667,
                        "f1-score": 0.11111111111111113,
                        "support": 15.0
                    }
                },
                "weather_storms_1_extra": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    }
                },
                "health_1_extra": {
                    "AFTER": {
                        "precision": 0.125,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.14285714285714288,
                        "support": 12.0
                    },
                    "BEFORE": {
                        "precision": 0.42857142857142855,
                        "recall": 0.21428571428571427,
                        "f1-score": 0.2857142857142857,
                        "support": 28.0
                    },
                    "COEX": {
                        "precision": 0.1,
                        "recall": 0.06666666666666667,
                        "f1-score": 0.08,
                        "support": 15.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.16363636363636364,
                    "macro avg": {
                        "precision": 0.16339285714285715,
                        "recall": 0.1119047619047619,
                        "f1-score": 0.12714285714285714,
                        "support": 55.0
                    },
                    "weighted avg": {
                        "precision": 0.2727272727272727,
                        "recall": 0.16363636363636364,
                        "f1-score": 0.19844155844155845,
                        "support": 55.0
                    }
                },
                "weather_floods_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.2916666666666667,
                        "f1-score": 0.3684210526315789,
                        "support": 24.0
                    },
                    "COEX": {
                        "precision": 0.5,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.22222222222222224,
                        "support": 28.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2,
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.10863095238095238,
                        "f1-score": 0.1476608187134503,
                        "support": 55.0
                    },
                    "weighted avg": {
                        "precision": 0.4727272727272727,
                        "recall": 0.2,
                        "f1-score": 0.2738968633705475,
                        "support": 55.0
                    }
                },
                "mining_4": {
                    "AFTER": {
                        "precision": 0.36363636363636365,
                        "recall": 0.36363636363636365,
                        "f1-score": 0.36363636363636365,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.5555555555555556,
                        "recall": 0.2,
                        "f1-score": 0.29411764705882354,
                        "support": 25.0
                    },
                    "COEX": {
                        "precision": 0.23076923076923078,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.27272727272727276,
                        "support": 9.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.26666666666666666,
                    "macro avg": {
                        "precision": 0.2874902874902875,
                        "recall": 0.22424242424242424,
                        "f1-score": 0.23262032085561496,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.443684710351377,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.30683303624480096,
                        "support": 45.0
                    }
                },
                "disasters_and_accidents_volcanoes_4": {
                    "AFTER": {
                        "precision": 0.4444444444444444,
                        "recall": 0.2,
                        "f1-score": 0.2758620689655173,
                        "support": 20.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 14.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.1111111111111111,
                    "macro avg": {
                        "precision": 0.1111111111111111,
                        "recall": 0.05,
                        "f1-score": 0.06896551724137932,
                        "support": 36.0
                    },
                    "weighted avg": {
                        "precision": 0.2469135802469136,
                        "recall": 0.1111111111111111,
                        "f1-score": 0.15325670498084296,
                        "support": 36.0
                    }
                },
                "politics_and_conflicts_elections_3": {
                    "AFTER": {
                        "precision": 0.75,
                        "recall": 0.6,
                        "f1-score": 0.6666666666666665,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.5454545454545454,
                        "recall": 1.0,
                        "f1-score": 0.7058823529411764,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.6,
                        "recall": 0.6,
                        "f1-score": 0.6,
                        "support": 15.0
                    },
                    "macro avg": {
                        "precision": 0.32386363636363635,
                        "recall": 0.4,
                        "f1-score": 0.34313725490196073,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.46818181818181814,
                        "recall": 0.6,
                        "f1-score": 0.5045751633986927,
                        "support": 15.0
                    }
                },
                "economy_and_business_strikes_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 10.0
                    },
                    "BEFORE": {
                        "precision": 0.2,
                        "recall": 0.09090909090909091,
                        "f1-score": 0.12500000000000003,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 7.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.03571428571428571,
                    "macro avg": {
                        "precision": 0.05,
                        "recall": 0.022727272727272728,
                        "f1-score": 0.03125000000000001,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.07857142857142858,
                        "recall": 0.03571428571428571,
                        "f1-score": 0.04910714285714286,
                        "support": 28.0
                    }
                },
                "space_2": {
                    "AFTER": {
                        "precision": 0.39285714285714285,
                        "recall": 0.11,
                        "f1-score": 0.17187499999999997,
                        "support": 100.0
                    },
                    "BEFORE": {
                        "precision": 0.47368421052631576,
                        "recall": 0.17647058823529413,
                        "f1-score": 0.2571428571428572,
                        "support": 51.0
                    },
                    "COEX": {
                        "precision": 0.1111111111111111,
                        "recall": 0.5,
                        "f1-score": 0.1818181818181818,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.13725490196078433,
                    "macro avg": {
                        "precision": 0.24441311612364242,
                        "recall": 0.19661764705882354,
                        "f1-score": 0.15270900974025972,
                        "support": 153.0
                    },
                    "weighted avg": {
                        "precision": 0.41611654408352033,
                        "recall": 0.13725490196078433,
                        "f1-score": 0.20042759528053644,
                        "support": 153.0
                    }
                },
                "politics_and_conflicts_resign_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    }
                },
                "environment_4": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.75,
                        "f1-score": 0.6,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.2,
                        "f1-score": 0.33333333333333337,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.5,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.4,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.4,
                    "macro avg": {
                        "precision": 0.5,
                        "recall": 0.3208333333333333,
                        "f1-score": 0.33333333333333337,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.6666666666666666,
                        "recall": 0.4,
                        "f1-score": 0.4311111111111111,
                        "support": 15.0
                    }
                },
                "space_1_extra": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.4,
                        "f1-score": 0.5714285714285715,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 6.0
                    },
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.1,
                        "f1-score": 0.14285714285714288,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.8333333333333334,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.4761904761904763,
                        "support": 6.0
                    }
                },
                "health_3": {
                    "AFTER": {
                        "precision": 0.375,
                        "recall": 0.375,
                        "f1-score": 0.375,
                        "support": 8.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2,
                    "macro avg": {
                        "precision": 0.09375,
                        "recall": 0.09375,
                        "f1-score": 0.09375,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.2,
                        "recall": 0.2,
                        "f1-score": 0.2,
                        "support": 15.0
                    }
                },
                "environment_3": {
                    "AFTER": {
                        "precision": 0.8333333333333334,
                        "recall": 0.45454545454545453,
                        "f1-score": 0.5882352941176471,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.4,
                        "recall": 1.0,
                        "f1-score": 0.5714285714285715,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.4666666666666667,
                        "recall": 0.4666666666666667,
                        "f1-score": 0.4666666666666667,
                        "support": 15.0
                    },
                    "macro avg": {
                        "precision": 0.30833333333333335,
                        "recall": 0.36363636363636365,
                        "f1-score": 0.28991596638655465,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.6644444444444446,
                        "recall": 0.4666666666666667,
                        "f1-score": 0.5075630252100841,
                        "support": 15.0
                    }
                },
                "government_and_politics_protests_3": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.5,
                        "f1-score": 0.6666666666666666,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 1.0,
                        "f1-score": 0.5,
                        "support": 1.0
                    },
                    "COEX": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.6666666666666666,
                        "recall": 0.6666666666666666,
                        "f1-score": 0.6666666666666666,
                        "support": 6.0
                    },
                    "macro avg": {
                        "precision": 0.5833333333333333,
                        "recall": 0.625,
                        "f1-score": 0.5416666666666666,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.8888888888888888,
                        "recall": 0.6666666666666666,
                        "f1-score": 0.6944444444444443,
                        "support": 6.0
                    }
                },
                "economy_and_business_financial_crisis_4": {
                    "AFTER": {
                        "precision": 0.7142857142857143,
                        "recall": 0.4166666666666667,
                        "f1-score": 0.5263157894736842,
                        "support": 12.0
                    },
                    "BEFORE": {
                        "precision": 0.14285714285714285,
                        "recall": 0.2,
                        "f1-score": 0.16666666666666666,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.16666666666666666,
                        "recall": 0.25,
                        "f1-score": 0.2,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.3333333333333333,
                    "macro avg": {
                        "precision": 0.255952380952381,
                        "recall": 0.21666666666666667,
                        "f1-score": 0.2232456140350877,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.473922902494331,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3785296574770259,
                        "support": 21.0
                    }
                },
                "computers_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    }
                },
                "crime_and_law_accuse_4": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.2,
                        "f1-score": 0.33333333333333337,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.2,
                        "f1-score": 0.28571428571428575,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.2,
                        "recall": 0.2,
                        "f1-score": 0.20000000000000004,
                        "support": 10.0
                    },
                    "macro avg": {
                        "precision": 0.375,
                        "recall": 0.1,
                        "f1-score": 0.15476190476190477,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.75,
                        "recall": 0.2,
                        "f1-score": 0.3095238095238096,
                        "support": 10.0
                    }
                },
                "culture_and_entertainment_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.25,
                        "recall": 0.5,
                        "f1-score": 0.3333333333333333,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.16666666666666666,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.16666666666666666,
                        "support": 6.0
                    },
                    "macro avg": {
                        "precision": 0.0625,
                        "recall": 0.125,
                        "f1-score": 0.08333333333333333,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.08333333333333333,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.1111111111111111,
                        "support": 6.0
                    }
                },
                "internet_2": {
                    "AFTER": {
                        "precision": 0.25,
                        "recall": 0.2,
                        "f1-score": 0.22222222222222224,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.5,
                        "f1-score": 0.5,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.3,
                        "recall": 0.3,
                        "f1-score": 0.3,
                        "support": 10.0
                    },
                    "macro avg": {
                        "precision": 0.1875,
                        "recall": 0.175,
                        "f1-score": 0.18055555555555555,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.325,
                        "recall": 0.3,
                        "f1-score": 0.3111111111111111,
                        "support": 10.0
                    }
                },
                "culture_and_entertainment_3": {
                    "AFTER": {
                        "precision": 0.375,
                        "recall": 0.6,
                        "f1-score": 0.4615384615384615,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.8333333333333334,
                        "recall": 0.8333333333333334,
                        "f1-score": 0.8333333333333334,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.5333333333333333,
                        "recall": 0.5333333333333333,
                        "f1-score": 0.5333333333333333,
                        "support": 15.0
                    },
                    "macro avg": {
                        "precision": 0.30208333333333337,
                        "recall": 0.35833333333333334,
                        "f1-score": 0.32371794871794873,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.4583333333333333,
                        "recall": 0.5333333333333333,
                        "f1-score": 0.48717948717948717,
                        "support": 15.0
                    }
                }
            },
            "note_events_cot": {
                "government_and_politics_riots_4": {
                    "AFTER": {
                        "precision": 0.1,
                        "recall": 0.25,
                        "f1-score": 0.14285714285714288,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 12.0
                    },
                    "COEX": {
                        "precision": 0.5,
                        "recall": 0.08333333333333333,
                        "f1-score": 0.14285714285714285,
                        "support": 12.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.07142857142857142,
                    "macro avg": {
                        "precision": 0.15,
                        "recall": 0.08333333333333333,
                        "f1-score": 0.07142857142857142,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.2285714285714286,
                        "recall": 0.07142857142857142,
                        "f1-score": 0.08163265306122448,
                        "support": 28.0
                    }
                },
                "rail_transport_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.08823529411764706,
                        "f1-score": 0.1621621621621622,
                        "support": 34.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.08333333333333333,
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.022058823529411766,
                        "f1-score": 0.04054054054054055,
                        "support": 36.0
                    },
                    "weighted avg": {
                        "precision": 0.9444444444444444,
                        "recall": 0.08333333333333333,
                        "f1-score": 0.1531531531531532,
                        "support": 36.0
                    }
                },
                "politics_and_conflicts_policy_change_2": {
                    "AFTER": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.5,
                        "recall": 1.0,
                        "f1-score": 0.6666666666666666,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 6.0
                    },
                    "macro avg": {
                        "precision": 0.20833333333333331,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.25,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.25,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.27777777777777773,
                        "support": 6.0
                    }
                },
                "politics_and_conflicts_drones_1": {
                    "AFTER": {
                        "precision": 0.125,
                        "recall": 0.09090909090909091,
                        "f1-score": 0.10526315789473685,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 8.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.047619047619047616,
                    "macro avg": {
                        "precision": 0.03125,
                        "recall": 0.022727272727272728,
                        "f1-score": 0.026315789473684213,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.06547619047619048,
                        "recall": 0.047619047619047616,
                        "f1-score": 0.055137844611528826,
                        "support": 21.0
                    }
                },
                "disasters_and_accidents_road_crash_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.09090909090909091,
                        "f1-score": 0.15384615384615385,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 10.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.047619047619047616,
                    "macro avg": {
                        "precision": 0.125,
                        "recall": 0.022727272727272728,
                        "f1-score": 0.038461538461538464,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.2619047619047619,
                        "recall": 0.047619047619047616,
                        "f1-score": 0.08058608058608059,
                        "support": 21.0
                    }
                },
                "crime_and_law_accuse_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.0,
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 10.0
                    }
                },
                "government_and_politics_protests_2": {
                    "AFTER": {
                        "precision": 0.1111111111111111,
                        "recall": 0.2,
                        "f1-score": 0.14285714285714285,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.6666666666666666,
                        "recall": 0.2,
                        "f1-score": 0.30769230769230765,
                        "support": 20.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.17857142857142858,
                    "macro avg": {
                        "precision": 0.19444444444444442,
                        "recall": 0.1,
                        "f1-score": 0.11263736263736263,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.496031746031746,
                        "recall": 0.17857142857142858,
                        "f1-score": 0.24529042386185243,
                        "support": 28.0
                    }
                },
                "politics_and_conflicts_elections_2": {
                    "AFTER": {
                        "precision": 0.625,
                        "recall": 0.22727272727272727,
                        "f1-score": 0.3333333333333333,
                        "support": 22.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 14.0
                    },
                    "COEX": {
                        "precision": 0.09090909090909091,
                        "recall": 0.1111111111111111,
                        "f1-score": 0.09999999999999999,
                        "support": 9.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.13333333333333333,
                    "macro avg": {
                        "precision": 0.17897727272727273,
                        "recall": 0.08459595959595959,
                        "f1-score": 0.10833333333333332,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.32373737373737377,
                        "recall": 0.13333333333333333,
                        "f1-score": 0.18296296296296294,
                        "support": 45.0
                    }
                },
                "environment_2": {
                    "AFTER": {
                        "precision": 0.5882352941176471,
                        "recall": 0.47619047619047616,
                        "f1-score": 0.5263157894736842,
                        "support": 21.0
                    },
                    "BEFORE": {
                        "precision": 0.5714285714285714,
                        "recall": 0.17391304347826086,
                        "f1-score": 0.26666666666666666,
                        "support": 23.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.3111111111111111,
                    "macro avg": {
                        "precision": 0.2899159663865546,
                        "recall": 0.16252587991718426,
                        "f1-score": 0.19824561403508772,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.5665732959850607,
                        "recall": 0.3111111111111111,
                        "f1-score": 0.38191033138401564,
                        "support": 45.0
                    }
                },
                "weather_floods_3": {
                    "AFTER": {
                        "precision": 0.2222222222222222,
                        "recall": 0.5,
                        "f1-score": 0.30769230769230765,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 7.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.13333333333333333,
                    "macro avg": {
                        "precision": 0.05555555555555555,
                        "recall": 0.125,
                        "f1-score": 0.07692307692307691,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.059259259259259255,
                        "recall": 0.13333333333333333,
                        "f1-score": 0.08205128205128204,
                        "support": 15.0
                    }
                },
                "sports_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    }
                },
                "health_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 9.0
                    },
                    "BEFORE": {
                        "precision": 0.2857142857142857,
                        "recall": 0.25,
                        "f1-score": 0.26666666666666666,
                        "support": 8.0
                    },
                    "COEX": {
                        "precision": 0.3333333333333333,
                        "recall": 0.25,
                        "f1-score": 0.28571428571428575,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.14285714285714285,
                    "macro avg": {
                        "precision": 0.15476190476190477,
                        "recall": 0.125,
                        "f1-score": 0.1380952380952381,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.17233560090702946,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.15600907029478459,
                        "support": 21.0
                    }
                },
                "weather_earthquakes_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "BEFORE": {
                        "precision": 0.8181818181818182,
                        "recall": 0.28125,
                        "f1-score": 0.41860465116279066,
                        "support": 32.0
                    },
                    "COEX": {
                        "precision": 0.1,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.11764705882352941,
                        "support": 7.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2222222222222222,
                    "macro avg": {
                        "precision": 0.22954545454545455,
                        "recall": 0.10602678571428571,
                        "f1-score": 0.13406292749658003,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.5973737373737374,
                        "recall": 0.2222222222222222,
                        "f1-score": 0.3159750721994224,
                        "support": 45.0
                    }
                },
                "space_4": {
                    "AFTER": {
                        "precision": 0.16666666666666666,
                        "recall": 0.18181818181818182,
                        "f1-score": 0.17391304347826086,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 15.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.07142857142857142,
                    "macro avg": {
                        "precision": 0.041666666666666664,
                        "recall": 0.045454545454545456,
                        "f1-score": 0.043478260869565216,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.06547619047619048,
                        "recall": 0.07142857142857142,
                        "f1-score": 0.06832298136645963,
                        "support": 28.0
                    }
                },
                "economy_and_business_strikes_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.25,
                        "f1-score": 0.4,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.16666666666666666,
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.0625,
                        "f1-score": 0.1,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.6666666666666666,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.26666666666666666,
                        "support": 6.0
                    }
                },
                "politics_and_conflicts_armed_conflict_2": {
                    "AFTER": {
                        "precision": 0.14285714285714285,
                        "recall": 1.0,
                        "f1-score": 0.25,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.09090909090909091,
                        "f1-score": 0.16666666666666669,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.13333333333333333,
                    "macro avg": {
                        "precision": 0.2857142857142857,
                        "recall": 0.2727272727272727,
                        "f1-score": 0.10416666666666667,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.7428571428571428,
                        "recall": 0.13333333333333333,
                        "f1-score": 0.1388888888888889,
                        "support": 15.0
                    }
                },
                "infectious_disease_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    }
                },
                "health_1": {
                    "AFTER": {
                        "precision": 0.3333333333333333,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.2222222222222222,
                        "support": 6.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "COEX": {
                        "precision": 0.25,
                        "recall": 1.0,
                        "f1-score": 0.4,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2,
                    "macro avg": {
                        "precision": 0.14583333333333331,
                        "recall": 0.2916666666666667,
                        "f1-score": 0.15555555555555556,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.225,
                        "recall": 0.2,
                        "f1-score": 0.17333333333333334,
                        "support": 10.0
                    }
                },
                "disasters_and_accidents_shipwreck_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 9.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.0,
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 21.0
                    }
                },
                "rail_transport_3": {
                    "AFTER": {
                        "precision": 0.3333333333333333,
                        "recall": 0.4,
                        "f1-score": 0.3636363636363636,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 10.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.13333333333333333,
                    "macro avg": {
                        "precision": 0.08333333333333333,
                        "recall": 0.1,
                        "f1-score": 0.0909090909090909,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.1111111111111111,
                        "recall": 0.13333333333333333,
                        "f1-score": 0.12121212121212119,
                        "support": 15.0
                    }
                },
                "weather_storms_1_extra": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    }
                },
                "health_1_extra": {
                    "AFTER": {
                        "precision": 0.28,
                        "recall": 0.5833333333333334,
                        "f1-score": 0.3783783783783784,
                        "support": 12.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 28.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 15.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.12727272727272726,
                    "macro avg": {
                        "precision": 0.07,
                        "recall": 0.14583333333333334,
                        "f1-score": 0.0945945945945946,
                        "support": 55.0
                    },
                    "weighted avg": {
                        "precision": 0.0610909090909091,
                        "recall": 0.12727272727272726,
                        "f1-score": 0.08255528255528255,
                        "support": 55.0
                    }
                },
                "weather_floods_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.041666666666666664,
                        "f1-score": 0.07692307692307693,
                        "support": 24.0
                    },
                    "COEX": {
                        "precision": 0.5,
                        "recall": 0.5,
                        "f1-score": 0.5,
                        "support": 28.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2727272727272727,
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.13541666666666666,
                        "f1-score": 0.14423076923076922,
                        "support": 55.0
                    },
                    "weighted avg": {
                        "precision": 0.4727272727272727,
                        "recall": 0.2727272727272727,
                        "f1-score": 0.28811188811188815,
                        "support": 55.0
                    }
                },
                "mining_4": {
                    "AFTER": {
                        "precision": 0.38461538461538464,
                        "recall": 0.45454545454545453,
                        "f1-score": 0.41666666666666663,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.4444444444444444,
                        "recall": 0.16,
                        "f1-score": 0.23529411764705882,
                        "support": 25.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 9.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2,
                    "macro avg": {
                        "precision": 0.20726495726495725,
                        "recall": 0.15363636363636363,
                        "f1-score": 0.16299019607843135,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.3409306742640076,
                        "recall": 0.2,
                        "f1-score": 0.23257080610021785,
                        "support": 45.0
                    }
                },
                "disasters_and_accidents_volcanoes_4": {
                    "AFTER": {
                        "precision": 0.125,
                        "recall": 0.05,
                        "f1-score": 0.07142857142857144,
                        "support": 20.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 14.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.027777777777777776,
                    "macro avg": {
                        "precision": 0.03125,
                        "recall": 0.0125,
                        "f1-score": 0.01785714285714286,
                        "support": 36.0
                    },
                    "weighted avg": {
                        "precision": 0.06944444444444445,
                        "recall": 0.027777777777777776,
                        "f1-score": 0.03968253968253969,
                        "support": 36.0
                    }
                },
                "politics_and_conflicts_elections_3": {
                    "AFTER": {
                        "precision": 0.25,
                        "recall": 0.2,
                        "f1-score": 0.22222222222222224,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 1.0,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.2857142857142857,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.13333333333333333,
                    "macro avg": {
                        "precision": 0.3125,
                        "recall": 0.09166666666666667,
                        "f1-score": 0.12698412698412698,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.48333333333333334,
                        "recall": 0.13333333333333333,
                        "f1-score": 0.18835978835978834,
                        "support": 15.0
                    }
                },
                "economy_and_business_strikes_3": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.2,
                        "f1-score": 0.28571428571428575,
                        "support": 10.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.09090909090909091,
                        "f1-score": 0.16666666666666669,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.2222222222222222,
                        "recall": 0.5714285714285714,
                        "f1-score": 0.32,
                        "support": 7.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.25,
                    "macro avg": {
                        "precision": 0.4305555555555556,
                        "recall": 0.21558441558441557,
                        "f1-score": 0.1930952380952381,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.6269841269841271,
                        "recall": 0.25,
                        "f1-score": 0.24751700680272112,
                        "support": 28.0
                    }
                },
                "space_2": {
                    "AFTER": {
                        "precision": 0.4722222222222222,
                        "recall": 0.34,
                        "f1-score": 0.39534883720930236,
                        "support": 100.0
                    },
                    "BEFORE": {
                        "precision": 0.023809523809523808,
                        "recall": 0.0196078431372549,
                        "f1-score": 0.02150537634408602,
                        "support": 51.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.22875816993464052,
                    "macro avg": {
                        "precision": 0.12400793650793651,
                        "recall": 0.08990196078431373,
                        "f1-score": 0.10421355338834709,
                        "support": 153.0
                    },
                    "weighted avg": {
                        "precision": 0.3165784832451499,
                        "recall": 0.22875816993464052,
                        "f1-score": 0.2655663915978995,
                        "support": 153.0
                    }
                },
                "politics_and_conflicts_resign_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    }
                },
                "environment_4": {
                    "AFTER": {
                        "precision": 0.3333333333333333,
                        "recall": 0.5,
                        "f1-score": 0.4,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.6,
                        "recall": 0.5,
                        "f1-score": 0.5454545454545454,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.3333333333333333,
                    "macro avg": {
                        "precision": 0.23333333333333334,
                        "recall": 0.25,
                        "f1-score": 0.23636363636363636,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.32888888888888884,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3248484848484849,
                        "support": 15.0
                    }
                },
                "space_1_extra": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.0,
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    }
                },
                "health_3": {
                    "AFTER": {
                        "precision": 0.3333333333333333,
                        "recall": 0.125,
                        "f1-score": 0.18181818181818182,
                        "support": 8.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.2222222222222222,
                        "support": 6.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.13333333333333333,
                    "macro avg": {
                        "precision": 0.16666666666666666,
                        "recall": 0.07291666666666666,
                        "f1-score": 0.10101010101010101,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.31111111111111106,
                        "recall": 0.13333333333333333,
                        "f1-score": 0.18585858585858586,
                        "support": 15.0
                    }
                },
                "environment_3": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.2727272727272727,
                        "f1-score": 0.42857142857142855,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.16666666666666666,
                        "recall": 0.5,
                        "f1-score": 0.25,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.5,
                        "recall": 0.5,
                        "f1-score": 0.5,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.3333333333333333,
                    "macro avg": {
                        "precision": 0.4166666666666667,
                        "recall": 0.3181818181818182,
                        "f1-score": 0.29464285714285715,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.8222222222222223,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.4142857142857143,
                        "support": 15.0
                    }
                },
                "government_and_politics_protests_3": {
                    "AFTER": {
                        "precision": 0.3333333333333333,
                        "recall": 0.25,
                        "f1-score": 0.28571428571428575,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.16666666666666666,
                    "macro avg": {
                        "precision": 0.08333333333333333,
                        "recall": 0.0625,
                        "f1-score": 0.07142857142857144,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.2222222222222222,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.1904761904761905,
                        "support": 6.0
                    }
                },
                "economy_and_business_financial_crisis_4": {
                    "AFTER": {
                        "precision": 0.3333333333333333,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.2222222222222222,
                        "support": 12.0
                    },
                    "BEFORE": {
                        "precision": 0.16666666666666666,
                        "recall": 0.2,
                        "f1-score": 0.1818181818181818,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 1.0,
                        "recall": 0.5,
                        "f1-score": 0.6666666666666666,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.23809523809523808,
                    "macro avg": {
                        "precision": 0.375,
                        "recall": 0.21666666666666667,
                        "f1-score": 0.2676767676767676,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.4206349206349206,
                        "recall": 0.23809523809523808,
                        "f1-score": 0.2972582972582972,
                        "support": 21.0
                    }
                },
                "computers_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    }
                },
                "crime_and_law_accuse_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.0,
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 10.0
                    }
                },
                "culture_and_entertainment_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.5,
                        "f1-score": 0.5,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.5,
                        "recall": 0.5,
                        "f1-score": 0.5,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 6.0
                    },
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.25,
                        "f1-score": 0.25,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 6.0
                    }
                },
                "internet_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.3333333333333333,
                        "recall": 1.0,
                        "f1-score": 0.5,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.1,
                    "macro avg": {
                        "precision": 0.08333333333333333,
                        "recall": 0.25,
                        "f1-score": 0.125,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.03333333333333333,
                        "recall": 0.1,
                        "f1-score": 0.05,
                        "support": 10.0
                    }
                },
                "culture_and_entertainment_3": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.2,
                        "f1-score": 0.28571428571428575,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.25,
                        "recall": 0.25,
                        "f1-score": 0.25,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.4,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3636363636363636,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.26666666666666666,
                    "macro avg": {
                        "precision": 0.2875,
                        "recall": 0.19583333333333333,
                        "f1-score": 0.22483766233766234,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.39333333333333337,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.3073593073593074,
                        "support": 15.0
                    }
                }
            },
            "refer_events_cot": {
                "government_and_politics_riots_4": {
                    "AFTER": {
                        "precision": 0.125,
                        "recall": 0.25,
                        "f1-score": 0.16666666666666666,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 12.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 12.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.03571428571428571,
                    "macro avg": {
                        "precision": 0.03125,
                        "recall": 0.0625,
                        "f1-score": 0.041666666666666664,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.017857142857142856,
                        "recall": 0.03571428571428571,
                        "f1-score": 0.023809523809523808,
                        "support": 28.0
                    }
                },
                "rail_transport_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.08823529411764706,
                        "f1-score": 0.1621621621621622,
                        "support": 34.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.08333333333333333,
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.022058823529411766,
                        "f1-score": 0.04054054054054055,
                        "support": 36.0
                    },
                    "weighted avg": {
                        "precision": 0.9444444444444444,
                        "recall": 0.08333333333333333,
                        "f1-score": 0.1531531531531532,
                        "support": 36.0
                    }
                },
                "politics_and_conflicts_policy_change_2": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.4,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.16666666666666666,
                    "macro avg": {
                        "precision": 0.125,
                        "recall": 0.08333333333333333,
                        "f1-score": 0.1,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.25,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.20000000000000004,
                        "support": 6.0
                    }
                },
                "politics_and_conflicts_drones_1": {
                    "AFTER": {
                        "precision": 0.14285714285714285,
                        "recall": 0.09090909090909091,
                        "f1-score": 0.1111111111111111,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.125,
                        "f1-score": 0.2,
                        "support": 8.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.09523809523809523,
                    "macro avg": {
                        "precision": 0.1607142857142857,
                        "recall": 0.05397727272727273,
                        "f1-score": 0.07777777777777778,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.26530612244897955,
                        "recall": 0.09523809523809523,
                        "f1-score": 0.13439153439153437,
                        "support": 21.0
                    }
                },
                "disasters_and_accidents_road_crash_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 10.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.0,
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 21.0
                    }
                },
                "crime_and_law_accuse_3": {
                    "AFTER": {
                        "precision": 0.4,
                        "recall": 0.5,
                        "f1-score": 0.4444444444444445,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2,
                    "macro avg": {
                        "precision": 0.1,
                        "recall": 0.125,
                        "f1-score": 0.11111111111111112,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.16,
                        "recall": 0.2,
                        "f1-score": 0.17777777777777778,
                        "support": 10.0
                    }
                },
                "government_and_politics_protests_2": {
                    "AFTER": {
                        "precision": 0.16666666666666666,
                        "recall": 0.2,
                        "f1-score": 0.1818181818181818,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.05,
                        "f1-score": 0.09090909090909091,
                        "support": 20.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.07142857142857142,
                    "macro avg": {
                        "precision": 0.16666666666666666,
                        "recall": 0.0625,
                        "f1-score": 0.06818181818181818,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.3869047619047619,
                        "recall": 0.07142857142857142,
                        "f1-score": 0.09740259740259741,
                        "support": 28.0
                    }
                },
                "politics_and_conflicts_elections_2": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.2727272727272727,
                        "f1-score": 0.3529411764705882,
                        "support": 22.0
                    },
                    "BEFORE": {
                        "precision": 0.125,
                        "recall": 0.07142857142857142,
                        "f1-score": 0.09090909090909091,
                        "support": 14.0
                    },
                    "COEX": {
                        "precision": 0.14285714285714285,
                        "recall": 0.1111111111111111,
                        "f1-score": 0.125,
                        "support": 9.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.17777777777777778,
                    "macro avg": {
                        "precision": 0.1919642857142857,
                        "recall": 0.1138167388167388,
                        "f1-score": 0.14221256684491979,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.3119047619047619,
                        "recall": 0.17777777777777778,
                        "f1-score": 0.2258318478906714,
                        "support": 45.0
                    }
                },
                "environment_2": {
                    "AFTER": {
                        "precision": 0.6363636363636364,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.43749999999999994,
                        "support": 21.0
                    },
                    "BEFORE": {
                        "precision": 0.6666666666666666,
                        "recall": 0.08695652173913043,
                        "f1-score": 0.15384615384615383,
                        "support": 23.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2,
                    "macro avg": {
                        "precision": 0.32575757575757575,
                        "recall": 0.10507246376811594,
                        "f1-score": 0.14783653846153844,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.6377104377104377,
                        "recall": 0.2,
                        "f1-score": 0.28279914529914524,
                        "support": 45.0
                    }
                },
                "weather_floods_3": {
                    "AFTER": {
                        "precision": 0.25,
                        "recall": 0.5,
                        "f1-score": 0.3333333333333333,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 7.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.13333333333333333,
                    "macro avg": {
                        "precision": 0.0625,
                        "recall": 0.125,
                        "f1-score": 0.08333333333333333,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.06666666666666667,
                        "recall": 0.13333333333333333,
                        "f1-score": 0.08888888888888888,
                        "support": 15.0
                    }
                },
                "sports_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    }
                },
                "health_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 9.0
                    },
                    "BEFORE": {
                        "precision": 0.2,
                        "recall": 0.125,
                        "f1-score": 0.15384615384615385,
                        "support": 8.0
                    },
                    "COEX": {
                        "precision": 0.25,
                        "recall": 0.25,
                        "f1-score": 0.25,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.09523809523809523,
                    "macro avg": {
                        "precision": 0.1125,
                        "recall": 0.09375,
                        "f1-score": 0.10096153846153846,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.12380952380952381,
                        "recall": 0.09523809523809523,
                        "f1-score": 0.10622710622710622,
                        "support": 21.0
                    }
                },
                "weather_earthquakes_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "BEFORE": {
                        "precision": 0.25,
                        "recall": 0.03125,
                        "f1-score": 0.05555555555555555,
                        "support": 32.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 7.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.022222222222222223,
                    "macro avg": {
                        "precision": 0.0625,
                        "recall": 0.0078125,
                        "f1-score": 0.013888888888888888,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.17777777777777778,
                        "recall": 0.022222222222222223,
                        "f1-score": 0.03950617283950617,
                        "support": 45.0
                    }
                },
                "space_4": {
                    "AFTER": {
                        "precision": 0.14285714285714285,
                        "recall": 0.09090909090909091,
                        "f1-score": 0.1111111111111111,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 15.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.03571428571428571,
                    "macro avg": {
                        "precision": 0.03571428571428571,
                        "recall": 0.022727272727272728,
                        "f1-score": 0.027777777777777776,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.05612244897959184,
                        "recall": 0.03571428571428571,
                        "f1-score": 0.04365079365079365,
                        "support": 28.0
                    }
                },
                "economy_and_business_strikes_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.25,
                        "f1-score": 0.3333333333333333,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.16666666666666666,
                    "macro avg": {
                        "precision": 0.125,
                        "recall": 0.0625,
                        "f1-score": 0.08333333333333333,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.2222222222222222,
                        "support": 6.0
                    }
                },
                "politics_and_conflicts_armed_conflict_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 3.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.06666666666666667,
                    "macro avg": {
                        "precision": 0.08333333333333333,
                        "recall": 0.08333333333333333,
                        "f1-score": 0.08333333333333333,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.06666666666666667,
                        "recall": 0.06666666666666667,
                        "f1-score": 0.06666666666666667,
                        "support": 15.0
                    }
                },
                "infectious_disease_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    }
                },
                "health_1": {
                    "AFTER": {
                        "precision": 0.4,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3636363636363636,
                        "support": 6.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "COEX": {
                        "precision": 0.5,
                        "recall": 1.0,
                        "f1-score": 0.6666666666666666,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.3,
                    "macro avg": {
                        "precision": 0.225,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.25757575757575757,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.29000000000000004,
                        "recall": 0.3,
                        "f1-score": 0.2848484848484848,
                        "support": 10.0
                    }
                },
                "disasters_and_accidents_shipwreck_2": {
                    "AFTER": {
                        "precision": 0.14285714285714285,
                        "recall": 0.09090909090909091,
                        "f1-score": 0.1111111111111111,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 9.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.047619047619047616,
                    "macro avg": {
                        "precision": 0.03571428571428571,
                        "recall": 0.022727272727272728,
                        "f1-score": 0.027777777777777776,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.07482993197278912,
                        "recall": 0.047619047619047616,
                        "f1-score": 0.0582010582010582,
                        "support": 21.0
                    }
                },
                "rail_transport_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.1,
                        "f1-score": 0.16666666666666669,
                        "support": 10.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.06666666666666667,
                    "macro avg": {
                        "precision": 0.125,
                        "recall": 0.025,
                        "f1-score": 0.04166666666666667,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.06666666666666667,
                        "f1-score": 0.11111111111111113,
                        "support": 15.0
                    }
                },
                "weather_storms_1_extra": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    }
                },
                "health_1_extra": {
                    "AFTER": {
                        "precision": 0.14285714285714285,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.15384615384615383,
                        "support": 12.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 28.0
                    },
                    "COEX": {
                        "precision": 0.125,
                        "recall": 0.06666666666666667,
                        "f1-score": 0.08695652173913045,
                        "support": 15.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.05454545454545454,
                    "macro avg": {
                        "precision": 0.06696428571428571,
                        "recall": 0.058333333333333334,
                        "f1-score": 0.06020066889632107,
                        "support": 55.0
                    },
                    "weighted avg": {
                        "precision": 0.06525974025974027,
                        "recall": 0.05454545454545454,
                        "f1-score": 0.057281848586196414,
                        "support": 55.0
                    }
                },
                "weather_floods_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 24.0
                    },
                    "COEX": {
                        "precision": 0.3333333333333333,
                        "recall": 0.07142857142857142,
                        "f1-score": 0.11764705882352941,
                        "support": 28.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.03636363636363636,
                    "macro avg": {
                        "precision": 0.08333333333333333,
                        "recall": 0.017857142857142856,
                        "f1-score": 0.029411764705882353,
                        "support": 55.0
                    },
                    "weighted avg": {
                        "precision": 0.16969696969696968,
                        "recall": 0.03636363636363636,
                        "f1-score": 0.059893048128342244,
                        "support": 55.0
                    }
                },
                "mining_4": {
                    "AFTER": {
                        "precision": 0.4166666666666667,
                        "recall": 0.45454545454545453,
                        "f1-score": 0.43478260869565216,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.04,
                        "f1-score": 0.07692307692307693,
                        "support": 25.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 9.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.13333333333333333,
                    "macro avg": {
                        "precision": 0.3541666666666667,
                        "recall": 0.12363636363636363,
                        "f1-score": 0.12792642140468227,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.6574074074074074,
                        "recall": 0.13333333333333333,
                        "f1-score": 0.14901523597175773,
                        "support": 45.0
                    }
                },
                "disasters_and_accidents_volcanoes_4": {
                    "AFTER": {
                        "precision": 0.25,
                        "recall": 0.1,
                        "f1-score": 0.14285714285714288,
                        "support": 20.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 14.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.05555555555555555,
                    "macro avg": {
                        "precision": 0.0625,
                        "recall": 0.025,
                        "f1-score": 0.03571428571428572,
                        "support": 36.0
                    },
                    "weighted avg": {
                        "precision": 0.1388888888888889,
                        "recall": 0.05555555555555555,
                        "f1-score": 0.07936507936507937,
                        "support": 36.0
                    }
                },
                "politics_and_conflicts_elections_3": {
                    "AFTER": {
                        "precision": 0.2,
                        "recall": 0.2,
                        "f1-score": 0.20000000000000004,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.6666666666666666,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.4444444444444444,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2,
                    "macro avg": {
                        "precision": 0.21666666666666667,
                        "recall": 0.13333333333333333,
                        "f1-score": 0.16111111111111112,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.2,
                        "f1-score": 0.24444444444444446,
                        "support": 15.0
                    }
                },
                "economy_and_business_strikes_3": {
                    "AFTER": {
                        "precision": 0.2,
                        "recall": 0.2,
                        "f1-score": 0.20000000000000004,
                        "support": 10.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.4,
                        "recall": 0.2857142857142857,
                        "f1-score": 0.3333333333333333,
                        "support": 7.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.14285714285714285,
                    "macro avg": {
                        "precision": 0.15000000000000002,
                        "recall": 0.12142857142857143,
                        "f1-score": 0.13333333333333333,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.17142857142857146,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.1547619047619048,
                        "support": 28.0
                    }
                },
                "space_2": {
                    "AFTER": {
                        "precision": 0.18518518518518517,
                        "recall": 0.05,
                        "f1-score": 0.07874015748031496,
                        "support": 100.0
                    },
                    "BEFORE": {
                        "precision": 0.25,
                        "recall": 0.0392156862745098,
                        "f1-score": 0.06779661016949153,
                        "support": 51.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.0457516339869281,
                    "macro avg": {
                        "precision": 0.1087962962962963,
                        "recall": 0.02230392156862745,
                        "f1-score": 0.036634191912451625,
                        "support": 153.0
                    },
                    "weighted avg": {
                        "precision": 0.2043694020818204,
                        "recall": 0.0457516339869281,
                        "f1-score": 0.07406302527238931,
                        "support": 153.0
                    }
                },
                "politics_and_conflicts_resign_1": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.5,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 3.0
                    },
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.08333333333333333,
                        "f1-score": 0.125,
                        "support": 3.0
                    },
                    "weighted avg": {
                        "precision": 1.0,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.5,
                        "support": 3.0
                    }
                },
                "environment_4": {
                    "AFTER": {
                        "precision": 0.4,
                        "recall": 0.5,
                        "f1-score": 0.4444444444444445,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.5,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.4,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.26666666666666666,
                    "macro avg": {
                        "precision": 0.225,
                        "recall": 0.20833333333333331,
                        "f1-score": 0.21111111111111114,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.30666666666666664,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.27851851851851855,
                        "support": 15.0
                    }
                },
                "space_1_extra": {
                    "AFTER": {
                        "precision": 0.3333333333333333,
                        "recall": 1.0,
                        "f1-score": 0.5,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.16666666666666666,
                    "macro avg": {
                        "precision": 0.08333333333333333,
                        "recall": 0.25,
                        "f1-score": 0.125,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.05555555555555555,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.08333333333333333,
                        "support": 6.0
                    }
                },
                "health_3": {
                    "AFTER": {
                        "precision": 0.25,
                        "recall": 0.125,
                        "f1-score": 0.16666666666666666,
                        "support": 8.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.06666666666666667,
                    "macro avg": {
                        "precision": 0.0625,
                        "recall": 0.03125,
                        "f1-score": 0.041666666666666664,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.13333333333333333,
                        "recall": 0.06666666666666667,
                        "f1-score": 0.08888888888888888,
                        "support": 15.0
                    }
                },
                "environment_3": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.09090909090909091,
                        "f1-score": 0.16666666666666669,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.2,
                        "recall": 0.5,
                        "f1-score": 0.28571428571428575,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.5,
                        "recall": 0.5,
                        "f1-score": 0.5,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2,
                    "macro avg": {
                        "precision": 0.425,
                        "recall": 0.2727272727272727,
                        "f1-score": 0.2380952380952381,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.8266666666666667,
                        "recall": 0.2,
                        "f1-score": 0.226984126984127,
                        "support": 15.0
                    }
                },
                "government_and_politics_protests_3": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.25,
                        "f1-score": 0.4,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "COEX": {
                        "precision": 0.3333333333333333,
                        "recall": 1.0,
                        "f1-score": 0.5,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.3333333333333333,
                    "macro avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3125,
                        "f1-score": 0.225,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.7222222222222222,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.35000000000000003,
                        "support": 6.0
                    }
                },
                "economy_and_business_financial_crisis_4": {
                    "AFTER": {
                        "precision": 0.3333333333333333,
                        "recall": 0.25,
                        "f1-score": 0.28571428571428575,
                        "support": 12.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.14285714285714285,
                    "macro avg": {
                        "precision": 0.08333333333333333,
                        "recall": 0.0625,
                        "f1-score": 0.07142857142857144,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.19047619047619047,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.163265306122449,
                        "support": 21.0
                    }
                },
                "computers_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    }
                },
                "crime_and_law_accuse_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 0.2,
                        "f1-score": 0.25,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.1,
                    "macro avg": {
                        "precision": 0.08333333333333333,
                        "recall": 0.05,
                        "f1-score": 0.0625,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.16666666666666666,
                        "recall": 0.1,
                        "f1-score": 0.125,
                        "support": 10.0
                    }
                },
                "culture_and_entertainment_1": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.5,
                        "f1-score": 0.5,
                        "support": 2.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.5,
                        "recall": 0.5,
                        "f1-score": 0.5,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 6.0
                    },
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.25,
                        "f1-score": 0.25,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 6.0
                    }
                },
                "internet_2": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.2,
                        "f1-score": 0.28571428571428575,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.3333333333333333,
                        "recall": 1.0,
                        "f1-score": 0.5,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2,
                    "macro avg": {
                        "precision": 0.20833333333333331,
                        "recall": 0.3,
                        "f1-score": 0.19642857142857145,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.2833333333333333,
                        "recall": 0.2,
                        "f1-score": 0.1928571428571429,
                        "support": 10.0
                    }
                },
                "culture_and_entertainment_3": {
                    "AFTER": {
                        "precision": 0.3333333333333333,
                        "recall": 0.2,
                        "f1-score": 0.25,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.2,
                        "recall": 0.25,
                        "f1-score": 0.22222222222222224,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.5,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.4,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.26666666666666666,
                    "macro avg": {
                        "precision": 0.2583333333333333,
                        "recall": 0.19583333333333333,
                        "f1-score": 0.21805555555555556,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.36444444444444446,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.30259259259259264,
                        "support": 15.0
                    }
                }
            },
            "careful_cot": {
                "government_and_politics_riots_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 0.08333333333333333,
                        "f1-score": 0.13333333333333333,
                        "support": 12.0
                    },
                    "COEX": {
                        "precision": 0.16666666666666666,
                        "recall": 0.08333333333333333,
                        "f1-score": 0.1111111111111111,
                        "support": 12.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.07142857142857142,
                    "macro avg": {
                        "precision": 0.125,
                        "recall": 0.041666666666666664,
                        "f1-score": 0.06111111111111111,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.21428571428571427,
                        "recall": 0.07142857142857142,
                        "f1-score": 0.10476190476190476,
                        "support": 28.0
                    }
                },
                "rail_transport_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.08823529411764706,
                        "f1-score": 0.1621621621621622,
                        "support": 34.0
                    },
                    "COEX": {
                        "precision": 0.1111111111111111,
                        "recall": 0.5,
                        "f1-score": 0.1818181818181818,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.1111111111111111,
                    "macro avg": {
                        "precision": 0.2777777777777778,
                        "recall": 0.14705882352941177,
                        "f1-score": 0.085995085995086,
                        "support": 36.0
                    },
                    "weighted avg": {
                        "precision": 0.9506172839506173,
                        "recall": 0.1111111111111111,
                        "f1-score": 0.16325416325416328,
                        "support": 36.0
                    }
                },
                "politics_and_conflicts_policy_change_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.5,
                        "f1-score": 0.5,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.3333333333333333,
                        "recall": 1.0,
                        "f1-score": 0.5,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 6.0
                    },
                    "macro avg": {
                        "precision": 0.20833333333333331,
                        "recall": 0.375,
                        "f1-score": 0.25,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.2222222222222222,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.25,
                        "support": 6.0
                    }
                },
                "politics_and_conflicts_drones_1": {
                    "AFTER": {
                        "precision": 0.3333333333333333,
                        "recall": 0.18181818181818182,
                        "f1-score": 0.23529411764705885,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 8.0
                    },
                    "COEX": {
                        "precision": 0.25,
                        "recall": 0.5,
                        "f1-score": 0.3333333333333333,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.14285714285714285,
                    "macro avg": {
                        "precision": 0.14583333333333331,
                        "recall": 0.17045454545454547,
                        "f1-score": 0.14215686274509803,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.19841269841269837,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.1549953314659197,
                        "support": 21.0
                    }
                },
                "disasters_and_accidents_road_crash_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "BEFORE": {
                        "precision": 0.6666666666666666,
                        "recall": 0.18181818181818182,
                        "f1-score": 0.28571428571428575,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 10.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.09523809523809523,
                    "macro avg": {
                        "precision": 0.16666666666666666,
                        "recall": 0.045454545454545456,
                        "f1-score": 0.07142857142857144,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.3492063492063492,
                        "recall": 0.09523809523809523,
                        "f1-score": 0.14965986394557826,
                        "support": 21.0
                    }
                },
                "crime_and_law_accuse_3": {
                    "AFTER": {
                        "precision": 0.4,
                        "recall": 0.5,
                        "f1-score": 0.4444444444444445,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.2222222222222222,
                        "support": 6.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.3,
                    "macro avg": {
                        "precision": 0.18333333333333335,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.16666666666666669,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.36,
                        "recall": 0.3,
                        "f1-score": 0.3111111111111111,
                        "support": 10.0
                    }
                },
                "government_and_politics_protests_2": {
                    "AFTER": {
                        "precision": 0.1111111111111111,
                        "recall": 0.2,
                        "f1-score": 0.14285714285714285,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.1,
                        "f1-score": 0.16666666666666669,
                        "support": 20.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.10714285714285714,
                    "macro avg": {
                        "precision": 0.1527777777777778,
                        "recall": 0.07500000000000001,
                        "f1-score": 0.07738095238095238,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.376984126984127,
                        "recall": 0.10714285714285714,
                        "f1-score": 0.14455782312925172,
                        "support": 28.0
                    }
                },
                "politics_and_conflicts_elections_2": {
                    "AFTER": {
                        "precision": 0.42857142857142855,
                        "recall": 0.13636363636363635,
                        "f1-score": 0.20689655172413793,
                        "support": 22.0
                    },
                    "BEFORE": {
                        "precision": 0.25,
                        "recall": 0.21428571428571427,
                        "f1-score": 0.23076923076923075,
                        "support": 14.0
                    },
                    "COEX": {
                        "precision": 0.09090909090909091,
                        "recall": 0.1111111111111111,
                        "f1-score": 0.09999999999999999,
                        "support": 9.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.15555555555555556,
                    "macro avg": {
                        "precision": 0.19237012987012989,
                        "recall": 0.11544011544011544,
                        "f1-score": 0.13441644562334218,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.30548340548340547,
                        "recall": 0.15555555555555556,
                        "f1-score": 0.19294429708222813,
                        "support": 45.0
                    }
                },
                "environment_2": {
                    "AFTER": {
                        "precision": 0.6666666666666666,
                        "recall": 0.38095238095238093,
                        "f1-score": 0.4848484848484849,
                        "support": 21.0
                    },
                    "BEFORE": {
                        "precision": 0.6666666666666666,
                        "recall": 0.2608695652173913,
                        "f1-score": 0.37500000000000006,
                        "support": 23.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.3111111111111111,
                    "macro avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.16045548654244307,
                        "f1-score": 0.21496212121212124,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.6518518518518518,
                        "recall": 0.3111111111111111,
                        "f1-score": 0.41792929292929304,
                        "support": 45.0
                    }
                },
                "weather_floods_3": {
                    "AFTER": {
                        "precision": 0.2,
                        "recall": 0.25,
                        "f1-score": 0.22222222222222224,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 7.0
                    },
                    "COEX": {
                        "precision": 0.2,
                        "recall": 0.25,
                        "f1-score": 0.22222222222222224,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.13333333333333333,
                    "macro avg": {
                        "precision": 0.1,
                        "recall": 0.125,
                        "f1-score": 0.11111111111111112,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.10666666666666667,
                        "recall": 0.13333333333333333,
                        "f1-score": 0.11851851851851852,
                        "support": 15.0
                    }
                },
                "sports_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    }
                },
                "health_4": {
                    "AFTER": {
                        "precision": 0.25,
                        "recall": 0.1111111111111111,
                        "f1-score": 0.15384615384615383,
                        "support": 9.0
                    },
                    "BEFORE": {
                        "precision": 0.14285714285714285,
                        "recall": 0.125,
                        "f1-score": 0.13333333333333333,
                        "support": 8.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.09523809523809523,
                    "macro avg": {
                        "precision": 0.09821428571428571,
                        "recall": 0.059027777777777776,
                        "f1-score": 0.07179487179487179,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.16156462585034012,
                        "recall": 0.09523809523809523,
                        "f1-score": 0.11672771672771672,
                        "support": 21.0
                    }
                },
                "weather_earthquakes_1": {
                    "AFTER": {
                        "precision": 0.08333333333333333,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.1111111111111111,
                        "support": 6.0
                    },
                    "BEFORE": {
                        "precision": 0.42857142857142855,
                        "recall": 0.09375,
                        "f1-score": 0.15384615384615383,
                        "support": 32.0
                    },
                    "COEX": {
                        "precision": 0.21739130434782608,
                        "recall": 0.7142857142857143,
                        "f1-score": 0.3333333333333333,
                        "support": 7.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2,
                    "macro avg": {
                        "precision": 0.18232401656314698,
                        "recall": 0.24367559523809523,
                        "f1-score": 0.14957264957264954,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.3496894409937888,
                        "recall": 0.2,
                        "f1-score": 0.17606837606837605,
                        "support": 45.0
                    }
                },
                "space_4": {
                    "AFTER": {
                        "precision": 0.18181818181818182,
                        "recall": 0.18181818181818182,
                        "f1-score": 0.18181818181818182,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 15.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.07142857142857142,
                    "macro avg": {
                        "precision": 0.045454545454545456,
                        "recall": 0.045454545454545456,
                        "f1-score": 0.045454545454545456,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.07142857142857142,
                        "recall": 0.07142857142857142,
                        "f1-score": 0.07142857142857142,
                        "support": 28.0
                    }
                },
                "economy_and_business_strikes_2": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 1.0,
                        "f1-score": 0.6666666666666666,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.16666666666666666,
                    "macro avg": {
                        "precision": 0.125,
                        "recall": 0.25,
                        "f1-score": 0.16666666666666666,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.08333333333333333,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.1111111111111111,
                        "support": 6.0
                    }
                },
                "politics_and_conflicts_armed_conflict_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.18181818181818182,
                        "f1-score": 0.3076923076923077,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.6666666666666666,
                        "recall": 0.6666666666666666,
                        "f1-score": 0.6666666666666666,
                        "support": 3.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.26666666666666666,
                    "macro avg": {
                        "precision": 0.41666666666666663,
                        "recall": 0.2121212121212121,
                        "f1-score": 0.24358974358974358,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.8666666666666667,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.358974358974359,
                        "support": 15.0
                    }
                },
                "infectious_disease_4": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.25,
                        "f1-score": 0.25,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    }
                },
                "health_1": {
                    "AFTER": {
                        "precision": 0.6666666666666666,
                        "recall": 0.6666666666666666,
                        "f1-score": 0.6666666666666666,
                        "support": 6.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.4,
                    "macro avg": {
                        "precision": 0.16666666666666666,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.16666666666666666,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.4,
                        "recall": 0.4,
                        "f1-score": 0.4,
                        "support": 10.0
                    }
                },
                "disasters_and_accidents_shipwreck_2": {
                    "AFTER": {
                        "precision": 0.4444444444444444,
                        "recall": 0.36363636363636365,
                        "f1-score": 0.39999999999999997,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.25,
                        "recall": 0.1111111111111111,
                        "f1-score": 0.15384615384615383,
                        "support": 9.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.23809523809523808,
                    "macro avg": {
                        "precision": 0.1736111111111111,
                        "recall": 0.11868686868686869,
                        "f1-score": 0.13846153846153844,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.33994708994708994,
                        "recall": 0.23809523809523808,
                        "f1-score": 0.2754578754578754,
                        "support": 21.0
                    }
                },
                "rail_transport_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 10.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.0,
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 15.0
                    }
                },
                "weather_storms_1_extra": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    }
                },
                "health_1_extra": {
                    "AFTER": {
                        "precision": 0.23809523809523808,
                        "recall": 0.4166666666666667,
                        "f1-score": 0.30303030303030304,
                        "support": 12.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.07142857142857142,
                        "f1-score": 0.125,
                        "support": 28.0
                    },
                    "COEX": {
                        "precision": 0.16666666666666666,
                        "recall": 0.06666666666666667,
                        "f1-score": 0.09523809523809522,
                        "support": 15.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.14545454545454545,
                    "macro avg": {
                        "precision": 0.2261904761904762,
                        "recall": 0.1386904761904762,
                        "f1-score": 0.13081709956709955,
                        "support": 55.0
                    },
                    "weighted avg": {
                        "precision": 0.35194805194805195,
                        "recall": 0.14545454545454545,
                        "f1-score": 0.15572609208972846,
                        "support": 55.0
                    }
                },
                "weather_floods_1": {
                    "AFTER": {
                        "precision": 0.058823529411764705,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.1,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.4,
                        "recall": 0.25,
                        "f1-score": 0.3076923076923077,
                        "support": 24.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 28.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.12727272727272726,
                    "macro avg": {
                        "precision": 0.11470588235294119,
                        "recall": 0.14583333333333331,
                        "f1-score": 0.10192307692307692,
                        "support": 55.0
                    },
                    "weighted avg": {
                        "precision": 0.17775401069518718,
                        "recall": 0.12727272727272726,
                        "f1-score": 0.13972027972027973,
                        "support": 55.0
                    }
                },
                "mining_4": {
                    "AFTER": {
                        "precision": 0.6,
                        "recall": 0.5454545454545454,
                        "f1-score": 0.5714285714285713,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.5714285714285714,
                        "recall": 0.16,
                        "f1-score": 0.25,
                        "support": 25.0
                    },
                    "COEX": {
                        "precision": 0.21428571428571427,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.2608695652173913,
                        "support": 9.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.28888888888888886,
                    "macro avg": {
                        "precision": 0.34642857142857136,
                        "recall": 0.2596969696969697,
                        "f1-score": 0.27057453416149063,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.506984126984127,
                        "recall": 0.28888888888888886,
                        "f1-score": 0.3307453416149068,
                        "support": 45.0
                    }
                },
                "disasters_and_accidents_volcanoes_4": {
                    "AFTER": {
                        "precision": 0.1111111111111111,
                        "recall": 0.05,
                        "f1-score": 0.06896551724137932,
                        "support": 20.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 14.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.027777777777777776,
                    "macro avg": {
                        "precision": 0.027777777777777776,
                        "recall": 0.0125,
                        "f1-score": 0.01724137931034483,
                        "support": 36.0
                    },
                    "weighted avg": {
                        "precision": 0.0617283950617284,
                        "recall": 0.027777777777777776,
                        "f1-score": 0.03831417624521074,
                        "support": 36.0
                    }
                },
                "politics_and_conflicts_elections_3": {
                    "AFTER": {
                        "precision": 0.2,
                        "recall": 0.2,
                        "f1-score": 0.20000000000000004,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.5,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.4,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2,
                    "macro avg": {
                        "precision": 0.175,
                        "recall": 0.13333333333333333,
                        "f1-score": 0.15000000000000002,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.26666666666666666,
                        "recall": 0.2,
                        "f1-score": 0.22666666666666668,
                        "support": 15.0
                    }
                },
                "economy_and_business_strikes_3": {
                    "AFTER": {
                        "precision": 0.2857142857142857,
                        "recall": 0.2,
                        "f1-score": 0.23529411764705882,
                        "support": 10.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.18181818181818182,
                        "f1-score": 0.26666666666666666,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 7.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.14285714285714285,
                    "macro avg": {
                        "precision": 0.19642857142857142,
                        "recall": 0.09545454545454546,
                        "f1-score": 0.12549019607843137,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.29846938775510207,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.1887955182072829,
                        "support": 28.0
                    }
                },
                "space_2": {
                    "AFTER": {
                        "precision": 0.39344262295081966,
                        "recall": 0.24,
                        "f1-score": 0.2981366459627329,
                        "support": 100.0
                    },
                    "BEFORE": {
                        "precision": 0.06,
                        "recall": 0.058823529411764705,
                        "f1-score": 0.0594059405940594,
                        "support": 51.0
                    },
                    "COEX": {
                        "precision": 0.047619047619047616,
                        "recall": 0.5,
                        "f1-score": 0.08695652173913042,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.1830065359477124,
                    "macro avg": {
                        "precision": 0.12526541764246682,
                        "recall": 0.19970588235294118,
                        "f1-score": 0.11112477707398069,
                        "support": 153.0
                    },
                    "weighted avg": {
                        "precision": 0.2777745123550331,
                        "recall": 0.1830065359477124,
                        "f1-score": 0.21579921967352014,
                        "support": 153.0
                    }
                },
                "politics_and_conflicts_resign_1": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.5,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 3.0
                    },
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.08333333333333333,
                        "f1-score": 0.125,
                        "support": 3.0
                    },
                    "weighted avg": {
                        "precision": 1.0,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.5,
                        "support": 3.0
                    }
                },
                "environment_4": {
                    "AFTER": {
                        "precision": 0.4,
                        "recall": 0.5,
                        "f1-score": 0.4444444444444445,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.25,
                        "recall": 0.2,
                        "f1-score": 0.22222222222222224,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2,
                    "macro avg": {
                        "precision": 0.1625,
                        "recall": 0.175,
                        "f1-score": 0.16666666666666669,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.19,
                        "recall": 0.2,
                        "f1-score": 0.19259259259259262,
                        "support": 15.0
                    }
                },
                "space_1_extra": {
                    "AFTER": {
                        "precision": 0.25,
                        "recall": 1.0,
                        "f1-score": 0.4,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.16666666666666666,
                    "macro avg": {
                        "precision": 0.0625,
                        "recall": 0.25,
                        "f1-score": 0.1,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.041666666666666664,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.06666666666666667,
                        "support": 6.0
                    }
                },
                "health_3": {
                    "AFTER": {
                        "precision": 0.2,
                        "recall": 0.125,
                        "f1-score": 0.15384615384615385,
                        "support": 8.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.06666666666666667,
                    "macro avg": {
                        "precision": 0.05,
                        "recall": 0.03125,
                        "f1-score": 0.038461538461538464,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.10666666666666667,
                        "recall": 0.06666666666666667,
                        "f1-score": 0.08205128205128205,
                        "support": 15.0
                    }
                },
                "environment_3": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.18181818181818182,
                        "f1-score": 0.3076923076923077,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.2222222222222222,
                        "recall": 1.0,
                        "f1-score": 0.3636363636363636,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.5,
                        "recall": 0.5,
                        "f1-score": 0.5,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.3333333333333333,
                    "macro avg": {
                        "precision": 0.4305555555555556,
                        "recall": 0.42045454545454547,
                        "f1-score": 0.2928321678321678,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.8296296296296296,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.34079254079254084,
                        "support": 15.0
                    }
                },
                "government_and_politics_protests_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 1.0,
                        "f1-score": 0.6666666666666666,
                        "support": 1.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.16666666666666666,
                    "macro avg": {
                        "precision": 0.125,
                        "recall": 0.25,
                        "f1-score": 0.16666666666666666,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.08333333333333333,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.1111111111111111,
                        "support": 6.0
                    }
                },
                "economy_and_business_financial_crisis_4": {
                    "AFTER": {
                        "precision": 0.5714285714285714,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.4210526315789474,
                        "support": 12.0
                    },
                    "BEFORE": {
                        "precision": 0.25,
                        "recall": 0.2,
                        "f1-score": 0.22222222222222224,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.5,
                        "recall": 0.5,
                        "f1-score": 0.5,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.3333333333333333,
                    "macro avg": {
                        "precision": 0.33035714285714285,
                        "recall": 0.2583333333333333,
                        "f1-score": 0.2858187134502924,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.48129251700680276,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3887496519075467,
                        "support": 21.0
                    }
                },
                "computers_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    }
                },
                "crime_and_law_accuse_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.2,
                        "f1-score": 0.33333333333333337,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.1,
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.05,
                        "f1-score": 0.08333333333333334,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.5,
                        "recall": 0.1,
                        "f1-score": 0.16666666666666669,
                        "support": 10.0
                    }
                },
                "culture_and_entertainment_1": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.5,
                        "f1-score": 0.5,
                        "support": 2.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.5,
                        "f1-score": 0.5,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.5,
                        "recall": 0.5,
                        "f1-score": 0.5,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.5,
                        "recall": 0.5,
                        "f1-score": 0.5,
                        "support": 6.0
                    },
                    "macro avg": {
                        "precision": 0.375,
                        "recall": 0.375,
                        "f1-score": 0.375,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.5,
                        "recall": 0.5,
                        "f1-score": 0.5,
                        "support": 6.0
                    }
                },
                "internet_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 0.25,
                        "f1-score": 0.28571428571428575,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.1,
                    "macro avg": {
                        "precision": 0.08333333333333333,
                        "recall": 0.0625,
                        "f1-score": 0.07142857142857144,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.13333333333333333,
                        "recall": 0.1,
                        "f1-score": 0.1142857142857143,
                        "support": 10.0
                    }
                },
                "culture_and_entertainment_3": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.4,
                        "f1-score": 0.4444444444444445,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.5454545454545454,
                        "recall": 1.0,
                        "f1-score": 0.7058823529411764,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.5333333333333333,
                        "recall": 0.5333333333333333,
                        "f1-score": 0.5333333333333333,
                        "support": 15.0
                    },
                    "macro avg": {
                        "precision": 0.26136363636363635,
                        "recall": 0.35,
                        "f1-score": 0.2875816993464052,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.38484848484848483,
                        "recall": 0.5333333333333333,
                        "f1-score": 0.43050108932461867,
                        "support": 15.0
                    }
                }
            },
            "simple_cot": {
                "government_and_politics_riots_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.08333333333333333,
                        "f1-score": 0.14285714285714285,
                        "support": 12.0
                    },
                    "COEX": {
                        "precision": 0.3333333333333333,
                        "recall": 0.08333333333333333,
                        "f1-score": 0.13333333333333333,
                        "support": 12.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.07142857142857142,
                    "macro avg": {
                        "precision": 0.20833333333333331,
                        "recall": 0.041666666666666664,
                        "f1-score": 0.06904761904761905,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.35714285714285715,
                        "recall": 0.07142857142857142,
                        "f1-score": 0.1183673469387755,
                        "support": 28.0
                    }
                },
                "rail_transport_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "BEFORE": {
                        "precision": 0.75,
                        "recall": 0.08823529411764706,
                        "f1-score": 0.15789473684210525,
                        "support": 34.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.08333333333333333,
                    "macro avg": {
                        "precision": 0.1875,
                        "recall": 0.022058823529411766,
                        "f1-score": 0.039473684210526314,
                        "support": 36.0
                    },
                    "weighted avg": {
                        "precision": 0.7083333333333334,
                        "recall": 0.08333333333333333,
                        "f1-score": 0.14912280701754385,
                        "support": 36.0
                    }
                },
                "politics_and_conflicts_policy_change_2": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.4,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.16666666666666666,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.16666666666666666,
                        "support": 6.0
                    },
                    "macro avg": {
                        "precision": 0.125,
                        "recall": 0.08333333333333333,
                        "f1-score": 0.1,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.25,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.20000000000000004,
                        "support": 6.0
                    }
                },
                "politics_and_conflicts_drones_1": {
                    "AFTER": {
                        "precision": 0.2,
                        "recall": 0.09090909090909091,
                        "f1-score": 0.12500000000000003,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.125,
                        "f1-score": 0.2,
                        "support": 8.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.09523809523809523,
                    "macro avg": {
                        "precision": 0.175,
                        "recall": 0.05397727272727273,
                        "f1-score": 0.08125000000000002,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.29523809523809524,
                        "recall": 0.09523809523809523,
                        "f1-score": 0.1416666666666667,
                        "support": 21.0
                    }
                },
                "disasters_and_accidents_road_crash_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.18181818181818182,
                        "f1-score": 0.26666666666666666,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 10.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.09523809523809523,
                    "macro avg": {
                        "precision": 0.125,
                        "recall": 0.045454545454545456,
                        "f1-score": 0.06666666666666667,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.2619047619047619,
                        "recall": 0.09523809523809523,
                        "f1-score": 0.13968253968253969,
                        "support": 21.0
                    }
                },
                "crime_and_law_accuse_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.0,
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 10.0
                    }
                },
                "government_and_politics_protests_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.05,
                        "f1-score": 0.09090909090909091,
                        "support": 20.0
                    },
                    "COEX": {
                        "precision": 0.25,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.28571428571428575,
                        "support": 3.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.07142857142857142,
                    "macro avg": {
                        "precision": 0.1875,
                        "recall": 0.09583333333333333,
                        "f1-score": 0.09415584415584416,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.38392857142857145,
                        "recall": 0.07142857142857142,
                        "f1-score": 0.09554730983302413,
                        "support": 28.0
                    }
                },
                "politics_and_conflicts_elections_2": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.18181818181818182,
                        "f1-score": 0.26666666666666666,
                        "support": 22.0
                    },
                    "BEFORE": {
                        "precision": 0.14285714285714285,
                        "recall": 0.07142857142857142,
                        "f1-score": 0.09523809523809523,
                        "support": 14.0
                    },
                    "COEX": {
                        "precision": 0.2222222222222222,
                        "recall": 0.2222222222222222,
                        "f1-score": 0.2222222222222222,
                        "support": 9.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.15555555555555556,
                    "macro avg": {
                        "precision": 0.21626984126984125,
                        "recall": 0.11886724386724387,
                        "f1-score": 0.146031746031746,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.15555555555555556,
                        "f1-score": 0.20444444444444443,
                        "support": 45.0
                    }
                },
                "environment_2": {
                    "AFTER": {
                        "precision": 0.8,
                        "recall": 0.19047619047619047,
                        "f1-score": 0.3076923076923077,
                        "support": 21.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.08695652173913043,
                        "f1-score": 0.14814814814814817,
                        "support": 23.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.13333333333333333,
                    "macro avg": {
                        "precision": 0.325,
                        "recall": 0.06935817805383022,
                        "f1-score": 0.11396011396011396,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.6288888888888889,
                        "recall": 0.13333333333333333,
                        "f1-score": 0.21930990819879712,
                        "support": 45.0
                    }
                },
                "weather_floods_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.2857142857142857,
                        "f1-score": 0.4444444444444445,
                        "support": 7.0
                    },
                    "COEX": {
                        "precision": 0.5,
                        "recall": 0.25,
                        "f1-score": 0.3333333333333333,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2,
                    "macro avg": {
                        "precision": 0.375,
                        "recall": 0.13392857142857142,
                        "f1-score": 0.19444444444444445,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.6,
                        "recall": 0.2,
                        "f1-score": 0.29629629629629634,
                        "support": 15.0
                    }
                },
                "sports_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    }
                },
                "health_4": {
                    "AFTER": {
                        "precision": 0.25,
                        "recall": 0.1111111111111111,
                        "f1-score": 0.15384615384615383,
                        "support": 9.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 8.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.047619047619047616,
                    "macro avg": {
                        "precision": 0.0625,
                        "recall": 0.027777777777777776,
                        "f1-score": 0.03846153846153846,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.10714285714285714,
                        "recall": 0.047619047619047616,
                        "f1-score": 0.06593406593406592,
                        "support": 21.0
                    }
                },
                "weather_earthquakes_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "BEFORE": {
                        "precision": 0.6666666666666666,
                        "recall": 0.1875,
                        "f1-score": 0.29268292682926833,
                        "support": 32.0
                    },
                    "COEX": {
                        "precision": 0.3333333333333333,
                        "recall": 0.5714285714285714,
                        "f1-score": 0.4210526315789474,
                        "support": 7.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2222222222222222,
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.18973214285714285,
                        "f1-score": 0.17843388960205392,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.5259259259259259,
                        "recall": 0.2222222222222222,
                        "f1-score": 0.27362715732420484,
                        "support": 45.0
                    }
                },
                "space_4": {
                    "AFTER": {
                        "precision": 0.2,
                        "recall": 0.09090909090909091,
                        "f1-score": 0.12500000000000003,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 15.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.03571428571428571,
                    "macro avg": {
                        "precision": 0.05,
                        "recall": 0.022727272727272728,
                        "f1-score": 0.03125000000000001,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.07857142857142858,
                        "recall": 0.03571428571428571,
                        "f1-score": 0.04910714285714286,
                        "support": 28.0
                    }
                },
                "economy_and_business_strikes_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.0,
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    }
                },
                "politics_and_conflicts_armed_conflict_2": {
                    "AFTER": {
                        "precision": 0.2,
                        "recall": 1.0,
                        "f1-score": 0.33333333333333337,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.06666666666666667,
                    "macro avg": {
                        "precision": 0.05,
                        "recall": 0.25,
                        "f1-score": 0.08333333333333334,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.013333333333333334,
                        "recall": 0.06666666666666667,
                        "f1-score": 0.022222222222222223,
                        "support": 15.0
                    }
                },
                "infectious_disease_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    }
                },
                "health_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "COEX": {
                        "precision": 0.5,
                        "recall": 1.0,
                        "f1-score": 0.6666666666666666,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.1,
                    "macro avg": {
                        "precision": 0.125,
                        "recall": 0.25,
                        "f1-score": 0.16666666666666666,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.05,
                        "recall": 0.1,
                        "f1-score": 0.06666666666666667,
                        "support": 10.0
                    }
                },
                "disasters_and_accidents_shipwreck_2": {
                    "AFTER": {
                        "precision": 0.16666666666666666,
                        "recall": 0.09090909090909091,
                        "f1-score": 0.11764705882352942,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 9.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.047619047619047616,
                    "macro avg": {
                        "precision": 0.041666666666666664,
                        "recall": 0.022727272727272728,
                        "f1-score": 0.029411764705882356,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.0873015873015873,
                        "recall": 0.047619047619047616,
                        "f1-score": 0.06162464985994398,
                        "support": 21.0
                    }
                },
                "rail_transport_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.1,
                        "f1-score": 0.16666666666666669,
                        "support": 10.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.06666666666666667,
                    "macro avg": {
                        "precision": 0.125,
                        "recall": 0.025,
                        "f1-score": 0.04166666666666667,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.06666666666666667,
                        "f1-score": 0.11111111111111113,
                        "support": 15.0
                    }
                },
                "weather_storms_1_extra": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.25,
                        "f1-score": 0.25,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    }
                },
                "health_1_extra": {
                    "AFTER": {
                        "precision": 0.35714285714285715,
                        "recall": 0.4166666666666667,
                        "f1-score": 0.3846153846153846,
                        "support": 12.0
                    },
                    "BEFORE": {
                        "precision": 0.42857142857142855,
                        "recall": 0.10714285714285714,
                        "f1-score": 0.17142857142857143,
                        "support": 28.0
                    },
                    "COEX": {
                        "precision": 0.125,
                        "recall": 0.06666666666666667,
                        "f1-score": 0.08695652173913045,
                        "support": 15.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.16363636363636364,
                    "macro avg": {
                        "precision": 0.22767857142857142,
                        "recall": 0.14761904761904762,
                        "f1-score": 0.16075011944577164,
                        "support": 55.0
                    },
                    "weighted avg": {
                        "precision": 0.33019480519480515,
                        "recall": 0.16363636363636364,
                        "f1-score": 0.194904226208574,
                        "support": 55.0
                    }
                },
                "weather_floods_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 24.0
                    },
                    "COEX": {
                        "precision": 0.3333333333333333,
                        "recall": 0.10714285714285714,
                        "f1-score": 0.16216216216216214,
                        "support": 28.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.05454545454545454,
                    "macro avg": {
                        "precision": 0.08333333333333333,
                        "recall": 0.026785714285714284,
                        "f1-score": 0.040540540540540536,
                        "support": 55.0
                    },
                    "weighted avg": {
                        "precision": 0.16969696969696968,
                        "recall": 0.05454545454545454,
                        "f1-score": 0.08255528255528255,
                        "support": 55.0
                    }
                },
                "mining_4": {
                    "AFTER": {
                        "precision": 0.6363636363636364,
                        "recall": 0.6363636363636364,
                        "f1-score": 0.6363636363636364,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 25.0
                    },
                    "COEX": {
                        "precision": 0.375,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.35294117647058826,
                        "support": 9.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2222222222222222,
                    "macro avg": {
                        "precision": 0.25284090909090906,
                        "recall": 0.24242424242424243,
                        "f1-score": 0.24732620320855614,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.23055555555555557,
                        "recall": 0.2222222222222222,
                        "f1-score": 0.22614379084967318,
                        "support": 45.0
                    }
                },
                "disasters_and_accidents_volcanoes_4": {
                    "AFTER": {
                        "precision": 0.2857142857142857,
                        "recall": 0.1,
                        "f1-score": 0.14814814814814817,
                        "support": 20.0
                    },
                    "BEFORE": {
                        "precision": 0.25,
                        "recall": 0.07142857142857142,
                        "f1-score": 0.11111111111111112,
                        "support": 14.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.08333333333333333,
                    "macro avg": {
                        "precision": 0.13392857142857142,
                        "recall": 0.04285714285714286,
                        "f1-score": 0.06481481481481483,
                        "support": 36.0
                    },
                    "weighted avg": {
                        "precision": 0.25595238095238093,
                        "recall": 0.08333333333333333,
                        "f1-score": 0.12551440329218108,
                        "support": 36.0
                    }
                },
                "politics_and_conflicts_elections_3": {
                    "AFTER": {
                        "precision": 0.2,
                        "recall": 0.2,
                        "f1-score": 0.20000000000000004,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 0.25,
                        "f1-score": 0.28571428571428575,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.2,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.1818181818181818,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2,
                    "macro avg": {
                        "precision": 0.18333333333333335,
                        "recall": 0.15416666666666667,
                        "f1-score": 0.16688311688311688,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.23555555555555555,
                        "recall": 0.2,
                        "f1-score": 0.2155844155844156,
                        "support": 15.0
                    }
                },
                "economy_and_business_strikes_3": {
                    "AFTER": {
                        "precision": 0.3333333333333333,
                        "recall": 0.2,
                        "f1-score": 0.25,
                        "support": 10.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.09090909090909091,
                        "f1-score": 0.15384615384615385,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.2,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.16666666666666666,
                        "support": 7.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.14285714285714285,
                    "macro avg": {
                        "precision": 0.2583333333333333,
                        "recall": 0.10844155844155844,
                        "f1-score": 0.14262820512820512,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.36547619047619045,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.1913919413919414,
                        "support": 28.0
                    }
                },
                "space_2": {
                    "AFTER": {
                        "precision": 0.4,
                        "recall": 0.12,
                        "f1-score": 0.18461538461538463,
                        "support": 100.0
                    },
                    "BEFORE": {
                        "precision": 0.12,
                        "recall": 0.058823529411764705,
                        "f1-score": 0.07894736842105263,
                        "support": 51.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.09803921568627451,
                    "macro avg": {
                        "precision": 0.13,
                        "recall": 0.04470588235294118,
                        "f1-score": 0.06589068825910932,
                        "support": 153.0
                    },
                    "weighted avg": {
                        "precision": 0.301437908496732,
                        "recall": 0.09803921568627451,
                        "f1-score": 0.146979439549099,
                        "support": 153.0
                    }
                },
                "politics_and_conflicts_resign_1": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.5,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 3.0
                    },
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.08333333333333333,
                        "f1-score": 0.125,
                        "support": 3.0
                    },
                    "weighted avg": {
                        "precision": 1.0,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.5,
                        "support": 3.0
                    }
                },
                "environment_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.25,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.2,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.06666666666666667,
                    "macro avg": {
                        "precision": 0.0625,
                        "recall": 0.041666666666666664,
                        "f1-score": 0.05,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.1,
                        "recall": 0.06666666666666667,
                        "f1-score": 0.08000000000000002,
                        "support": 15.0
                    }
                },
                "space_1_extra": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.0,
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    }
                },
                "health_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 8.0
                    },
                    "BEFORE": {
                        "precision": 0.2,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.1818181818181818,
                        "support": 6.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.06666666666666667,
                    "macro avg": {
                        "precision": 0.05,
                        "recall": 0.041666666666666664,
                        "f1-score": 0.04545454545454545,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.08000000000000002,
                        "recall": 0.06666666666666667,
                        "f1-score": 0.07272727272727272,
                        "support": 15.0
                    }
                },
                "environment_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.0,
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 15.0
                    }
                },
                "government_and_politics_protests_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 1.0,
                        "f1-score": 0.6666666666666666,
                        "support": 1.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.16666666666666666,
                    "macro avg": {
                        "precision": 0.125,
                        "recall": 0.25,
                        "f1-score": 0.16666666666666666,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.08333333333333333,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.1111111111111111,
                        "support": 6.0
                    }
                },
                "economy_and_business_financial_crisis_4": {
                    "AFTER": {
                        "precision": 0.2857142857142857,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.2105263157894737,
                        "support": 12.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.09523809523809523,
                    "macro avg": {
                        "precision": 0.07142857142857142,
                        "recall": 0.041666666666666664,
                        "f1-score": 0.052631578947368425,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.16326530612244897,
                        "recall": 0.09523809523809523,
                        "f1-score": 0.12030075187969927,
                        "support": 21.0
                    }
                },
                "computers_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    }
                },
                "crime_and_law_accuse_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.0,
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 10.0
                    }
                },
                "culture_and_entertainment_1": {
                    "AFTER": {
                        "precision": 0.3333333333333333,
                        "recall": 0.5,
                        "f1-score": 0.4,
                        "support": 2.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.16666666666666666,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.16666666666666666,
                        "support": 6.0
                    },
                    "macro avg": {
                        "precision": 0.08333333333333333,
                        "recall": 0.125,
                        "f1-score": 0.1,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.1111111111111111,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.13333333333333333,
                        "support": 6.0
                    }
                },
                "internet_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.5,
                        "recall": 1.0,
                        "f1-score": 0.6666666666666666,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.1,
                    "macro avg": {
                        "precision": 0.125,
                        "recall": 0.25,
                        "f1-score": 0.16666666666666666,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.05,
                        "recall": 0.1,
                        "f1-score": 0.06666666666666667,
                        "support": 10.0
                    }
                },
                "culture_and_entertainment_3": {
                    "AFTER": {
                        "precision": 0.3333333333333333,
                        "recall": 0.2,
                        "f1-score": 0.25,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.2,
                        "recall": 0.25,
                        "f1-score": 0.22222222222222224,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.5,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.4,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.26666666666666666,
                    "macro avg": {
                        "precision": 0.2583333333333333,
                        "recall": 0.19583333333333333,
                        "f1-score": 0.21805555555555556,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.36444444444444446,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.30259259259259264,
                        "support": 15.0
                    }
                }
            }
        }
    }
}

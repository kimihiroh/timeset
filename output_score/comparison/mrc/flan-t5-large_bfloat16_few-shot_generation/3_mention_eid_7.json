{
    "args": {
        "batch_size": 4,
        "dataset_name": "ctf-mrc",
        "device": "cuda",
        "dirpath_log": "log",
        "dirpath_model": null,
        "dirpath_output": "output/comparison",
        "dirpath_output_score": "output_score/comparison",
        "filepath_test": "data/preprocessed/ctf-sample/test.json",
        "filepath_dev": "data/preprocessed/ctf-sample/dev.json",
        "inference_type": "few-shot",
        "local_rank": 0,
        "marker": "eid",
        "max_new_tokens": 512,
        "model_id": "google/flan-t5-large",
        "num_demonstration": 3,
        "num_gpu": 1,
        "num_cpu": 4,
        "peft_model_path": null,
        "precision_type": "bfloat16",
        "representation": "mention",
        "seed": 7,
        "temperature": 0.0,
        "dirpath_model_cache": "/data/tir/projects/tir6/general/kimihiro/.cache/huggingface/transformers"
    },
    "average": {
        "document-and-pair-wise-scores": {
            "range": {
                "min": 0.09470693281239917,
                "median": 0.18872690180563562,
                "max": 0.2397481452729345
            },
            "individual": {
                "simple": 0.2397481452729345,
                "simple_events": 0.13263865867060426,
                "note": 0.1980118682559554,
                "note_events": 0.1412083437160887,
                "qa": 0.206096088319195,
                "qa_events": 0.17944193535531583,
                "refer": 0.2176941531290038,
                "refer_events": 0.14993256571967034,
                "hint": 0.21178114527512593,
                "pick": 0.09470693281239917
            }
        }
    },
    "individuals": {
        "document-and-pair-wise-scores": {
            "simple": {
                "government_and_politics_riots_4": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.5,
                        "f1-score": 0.5,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.6,
                        "recall": 0.25,
                        "f1-score": 0.35294117647058826,
                        "support": 12.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 12.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.17857142857142858,
                    "macro avg": {
                        "precision": 0.275,
                        "recall": 0.1875,
                        "f1-score": 0.21323529411764708,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.32857142857142857,
                        "recall": 0.17857142857142858,
                        "f1-score": 0.22268907563025211,
                        "support": 28.0
                    }
                },
                "rail_transport_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "BEFORE": {
                        "precision": 0.75,
                        "recall": 0.08823529411764706,
                        "f1-score": 0.15789473684210525,
                        "support": 34.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.08333333333333333,
                    "macro avg": {
                        "precision": 0.1875,
                        "recall": 0.022058823529411766,
                        "f1-score": 0.039473684210526314,
                        "support": 36.0
                    },
                    "weighted avg": {
                        "precision": 0.7083333333333334,
                        "recall": 0.08333333333333333,
                        "f1-score": 0.14912280701754385,
                        "support": 36.0
                    }
                },
                "politics_and_conflicts_policy_change_2": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.5,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.6666666666666666,
                        "recall": 1.0,
                        "f1-score": 0.8,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.5,
                        "recall": 1.0,
                        "f1-score": 0.6666666666666666,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.6666666666666666,
                        "recall": 0.6666666666666666,
                        "f1-score": 0.6666666666666666,
                        "support": 6.0
                    },
                    "macro avg": {
                        "precision": 0.5416666666666666,
                        "recall": 0.5833333333333333,
                        "f1-score": 0.4916666666666667,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.8055555555555555,
                        "recall": 0.6666666666666666,
                        "f1-score": 0.6277777777777778,
                        "support": 6.0
                    }
                },
                "politics_and_conflicts_drones_1": {
                    "AFTER": {
                        "precision": 0.25,
                        "recall": 0.09090909090909091,
                        "f1-score": 0.13333333333333333,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 8.0
                    },
                    "COEX": {
                        "precision": 0.2,
                        "recall": 0.5,
                        "f1-score": 0.28571428571428575,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.09523809523809523,
                    "macro avg": {
                        "precision": 0.1125,
                        "recall": 0.14772727272727273,
                        "f1-score": 0.10476190476190478,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.15,
                        "recall": 0.09523809523809523,
                        "f1-score": 0.09705215419501133,
                        "support": 21.0
                    }
                },
                "disasters_and_accidents_road_crash_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.6,
                        "recall": 0.3,
                        "f1-score": 0.4,
                        "support": 10.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.14285714285714285,
                    "macro avg": {
                        "precision": 0.15,
                        "recall": 0.075,
                        "f1-score": 0.1,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.2857142857142857,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.19047619047619047,
                        "support": 21.0
                    }
                },
                "crime_and_law_accuse_3": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.75,
                        "f1-score": 0.6,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.3,
                    "macro avg": {
                        "precision": 0.125,
                        "recall": 0.1875,
                        "f1-score": 0.15,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.2,
                        "recall": 0.3,
                        "f1-score": 0.24,
                        "support": 10.0
                    }
                },
                "government_and_politics_protests_2": {
                    "AFTER": {
                        "precision": 0.16666666666666666,
                        "recall": 0.2,
                        "f1-score": 0.1818181818181818,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 20.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.03571428571428571,
                    "macro avg": {
                        "precision": 0.041666666666666664,
                        "recall": 0.05,
                        "f1-score": 0.04545454545454545,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.02976190476190476,
                        "recall": 0.03571428571428571,
                        "f1-score": 0.032467532467532464,
                        "support": 28.0
                    }
                },
                "politics_and_conflicts_elections_2": {
                    "AFTER": {
                        "precision": 0.5555555555555556,
                        "recall": 0.22727272727272727,
                        "f1-score": 0.3225806451612903,
                        "support": 22.0
                    },
                    "BEFORE": {
                        "precision": 0.25,
                        "recall": 0.07142857142857142,
                        "f1-score": 0.11111111111111112,
                        "support": 14.0
                    },
                    "COEX": {
                        "precision": 0.42857142857142855,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.375,
                        "support": 9.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2,
                    "macro avg": {
                        "precision": 0.30853174603174605,
                        "recall": 0.158008658008658,
                        "f1-score": 0.20217293906810035,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.43509700176366845,
                        "recall": 0.2,
                        "f1-score": 0.2672739944245321,
                        "support": 45.0
                    }
                },
                "environment_2": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.2857142857142857,
                        "f1-score": 0.36363636363636365,
                        "support": 21.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.13043478260869565,
                        "f1-score": 0.20689655172413793,
                        "support": 23.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2,
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.10403726708074534,
                        "f1-score": 0.1426332288401254,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.4888888888888889,
                        "recall": 0.2,
                        "f1-score": 0.2754440961337513,
                        "support": 45.0
                    }
                },
                "weather_floods_3": {
                    "AFTER": {
                        "precision": 0.2,
                        "recall": 0.25,
                        "f1-score": 0.22222222222222224,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.25,
                        "support": 7.0
                    },
                    "COEX": {
                        "precision": 0.75,
                        "recall": 0.75,
                        "f1-score": 0.75,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.3333333333333333,
                    "macro avg": {
                        "precision": 0.4875,
                        "recall": 0.2857142857142857,
                        "f1-score": 0.3055555555555556,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.7200000000000001,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.37592592592592594,
                        "support": 15.0
                    }
                },
                "sports_1": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.5,
                        "f1-score": 0.6666666666666666,
                        "support": 2.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 3.0
                    },
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.125,
                        "f1-score": 0.16666666666666666,
                        "support": 3.0
                    },
                    "weighted avg": {
                        "precision": 0.6666666666666666,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.4444444444444444,
                        "support": 3.0
                    }
                },
                "health_4": {
                    "AFTER": {
                        "precision": 0.3333333333333333,
                        "recall": 0.2222222222222222,
                        "f1-score": 0.26666666666666666,
                        "support": 9.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 8.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.09523809523809523,
                    "macro avg": {
                        "precision": 0.08333333333333333,
                        "recall": 0.05555555555555555,
                        "f1-score": 0.06666666666666667,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.14285714285714285,
                        "recall": 0.09523809523809523,
                        "f1-score": 0.11428571428571428,
                        "support": 21.0
                    }
                },
                "weather_earthquakes_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "BEFORE": {
                        "precision": 0.6666666666666666,
                        "recall": 0.25,
                        "f1-score": 0.36363636363636365,
                        "support": 32.0
                    },
                    "COEX": {
                        "precision": 0.2222222222222222,
                        "recall": 0.2857142857142857,
                        "f1-score": 0.25,
                        "support": 7.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2222222222222222,
                    "macro avg": {
                        "precision": 0.2222222222222222,
                        "recall": 0.13392857142857142,
                        "f1-score": 0.1534090909090909,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.5086419753086419,
                        "recall": 0.2222222222222222,
                        "f1-score": 0.2974747474747475,
                        "support": 45.0
                    }
                },
                "space_4": {
                    "AFTER": {
                        "precision": 0.16666666666666666,
                        "recall": 0.09090909090909091,
                        "f1-score": 0.11764705882352942,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.16666666666666666,
                        "recall": 0.06666666666666667,
                        "f1-score": 0.09523809523809522,
                        "support": 15.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.07142857142857142,
                    "macro avg": {
                        "precision": 0.08333333333333333,
                        "recall": 0.0393939393939394,
                        "f1-score": 0.05322128851540616,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.15476190476190474,
                        "recall": 0.07142857142857142,
                        "f1-score": 0.09723889555822329,
                        "support": 28.0
                    }
                },
                "economy_and_business_strikes_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.6666666666666666,
                        "recall": 0.5,
                        "f1-score": 0.5714285714285715,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.5,
                        "recall": 1.0,
                        "f1-score": 0.6666666666666666,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.5,
                        "recall": 0.5,
                        "f1-score": 0.5,
                        "support": 6.0
                    },
                    "macro avg": {
                        "precision": 0.29166666666666663,
                        "recall": 0.375,
                        "f1-score": 0.30952380952380953,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.5277777777777778,
                        "recall": 0.5,
                        "f1-score": 0.4920634920634921,
                        "support": 6.0
                    }
                },
                "politics_and_conflicts_armed_conflict_2": {
                    "AFTER": {
                        "precision": 0.14285714285714285,
                        "recall": 1.0,
                        "f1-score": 0.25,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.2727272727272727,
                        "f1-score": 0.42857142857142855,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 3.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.3333333333333333,
                    "macro avg": {
                        "precision": 0.369047619047619,
                        "recall": 0.4015151515151515,
                        "f1-score": 0.25297619047619047,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.8095238095238095,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.39761904761904765,
                        "support": 15.0
                    }
                },
                "infectious_disease_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    }
                },
                "health_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.4,
                        "support": 3.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.1,
                    "macro avg": {
                        "precision": 0.125,
                        "recall": 0.08333333333333333,
                        "f1-score": 0.1,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.15,
                        "recall": 0.1,
                        "f1-score": 0.12000000000000002,
                        "support": 10.0
                    }
                },
                "disasters_and_accidents_shipwreck_2": {
                    "AFTER": {
                        "precision": 0.16666666666666666,
                        "recall": 0.09090909090909091,
                        "f1-score": 0.11764705882352942,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.25,
                        "recall": 0.1111111111111111,
                        "f1-score": 0.15384615384615383,
                        "support": 9.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.09523809523809523,
                    "macro avg": {
                        "precision": 0.10416666666666666,
                        "recall": 0.050505050505050504,
                        "f1-score": 0.06787330316742081,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.19444444444444442,
                        "recall": 0.09523809523809523,
                        "f1-score": 0.1275587157940099,
                        "support": 21.0
                    }
                },
                "rail_transport_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.6666666666666666,
                        "recall": 0.2,
                        "f1-score": 0.30769230769230765,
                        "support": 10.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.13333333333333333,
                    "macro avg": {
                        "precision": 0.16666666666666666,
                        "recall": 0.05,
                        "f1-score": 0.07692307692307691,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.4444444444444444,
                        "recall": 0.13333333333333333,
                        "f1-score": 0.20512820512820512,
                        "support": 15.0
                    }
                },
                "weather_storms_1_extra": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    }
                },
                "health_1_extra": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 12.0
                    },
                    "BEFORE": {
                        "precision": 0.8,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.24242424242424243,
                        "support": 28.0
                    },
                    "COEX": {
                        "precision": 0.2,
                        "recall": 0.06666666666666667,
                        "f1-score": 0.1,
                        "support": 15.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.09090909090909091,
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.052380952380952375,
                        "f1-score": 0.0856060606060606,
                        "support": 55.0
                    },
                    "weighted avg": {
                        "precision": 0.46181818181818185,
                        "recall": 0.09090909090909091,
                        "f1-score": 0.1506887052341598,
                        "support": 55.0
                    }
                },
                "weather_floods_1": {
                    "AFTER": {
                        "precision": 0.07692307692307693,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.125,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 0.041666666666666664,
                        "f1-score": 0.07407407407407407,
                        "support": 24.0
                    },
                    "COEX": {
                        "precision": 0.75,
                        "recall": 0.10714285714285714,
                        "f1-score": 0.1875,
                        "support": 28.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.09090909090909091,
                    "macro avg": {
                        "precision": 0.29006410256410253,
                        "recall": 0.12053571428571429,
                        "f1-score": 0.09664351851851852,
                        "support": 55.0
                    },
                    "weighted avg": {
                        "precision": 0.5314685314685315,
                        "recall": 0.09090909090909091,
                        "f1-score": 0.1345959595959596,
                        "support": 55.0
                    }
                },
                "mining_4": {
                    "AFTER": {
                        "precision": 0.1111111111111111,
                        "recall": 0.09090909090909091,
                        "f1-score": 0.09999999999999999,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 25.0
                    },
                    "COEX": {
                        "precision": 0.4,
                        "recall": 0.2222222222222222,
                        "f1-score": 0.2857142857142857,
                        "support": 9.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.06666666666666667,
                    "macro avg": {
                        "precision": 0.12777777777777777,
                        "recall": 0.07828282828282829,
                        "f1-score": 0.09642857142857142,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.10716049382716049,
                        "recall": 0.06666666666666667,
                        "f1-score": 0.08158730158730157,
                        "support": 45.0
                    }
                },
                "disasters_and_accidents_volcanoes_4": {
                    "AFTER": {
                        "precision": 0.2222222222222222,
                        "recall": 0.1,
                        "f1-score": 0.13793103448275865,
                        "support": 20.0
                    },
                    "BEFORE": {
                        "precision": 0.6,
                        "recall": 0.21428571428571427,
                        "f1-score": 0.3157894736842105,
                        "support": 14.0
                    },
                    "COEX": {
                        "precision": 0.25,
                        "recall": 0.5,
                        "f1-score": 0.3333333333333333,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.16666666666666666,
                    "macro avg": {
                        "precision": 0.26805555555555555,
                        "recall": 0.20357142857142857,
                        "f1-score": 0.19676346037507564,
                        "support": 36.0
                    },
                    "weighted avg": {
                        "precision": 0.370679012345679,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.21795388855279962,
                        "support": 36.0
                    }
                },
                "politics_and_conflicts_elections_3": {
                    "AFTER": {
                        "precision": 0.2,
                        "recall": 0.2,
                        "f1-score": 0.20000000000000004,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.6666666666666666,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.4444444444444444,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2,
                    "macro avg": {
                        "precision": 0.21666666666666667,
                        "recall": 0.13333333333333333,
                        "f1-score": 0.16111111111111112,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.2,
                        "f1-score": 0.24444444444444446,
                        "support": 15.0
                    }
                },
                "economy_and_business_strikes_3": {
                    "AFTER": {
                        "precision": 0.25,
                        "recall": 0.1,
                        "f1-score": 0.14285714285714288,
                        "support": 10.0
                    },
                    "BEFORE": {
                        "precision": 0.25,
                        "recall": 0.09090909090909091,
                        "f1-score": 0.13333333333333333,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.42857142857142855,
                        "recall": 0.42857142857142855,
                        "f1-score": 0.42857142857142855,
                        "support": 7.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.17857142857142858,
                    "macro avg": {
                        "precision": 0.23214285714285715,
                        "recall": 0.15487012987012988,
                        "f1-score": 0.17619047619047618,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.29464285714285715,
                        "recall": 0.17857142857142858,
                        "f1-score": 0.21054421768707485,
                        "support": 28.0
                    }
                },
                "space_2": {
                    "AFTER": {
                        "precision": 0.36363636363636365,
                        "recall": 0.08,
                        "f1-score": 0.13114754098360654,
                        "support": 100.0
                    },
                    "BEFORE": {
                        "precision": 0.26666666666666666,
                        "recall": 0.0784313725490196,
                        "f1-score": 0.1212121212121212,
                        "support": 51.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.0784313725490196,
                    "macro avg": {
                        "precision": 0.1575757575757576,
                        "recall": 0.039607843137254906,
                        "f1-score": 0.06308991554893194,
                        "support": 153.0
                    },
                    "weighted avg": {
                        "precision": 0.32655971479500895,
                        "recall": 0.0784313725490196,
                        "f1-score": 0.12612138745214926,
                        "support": 153.0
                    }
                },
                "politics_and_conflicts_resign_1": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.5,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 3.0
                    },
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.08333333333333333,
                        "f1-score": 0.125,
                        "support": 3.0
                    },
                    "weighted avg": {
                        "precision": 1.0,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.5,
                        "support": 3.0
                    }
                },
                "environment_4": {
                    "AFTER": {
                        "precision": 0.4,
                        "recall": 0.5,
                        "f1-score": 0.4444444444444445,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 0.2,
                        "f1-score": 0.25,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2,
                    "macro avg": {
                        "precision": 0.18333333333333335,
                        "recall": 0.175,
                        "f1-score": 0.1736111111111111,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.21777777777777776,
                        "recall": 0.2,
                        "f1-score": 0.20185185185185184,
                        "support": 15.0
                    }
                },
                "space_1_extra": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.6666666666666666,
                        "recall": 0.4,
                        "f1-score": 0.5,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 6.0
                    },
                    "macro avg": {
                        "precision": 0.16666666666666666,
                        "recall": 0.1,
                        "f1-score": 0.125,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.5555555555555555,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.4166666666666667,
                        "support": 6.0
                    }
                },
                "health_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 8.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.0,
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 15.0
                    }
                },
                "environment_3": {
                    "AFTER": {
                        "precision": 0.75,
                        "recall": 0.2727272727272727,
                        "f1-score": 0.39999999999999997,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.2,
                        "recall": 0.5,
                        "f1-score": 0.28571428571428575,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.26666666666666666,
                    "macro avg": {
                        "precision": 0.2375,
                        "recall": 0.19318181818181818,
                        "f1-score": 0.17142857142857143,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.5766666666666667,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.33142857142857135,
                        "support": 15.0
                    }
                },
                "government_and_politics_protests_3": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.5,
                        "f1-score": 0.5,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.3333333333333333,
                    "macro avg": {
                        "precision": 0.125,
                        "recall": 0.125,
                        "f1-score": 0.125,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 6.0
                    }
                },
                "economy_and_business_financial_crisis_4": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.25,
                        "f1-score": 0.3333333333333333,
                        "support": 12.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.3333333333333333,
                        "recall": 0.5,
                        "f1-score": 0.4,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.23809523809523808,
                    "macro avg": {
                        "precision": 0.20833333333333331,
                        "recall": 0.1875,
                        "f1-score": 0.18333333333333335,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.3492063492063492,
                        "recall": 0.23809523809523808,
                        "f1-score": 0.26666666666666666,
                        "support": 21.0
                    }
                },
                "computers_2": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.25,
                        "f1-score": 0.25,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    }
                },
                "crime_and_law_accuse_4": {
                    "AFTER": {
                        "precision": 0.2,
                        "recall": 0.2,
                        "f1-score": 0.20000000000000004,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.1,
                    "macro avg": {
                        "precision": 0.05,
                        "recall": 0.05,
                        "f1-score": 0.05000000000000001,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.1,
                        "recall": 0.1,
                        "f1-score": 0.10000000000000002,
                        "support": 10.0
                    }
                },
                "culture_and_entertainment_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.5,
                        "recall": 0.5,
                        "f1-score": 0.5,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.16666666666666666,
                    "macro avg": {
                        "precision": 0.125,
                        "recall": 0.125,
                        "f1-score": 0.125,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.16666666666666666,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.16666666666666666,
                        "support": 6.0
                    }
                },
                "internet_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 10.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 10.0
                    }
                },
                "culture_and_entertainment_3": {
                    "AFTER": {
                        "precision": 0.2,
                        "recall": 0.2,
                        "f1-score": 0.20000000000000004,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 1.0,
                        "recall": 0.5,
                        "f1-score": 0.6666666666666666,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.26666666666666666,
                    "macro avg": {
                        "precision": 0.3,
                        "recall": 0.175,
                        "f1-score": 0.21666666666666667,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.4666666666666667,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.3333333333333333,
                        "support": 15.0
                    }
                }
            },
            "simple_events": {
                "government_and_politics_riots_4": {
                    "AFTER": {
                        "precision": 0.14285714285714285,
                        "recall": 0.25,
                        "f1-score": 0.18181818181818182,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.08333333333333333,
                        "f1-score": 0.15384615384615385,
                        "support": 12.0
                    },
                    "COEX": {
                        "precision": 0.3333333333333333,
                        "recall": 0.08333333333333333,
                        "f1-score": 0.13333333333333333,
                        "support": 12.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.10714285714285714,
                    "macro avg": {
                        "precision": 0.369047619047619,
                        "recall": 0.10416666666666666,
                        "f1-score": 0.11724941724941726,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.5918367346938774,
                        "recall": 0.10714285714285714,
                        "f1-score": 0.14905094905094904,
                        "support": 28.0
                    }
                },
                "rail_transport_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.058823529411764705,
                        "f1-score": 0.1111111111111111,
                        "support": 34.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.05555555555555555,
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.014705882352941176,
                        "f1-score": 0.027777777777777776,
                        "support": 36.0
                    },
                    "weighted avg": {
                        "precision": 0.9444444444444444,
                        "recall": 0.05555555555555555,
                        "f1-score": 0.10493827160493827,
                        "support": 36.0
                    }
                },
                "politics_and_conflicts_policy_change_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.0,
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    }
                },
                "politics_and_conflicts_drones_1": {
                    "AFTER": {
                        "precision": 0.16666666666666666,
                        "recall": 0.09090909090909091,
                        "f1-score": 0.11764705882352942,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 8.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.047619047619047616,
                    "macro avg": {
                        "precision": 0.041666666666666664,
                        "recall": 0.022727272727272728,
                        "f1-score": 0.029411764705882356,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.0873015873015873,
                        "recall": 0.047619047619047616,
                        "f1-score": 0.06162464985994398,
                        "support": 21.0
                    }
                },
                "disasters_and_accidents_road_crash_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 10.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.0,
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 21.0
                    }
                },
                "crime_and_law_accuse_3": {
                    "AFTER": {
                        "precision": 0.4,
                        "recall": 0.5,
                        "f1-score": 0.4444444444444445,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2,
                    "macro avg": {
                        "precision": 0.1,
                        "recall": 0.125,
                        "f1-score": 0.11111111111111112,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.16,
                        "recall": 0.2,
                        "f1-score": 0.17777777777777778,
                        "support": 10.0
                    }
                },
                "government_and_politics_protests_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.1,
                        "f1-score": 0.18181818181818182,
                        "support": 20.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.07142857142857142,
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.025,
                        "f1-score": 0.045454545454545456,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.7142857142857143,
                        "recall": 0.07142857142857142,
                        "f1-score": 0.12987012987012989,
                        "support": 28.0
                    }
                },
                "politics_and_conflicts_elections_2": {
                    "AFTER": {
                        "precision": 0.6,
                        "recall": 0.2727272727272727,
                        "f1-score": 0.37499999999999994,
                        "support": 22.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 14.0
                    },
                    "COEX": {
                        "precision": 0.14285714285714285,
                        "recall": 0.1111111111111111,
                        "f1-score": 0.125,
                        "support": 9.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.15555555555555556,
                    "macro avg": {
                        "precision": 0.18571428571428572,
                        "recall": 0.09595959595959595,
                        "f1-score": 0.12499999999999999,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.32190476190476186,
                        "recall": 0.15555555555555556,
                        "f1-score": 0.2083333333333333,
                        "support": 45.0
                    }
                },
                "environment_2": {
                    "AFTER": {
                        "precision": 0.3333333333333333,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.2,
                        "support": 21.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.043478260869565216,
                        "f1-score": 0.08,
                        "support": 23.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.08888888888888889,
                    "macro avg": {
                        "precision": 0.20833333333333331,
                        "recall": 0.046583850931677016,
                        "f1-score": 0.07,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.4111111111111111,
                        "recall": 0.08888888888888889,
                        "f1-score": 0.13422222222222221,
                        "support": 45.0
                    }
                },
                "weather_floods_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 7.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.0,
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 15.0
                    }
                },
                "sports_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.0,
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    }
                },
                "health_4": {
                    "AFTER": {
                        "precision": 0.25,
                        "recall": 0.1111111111111111,
                        "f1-score": 0.15384615384615383,
                        "support": 9.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 8.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.047619047619047616,
                    "macro avg": {
                        "precision": 0.0625,
                        "recall": 0.027777777777777776,
                        "f1-score": 0.03846153846153846,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.10714285714285714,
                        "recall": 0.047619047619047616,
                        "f1-score": 0.06593406593406592,
                        "support": 21.0
                    }
                },
                "weather_earthquakes_1": {
                    "AFTER": {
                        "precision": 0.1,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.125,
                        "support": 6.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 32.0
                    },
                    "COEX": {
                        "precision": 0.14285714285714285,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.14285714285714285,
                        "support": 7.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.044444444444444446,
                    "macro avg": {
                        "precision": 0.060714285714285714,
                        "recall": 0.07738095238095238,
                        "f1-score": 0.06696428571428571,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.035555555555555556,
                        "recall": 0.044444444444444446,
                        "f1-score": 0.03888888888888889,
                        "support": 45.0
                    }
                },
                "space_4": {
                    "AFTER": {
                        "precision": 0.42857142857142855,
                        "recall": 0.2727272727272727,
                        "f1-score": 0.33333333333333326,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 15.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.10714285714285714,
                    "macro avg": {
                        "precision": 0.10714285714285714,
                        "recall": 0.06818181818181818,
                        "f1-score": 0.08333333333333331,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.1683673469387755,
                        "recall": 0.10714285714285714,
                        "f1-score": 0.13095238095238093,
                        "support": 28.0
                    }
                },
                "economy_and_business_strikes_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.25,
                        "f1-score": 0.3333333333333333,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.16666666666666666,
                    "macro avg": {
                        "precision": 0.125,
                        "recall": 0.0625,
                        "f1-score": 0.08333333333333333,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.2222222222222222,
                        "support": 6.0
                    }
                },
                "politics_and_conflicts_armed_conflict_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.09090909090909091,
                        "f1-score": 0.15384615384615385,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.06666666666666667,
                    "macro avg": {
                        "precision": 0.125,
                        "recall": 0.022727272727272728,
                        "f1-score": 0.038461538461538464,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.36666666666666664,
                        "recall": 0.06666666666666667,
                        "f1-score": 0.11282051282051284,
                        "support": 15.0
                    }
                },
                "infectious_disease_4": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.25,
                        "f1-score": 0.25,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    }
                },
                "health_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.0,
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 10.0
                    }
                },
                "disasters_and_accidents_shipwreck_2": {
                    "AFTER": {
                        "precision": 0.2,
                        "recall": 0.09090909090909091,
                        "f1-score": 0.12500000000000003,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 9.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.047619047619047616,
                    "macro avg": {
                        "precision": 0.05,
                        "recall": 0.022727272727272728,
                        "f1-score": 0.03125000000000001,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.10476190476190476,
                        "recall": 0.047619047619047616,
                        "f1-score": 0.0654761904761905,
                        "support": 21.0
                    }
                },
                "rail_transport_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 0.1,
                        "f1-score": 0.15384615384615383,
                        "support": 10.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.06666666666666667,
                    "macro avg": {
                        "precision": 0.08333333333333333,
                        "recall": 0.025,
                        "f1-score": 0.03846153846153846,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.2222222222222222,
                        "recall": 0.06666666666666667,
                        "f1-score": 0.10256410256410256,
                        "support": 15.0
                    }
                },
                "weather_storms_1_extra": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    }
                },
                "health_1_extra": {
                    "AFTER": {
                        "precision": 0.2,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.1818181818181818,
                        "support": 12.0
                    },
                    "BEFORE": {
                        "precision": 0.75,
                        "recall": 0.10714285714285714,
                        "f1-score": 0.1875,
                        "support": 28.0
                    },
                    "COEX": {
                        "precision": 0.2,
                        "recall": 0.06666666666666667,
                        "f1-score": 0.1,
                        "support": 15.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.10909090909090909,
                    "macro avg": {
                        "precision": 0.2875,
                        "recall": 0.08511904761904761,
                        "f1-score": 0.11732954545454544,
                        "support": 55.0
                    },
                    "weighted avg": {
                        "precision": 0.48,
                        "recall": 0.10909090909090909,
                        "f1-score": 0.16239669421487604,
                        "support": 55.0
                    }
                },
                "weather_floods_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.4,
                        "recall": 0.08333333333333333,
                        "f1-score": 0.13793103448275862,
                        "support": 24.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 28.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.03636363636363636,
                    "macro avg": {
                        "precision": 0.1,
                        "recall": 0.020833333333333332,
                        "f1-score": 0.034482758620689655,
                        "support": 55.0
                    },
                    "weighted avg": {
                        "precision": 0.17454545454545456,
                        "recall": 0.03636363636363636,
                        "f1-score": 0.06018808777429467,
                        "support": 55.0
                    }
                },
                "mining_4": {
                    "AFTER": {
                        "precision": 0.18181818181818182,
                        "recall": 0.18181818181818182,
                        "f1-score": 0.18181818181818182,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 25.0
                    },
                    "COEX": {
                        "precision": 0.2,
                        "recall": 0.1111111111111111,
                        "f1-score": 0.14285714285714285,
                        "support": 9.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.06666666666666667,
                    "macro avg": {
                        "precision": 0.09545454545454546,
                        "recall": 0.07323232323232323,
                        "f1-score": 0.08116883116883117,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.08444444444444445,
                        "recall": 0.06666666666666667,
                        "f1-score": 0.073015873015873,
                        "support": 45.0
                    }
                },
                "disasters_and_accidents_volcanoes_4": {
                    "AFTER": {
                        "precision": 0.3333333333333333,
                        "recall": 0.1,
                        "f1-score": 0.15384615384615383,
                        "support": 20.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.22222222222222224,
                        "support": 14.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.1111111111111111,
                    "macro avg": {
                        "precision": 0.20833333333333331,
                        "recall": 0.060714285714285714,
                        "f1-score": 0.09401709401709402,
                        "support": 36.0
                    },
                    "weighted avg": {
                        "precision": 0.3796296296296296,
                        "recall": 0.1111111111111111,
                        "f1-score": 0.1718898385565052,
                        "support": 36.0
                    }
                },
                "politics_and_conflicts_elections_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 1.0,
                        "recall": 0.5,
                        "f1-score": 0.6666666666666666,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2,
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.125,
                        "f1-score": 0.16666666666666666,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.4,
                        "recall": 0.2,
                        "f1-score": 0.26666666666666666,
                        "support": 15.0
                    }
                },
                "economy_and_business_strikes_3": {
                    "AFTER": {
                        "precision": 0.2,
                        "recall": 0.1,
                        "f1-score": 0.13333333333333333,
                        "support": 10.0
                    },
                    "BEFORE": {
                        "precision": 0.2,
                        "recall": 0.09090909090909091,
                        "f1-score": 0.12500000000000003,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.5,
                        "recall": 0.42857142857142855,
                        "f1-score": 0.4615384615384615,
                        "support": 7.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.17857142857142858,
                    "macro avg": {
                        "precision": 0.225,
                        "recall": 0.15487012987012988,
                        "f1-score": 0.17996794871794872,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.275,
                        "recall": 0.17857142857142858,
                        "f1-score": 0.21211080586080586,
                        "support": 28.0
                    }
                },
                "space_2": {
                    "AFTER": {
                        "precision": 0.0625,
                        "recall": 0.01,
                        "f1-score": 0.01724137931034483,
                        "support": 100.0
                    },
                    "BEFORE": {
                        "precision": 0.1,
                        "recall": 0.0196078431372549,
                        "f1-score": 0.032786885245901634,
                        "support": 51.0
                    },
                    "COEX": {
                        "precision": 0.1,
                        "recall": 0.5,
                        "f1-score": 0.16666666666666669,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.0196078431372549,
                    "macro avg": {
                        "precision": 0.065625,
                        "recall": 0.13240196078431374,
                        "f1-score": 0.05417373280572829,
                        "support": 153.0
                    },
                    "weighted avg": {
                        "precision": 0.07549019607843138,
                        "recall": 0.0196078431372549,
                        "f1-score": 0.024376486352345097,
                        "support": 153.0
                    }
                },
                "politics_and_conflicts_resign_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    }
                },
                "environment_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.4,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3636363636363636,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.13333333333333333,
                    "macro avg": {
                        "precision": 0.1,
                        "recall": 0.08333333333333333,
                        "f1-score": 0.0909090909090909,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.16000000000000003,
                        "recall": 0.13333333333333333,
                        "f1-score": 0.14545454545454545,
                        "support": 15.0
                    }
                },
                "space_1_extra": {
                    "AFTER": {
                        "precision": 0.3333333333333333,
                        "recall": 1.0,
                        "f1-score": 0.5,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.16666666666666666,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.16666666666666666,
                        "support": 6.0
                    },
                    "macro avg": {
                        "precision": 0.08333333333333333,
                        "recall": 0.25,
                        "f1-score": 0.125,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.05555555555555555,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.08333333333333333,
                        "support": 6.0
                    }
                },
                "health_3": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.125,
                        "f1-score": 0.2222222222222222,
                        "support": 8.0
                    },
                    "BEFORE": {
                        "precision": 0.25,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.2,
                        "support": 6.0
                    },
                    "COEX": {
                        "precision": 0.5,
                        "recall": 1.0,
                        "f1-score": 0.6666666666666666,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2,
                    "macro avg": {
                        "precision": 0.4375,
                        "recall": 0.32291666666666663,
                        "f1-score": 0.2722222222222222,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.6666666666666666,
                        "recall": 0.2,
                        "f1-score": 0.24296296296296296,
                        "support": 15.0
                    }
                },
                "environment_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.3333333333333333,
                        "recall": 0.5,
                        "f1-score": 0.4,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.06666666666666667,
                    "macro avg": {
                        "precision": 0.08333333333333333,
                        "recall": 0.125,
                        "f1-score": 0.1,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.04444444444444444,
                        "recall": 0.06666666666666667,
                        "f1-score": 0.05333333333333334,
                        "support": 15.0
                    }
                },
                "government_and_politics_protests_3": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.25,
                        "f1-score": 0.4,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 1.0,
                        "f1-score": 0.6666666666666666,
                        "support": 1.0
                    },
                    "COEX": {
                        "precision": 0.5,
                        "recall": 1.0,
                        "f1-score": 0.6666666666666666,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.5,
                    "macro avg": {
                        "precision": 0.5,
                        "recall": 0.5625,
                        "f1-score": 0.43333333333333335,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.8333333333333334,
                        "recall": 0.5,
                        "f1-score": 0.4888888888888889,
                        "support": 6.0
                    }
                },
                "economy_and_business_financial_crisis_4": {
                    "AFTER": {
                        "precision": 0.2857142857142857,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.2105263157894737,
                        "support": 12.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.25,
                        "recall": 0.25,
                        "f1-score": 0.25,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.14285714285714285,
                    "macro avg": {
                        "precision": 0.13392857142857142,
                        "recall": 0.10416666666666666,
                        "f1-score": 0.11513157894736842,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.2108843537414966,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.16791979949874689,
                        "support": 21.0
                    }
                },
                "computers_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    }
                },
                "crime_and_law_accuse_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.0,
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 10.0
                    }
                },
                "culture_and_entertainment_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.0,
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    }
                },
                "internet_2": {
                    "AFTER": {
                        "precision": 0.3333333333333333,
                        "recall": 0.2,
                        "f1-score": 0.25,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.25,
                        "f1-score": 0.3333333333333333,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2,
                    "macro avg": {
                        "precision": 0.20833333333333331,
                        "recall": 0.1125,
                        "f1-score": 0.14583333333333331,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.36666666666666664,
                        "recall": 0.2,
                        "f1-score": 0.2583333333333333,
                        "support": 10.0
                    }
                },
                "culture_and_entertainment_3": {
                    "AFTER": {
                        "precision": 0.3333333333333333,
                        "recall": 0.2,
                        "f1-score": 0.25,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.25,
                        "f1-score": 0.4,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.13333333333333333,
                    "macro avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.1125,
                        "f1-score": 0.1625,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.3777777777777777,
                        "recall": 0.13333333333333333,
                        "f1-score": 0.19,
                        "support": 15.0
                    }
                }
            },
            "note": {
                "government_and_politics_riots_4": {
                    "AFTER": {
                        "precision": 0.2222222222222222,
                        "recall": 0.5,
                        "f1-score": 0.30769230769230765,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.25,
                        "support": 12.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 12.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.14285714285714285,
                    "macro avg": {
                        "precision": 0.18055555555555555,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.13942307692307693,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.24603174603174605,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.1510989010989011,
                        "support": 28.0
                    }
                },
                "rail_transport_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.17647058823529413,
                        "f1-score": 0.3,
                        "support": 34.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.16666666666666666,
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.04411764705882353,
                        "f1-score": 0.075,
                        "support": 36.0
                    },
                    "weighted avg": {
                        "precision": 0.9444444444444444,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.2833333333333333,
                        "support": 36.0
                    }
                },
                "politics_and_conflicts_policy_change_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.0,
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    }
                },
                "politics_and_conflicts_drones_1": {
                    "AFTER": {
                        "precision": 0.16666666666666666,
                        "recall": 0.09090909090909091,
                        "f1-score": 0.11764705882352942,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.75,
                        "recall": 0.375,
                        "f1-score": 0.5,
                        "support": 8.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.19047619047619047,
                    "macro avg": {
                        "precision": 0.22916666666666666,
                        "recall": 0.11647727272727273,
                        "f1-score": 0.15441176470588236,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.373015873015873,
                        "recall": 0.19047619047619047,
                        "f1-score": 0.25210084033613445,
                        "support": 21.0
                    }
                },
                "disasters_and_accidents_road_crash_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "BEFORE": {
                        "precision": 0.6666666666666666,
                        "recall": 0.18181818181818182,
                        "f1-score": 0.28571428571428575,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 10.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.09523809523809523,
                    "macro avg": {
                        "precision": 0.16666666666666666,
                        "recall": 0.045454545454545456,
                        "f1-score": 0.07142857142857144,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.3492063492063492,
                        "recall": 0.09523809523809523,
                        "f1-score": 0.14965986394557826,
                        "support": 21.0
                    }
                },
                "crime_and_law_accuse_3": {
                    "AFTER": {
                        "precision": 0.2,
                        "recall": 0.25,
                        "f1-score": 0.22222222222222224,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.6666666666666666,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.4444444444444444,
                        "support": 6.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.3,
                    "macro avg": {
                        "precision": 0.21666666666666667,
                        "recall": 0.14583333333333331,
                        "f1-score": 0.16666666666666666,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.48,
                        "recall": 0.3,
                        "f1-score": 0.3555555555555555,
                        "support": 10.0
                    }
                },
                "government_and_politics_protests_2": {
                    "AFTER": {
                        "precision": 0.14285714285714285,
                        "recall": 0.2,
                        "f1-score": 0.16666666666666666,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.4,
                        "recall": 0.1,
                        "f1-score": 0.16000000000000003,
                        "support": 20.0
                    },
                    "COEX": {
                        "precision": 0.6666666666666666,
                        "recall": 0.6666666666666666,
                        "f1-score": 0.6666666666666666,
                        "support": 3.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.17857142857142858,
                    "macro avg": {
                        "precision": 0.3023809523809524,
                        "recall": 0.24166666666666667,
                        "f1-score": 0.24833333333333332,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.3826530612244898,
                        "recall": 0.17857142857142858,
                        "f1-score": 0.21547619047619052,
                        "support": 28.0
                    }
                },
                "politics_and_conflicts_elections_2": {
                    "AFTER": {
                        "precision": 0.4,
                        "recall": 0.09090909090909091,
                        "f1-score": 0.14814814814814814,
                        "support": 22.0
                    },
                    "BEFORE": {
                        "precision": 0.4,
                        "recall": 0.2857142857142857,
                        "f1-score": 0.3333333333333333,
                        "support": 14.0
                    },
                    "COEX": {
                        "precision": 0.4,
                        "recall": 0.2222222222222222,
                        "f1-score": 0.2857142857142857,
                        "support": 9.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.17777777777777778,
                    "macro avg": {
                        "precision": 0.30000000000000004,
                        "recall": 0.1497113997113997,
                        "f1-score": 0.1917989417989418,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.4000000000000001,
                        "recall": 0.17777777777777778,
                        "f1-score": 0.23327454438565548,
                        "support": 45.0
                    }
                },
                "environment_2": {
                    "AFTER": {
                        "precision": 0.38461538461538464,
                        "recall": 0.23809523809523808,
                        "f1-score": 0.2941176470588235,
                        "support": 21.0
                    },
                    "BEFORE": {
                        "precision": 0.2857142857142857,
                        "recall": 0.08695652173913043,
                        "f1-score": 0.13333333333333333,
                        "support": 23.0
                    },
                    "COEX": {
                        "precision": 0.1111111111111111,
                        "recall": 1.0,
                        "f1-score": 0.19999999999999998,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.17777777777777778,
                    "macro avg": {
                        "precision": 0.1953601953601954,
                        "recall": 0.33126293995859213,
                        "f1-score": 0.15686274509803919,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.32798806132139463,
                        "recall": 0.17777777777777778,
                        "f1-score": 0.20984749455337687,
                        "support": 45.0
                    }
                },
                "weather_floods_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 7.0
                    },
                    "COEX": {
                        "precision": 0.5,
                        "recall": 0.25,
                        "f1-score": 0.3333333333333333,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.06666666666666667,
                    "macro avg": {
                        "precision": 0.125,
                        "recall": 0.0625,
                        "f1-score": 0.08333333333333333,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.13333333333333333,
                        "recall": 0.06666666666666667,
                        "f1-score": 0.08888888888888888,
                        "support": 15.0
                    }
                },
                "sports_1": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.5,
                        "f1-score": 0.6666666666666666,
                        "support": 2.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 1.0,
                        "f1-score": 0.6666666666666666,
                        "support": 1.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.6666666666666666,
                        "recall": 0.6666666666666666,
                        "f1-score": 0.6666666666666666,
                        "support": 3.0
                    },
                    "macro avg": {
                        "precision": 0.375,
                        "recall": 0.375,
                        "f1-score": 0.3333333333333333,
                        "support": 3.0
                    },
                    "weighted avg": {
                        "precision": 0.8333333333333334,
                        "recall": 0.6666666666666666,
                        "f1-score": 0.6666666666666666,
                        "support": 3.0
                    }
                },
                "health_4": {
                    "AFTER": {
                        "precision": 0.42857142857142855,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.375,
                        "support": 9.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 8.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.14285714285714285,
                    "macro avg": {
                        "precision": 0.10714285714285714,
                        "recall": 0.08333333333333333,
                        "f1-score": 0.09375,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.18367346938775508,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.16071428571428573,
                        "support": 21.0
                    }
                },
                "weather_earthquakes_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "BEFORE": {
                        "precision": 0.4,
                        "recall": 0.0625,
                        "f1-score": 0.10810810810810811,
                        "support": 32.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 7.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.044444444444444446,
                    "macro avg": {
                        "precision": 0.1,
                        "recall": 0.015625,
                        "f1-score": 0.02702702702702703,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.28444444444444444,
                        "recall": 0.044444444444444446,
                        "f1-score": 0.07687687687687689,
                        "support": 45.0
                    }
                },
                "space_4": {
                    "AFTER": {
                        "precision": 0.16666666666666666,
                        "recall": 0.09090909090909091,
                        "f1-score": 0.11764705882352942,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.25,
                        "recall": 0.06666666666666667,
                        "f1-score": 0.10526315789473685,
                        "support": 15.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.07142857142857142,
                    "macro avg": {
                        "precision": 0.10416666666666666,
                        "recall": 0.0393939393939394,
                        "f1-score": 0.05572755417956657,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.1994047619047619,
                        "recall": 0.07142857142857142,
                        "f1-score": 0.10260946483856702,
                        "support": 28.0
                    }
                },
                "economy_and_business_strikes_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.25,
                        "f1-score": 0.3333333333333333,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.3333333333333333,
                    "macro avg": {
                        "precision": 0.375,
                        "recall": 0.3125,
                        "f1-score": 0.3333333333333333,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.5,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.38888888888888884,
                        "support": 6.0
                    }
                },
                "politics_and_conflicts_armed_conflict_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.09090909090909091,
                        "f1-score": 0.15384615384615385,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.06666666666666667,
                    "macro avg": {
                        "precision": 0.125,
                        "recall": 0.022727272727272728,
                        "f1-score": 0.038461538461538464,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.36666666666666664,
                        "recall": 0.06666666666666667,
                        "f1-score": 0.11282051282051284,
                        "support": 15.0
                    }
                },
                "infectious_disease_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    }
                },
                "health_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "COEX": {
                        "precision": 0.5,
                        "recall": 1.0,
                        "f1-score": 0.6666666666666666,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.1,
                    "macro avg": {
                        "precision": 0.125,
                        "recall": 0.25,
                        "f1-score": 0.16666666666666666,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.05,
                        "recall": 0.1,
                        "f1-score": 0.06666666666666667,
                        "support": 10.0
                    }
                },
                "disasters_and_accidents_shipwreck_2": {
                    "AFTER": {
                        "precision": 0.2727272727272727,
                        "recall": 0.2727272727272727,
                        "f1-score": 0.2727272727272727,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 9.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.14285714285714285,
                    "macro avg": {
                        "precision": 0.06818181818181818,
                        "recall": 0.06818181818181818,
                        "f1-score": 0.06818181818181818,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.14285714285714285,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.14285714285714285,
                        "support": 21.0
                    }
                },
                "rail_transport_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 0.1,
                        "f1-score": 0.15384615384615383,
                        "support": 10.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.06666666666666667,
                    "macro avg": {
                        "precision": 0.08333333333333333,
                        "recall": 0.025,
                        "f1-score": 0.03846153846153846,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.2222222222222222,
                        "recall": 0.06666666666666667,
                        "f1-score": 0.10256410256410256,
                        "support": 15.0
                    }
                },
                "weather_storms_1_extra": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    }
                },
                "health_1_extra": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 12.0
                    },
                    "BEFORE": {
                        "precision": 0.45454545454545453,
                        "recall": 0.17857142857142858,
                        "f1-score": 0.25641025641025644,
                        "support": 28.0
                    },
                    "COEX": {
                        "precision": 0.2,
                        "recall": 0.06666666666666667,
                        "f1-score": 0.1,
                        "support": 15.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.10909090909090909,
                    "macro avg": {
                        "precision": 0.16363636363636364,
                        "recall": 0.061309523809523814,
                        "f1-score": 0.08910256410256412,
                        "support": 55.0
                    },
                    "weighted avg": {
                        "precision": 0.28595041322314046,
                        "recall": 0.10909090909090909,
                        "f1-score": 0.15780885780885784,
                        "support": 55.0
                    }
                },
                "weather_floods_1": {
                    "AFTER": {
                        "precision": 0.07692307692307693,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.125,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.125,
                        "f1-score": 0.2,
                        "support": 24.0
                    },
                    "COEX": {
                        "precision": 0.6,
                        "recall": 0.10714285714285714,
                        "f1-score": 0.18181818181818182,
                        "support": 28.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.12727272727272726,
                    "macro avg": {
                        "precision": 0.2942307692307692,
                        "recall": 0.14136904761904762,
                        "f1-score": 0.12670454545454546,
                        "support": 55.0
                    },
                    "weighted avg": {
                        "precision": 0.5278321678321678,
                        "recall": 0.12727272727272726,
                        "f1-score": 0.18665289256198347,
                        "support": 55.0
                    }
                },
                "mining_4": {
                    "AFTER": {
                        "precision": 0.23076923076923078,
                        "recall": 0.2727272727272727,
                        "f1-score": 0.24999999999999994,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 0.08,
                        "f1-score": 0.12903225806451613,
                        "support": 25.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 9.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.1111111111111111,
                    "macro avg": {
                        "precision": 0.14102564102564102,
                        "recall": 0.08818181818181818,
                        "f1-score": 0.09475806451612902,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.24159544159544158,
                        "recall": 0.1111111111111111,
                        "f1-score": 0.13279569892473117,
                        "support": 45.0
                    }
                },
                "disasters_and_accidents_volcanoes_4": {
                    "AFTER": {
                        "precision": 0.42857142857142855,
                        "recall": 0.15,
                        "f1-score": 0.2222222222222222,
                        "support": 20.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 0.07142857142857142,
                        "f1-score": 0.11764705882352941,
                        "support": 14.0
                    },
                    "COEX": {
                        "precision": 0.14285714285714285,
                        "recall": 0.5,
                        "f1-score": 0.22222222222222224,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.1388888888888889,
                    "macro avg": {
                        "precision": 0.22619047619047616,
                        "recall": 0.18035714285714285,
                        "f1-score": 0.14052287581699346,
                        "support": 36.0
                    },
                    "weighted avg": {
                        "precision": 0.37566137566137564,
                        "recall": 0.1388888888888889,
                        "f1-score": 0.18155410312273057,
                        "support": 36.0
                    }
                },
                "politics_and_conflicts_elections_3": {
                    "AFTER": {
                        "precision": 0.6,
                        "recall": 0.6,
                        "f1-score": 0.6,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.16666666666666666,
                        "recall": 0.25,
                        "f1-score": 0.2,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.6666666666666666,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.4444444444444444,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.4,
                    "macro avg": {
                        "precision": 0.3583333333333333,
                        "recall": 0.29583333333333334,
                        "f1-score": 0.3111111111111111,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.5111111111111111,
                        "recall": 0.4,
                        "f1-score": 0.4311111111111111,
                        "support": 15.0
                    }
                },
                "economy_and_business_strikes_3": {
                    "AFTER": {
                        "precision": 0.125,
                        "recall": 0.1,
                        "f1-score": 0.11111111111111112,
                        "support": 10.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 0.09090909090909091,
                        "f1-score": 0.14285714285714288,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.5,
                        "recall": 0.2857142857142857,
                        "f1-score": 0.36363636363636365,
                        "support": 7.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.14285714285714285,
                    "macro avg": {
                        "precision": 0.23958333333333331,
                        "recall": 0.11915584415584415,
                        "f1-score": 0.15440115440115443,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.3005952380952381,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.18671407957122246,
                        "support": 28.0
                    }
                },
                "space_2": {
                    "AFTER": {
                        "precision": 0.45454545454545453,
                        "recall": 0.1,
                        "f1-score": 0.16393442622950818,
                        "support": 100.0
                    },
                    "BEFORE": {
                        "precision": 0.4375,
                        "recall": 0.13725490196078433,
                        "f1-score": 0.20895522388059706,
                        "support": 51.0
                    },
                    "COEX": {
                        "precision": 0.1,
                        "recall": 0.5,
                        "f1-score": 0.16666666666666669,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.11764705882352941,
                    "macro avg": {
                        "precision": 0.24801136363636364,
                        "recall": 0.1843137254901961,
                        "f1-score": 0.13488907919419296,
                        "support": 153.0
                    },
                    "weighted avg": {
                        "precision": 0.444229055258467,
                        "recall": 0.11764705882352941,
                        "f1-score": 0.17897707434114118,
                        "support": 153.0
                    }
                },
                "politics_and_conflicts_resign_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    }
                },
                "environment_4": {
                    "AFTER": {
                        "precision": 0.2,
                        "recall": 0.25,
                        "f1-score": 0.22222222222222224,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.6666666666666666,
                        "recall": 0.4,
                        "f1-score": 0.5,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.3333333333333333,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.2222222222222222,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.26666666666666666,
                    "macro avg": {
                        "precision": 0.3,
                        "recall": 0.20416666666666666,
                        "f1-score": 0.2361111111111111,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.40888888888888886,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.3148148148148148,
                        "support": 15.0
                    }
                },
                "space_1_extra": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 1.0,
                        "f1-score": 0.6666666666666666,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.4,
                        "f1-score": 0.5714285714285715,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.5,
                        "recall": 0.5,
                        "f1-score": 0.5,
                        "support": 6.0
                    },
                    "macro avg": {
                        "precision": 0.375,
                        "recall": 0.35,
                        "f1-score": 0.30952380952380953,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.9166666666666666,
                        "recall": 0.5,
                        "f1-score": 0.5873015873015873,
                        "support": 6.0
                    }
                },
                "health_3": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.25,
                        "f1-score": 0.3333333333333333,
                        "support": 8.0
                    },
                    "BEFORE": {
                        "precision": 0.25,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.2,
                        "support": 6.0
                    },
                    "COEX": {
                        "precision": 0.3333333333333333,
                        "recall": 1.0,
                        "f1-score": 0.5,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.26666666666666666,
                    "macro avg": {
                        "precision": 0.2708333333333333,
                        "recall": 0.35416666666666663,
                        "f1-score": 0.2583333333333333,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.3888888888888889,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.29111111111111115,
                        "support": 15.0
                    }
                },
                "environment_3": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.36363636363636365,
                        "f1-score": 0.5333333333333333,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.16666666666666666,
                        "recall": 0.5,
                        "f1-score": 0.25,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.3333333333333333,
                    "macro avg": {
                        "precision": 0.2916666666666667,
                        "recall": 0.2159090909090909,
                        "f1-score": 0.19583333333333333,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.7555555555555556,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.4244444444444444,
                        "support": 15.0
                    }
                },
                "government_and_politics_protests_3": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.25,
                        "f1-score": 0.3333333333333333,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.16666666666666666,
                    "macro avg": {
                        "precision": 0.125,
                        "recall": 0.0625,
                        "f1-score": 0.08333333333333333,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.2222222222222222,
                        "support": 6.0
                    }
                },
                "economy_and_business_financial_crisis_4": {
                    "AFTER": {
                        "precision": 0.42857142857142855,
                        "recall": 0.25,
                        "f1-score": 0.3157894736842105,
                        "support": 12.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.16666666666666666,
                        "recall": 0.25,
                        "f1-score": 0.2,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.19047619047619047,
                    "macro avg": {
                        "precision": 0.1488095238095238,
                        "recall": 0.125,
                        "f1-score": 0.12894736842105264,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.2766439909297052,
                        "recall": 0.19047619047619047,
                        "f1-score": 0.21854636591478696,
                        "support": 21.0
                    }
                },
                "computers_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    }
                },
                "crime_and_law_accuse_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.0,
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 10.0
                    }
                },
                "culture_and_entertainment_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.5,
                        "f1-score": 0.5,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.16666666666666666,
                    "macro avg": {
                        "precision": 0.125,
                        "recall": 0.125,
                        "f1-score": 0.125,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.16666666666666666,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.16666666666666666,
                        "support": 6.0
                    }
                },
                "internet_2": {
                    "AFTER": {
                        "precision": 0.25,
                        "recall": 0.2,
                        "f1-score": 0.22222222222222224,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.6666666666666666,
                        "recall": 0.5,
                        "f1-score": 0.5714285714285715,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.3,
                        "recall": 0.3,
                        "f1-score": 0.3,
                        "support": 10.0
                    },
                    "macro avg": {
                        "precision": 0.22916666666666666,
                        "recall": 0.175,
                        "f1-score": 0.19841269841269843,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.39166666666666666,
                        "recall": 0.3,
                        "f1-score": 0.3396825396825397,
                        "support": 10.0
                    }
                },
                "culture_and_entertainment_3": {
                    "AFTER": {
                        "precision": 0.125,
                        "recall": 0.2,
                        "f1-score": 0.15384615384615385,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.3333333333333333,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.2222222222222222,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.13333333333333333,
                    "macro avg": {
                        "precision": 0.11458333333333333,
                        "recall": 0.09166666666666667,
                        "f1-score": 0.09401709401709402,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.175,
                        "recall": 0.13333333333333333,
                        "f1-score": 0.14017094017094017,
                        "support": 15.0
                    }
                }
            },
            "note_events": {
                "government_and_politics_riots_4": {
                    "AFTER": {
                        "precision": 0.16666666666666666,
                        "recall": 0.25,
                        "f1-score": 0.2,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.08333333333333333,
                        "f1-score": 0.14285714285714285,
                        "support": 12.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 12.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.07142857142857142,
                    "macro avg": {
                        "precision": 0.16666666666666666,
                        "recall": 0.08333333333333333,
                        "f1-score": 0.08571428571428572,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.2380952380952381,
                        "recall": 0.07142857142857142,
                        "f1-score": 0.08979591836734693,
                        "support": 28.0
                    }
                },
                "rail_transport_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.11764705882352941,
                        "f1-score": 0.21052631578947367,
                        "support": 34.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.1111111111111111,
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.029411764705882353,
                        "f1-score": 0.05263157894736842,
                        "support": 36.0
                    },
                    "weighted avg": {
                        "precision": 0.9444444444444444,
                        "recall": 0.1111111111111111,
                        "f1-score": 0.19883040935672514,
                        "support": 36.0
                    }
                },
                "politics_and_conflicts_policy_change_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.0,
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    }
                },
                "politics_and_conflicts_drones_1": {
                    "AFTER": {
                        "precision": 0.16666666666666666,
                        "recall": 0.09090909090909091,
                        "f1-score": 0.11764705882352942,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.125,
                        "f1-score": 0.2,
                        "support": 8.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.09523809523809523,
                    "macro avg": {
                        "precision": 0.16666666666666666,
                        "recall": 0.05397727272727273,
                        "f1-score": 0.07941176470588236,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.2777777777777778,
                        "recall": 0.09523809523809523,
                        "f1-score": 0.13781512605042018,
                        "support": 21.0
                    }
                },
                "disasters_and_accidents_road_crash_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.6,
                        "recall": 0.3,
                        "f1-score": 0.4,
                        "support": 10.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.14285714285714285,
                    "macro avg": {
                        "precision": 0.15,
                        "recall": 0.075,
                        "f1-score": 0.1,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.2857142857142857,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.19047619047619047,
                        "support": 21.0
                    }
                },
                "crime_and_law_accuse_3": {
                    "AFTER": {
                        "precision": 0.2,
                        "recall": 0.25,
                        "f1-score": 0.22222222222222224,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.1,
                    "macro avg": {
                        "precision": 0.05,
                        "recall": 0.0625,
                        "f1-score": 0.05555555555555556,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.08,
                        "recall": 0.1,
                        "f1-score": 0.08888888888888889,
                        "support": 10.0
                    }
                },
                "government_and_politics_protests_2": {
                    "AFTER": {
                        "precision": 0.1111111111111111,
                        "recall": 0.2,
                        "f1-score": 0.14285714285714285,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 0.05,
                        "f1-score": 0.08695652173913045,
                        "support": 20.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.07142857142857142,
                    "macro avg": {
                        "precision": 0.1111111111111111,
                        "recall": 0.0625,
                        "f1-score": 0.05745341614906832,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.2579365079365079,
                        "recall": 0.07142857142857142,
                        "f1-score": 0.08762200532386867,
                        "support": 28.0
                    }
                },
                "politics_and_conflicts_elections_2": {
                    "AFTER": {
                        "precision": 0.4444444444444444,
                        "recall": 0.18181818181818182,
                        "f1-score": 0.2580645161290322,
                        "support": 22.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 14.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 9.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.08888888888888889,
                    "macro avg": {
                        "precision": 0.1111111111111111,
                        "recall": 0.045454545454545456,
                        "f1-score": 0.06451612903225805,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.21728395061728392,
                        "recall": 0.08888888888888889,
                        "f1-score": 0.12616487455197128,
                        "support": 45.0
                    }
                },
                "environment_2": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.23809523809523808,
                        "f1-score": 0.3225806451612903,
                        "support": 21.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 23.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.1111111111111111,
                    "macro avg": {
                        "precision": 0.125,
                        "recall": 0.05952380952380952,
                        "f1-score": 0.08064516129032258,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.23333333333333334,
                        "recall": 0.1111111111111111,
                        "f1-score": 0.15053763440860216,
                        "support": 45.0
                    }
                },
                "weather_floods_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.22222222222222224,
                        "support": 7.0
                    },
                    "COEX": {
                        "precision": 0.3333333333333333,
                        "recall": 0.5,
                        "f1-score": 0.4,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2,
                    "macro avg": {
                        "precision": 0.20833333333333331,
                        "recall": 0.1607142857142857,
                        "f1-score": 0.15555555555555556,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.3222222222222222,
                        "recall": 0.2,
                        "f1-score": 0.2103703703703704,
                        "support": 15.0
                    }
                },
                "sports_1": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.5,
                        "f1-score": 0.5,
                        "support": 2.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 3.0
                    },
                    "macro avg": {
                        "precision": 0.125,
                        "recall": 0.125,
                        "f1-score": 0.125,
                        "support": 3.0
                    },
                    "weighted avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 3.0
                    }
                },
                "health_4": {
                    "AFTER": {
                        "precision": 0.6,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.42857142857142855,
                        "support": 9.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 8.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.14285714285714285,
                    "macro avg": {
                        "precision": 0.15,
                        "recall": 0.08333333333333333,
                        "f1-score": 0.10714285714285714,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.2571428571428571,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.18367346938775508,
                        "support": 21.0
                    }
                },
                "weather_earthquakes_1": {
                    "AFTER": {
                        "precision": 0.18181818181818182,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.23529411764705885,
                        "support": 6.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 32.0
                    },
                    "COEX": {
                        "precision": 1.0,
                        "recall": 0.42857142857142855,
                        "f1-score": 0.6,
                        "support": 7.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.1111111111111111,
                    "macro avg": {
                        "precision": 0.29545454545454547,
                        "recall": 0.19047619047619047,
                        "f1-score": 0.2088235294117647,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.1797979797979798,
                        "recall": 0.1111111111111111,
                        "f1-score": 0.1247058823529412,
                        "support": 45.0
                    }
                },
                "space_4": {
                    "AFTER": {
                        "precision": 0.4444444444444444,
                        "recall": 0.36363636363636365,
                        "f1-score": 0.39999999999999997,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.06666666666666667,
                        "f1-score": 0.11764705882352941,
                        "support": 15.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.17857142857142858,
                    "macro avg": {
                        "precision": 0.2361111111111111,
                        "recall": 0.10757575757575757,
                        "f1-score": 0.12941176470588234,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.4424603174603175,
                        "recall": 0.17857142857142858,
                        "f1-score": 0.22016806722689072,
                        "support": 28.0
                    }
                },
                "economy_and_business_strikes_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.25,
                        "f1-score": 0.3333333333333333,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.16666666666666666,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.16666666666666666,
                        "support": 6.0
                    },
                    "macro avg": {
                        "precision": 0.125,
                        "recall": 0.0625,
                        "f1-score": 0.08333333333333333,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.2222222222222222,
                        "support": 6.0
                    }
                },
                "politics_and_conflicts_armed_conflict_2": {
                    "AFTER": {
                        "precision": 0.16666666666666666,
                        "recall": 1.0,
                        "f1-score": 0.2857142857142857,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.2,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.25,
                        "support": 3.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.13333333333333333,
                    "macro avg": {
                        "precision": 0.09166666666666667,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.13392857142857142,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.051111111111111114,
                        "recall": 0.13333333333333333,
                        "f1-score": 0.06904761904761904,
                        "support": 15.0
                    }
                },
                "infectious_disease_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    }
                },
                "health_1": {
                    "AFTER": {
                        "precision": 0.3333333333333333,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.2222222222222222,
                        "support": 6.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.1,
                    "macro avg": {
                        "precision": 0.08333333333333333,
                        "recall": 0.041666666666666664,
                        "f1-score": 0.05555555555555555,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.2,
                        "recall": 0.1,
                        "f1-score": 0.13333333333333333,
                        "support": 10.0
                    }
                },
                "disasters_and_accidents_shipwreck_2": {
                    "AFTER": {
                        "precision": 0.16666666666666666,
                        "recall": 0.09090909090909091,
                        "f1-score": 0.11764705882352942,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 9.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.047619047619047616,
                    "macro avg": {
                        "precision": 0.041666666666666664,
                        "recall": 0.022727272727272728,
                        "f1-score": 0.029411764705882356,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.0873015873015873,
                        "recall": 0.047619047619047616,
                        "f1-score": 0.06162464985994398,
                        "support": 21.0
                    }
                },
                "rail_transport_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 10.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.0,
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 15.0
                    }
                },
                "weather_storms_1_extra": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    }
                },
                "health_1_extra": {
                    "AFTER": {
                        "precision": 0.1,
                        "recall": 0.08333333333333333,
                        "f1-score": 0.0909090909090909,
                        "support": 12.0
                    },
                    "BEFORE": {
                        "precision": 0.6666666666666666,
                        "recall": 0.07142857142857142,
                        "f1-score": 0.12903225806451613,
                        "support": 28.0
                    },
                    "COEX": {
                        "precision": 0.16666666666666666,
                        "recall": 0.06666666666666667,
                        "f1-score": 0.09523809523809522,
                        "support": 15.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.07272727272727272,
                    "macro avg": {
                        "precision": 0.2333333333333333,
                        "recall": 0.055357142857142855,
                        "f1-score": 0.07879486105292556,
                        "support": 55.0
                    },
                    "weighted avg": {
                        "precision": 0.4066666666666666,
                        "recall": 0.07272727272727272,
                        "f1-score": 0.11149788627794492,
                        "support": 55.0
                    }
                },
                "weather_floods_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 0.041666666666666664,
                        "f1-score": 0.07407407407407407,
                        "support": 24.0
                    },
                    "COEX": {
                        "precision": 0.7142857142857143,
                        "recall": 0.17857142857142858,
                        "f1-score": 0.2857142857142857,
                        "support": 28.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.10909090909090909,
                    "macro avg": {
                        "precision": 0.2619047619047619,
                        "recall": 0.05505952380952381,
                        "f1-score": 0.08994708994708994,
                        "support": 55.0
                    },
                    "weighted avg": {
                        "precision": 0.509090909090909,
                        "recall": 0.10909090909090909,
                        "f1-score": 0.17777777777777778,
                        "support": 55.0
                    }
                },
                "mining_4": {
                    "AFTER": {
                        "precision": 0.08333333333333333,
                        "recall": 0.09090909090909091,
                        "f1-score": 0.08695652173913043,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 25.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 9.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.022222222222222223,
                    "macro avg": {
                        "precision": 0.020833333333333332,
                        "recall": 0.022727272727272728,
                        "f1-score": 0.021739130434782608,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.02037037037037037,
                        "recall": 0.022222222222222223,
                        "f1-score": 0.021256038647342997,
                        "support": 45.0
                    }
                },
                "disasters_and_accidents_volcanoes_4": {
                    "AFTER": {
                        "precision": 0.4,
                        "recall": 0.2,
                        "f1-score": 0.26666666666666666,
                        "support": 20.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 14.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.1111111111111111,
                    "macro avg": {
                        "precision": 0.1,
                        "recall": 0.05,
                        "f1-score": 0.06666666666666667,
                        "support": 36.0
                    },
                    "weighted avg": {
                        "precision": 0.2222222222222222,
                        "recall": 0.1111111111111111,
                        "f1-score": 0.14814814814814814,
                        "support": 36.0
                    }
                },
                "politics_and_conflicts_elections_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.75,
                        "recall": 0.5,
                        "f1-score": 0.6,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2,
                    "macro avg": {
                        "precision": 0.1875,
                        "recall": 0.125,
                        "f1-score": 0.15,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.3,
                        "recall": 0.2,
                        "f1-score": 0.23999999999999996,
                        "support": 15.0
                    }
                },
                "economy_and_business_strikes_3": {
                    "AFTER": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3,
                        "f1-score": 0.3157894736842105,
                        "support": 10.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.18181818181818182,
                        "f1-score": 0.3076923076923077,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.6,
                        "recall": 0.42857142857142855,
                        "f1-score": 0.5,
                        "support": 7.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2857142857142857,
                    "macro avg": {
                        "precision": 0.4833333333333333,
                        "recall": 0.22759740259740258,
                        "f1-score": 0.2808704453441295,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.6619047619047619,
                        "recall": 0.2857142857142857,
                        "f1-score": 0.35866107576633893,
                        "support": 28.0
                    }
                },
                "space_2": {
                    "AFTER": {
                        "precision": 0.16666666666666666,
                        "recall": 0.03,
                        "f1-score": 0.05084745762711864,
                        "support": 100.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 51.0
                    },
                    "COEX": {
                        "precision": 0.1111111111111111,
                        "recall": 0.5,
                        "f1-score": 0.1818181818181818,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.026143790849673203,
                    "macro avg": {
                        "precision": 0.06944444444444445,
                        "recall": 0.1325,
                        "f1-score": 0.05816640986132511,
                        "support": 153.0
                    },
                    "weighted avg": {
                        "precision": 0.11038489469862017,
                        "recall": 0.026143790849673203,
                        "f1-score": 0.03561034069508645,
                        "support": 153.0
                    }
                },
                "politics_and_conflicts_resign_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.0,
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    }
                },
                "environment_4": {
                    "AFTER": {
                        "precision": 0.6666666666666666,
                        "recall": 0.5,
                        "f1-score": 0.5714285714285715,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.26666666666666666,
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.20833333333333331,
                        "f1-score": 0.22619047619047622,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.31111111111111106,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.28571428571428575,
                        "support": 15.0
                    }
                },
                "space_1_extra": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.0,
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    }
                },
                "health_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 8.0
                    },
                    "BEFORE": {
                        "precision": 0.16666666666666666,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.16666666666666666,
                        "support": 6.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.06666666666666667,
                    "macro avg": {
                        "precision": 0.041666666666666664,
                        "recall": 0.041666666666666664,
                        "f1-score": 0.041666666666666664,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.06666666666666667,
                        "recall": 0.06666666666666667,
                        "f1-score": 0.06666666666666667,
                        "support": 15.0
                    }
                },
                "environment_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.0,
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 15.0
                    }
                },
                "government_and_politics_protests_3": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.25,
                        "f1-score": 0.3333333333333333,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "COEX": {
                        "precision": 0.3333333333333333,
                        "recall": 1.0,
                        "f1-score": 0.5,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.3333333333333333,
                    "macro avg": {
                        "precision": 0.20833333333333331,
                        "recall": 0.3125,
                        "f1-score": 0.20833333333333331,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.3888888888888889,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3055555555555555,
                        "support": 6.0
                    }
                },
                "economy_and_business_financial_crisis_4": {
                    "AFTER": {
                        "precision": 0.3333333333333333,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.2222222222222222,
                        "support": 12.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.2,
                        "recall": 0.25,
                        "f1-score": 0.22222222222222224,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.14285714285714285,
                    "macro avg": {
                        "precision": 0.13333333333333333,
                        "recall": 0.10416666666666666,
                        "f1-score": 0.1111111111111111,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.22857142857142856,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.1693121693121693,
                        "support": 21.0
                    }
                },
                "computers_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    }
                },
                "crime_and_law_accuse_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.0,
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 10.0
                    }
                },
                "culture_and_entertainment_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.6666666666666666,
                        "recall": 1.0,
                        "f1-score": 0.8,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.3333333333333333,
                    "macro avg": {
                        "precision": 0.16666666666666666,
                        "recall": 0.25,
                        "f1-score": 0.2,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.2222222222222222,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.26666666666666666,
                        "support": 6.0
                    }
                },
                "internet_2": {
                    "AFTER": {
                        "precision": 0.6666666666666666,
                        "recall": 0.4,
                        "f1-score": 0.5,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.25,
                        "f1-score": 0.3333333333333333,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.3333333333333333,
                        "recall": 1.0,
                        "f1-score": 0.5,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.4,
                    "macro avg": {
                        "precision": 0.37499999999999994,
                        "recall": 0.4125,
                        "f1-score": 0.3333333333333333,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.5666666666666667,
                        "recall": 0.4,
                        "f1-score": 0.4333333333333333,
                        "support": 10.0
                    }
                },
                "culture_and_entertainment_3": {
                    "AFTER": {
                        "precision": 0.3333333333333333,
                        "recall": 0.2,
                        "f1-score": 0.25,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 0.25,
                        "f1-score": 0.28571428571428575,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.75,
                        "recall": 0.5,
                        "f1-score": 0.6,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.3333333333333333,
                    "macro avg": {
                        "precision": 0.35416666666666663,
                        "recall": 0.2375,
                        "f1-score": 0.2839285714285714,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.5,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3995238095238095,
                        "support": 15.0
                    }
                }
            },
            "qa": {
                "government_and_politics_riots_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 0.08333333333333333,
                        "f1-score": 0.13333333333333333,
                        "support": 12.0
                    },
                    "COEX": {
                        "precision": 0.16666666666666666,
                        "recall": 0.08333333333333333,
                        "f1-score": 0.1111111111111111,
                        "support": 12.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.07142857142857142,
                    "macro avg": {
                        "precision": 0.125,
                        "recall": 0.041666666666666664,
                        "f1-score": 0.06111111111111111,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.21428571428571427,
                        "recall": 0.07142857142857142,
                        "f1-score": 0.10476190476190476,
                        "support": 28.0
                    }
                },
                "rail_transport_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "BEFORE": {
                        "precision": 0.8333333333333334,
                        "recall": 0.14705882352941177,
                        "f1-score": 0.25,
                        "support": 34.0
                    },
                    "COEX": {
                        "precision": 0.16666666666666666,
                        "recall": 0.5,
                        "f1-score": 0.25,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.16666666666666666,
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.16176470588235295,
                        "f1-score": 0.125,
                        "support": 36.0
                    },
                    "weighted avg": {
                        "precision": 0.7962962962962963,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.25,
                        "support": 36.0
                    }
                },
                "politics_and_conflicts_policy_change_2": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.5,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.5,
                        "recall": 1.0,
                        "f1-score": 0.6666666666666666,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.3333333333333333,
                    "macro avg": {
                        "precision": 0.375,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.29166666666666663,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.5833333333333334,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3611111111111111,
                        "support": 6.0
                    }
                },
                "politics_and_conflicts_drones_1": {
                    "AFTER": {
                        "precision": 0.2857142857142857,
                        "recall": 0.18181818181818182,
                        "f1-score": 0.2222222222222222,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 8.0
                    },
                    "COEX": {
                        "precision": 0.2,
                        "recall": 0.5,
                        "f1-score": 0.28571428571428575,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.14285714285714285,
                    "macro avg": {
                        "precision": 0.12142857142857143,
                        "recall": 0.17045454545454547,
                        "f1-score": 0.12698412698412698,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.16870748299319727,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.1436130007558579,
                        "support": 21.0
                    }
                },
                "disasters_and_accidents_road_crash_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.09090909090909091,
                        "f1-score": 0.15384615384615385,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 10.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.047619047619047616,
                    "macro avg": {
                        "precision": 0.125,
                        "recall": 0.022727272727272728,
                        "f1-score": 0.038461538461538464,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.2619047619047619,
                        "recall": 0.047619047619047616,
                        "f1-score": 0.08058608058608059,
                        "support": 21.0
                    }
                },
                "crime_and_law_accuse_3": {
                    "AFTER": {
                        "precision": 0.3333333333333333,
                        "recall": 0.25,
                        "f1-score": 0.28571428571428575,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.25,
                        "support": 6.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2,
                    "macro avg": {
                        "precision": 0.20833333333333331,
                        "recall": 0.10416666666666666,
                        "f1-score": 0.13392857142857145,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.4333333333333333,
                        "recall": 0.2,
                        "f1-score": 0.26428571428571435,
                        "support": 10.0
                    }
                },
                "government_and_politics_protests_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 20.0
                    },
                    "COEX": {
                        "precision": 0.75,
                        "recall": 1.0,
                        "f1-score": 0.8571428571428571,
                        "support": 3.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.10714285714285714,
                    "macro avg": {
                        "precision": 0.1875,
                        "recall": 0.25,
                        "f1-score": 0.21428571428571427,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.08035714285714286,
                        "recall": 0.10714285714285714,
                        "f1-score": 0.09183673469387754,
                        "support": 28.0
                    }
                },
                "politics_and_conflicts_elections_2": {
                    "AFTER": {
                        "precision": 0.8,
                        "recall": 0.18181818181818182,
                        "f1-score": 0.2962962962962963,
                        "support": 22.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 14.0
                    },
                    "COEX": {
                        "precision": 0.375,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.35294117647058826,
                        "support": 9.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.15555555555555556,
                    "macro avg": {
                        "precision": 0.29375,
                        "recall": 0.12878787878787878,
                        "f1-score": 0.16230936819172115,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.46611111111111114,
                        "recall": 0.15555555555555556,
                        "f1-score": 0.21544420237230694,
                        "support": 45.0
                    }
                },
                "environment_2": {
                    "AFTER": {
                        "precision": 0.6,
                        "recall": 0.2857142857142857,
                        "f1-score": 0.3870967741935483,
                        "support": 21.0
                    },
                    "BEFORE": {
                        "precision": 0.75,
                        "recall": 0.391304347826087,
                        "f1-score": 0.5142857142857143,
                        "support": 23.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.3333333333333333,
                    "macro avg": {
                        "precision": 0.3375,
                        "recall": 0.16925465838509318,
                        "f1-score": 0.22534562211981568,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.6633333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.4435023041474654,
                        "support": 45.0
                    }
                },
                "weather_floods_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.25,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.18181818181818182,
                        "support": 7.0
                    },
                    "COEX": {
                        "precision": 0.6,
                        "recall": 0.75,
                        "f1-score": 0.6666666666666665,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.26666666666666666,
                    "macro avg": {
                        "precision": 0.2125,
                        "recall": 0.2232142857142857,
                        "f1-score": 0.2121212121212121,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.27666666666666667,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.2626262626262626,
                        "support": 15.0
                    }
                },
                "sports_1": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.5,
                        "f1-score": 0.5,
                        "support": 2.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 3.0
                    },
                    "macro avg": {
                        "precision": 0.125,
                        "recall": 0.125,
                        "f1-score": 0.125,
                        "support": 3.0
                    },
                    "weighted avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 3.0
                    }
                },
                "health_4": {
                    "AFTER": {
                        "precision": 0.25,
                        "recall": 0.1111111111111111,
                        "f1-score": 0.15384615384615383,
                        "support": 9.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 8.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.047619047619047616,
                    "macro avg": {
                        "precision": 0.0625,
                        "recall": 0.027777777777777776,
                        "f1-score": 0.03846153846153846,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.10714285714285714,
                        "recall": 0.047619047619047616,
                        "f1-score": 0.06593406593406592,
                        "support": 21.0
                    }
                },
                "weather_earthquakes_1": {
                    "AFTER": {
                        "precision": 0.1111111111111111,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.13333333333333333,
                        "support": 6.0
                    },
                    "BEFORE": {
                        "precision": 0.4,
                        "recall": 0.0625,
                        "f1-score": 0.10810810810810811,
                        "support": 32.0
                    },
                    "COEX": {
                        "precision": 0.25,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.18181818181818182,
                        "support": 7.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.08888888888888889,
                    "macro avg": {
                        "precision": 0.19027777777777777,
                        "recall": 0.09300595238095238,
                        "f1-score": 0.10581490581490582,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.33814814814814814,
                        "recall": 0.08888888888888889,
                        "f1-score": 0.12293748293748294,
                        "support": 45.0
                    }
                },
                "space_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.125,
                        "recall": 0.06666666666666667,
                        "f1-score": 0.08695652173913045,
                        "support": 15.0
                    },
                    "COEX": {
                        "precision": 0.3333333333333333,
                        "recall": 0.5,
                        "f1-score": 0.4,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.07142857142857142,
                    "macro avg": {
                        "precision": 0.11458333333333333,
                        "recall": 0.14166666666666666,
                        "f1-score": 0.12173913043478261,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.09077380952380952,
                        "recall": 0.07142857142857142,
                        "f1-score": 0.0751552795031056,
                        "support": 28.0
                    }
                },
                "economy_and_business_strikes_2": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 1.0,
                        "f1-score": 0.6666666666666666,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.5,
                        "f1-score": 0.6666666666666666,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.5,
                    "macro avg": {
                        "precision": 0.375,
                        "recall": 0.375,
                        "f1-score": 0.3333333333333333,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.75,
                        "recall": 0.5,
                        "f1-score": 0.5555555555555555,
                        "support": 6.0
                    }
                },
                "politics_and_conflicts_armed_conflict_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.36363636363636365,
                        "f1-score": 0.5333333333333333,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 3.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.3333333333333333,
                    "macro avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.17424242424242425,
                        "f1-score": 0.21666666666666667,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.8,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.45777777777777773,
                        "support": 15.0
                    }
                },
                "infectious_disease_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    }
                },
                "health_1": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.25,
                        "support": 6.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.1,
                    "macro avg": {
                        "precision": 0.125,
                        "recall": 0.041666666666666664,
                        "f1-score": 0.0625,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.3,
                        "recall": 0.1,
                        "f1-score": 0.15,
                        "support": 10.0
                    }
                },
                "disasters_and_accidents_shipwreck_2": {
                    "AFTER": {
                        "precision": 0.4444444444444444,
                        "recall": 0.36363636363636365,
                        "f1-score": 0.39999999999999997,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.6666666666666666,
                        "recall": 0.2222222222222222,
                        "f1-score": 0.3333333333333333,
                        "support": 9.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2857142857142857,
                    "macro avg": {
                        "precision": 0.2777777777777778,
                        "recall": 0.14646464646464646,
                        "f1-score": 0.18333333333333332,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.5185185185185185,
                        "recall": 0.2857142857142857,
                        "f1-score": 0.35238095238095235,
                        "support": 21.0
                    }
                },
                "rail_transport_3": {
                    "AFTER": {
                        "precision": 0.14285714285714285,
                        "recall": 0.2,
                        "f1-score": 0.16666666666666666,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 10.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.06666666666666667,
                        "recall": 0.06666666666666667,
                        "f1-score": 0.06666666666666667,
                        "support": 15.0
                    },
                    "macro avg": {
                        "precision": 0.03571428571428571,
                        "recall": 0.05,
                        "f1-score": 0.041666666666666664,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.04761904761904761,
                        "recall": 0.06666666666666667,
                        "f1-score": 0.05555555555555555,
                        "support": 15.0
                    }
                },
                "weather_storms_1_extra": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    }
                },
                "health_1_extra": {
                    "AFTER": {
                        "precision": 0.08333333333333333,
                        "recall": 0.08333333333333333,
                        "f1-score": 0.08333333333333333,
                        "support": 12.0
                    },
                    "BEFORE": {
                        "precision": 0.2,
                        "recall": 0.03571428571428571,
                        "f1-score": 0.06060606060606061,
                        "support": 28.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 15.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.03636363636363636,
                    "macro avg": {
                        "precision": 0.07083333333333333,
                        "recall": 0.02976190476190476,
                        "f1-score": 0.03598484848484848,
                        "support": 55.0
                    },
                    "weighted avg": {
                        "precision": 0.12000000000000001,
                        "recall": 0.03636363636363636,
                        "f1-score": 0.04903581267217631,
                        "support": 55.0
                    }
                },
                "weather_floods_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.4,
                        "recall": 0.08333333333333333,
                        "f1-score": 0.13793103448275862,
                        "support": 24.0
                    },
                    "COEX": {
                        "precision": 0.5714285714285714,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.2285714285714286,
                        "support": 28.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.10909090909090909,
                    "macro avg": {
                        "precision": 0.24285714285714285,
                        "recall": 0.05654761904761904,
                        "f1-score": 0.0916256157635468,
                        "support": 55.0
                    },
                    "weighted avg": {
                        "precision": 0.46545454545454545,
                        "recall": 0.10909090909090909,
                        "f1-score": 0.17655172413793102,
                        "support": 55.0
                    }
                },
                "mining_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.14285714285714285,
                        "recall": 0.04,
                        "f1-score": 0.0625,
                        "support": 25.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 9.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.022222222222222223,
                    "macro avg": {
                        "precision": 0.03571428571428571,
                        "recall": 0.01,
                        "f1-score": 0.015625,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.07936507936507936,
                        "recall": 0.022222222222222223,
                        "f1-score": 0.034722222222222224,
                        "support": 45.0
                    }
                },
                "disasters_and_accidents_volcanoes_4": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.15,
                        "f1-score": 0.23076923076923075,
                        "support": 20.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.21428571428571427,
                        "f1-score": 0.3,
                        "support": 14.0
                    },
                    "COEX": {
                        "precision": 0.14285714285714285,
                        "recall": 0.5,
                        "f1-score": 0.22222222222222224,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.19444444444444445,
                    "macro avg": {
                        "precision": 0.2857142857142857,
                        "recall": 0.21607142857142858,
                        "f1-score": 0.18824786324786325,
                        "support": 36.0
                    },
                    "weighted avg": {
                        "precision": 0.4801587301587301,
                        "recall": 0.19444444444444445,
                        "f1-score": 0.25721747388414057,
                        "support": 36.0
                    }
                },
                "politics_and_conflicts_elections_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.6666666666666666,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.4444444444444444,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.13333333333333333,
                    "macro avg": {
                        "precision": 0.16666666666666666,
                        "recall": 0.08333333333333333,
                        "f1-score": 0.1111111111111111,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.26666666666666666,
                        "recall": 0.13333333333333333,
                        "f1-score": 0.17777777777777776,
                        "support": 15.0
                    }
                },
                "economy_and_business_strikes_3": {
                    "AFTER": {
                        "precision": 0.3333333333333333,
                        "recall": 0.1,
                        "f1-score": 0.15384615384615383,
                        "support": 10.0
                    },
                    "BEFORE": {
                        "precision": 0.6666666666666666,
                        "recall": 0.18181818181818182,
                        "f1-score": 0.28571428571428575,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.5,
                        "recall": 0.2857142857142857,
                        "f1-score": 0.36363636363636365,
                        "support": 7.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.17857142857142858,
                    "macro avg": {
                        "precision": 0.375,
                        "recall": 0.1418831168831169,
                        "f1-score": 0.2007992007992008,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.5059523809523809,
                        "recall": 0.17857142857142858,
                        "f1-score": 0.25809904381332954,
                        "support": 28.0
                    }
                },
                "space_2": {
                    "AFTER": {
                        "precision": 0.3684210526315789,
                        "recall": 0.07,
                        "f1-score": 0.11764705882352942,
                        "support": 100.0
                    },
                    "BEFORE": {
                        "precision": 0.2631578947368421,
                        "recall": 0.09803921568627451,
                        "f1-score": 0.14285714285714285,
                        "support": 51.0
                    },
                    "COEX": {
                        "precision": 0.07142857142857142,
                        "recall": 0.5,
                        "f1-score": 0.125,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.08496732026143791,
                    "macro avg": {
                        "precision": 0.1757518796992481,
                        "recall": 0.1670098039215686,
                        "f1-score": 0.09637605042016807,
                        "support": 153.0
                    },
                    "weighted avg": {
                        "precision": 0.32945107867708484,
                        "recall": 0.08496732026143791,
                        "f1-score": 0.12614653704619103,
                        "support": 153.0
                    }
                },
                "politics_and_conflicts_resign_1": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.5,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 3.0
                    },
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.08333333333333333,
                        "f1-score": 0.125,
                        "support": 3.0
                    },
                    "weighted avg": {
                        "precision": 1.0,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.5,
                        "support": 3.0
                    }
                },
                "environment_4": {
                    "AFTER": {
                        "precision": 0.2,
                        "recall": 0.25,
                        "f1-score": 0.22222222222222224,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.3333333333333333,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.2222222222222222,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.13333333333333333,
                    "macro avg": {
                        "precision": 0.13333333333333333,
                        "recall": 0.10416666666666666,
                        "f1-score": 0.1111111111111111,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.18666666666666665,
                        "recall": 0.13333333333333333,
                        "f1-score": 0.14814814814814817,
                        "support": 15.0
                    }
                },
                "space_1_extra": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.2,
                        "f1-score": 0.28571428571428575,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.16666666666666666,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.16666666666666666,
                        "support": 6.0
                    },
                    "macro avg": {
                        "precision": 0.125,
                        "recall": 0.05,
                        "f1-score": 0.07142857142857144,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.4166666666666667,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.23809523809523814,
                        "support": 6.0
                    }
                },
                "health_3": {
                    "AFTER": {
                        "precision": 0.3333333333333333,
                        "recall": 0.125,
                        "f1-score": 0.18181818181818182,
                        "support": 8.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "COEX": {
                        "precision": 0.2,
                        "recall": 1.0,
                        "f1-score": 0.33333333333333337,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.13333333333333333,
                    "macro avg": {
                        "precision": 0.13333333333333333,
                        "recall": 0.28125,
                        "f1-score": 0.12878787878787878,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.19111111111111112,
                        "recall": 0.13333333333333333,
                        "f1-score": 0.11919191919191921,
                        "support": 15.0
                    }
                },
                "environment_3": {
                    "AFTER": {
                        "precision": 0.6,
                        "recall": 0.2727272727272727,
                        "f1-score": 0.37499999999999994,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.3333333333333333,
                        "recall": 0.5,
                        "f1-score": 0.4,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.26666666666666666,
                    "macro avg": {
                        "precision": 0.23333333333333334,
                        "recall": 0.19318181818181818,
                        "f1-score": 0.19374999999999998,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.48444444444444446,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.32833333333333325,
                        "support": 15.0
                    }
                },
                "government_and_politics_protests_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.0,
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    }
                },
                "economy_and_business_financial_crisis_4": {
                    "AFTER": {
                        "precision": 0.3333333333333333,
                        "recall": 0.08333333333333333,
                        "f1-score": 0.13333333333333333,
                        "support": 12.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.047619047619047616,
                    "macro avg": {
                        "precision": 0.08333333333333333,
                        "recall": 0.020833333333333332,
                        "f1-score": 0.03333333333333333,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.19047619047619047,
                        "recall": 0.047619047619047616,
                        "f1-score": 0.0761904761904762,
                        "support": 21.0
                    }
                },
                "computers_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    }
                },
                "crime_and_law_accuse_4": {
                    "AFTER": {
                        "precision": 0.3333333333333333,
                        "recall": 0.2,
                        "f1-score": 0.25,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 0.2,
                        "f1-score": 0.25,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2,
                    "macro avg": {
                        "precision": 0.16666666666666666,
                        "recall": 0.1,
                        "f1-score": 0.125,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.2,
                        "f1-score": 0.25,
                        "support": 10.0
                    }
                },
                "culture_and_entertainment_1": {
                    "AFTER": {
                        "precision": 0.25,
                        "recall": 0.5,
                        "f1-score": 0.3333333333333333,
                        "support": 2.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 1.0,
                        "recall": 0.5,
                        "f1-score": 0.6666666666666666,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 6.0
                    },
                    "macro avg": {
                        "precision": 0.3125,
                        "recall": 0.25,
                        "f1-score": 0.25,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.4166666666666667,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 6.0
                    }
                },
                "internet_2": {
                    "AFTER": {
                        "precision": 0.6666666666666666,
                        "recall": 0.4,
                        "f1-score": 0.5,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2,
                    "macro avg": {
                        "precision": 0.16666666666666666,
                        "recall": 0.1,
                        "f1-score": 0.125,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.2,
                        "f1-score": 0.25,
                        "support": 10.0
                    }
                },
                "culture_and_entertainment_3": {
                    "AFTER": {
                        "precision": 0.75,
                        "recall": 0.6,
                        "f1-score": 0.6666666666666665,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.6666666666666666,
                        "recall": 0.5,
                        "f1-score": 0.5714285714285715,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.5,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.4,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.4666666666666667,
                    "macro avg": {
                        "precision": 0.47916666666666663,
                        "recall": 0.35833333333333334,
                        "f1-score": 0.4095238095238095,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.6277777777777778,
                        "recall": 0.4666666666666667,
                        "f1-score": 0.5346031746031746,
                        "support": 15.0
                    }
                }
            },
            "qa_events": {
                "government_and_politics_riots_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.6666666666666666,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.26666666666666666,
                        "support": 12.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 12.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.07142857142857142,
                    "macro avg": {
                        "precision": 0.16666666666666666,
                        "recall": 0.041666666666666664,
                        "f1-score": 0.06666666666666667,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.2857142857142857,
                        "recall": 0.07142857142857142,
                        "f1-score": 0.1142857142857143,
                        "support": 28.0
                    }
                },
                "rail_transport_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.11764705882352941,
                        "f1-score": 0.21052631578947367,
                        "support": 34.0
                    },
                    "COEX": {
                        "precision": 0.16666666666666666,
                        "recall": 0.5,
                        "f1-score": 0.25,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.1388888888888889,
                    "macro avg": {
                        "precision": 0.2916666666666667,
                        "recall": 0.15441176470588236,
                        "f1-score": 0.11513157894736842,
                        "support": 36.0
                    },
                    "weighted avg": {
                        "precision": 0.9537037037037037,
                        "recall": 0.1388888888888889,
                        "f1-score": 0.212719298245614,
                        "support": 36.0
                    }
                },
                "politics_and_conflicts_policy_change_2": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.4,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.3333333333333333,
                    "macro avg": {
                        "precision": 0.375,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.35,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.4166666666666667,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3666666666666667,
                        "support": 6.0
                    }
                },
                "politics_and_conflicts_drones_1": {
                    "AFTER": {
                        "precision": 0.3333333333333333,
                        "recall": 0.09090909090909091,
                        "f1-score": 0.14285714285714288,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 8.0
                    },
                    "COEX": {
                        "precision": 0.16666666666666666,
                        "recall": 0.5,
                        "f1-score": 0.25,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.09523809523809523,
                    "macro avg": {
                        "precision": 0.125,
                        "recall": 0.14772727272727273,
                        "f1-score": 0.09821428571428573,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.19047619047619047,
                        "recall": 0.09523809523809523,
                        "f1-score": 0.09863945578231294,
                        "support": 21.0
                    }
                },
                "disasters_and_accidents_road_crash_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 10.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.0,
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 21.0
                    }
                },
                "crime_and_law_accuse_3": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.25,
                        "f1-score": 0.3333333333333333,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.6666666666666666,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.4444444444444444,
                        "support": 6.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.3,
                    "macro avg": {
                        "precision": 0.29166666666666663,
                        "recall": 0.14583333333333331,
                        "f1-score": 0.19444444444444442,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.6,
                        "recall": 0.3,
                        "f1-score": 0.4,
                        "support": 10.0
                    }
                },
                "government_and_politics_protests_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 20.0
                    },
                    "COEX": {
                        "precision": 0.5,
                        "recall": 0.6666666666666666,
                        "f1-score": 0.5714285714285715,
                        "support": 3.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.07142857142857142,
                    "macro avg": {
                        "precision": 0.125,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.14285714285714288,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.05357142857142857,
                        "recall": 0.07142857142857142,
                        "f1-score": 0.06122448979591837,
                        "support": 28.0
                    }
                },
                "politics_and_conflicts_elections_2": {
                    "AFTER": {
                        "precision": 0.2857142857142857,
                        "recall": 0.09090909090909091,
                        "f1-score": 0.13793103448275862,
                        "support": 22.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 14.0
                    },
                    "COEX": {
                        "precision": 0.6,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.42857142857142855,
                        "support": 9.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.1111111111111111,
                    "macro avg": {
                        "precision": 0.22142857142857142,
                        "recall": 0.10606060606060605,
                        "f1-score": 0.1416256157635468,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.2596825396825397,
                        "recall": 0.1111111111111111,
                        "f1-score": 0.15314723590585658,
                        "support": 45.0
                    }
                },
                "environment_2": {
                    "AFTER": {
                        "precision": 0.6666666666666666,
                        "recall": 0.38095238095238093,
                        "f1-score": 0.4848484848484849,
                        "support": 21.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 23.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.17777777777777778,
                    "macro avg": {
                        "precision": 0.16666666666666666,
                        "recall": 0.09523809523809523,
                        "f1-score": 0.12121212121212123,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.3111111111111111,
                        "recall": 0.17777777777777778,
                        "f1-score": 0.2262626262626263,
                        "support": 45.0
                    }
                },
                "weather_floods_3": {
                    "AFTER": {
                        "precision": 0.2,
                        "recall": 0.25,
                        "f1-score": 0.22222222222222224,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 7.0
                    },
                    "COEX": {
                        "precision": 0.75,
                        "recall": 0.75,
                        "f1-score": 0.75,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.26666666666666666,
                    "macro avg": {
                        "precision": 0.2375,
                        "recall": 0.25,
                        "f1-score": 0.24305555555555555,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.2533333333333333,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.25925925925925924,
                        "support": 15.0
                    }
                },
                "sports_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    }
                },
                "health_4": {
                    "AFTER": {
                        "precision": 0.6,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.42857142857142855,
                        "support": 9.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 8.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.14285714285714285,
                    "macro avg": {
                        "precision": 0.15,
                        "recall": 0.08333333333333333,
                        "f1-score": 0.10714285714285714,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.2571428571428571,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.18367346938775508,
                        "support": 21.0
                    }
                },
                "weather_earthquakes_1": {
                    "AFTER": {
                        "precision": 0.05555555555555555,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.08333333333333333,
                        "support": 6.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.09375,
                        "f1-score": 0.17142857142857143,
                        "support": 32.0
                    },
                    "COEX": {
                        "precision": 0.3333333333333333,
                        "recall": 0.42857142857142855,
                        "f1-score": 0.375,
                        "support": 7.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.15555555555555556,
                    "macro avg": {
                        "precision": 0.3472222222222222,
                        "recall": 0.17224702380952378,
                        "f1-score": 0.1574404761904762,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.7703703703703705,
                        "recall": 0.15555555555555556,
                        "f1-score": 0.19134920634920635,
                        "support": 45.0
                    }
                },
                "space_4": {
                    "AFTER": {
                        "precision": 0.3333333333333333,
                        "recall": 0.09090909090909091,
                        "f1-score": 0.14285714285714288,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.2,
                        "recall": 0.06666666666666667,
                        "f1-score": 0.1,
                        "support": 15.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.07142857142857142,
                    "macro avg": {
                        "precision": 0.13333333333333333,
                        "recall": 0.0393939393939394,
                        "f1-score": 0.06071428571428572,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.23809523809523808,
                        "recall": 0.07142857142857142,
                        "f1-score": 0.10969387755102042,
                        "support": 28.0
                    }
                },
                "economy_and_business_strikes_2": {
                    "AFTER": {
                        "precision": 0.3333333333333333,
                        "recall": 1.0,
                        "f1-score": 0.5,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.25,
                        "f1-score": 0.4,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.5,
                    "macro avg": {
                        "precision": 0.5833333333333333,
                        "recall": 0.5625,
                        "f1-score": 0.475,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.8888888888888888,
                        "recall": 0.5,
                        "f1-score": 0.5166666666666667,
                        "support": 6.0
                    }
                },
                "politics_and_conflicts_armed_conflict_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.2727272727272727,
                        "f1-score": 0.42857142857142855,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.4,
                        "recall": 0.6666666666666666,
                        "f1-score": 0.5,
                        "support": 3.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.3333333333333333,
                    "macro avg": {
                        "precision": 0.35,
                        "recall": 0.23484848484848483,
                        "f1-score": 0.23214285714285715,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.8133333333333332,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.4142857142857143,
                        "support": 15.0
                    }
                },
                "infectious_disease_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    }
                },
                "health_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.0,
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 10.0
                    }
                },
                "disasters_and_accidents_shipwreck_2": {
                    "AFTER": {
                        "precision": 0.375,
                        "recall": 0.2727272727272727,
                        "f1-score": 0.3157894736842105,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 9.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.14285714285714285,
                    "macro avg": {
                        "precision": 0.09375,
                        "recall": 0.06818181818181818,
                        "f1-score": 0.07894736842105263,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.19642857142857142,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.16541353383458646,
                        "support": 21.0
                    }
                },
                "rail_transport_3": {
                    "AFTER": {
                        "precision": 0.3333333333333333,
                        "recall": 0.2,
                        "f1-score": 0.25,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 10.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.06666666666666667,
                    "macro avg": {
                        "precision": 0.08333333333333333,
                        "recall": 0.05,
                        "f1-score": 0.0625,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.1111111111111111,
                        "recall": 0.06666666666666667,
                        "f1-score": 0.08333333333333333,
                        "support": 15.0
                    }
                },
                "weather_storms_1_extra": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    }
                },
                "health_1_extra": {
                    "AFTER": {
                        "precision": 0.06666666666666667,
                        "recall": 0.08333333333333333,
                        "f1-score": 0.07407407407407407,
                        "support": 12.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 28.0
                    },
                    "COEX": {
                        "precision": 0.4,
                        "recall": 0.13333333333333333,
                        "f1-score": 0.2,
                        "support": 15.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.05454545454545454,
                    "macro avg": {
                        "precision": 0.11666666666666667,
                        "recall": 0.05416666666666667,
                        "f1-score": 0.06851851851851852,
                        "support": 55.0
                    },
                    "weighted avg": {
                        "precision": 0.12363636363636363,
                        "recall": 0.05454545454545454,
                        "f1-score": 0.0707070707070707,
                        "support": 55.0
                    }
                },
                "weather_floods_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.375,
                        "recall": 0.125,
                        "f1-score": 0.1875,
                        "support": 24.0
                    },
                    "COEX": {
                        "precision": 0.5,
                        "recall": 0.10714285714285714,
                        "f1-score": 0.17647058823529413,
                        "support": 28.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.10909090909090909,
                    "macro avg": {
                        "precision": 0.21875,
                        "recall": 0.05803571428571429,
                        "f1-score": 0.09099264705882354,
                        "support": 55.0
                    },
                    "weighted avg": {
                        "precision": 0.41818181818181815,
                        "recall": 0.10909090909090909,
                        "f1-score": 0.1716577540106952,
                        "support": 55.0
                    }
                },
                "mining_4": {
                    "AFTER": {
                        "precision": 0.15384615384615385,
                        "recall": 0.18181818181818182,
                        "f1-score": 0.16666666666666669,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.08,
                        "f1-score": 0.14814814814814814,
                        "support": 25.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 9.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.08888888888888889,
                    "macro avg": {
                        "precision": 0.28846153846153844,
                        "recall": 0.06545454545454546,
                        "f1-score": 0.0787037037037037,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.5931623931623932,
                        "recall": 0.08888888888888889,
                        "f1-score": 0.12304526748971192,
                        "support": 45.0
                    }
                },
                "disasters_and_accidents_volcanoes_4": {
                    "AFTER": {
                        "precision": 0.6,
                        "recall": 0.15,
                        "f1-score": 0.24,
                        "support": 20.0
                    },
                    "BEFORE": {
                        "precision": 0.4,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.21052631578947364,
                        "support": 14.0
                    },
                    "COEX": {
                        "precision": 0.14285714285714285,
                        "recall": 0.5,
                        "f1-score": 0.22222222222222224,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.16666666666666666,
                    "macro avg": {
                        "precision": 0.2857142857142857,
                        "recall": 0.1982142857142857,
                        "f1-score": 0.16818713450292397,
                        "support": 36.0
                    },
                    "weighted avg": {
                        "precision": 0.49682539682539684,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.22755035737491877,
                        "support": 36.0
                    }
                },
                "politics_and_conflicts_elections_3": {
                    "AFTER": {
                        "precision": 0.14285714285714285,
                        "recall": 0.2,
                        "f1-score": 0.16666666666666666,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.5,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.25,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.13333333333333333,
                    "macro avg": {
                        "precision": 0.1607142857142857,
                        "recall": 0.09166666666666667,
                        "f1-score": 0.10416666666666666,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.24761904761904763,
                        "recall": 0.13333333333333333,
                        "f1-score": 0.15555555555555553,
                        "support": 15.0
                    }
                },
                "economy_and_business_strikes_3": {
                    "AFTER": {
                        "precision": 0.3333333333333333,
                        "recall": 0.2,
                        "f1-score": 0.25,
                        "support": 10.0
                    },
                    "BEFORE": {
                        "precision": 0.25,
                        "recall": 0.09090909090909091,
                        "f1-score": 0.13333333333333333,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.4,
                        "recall": 0.2857142857142857,
                        "f1-score": 0.3333333333333333,
                        "support": 7.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.17857142857142858,
                    "macro avg": {
                        "precision": 0.24583333333333332,
                        "recall": 0.14415584415584415,
                        "f1-score": 0.17916666666666664,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.31726190476190474,
                        "recall": 0.17857142857142858,
                        "f1-score": 0.225,
                        "support": 28.0
                    }
                },
                "space_2": {
                    "AFTER": {
                        "precision": 0.29411764705882354,
                        "recall": 0.05,
                        "f1-score": 0.08547008547008549,
                        "support": 100.0
                    },
                    "BEFORE": {
                        "precision": 0.2857142857142857,
                        "recall": 0.0784313725490196,
                        "f1-score": 0.12307692307692307,
                        "support": 51.0
                    },
                    "COEX": {
                        "precision": 0.08333333333333333,
                        "recall": 0.5,
                        "f1-score": 0.14285714285714285,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.06535947712418301,
                    "macro avg": {
                        "precision": 0.16579131652661064,
                        "recall": 0.1571078431372549,
                        "f1-score": 0.08785103785103784,
                        "support": 153.0
                    },
                    "weighted avg": {
                        "precision": 0.28856117610442866,
                        "recall": 0.06535947712418301,
                        "f1-score": 0.09875585561860073,
                        "support": 153.0
                    }
                },
                "politics_and_conflicts_resign_1": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.5,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 3.0
                    },
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.08333333333333333,
                        "f1-score": 0.125,
                        "support": 3.0
                    },
                    "weighted avg": {
                        "precision": 1.0,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.5,
                        "support": 3.0
                    }
                },
                "environment_4": {
                    "AFTER": {
                        "precision": 0.42857142857142855,
                        "recall": 0.75,
                        "f1-score": 0.5454545454545454,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.2,
                        "f1-score": 0.28571428571428575,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.5,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.25,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.3333333333333333,
                    "macro avg": {
                        "precision": 0.35714285714285715,
                        "recall": 0.2791666666666667,
                        "f1-score": 0.2702922077922078,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.48095238095238096,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3406926406926407,
                        "support": 15.0
                    }
                },
                "space_1_extra": {
                    "AFTER": {
                        "precision": 0.3333333333333333,
                        "recall": 1.0,
                        "f1-score": 0.5,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.2,
                        "f1-score": 0.33333333333333337,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.3333333333333333,
                    "macro avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3,
                        "f1-score": 0.20833333333333334,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.8888888888888888,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.36111111111111116,
                        "support": 6.0
                    }
                },
                "health_3": {
                    "AFTER": {
                        "precision": 0.2,
                        "recall": 0.125,
                        "f1-score": 0.15384615384615385,
                        "support": 8.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.06666666666666667,
                    "macro avg": {
                        "precision": 0.05,
                        "recall": 0.03125,
                        "f1-score": 0.038461538461538464,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.10666666666666667,
                        "recall": 0.06666666666666667,
                        "f1-score": 0.08205128205128205,
                        "support": 15.0
                    }
                },
                "environment_3": {
                    "AFTER": {
                        "precision": 0.8,
                        "recall": 0.36363636363636365,
                        "f1-score": 0.5000000000000001,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.5,
                        "f1-score": 0.5,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.3333333333333333,
                    "macro avg": {
                        "precision": 0.325,
                        "recall": 0.2159090909090909,
                        "f1-score": 0.25,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.6533333333333334,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.4333333333333334,
                        "support": 15.0
                    }
                },
                "government_and_politics_protests_3": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.25,
                        "f1-score": 0.3333333333333333,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "COEX": {
                        "precision": 0.5,
                        "recall": 1.0,
                        "f1-score": 0.6666666666666666,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.3333333333333333,
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.3125,
                        "f1-score": 0.25,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.4166666666666667,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 6.0
                    }
                },
                "economy_and_business_financial_crisis_4": {
                    "AFTER": {
                        "precision": 0.4,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.23529411764705882,
                        "support": 12.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.25,
                        "recall": 0.25,
                        "f1-score": 0.25,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.14285714285714285,
                    "macro avg": {
                        "precision": 0.1625,
                        "recall": 0.10416666666666666,
                        "f1-score": 0.1213235294117647,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.2761904761904762,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.18207282913165265,
                        "support": 21.0
                    }
                },
                "computers_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    }
                },
                "crime_and_law_accuse_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.0,
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 10.0
                    }
                },
                "culture_and_entertainment_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    }
                },
                "internet_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.0,
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 10.0
                    }
                },
                "culture_and_entertainment_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 0.25,
                        "f1-score": 0.28571428571428575,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.75,
                        "recall": 0.5,
                        "f1-score": 0.6,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.26666666666666666,
                    "macro avg": {
                        "precision": 0.2708333333333333,
                        "recall": 0.1875,
                        "f1-score": 0.22142857142857142,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.3888888888888889,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.3161904761904762,
                        "support": 15.0
                    }
                }
            },
            "refer": {
                "government_and_politics_riots_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.75,
                        "recall": 0.25,
                        "f1-score": 0.375,
                        "support": 12.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 12.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.10714285714285714,
                    "macro avg": {
                        "precision": 0.1875,
                        "recall": 0.0625,
                        "f1-score": 0.09375,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.32142857142857145,
                        "recall": 0.10714285714285714,
                        "f1-score": 0.16071428571428573,
                        "support": 28.0
                    }
                },
                "rail_transport_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "BEFORE": {
                        "precision": 0.8,
                        "recall": 0.11764705882352941,
                        "f1-score": 0.20512820512820512,
                        "support": 34.0
                    },
                    "COEX": {
                        "precision": 0.25,
                        "recall": 0.5,
                        "f1-score": 0.3333333333333333,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.1388888888888889,
                    "macro avg": {
                        "precision": 0.2625,
                        "recall": 0.15441176470588236,
                        "f1-score": 0.1346153846153846,
                        "support": 36.0
                    },
                    "weighted avg": {
                        "precision": 0.7694444444444445,
                        "recall": 0.1388888888888889,
                        "f1-score": 0.21225071225071226,
                        "support": 36.0
                    }
                },
                "politics_and_conflicts_policy_change_2": {
                    "AFTER": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.16666666666666666,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.16666666666666666,
                        "support": 6.0
                    },
                    "macro avg": {
                        "precision": 0.08333333333333333,
                        "recall": 0.08333333333333333,
                        "f1-score": 0.08333333333333333,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.16666666666666666,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.16666666666666666,
                        "support": 6.0
                    }
                },
                "politics_and_conflicts_drones_1": {
                    "AFTER": {
                        "precision": 0.42857142857142855,
                        "recall": 0.2727272727272727,
                        "f1-score": 0.33333333333333326,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 8.0
                    },
                    "COEX": {
                        "precision": 0.2,
                        "recall": 0.5,
                        "f1-score": 0.28571428571428575,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.19047619047619047,
                    "macro avg": {
                        "precision": 0.15714285714285714,
                        "recall": 0.19318181818181818,
                        "f1-score": 0.15476190476190477,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.2435374149659864,
                        "recall": 0.19047619047619047,
                        "f1-score": 0.20181405895691606,
                        "support": 21.0
                    }
                },
                "disasters_and_accidents_road_crash_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "BEFORE": {
                        "precision": 0.25,
                        "recall": 0.09090909090909091,
                        "f1-score": 0.13333333333333333,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 10.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.047619047619047616,
                    "macro avg": {
                        "precision": 0.0625,
                        "recall": 0.022727272727272728,
                        "f1-score": 0.03333333333333333,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.13095238095238096,
                        "recall": 0.047619047619047616,
                        "f1-score": 0.06984126984126984,
                        "support": 21.0
                    }
                },
                "crime_and_law_accuse_3": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.5,
                        "f1-score": 0.5,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2,
                    "macro avg": {
                        "precision": 0.125,
                        "recall": 0.125,
                        "f1-score": 0.125,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.2,
                        "recall": 0.2,
                        "f1-score": 0.2,
                        "support": 10.0
                    }
                },
                "government_and_politics_protests_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.05,
                        "f1-score": 0.09090909090909091,
                        "support": 20.0
                    },
                    "COEX": {
                        "precision": 0.25,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.28571428571428575,
                        "support": 3.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.07142857142857142,
                    "macro avg": {
                        "precision": 0.1875,
                        "recall": 0.09583333333333333,
                        "f1-score": 0.09415584415584416,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.38392857142857145,
                        "recall": 0.07142857142857142,
                        "f1-score": 0.09554730983302413,
                        "support": 28.0
                    }
                },
                "politics_and_conflicts_elections_2": {
                    "AFTER": {
                        "precision": 0.5714285714285714,
                        "recall": 0.18181818181818182,
                        "f1-score": 0.27586206896551724,
                        "support": 22.0
                    },
                    "BEFORE": {
                        "precision": 0.14285714285714285,
                        "recall": 0.07142857142857142,
                        "f1-score": 0.09523809523809523,
                        "support": 14.0
                    },
                    "COEX": {
                        "precision": 0.3333333333333333,
                        "recall": 0.1111111111111111,
                        "f1-score": 0.16666666666666666,
                        "support": 9.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.13333333333333333,
                    "macro avg": {
                        "precision": 0.26190476190476186,
                        "recall": 0.0910894660894661,
                        "f1-score": 0.13444170771756978,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.3904761904761904,
                        "recall": 0.13333333333333333,
                        "f1-score": 0.19782886334610472,
                        "support": 45.0
                    }
                },
                "environment_2": {
                    "AFTER": {
                        "precision": 0.25,
                        "recall": 0.09523809523809523,
                        "f1-score": 0.13793103448275862,
                        "support": 21.0
                    },
                    "BEFORE": {
                        "precision": 0.375,
                        "recall": 0.13043478260869565,
                        "f1-score": 0.19354838709677416,
                        "support": 23.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.1111111111111111,
                    "macro avg": {
                        "precision": 0.15625,
                        "recall": 0.05641821946169772,
                        "f1-score": 0.0828698553948832,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.30833333333333335,
                        "recall": 0.1111111111111111,
                        "f1-score": 0.1632925472747497,
                        "support": 45.0
                    }
                },
                "weather_floods_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 7.0
                    },
                    "COEX": {
                        "precision": 0.25,
                        "recall": 0.25,
                        "f1-score": 0.25,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.06666666666666667,
                    "macro avg": {
                        "precision": 0.0625,
                        "recall": 0.0625,
                        "f1-score": 0.0625,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.06666666666666667,
                        "recall": 0.06666666666666667,
                        "f1-score": 0.06666666666666667,
                        "support": 15.0
                    }
                },
                "sports_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    }
                },
                "health_4": {
                    "AFTER": {
                        "precision": 0.25,
                        "recall": 0.1111111111111111,
                        "f1-score": 0.15384615384615383,
                        "support": 9.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.25,
                        "f1-score": 0.3333333333333333,
                        "support": 8.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.14285714285714285,
                    "macro avg": {
                        "precision": 0.1875,
                        "recall": 0.09027777777777778,
                        "f1-score": 0.12179487179487178,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.2976190476190476,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.1929181929181929,
                        "support": 21.0
                    }
                },
                "weather_earthquakes_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "BEFORE": {
                        "precision": 0.6666666666666666,
                        "recall": 0.125,
                        "f1-score": 0.21052631578947367,
                        "support": 32.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 7.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.08888888888888889,
                    "macro avg": {
                        "precision": 0.16666666666666666,
                        "recall": 0.03125,
                        "f1-score": 0.05263157894736842,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.47407407407407404,
                        "recall": 0.08888888888888889,
                        "f1-score": 0.1497076023391813,
                        "support": 45.0
                    }
                },
                "space_4": {
                    "AFTER": {
                        "precision": 0.5555555555555556,
                        "recall": 0.45454545454545453,
                        "f1-score": 0.5,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 15.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.17857142857142858,
                    "macro avg": {
                        "precision": 0.1388888888888889,
                        "recall": 0.11363636363636363,
                        "f1-score": 0.125,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.21825396825396828,
                        "recall": 0.17857142857142858,
                        "f1-score": 0.19642857142857142,
                        "support": 28.0
                    }
                },
                "economy_and_business_strikes_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.75,
                        "f1-score": 0.8571428571428571,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.5,
                        "recall": 1.0,
                        "f1-score": 0.6666666666666666,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.6666666666666666,
                    "macro avg": {
                        "precision": 0.375,
                        "recall": 0.4375,
                        "f1-score": 0.38095238095238093,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.75,
                        "recall": 0.6666666666666666,
                        "f1-score": 0.6825396825396824,
                        "support": 6.0
                    }
                },
                "politics_and_conflicts_armed_conflict_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.6666666666666666,
                        "recall": 0.18181818181818182,
                        "f1-score": 0.28571428571428575,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.13333333333333333,
                    "macro avg": {
                        "precision": 0.16666666666666666,
                        "recall": 0.045454545454545456,
                        "f1-score": 0.07142857142857144,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.4888888888888889,
                        "recall": 0.13333333333333333,
                        "f1-score": 0.20952380952380956,
                        "support": 15.0
                    }
                },
                "infectious_disease_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    }
                },
                "health_1": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.4,
                        "support": 6.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.5,
                        "support": 3.0
                    },
                    "COEX": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.4,
                    "macro avg": {
                        "precision": 0.625,
                        "recall": 0.41666666666666663,
                        "f1-score": 0.475,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.7,
                        "recall": 0.4,
                        "f1-score": 0.49000000000000005,
                        "support": 10.0
                    }
                },
                "disasters_and_accidents_shipwreck_2": {
                    "AFTER": {
                        "precision": 0.6,
                        "recall": 0.2727272727272727,
                        "f1-score": 0.37499999999999994,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.2222222222222222,
                        "f1-score": 0.30769230769230765,
                        "support": 9.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.23809523809523808,
                    "macro avg": {
                        "precision": 0.275,
                        "recall": 0.12373737373737373,
                        "f1-score": 0.1706730769230769,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.5285714285714286,
                        "recall": 0.23809523809523808,
                        "f1-score": 0.32829670329670324,
                        "support": 21.0
                    }
                },
                "rail_transport_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.6666666666666666,
                        "recall": 0.2,
                        "f1-score": 0.30769230769230765,
                        "support": 10.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.13333333333333333,
                    "macro avg": {
                        "precision": 0.16666666666666666,
                        "recall": 0.05,
                        "f1-score": 0.07692307692307691,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.4444444444444444,
                        "recall": 0.13333333333333333,
                        "f1-score": 0.20512820512820512,
                        "support": 15.0
                    }
                },
                "weather_storms_1_extra": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    }
                },
                "health_1_extra": {
                    "AFTER": {
                        "precision": 0.25,
                        "recall": 0.25,
                        "f1-score": 0.25,
                        "support": 12.0
                    },
                    "BEFORE": {
                        "precision": 0.75,
                        "recall": 0.10714285714285714,
                        "f1-score": 0.1875,
                        "support": 28.0
                    },
                    "COEX": {
                        "precision": 0.2857142857142857,
                        "recall": 0.13333333333333333,
                        "f1-score": 0.18181818181818182,
                        "support": 15.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.14545454545454545,
                    "macro avg": {
                        "precision": 0.3214285714285714,
                        "recall": 0.12261904761904763,
                        "f1-score": 0.15482954545454547,
                        "support": 55.0
                    },
                    "weighted avg": {
                        "precision": 0.5142857142857142,
                        "recall": 0.14545454545454545,
                        "f1-score": 0.19958677685950413,
                        "support": 55.0
                    }
                },
                "weather_floods_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.2,
                        "recall": 0.041666666666666664,
                        "f1-score": 0.06896551724137931,
                        "support": 24.0
                    },
                    "COEX": {
                        "precision": 0.6,
                        "recall": 0.10714285714285714,
                        "f1-score": 0.18181818181818182,
                        "support": 28.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.07272727272727272,
                    "macro avg": {
                        "precision": 0.2,
                        "recall": 0.03720238095238095,
                        "f1-score": 0.06269592476489028,
                        "support": 55.0
                    },
                    "weighted avg": {
                        "precision": 0.39272727272727276,
                        "recall": 0.07272727272727272,
                        "f1-score": 0.1226560273582217,
                        "support": 55.0
                    }
                },
                "mining_4": {
                    "AFTER": {
                        "precision": 0.25,
                        "recall": 0.18181818181818182,
                        "f1-score": 0.2105263157894737,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 0.08,
                        "f1-score": 0.12903225806451613,
                        "support": 25.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 9.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.08888888888888889,
                    "macro avg": {
                        "precision": 0.14583333333333331,
                        "recall": 0.06545454545454546,
                        "f1-score": 0.08488964346349745,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.24629629629629626,
                        "recall": 0.08888888888888889,
                        "f1-score": 0.12314657611771364,
                        "support": 45.0
                    }
                },
                "disasters_and_accidents_volcanoes_4": {
                    "AFTER": {
                        "precision": 0.8,
                        "recall": 0.2,
                        "f1-score": 0.32000000000000006,
                        "support": 20.0
                    },
                    "BEFORE": {
                        "precision": 0.2857142857142857,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.19047619047619047,
                        "support": 14.0
                    },
                    "COEX": {
                        "precision": 0.14285714285714285,
                        "recall": 0.5,
                        "f1-score": 0.22222222222222224,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.19444444444444445,
                    "macro avg": {
                        "precision": 0.30714285714285716,
                        "recall": 0.21071428571428572,
                        "f1-score": 0.18317460317460318,
                        "support": 36.0
                    },
                    "weighted avg": {
                        "precision": 0.5634920634920635,
                        "recall": 0.19444444444444445,
                        "f1-score": 0.26419753086419756,
                        "support": 36.0
                    }
                },
                "politics_and_conflicts_elections_3": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.4,
                        "f1-score": 0.5714285714285715,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.5,
                        "f1-score": 0.5,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 1.0,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.5,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.4,
                    "macro avg": {
                        "precision": 0.625,
                        "recall": 0.30833333333333335,
                        "f1-score": 0.3928571428571429,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.8666666666666667,
                        "recall": 0.4,
                        "f1-score": 0.5238095238095238,
                        "support": 15.0
                    }
                },
                "economy_and_business_strikes_3": {
                    "AFTER": {
                        "precision": 0.14285714285714285,
                        "recall": 0.1,
                        "f1-score": 0.11764705882352941,
                        "support": 10.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 0.18181818181818182,
                        "f1-score": 0.23529411764705885,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.6,
                        "recall": 0.42857142857142855,
                        "f1-score": 0.5,
                        "support": 7.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.21428571428571427,
                    "macro avg": {
                        "precision": 0.26904761904761904,
                        "recall": 0.1775974025974026,
                        "f1-score": 0.21323529411764708,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.3319727891156462,
                        "recall": 0.21428571428571427,
                        "f1-score": 0.25945378151260506,
                        "support": 28.0
                    }
                },
                "space_2": {
                    "AFTER": {
                        "precision": 0.25,
                        "recall": 0.05,
                        "f1-score": 0.08333333333333334,
                        "support": 100.0
                    },
                    "BEFORE": {
                        "precision": 0.1,
                        "recall": 0.0196078431372549,
                        "f1-score": 0.032786885245901634,
                        "support": 51.0
                    },
                    "COEX": {
                        "precision": 0.07692307692307693,
                        "recall": 0.5,
                        "f1-score": 0.13333333333333336,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.0457516339869281,
                    "macro avg": {
                        "precision": 0.10673076923076923,
                        "recall": 0.14240196078431372,
                        "f1-score": 0.06236338797814209,
                        "support": 153.0
                    },
                    "weighted avg": {
                        "precision": 0.197737556561086,
                        "recall": 0.0457516339869281,
                        "f1-score": 0.06713811207543127,
                        "support": 153.0
                    }
                },
                "politics_and_conflicts_resign_1": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.5,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 3.0
                    },
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.08333333333333333,
                        "f1-score": 0.125,
                        "support": 3.0
                    },
                    "weighted avg": {
                        "precision": 1.0,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.5,
                        "support": 3.0
                    }
                },
                "environment_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.4,
                        "f1-score": 0.4444444444444445,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 1.0,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.5,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.26666666666666666,
                    "macro avg": {
                        "precision": 0.375,
                        "recall": 0.18333333333333335,
                        "f1-score": 0.2361111111111111,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.5666666666666667,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.34814814814814815,
                        "support": 15.0
                    }
                },
                "space_1_extra": {
                    "AFTER": {
                        "precision": 0.25,
                        "recall": 1.0,
                        "f1-score": 0.4,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.16666666666666666,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.16666666666666666,
                        "support": 6.0
                    },
                    "macro avg": {
                        "precision": 0.0625,
                        "recall": 0.25,
                        "f1-score": 0.1,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.041666666666666664,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.06666666666666667,
                        "support": 6.0
                    }
                },
                "health_3": {
                    "AFTER": {
                        "precision": 0.4,
                        "recall": 0.25,
                        "f1-score": 0.3076923076923077,
                        "support": 8.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.2222222222222222,
                        "support": 6.0
                    },
                    "COEX": {
                        "precision": 0.3333333333333333,
                        "recall": 1.0,
                        "f1-score": 0.5,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.26666666666666666,
                    "macro avg": {
                        "precision": 0.26666666666666666,
                        "recall": 0.35416666666666663,
                        "f1-score": 0.25747863247863245,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.3688888888888889,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.2863247863247863,
                        "support": 15.0
                    }
                },
                "environment_3": {
                    "AFTER": {
                        "precision": 0.3333333333333333,
                        "recall": 0.09090909090909091,
                        "f1-score": 0.14285714285714288,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.25,
                        "recall": 0.5,
                        "f1-score": 0.3333333333333333,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.13333333333333333,
                    "macro avg": {
                        "precision": 0.14583333333333331,
                        "recall": 0.14772727272727273,
                        "f1-score": 0.11904761904761904,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.27777777777777773,
                        "recall": 0.13333333333333333,
                        "f1-score": 0.1492063492063492,
                        "support": 15.0
                    }
                },
                "government_and_politics_protests_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "COEX": {
                        "precision": 0.5,
                        "recall": 1.0,
                        "f1-score": 0.6666666666666666,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.16666666666666666,
                    "macro avg": {
                        "precision": 0.125,
                        "recall": 0.25,
                        "f1-score": 0.16666666666666666,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.08333333333333333,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.1111111111111111,
                        "support": 6.0
                    }
                },
                "economy_and_business_financial_crisis_4": {
                    "AFTER": {
                        "precision": 0.42857142857142855,
                        "recall": 0.25,
                        "f1-score": 0.3157894736842105,
                        "support": 12.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.2,
                        "f1-score": 0.28571428571428575,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.19047619047619047,
                    "macro avg": {
                        "precision": 0.23214285714285715,
                        "recall": 0.1125,
                        "f1-score": 0.15037593984962405,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.3639455782312925,
                        "recall": 0.19047619047619047,
                        "f1-score": 0.2484783387039026,
                        "support": 21.0
                    }
                },
                "computers_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    }
                },
                "crime_and_law_accuse_4": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.2,
                        "f1-score": 0.33333333333333337,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.2,
                        "f1-score": 0.28571428571428575,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2,
                    "macro avg": {
                        "precision": 0.375,
                        "recall": 0.1,
                        "f1-score": 0.15476190476190477,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.75,
                        "recall": 0.2,
                        "f1-score": 0.3095238095238096,
                        "support": 10.0
                    }
                },
                "culture_and_entertainment_1": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.5,
                        "f1-score": 0.5,
                        "support": 2.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.5,
                        "f1-score": 0.6666666666666666,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.6666666666666666,
                    "macro avg": {
                        "precision": 0.625,
                        "recall": 0.5,
                        "f1-score": 0.5416666666666666,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.8333333333333334,
                        "recall": 0.6666666666666666,
                        "f1-score": 0.7222222222222222,
                        "support": 6.0
                    }
                },
                "internet_2": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.2,
                        "f1-score": 0.28571428571428575,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.25,
                        "f1-score": 0.3333333333333333,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2,
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.1125,
                        "f1-score": 0.15476190476190477,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.45,
                        "recall": 0.2,
                        "f1-score": 0.2761904761904762,
                        "support": 10.0
                    }
                },
                "culture_and_entertainment_3": {
                    "AFTER": {
                        "precision": 0.25,
                        "recall": 0.2,
                        "f1-score": 0.22222222222222224,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.25,
                        "recall": 0.25,
                        "f1-score": 0.25,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.13333333333333333,
                    "macro avg": {
                        "precision": 0.125,
                        "recall": 0.1125,
                        "f1-score": 0.11805555555555555,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.15,
                        "recall": 0.13333333333333333,
                        "f1-score": 0.14074074074074075,
                        "support": 15.0
                    }
                }
            },
            "refer_events": {
                "government_and_politics_riots_4": {
                    "AFTER": {
                        "precision": 0.25,
                        "recall": 0.75,
                        "f1-score": 0.375,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 12.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 12.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.10714285714285714,
                    "macro avg": {
                        "precision": 0.0625,
                        "recall": 0.1875,
                        "f1-score": 0.09375,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.03571428571428571,
                        "recall": 0.10714285714285714,
                        "f1-score": 0.05357142857142857,
                        "support": 28.0
                    }
                },
                "rail_transport_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.11764705882352941,
                        "f1-score": 0.21052631578947367,
                        "support": 34.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.1111111111111111,
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.029411764705882353,
                        "f1-score": 0.05263157894736842,
                        "support": 36.0
                    },
                    "weighted avg": {
                        "precision": 0.9444444444444444,
                        "recall": 0.1111111111111111,
                        "f1-score": 0.19883040935672514,
                        "support": 36.0
                    }
                },
                "politics_and_conflicts_policy_change_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.0,
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    }
                },
                "politics_and_conflicts_drones_1": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.18181818181818182,
                        "f1-score": 0.26666666666666666,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.125,
                        "f1-score": 0.2222222222222222,
                        "support": 8.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.14285714285714285,
                    "macro avg": {
                        "precision": 0.375,
                        "recall": 0.07670454545454546,
                        "f1-score": 0.12222222222222222,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.6428571428571429,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.2243386243386243,
                        "support": 21.0
                    }
                },
                "disasters_and_accidents_road_crash_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 10.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.0,
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 21.0
                    }
                },
                "crime_and_law_accuse_3": {
                    "AFTER": {
                        "precision": 0.16666666666666666,
                        "recall": 0.25,
                        "f1-score": 0.2,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.1,
                    "macro avg": {
                        "precision": 0.041666666666666664,
                        "recall": 0.0625,
                        "f1-score": 0.05,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.06666666666666667,
                        "recall": 0.1,
                        "f1-score": 0.08,
                        "support": 10.0
                    }
                },
                "government_and_politics_protests_2": {
                    "AFTER": {
                        "precision": 0.2,
                        "recall": 0.2,
                        "f1-score": 0.20000000000000004,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 20.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.03571428571428571,
                    "macro avg": {
                        "precision": 0.05,
                        "recall": 0.05,
                        "f1-score": 0.05000000000000001,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.03571428571428571,
                        "recall": 0.03571428571428571,
                        "f1-score": 0.03571428571428572,
                        "support": 28.0
                    }
                },
                "politics_and_conflicts_elections_2": {
                    "AFTER": {
                        "precision": 0.4444444444444444,
                        "recall": 0.18181818181818182,
                        "f1-score": 0.2580645161290322,
                        "support": 22.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.22222222222222224,
                        "support": 14.0
                    },
                    "COEX": {
                        "precision": 0.25,
                        "recall": 0.1111111111111111,
                        "f1-score": 0.15384615384615383,
                        "support": 9.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.15555555555555556,
                    "macro avg": {
                        "precision": 0.2986111111111111,
                        "recall": 0.10894660894660894,
                        "f1-score": 0.15853322304935208,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.4228395061728395,
                        "recall": 0.15555555555555556,
                        "f1-score": 0.22606990779033787,
                        "support": 45.0
                    }
                },
                "environment_2": {
                    "AFTER": {
                        "precision": 0.16666666666666666,
                        "recall": 0.047619047619047616,
                        "f1-score": 0.07407407407407407,
                        "support": 21.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 23.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.022222222222222223,
                    "macro avg": {
                        "precision": 0.041666666666666664,
                        "recall": 0.011904761904761904,
                        "f1-score": 0.018518518518518517,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.07777777777777778,
                        "recall": 0.022222222222222223,
                        "f1-score": 0.0345679012345679,
                        "support": 45.0
                    }
                },
                "weather_floods_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.22222222222222224,
                        "support": 7.0
                    },
                    "COEX": {
                        "precision": 0.5,
                        "recall": 0.25,
                        "f1-score": 0.3333333333333333,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.13333333333333333,
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.09821428571428571,
                        "f1-score": 0.1388888888888889,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.36666666666666664,
                        "recall": 0.13333333333333333,
                        "f1-score": 0.1925925925925926,
                        "support": 15.0
                    }
                },
                "sports_1": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.5,
                        "f1-score": 0.6666666666666666,
                        "support": 2.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 3.0
                    },
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.125,
                        "f1-score": 0.16666666666666666,
                        "support": 3.0
                    },
                    "weighted avg": {
                        "precision": 0.6666666666666666,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.4444444444444444,
                        "support": 3.0
                    }
                },
                "health_4": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.1111111111111111,
                        "f1-score": 0.1818181818181818,
                        "support": 9.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 8.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.047619047619047616,
                    "macro avg": {
                        "precision": 0.125,
                        "recall": 0.027777777777777776,
                        "f1-score": 0.04545454545454545,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.21428571428571427,
                        "recall": 0.047619047619047616,
                        "f1-score": 0.07792207792207792,
                        "support": 21.0
                    }
                },
                "weather_earthquakes_1": {
                    "AFTER": {
                        "precision": 0.125,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.14285714285714288,
                        "support": 6.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 32.0
                    },
                    "COEX": {
                        "precision": 0.5,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.22222222222222224,
                        "support": 7.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.044444444444444446,
                    "macro avg": {
                        "precision": 0.15625,
                        "recall": 0.07738095238095238,
                        "f1-score": 0.09126984126984128,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.09444444444444444,
                        "recall": 0.044444444444444446,
                        "f1-score": 0.053615520282186954,
                        "support": 45.0
                    }
                },
                "space_4": {
                    "AFTER": {
                        "precision": 0.16666666666666666,
                        "recall": 0.09090909090909091,
                        "f1-score": 0.11764705882352942,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 15.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.03571428571428571,
                    "macro avg": {
                        "precision": 0.041666666666666664,
                        "recall": 0.022727272727272728,
                        "f1-score": 0.029411764705882356,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.06547619047619048,
                        "recall": 0.03571428571428571,
                        "f1-score": 0.046218487394957986,
                        "support": 28.0
                    }
                },
                "economy_and_business_strikes_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.0,
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    }
                },
                "politics_and_conflicts_armed_conflict_2": {
                    "AFTER": {
                        "precision": 0.3333333333333333,
                        "recall": 1.0,
                        "f1-score": 0.5,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.09090909090909091,
                        "f1-score": 0.16666666666666669,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.13333333333333333,
                    "macro avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.2727272727272727,
                        "f1-score": 0.16666666666666669,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.7555555555555556,
                        "recall": 0.13333333333333333,
                        "f1-score": 0.15555555555555556,
                        "support": 15.0
                    }
                },
                "infectious_disease_4": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.25,
                        "f1-score": 0.25,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    }
                },
                "health_1": {
                    "AFTER": {
                        "precision": 0.4,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3636363636363636,
                        "support": 6.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2,
                    "macro avg": {
                        "precision": 0.1,
                        "recall": 0.08333333333333333,
                        "f1-score": 0.0909090909090909,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.24000000000000005,
                        "recall": 0.2,
                        "f1-score": 0.21818181818181817,
                        "support": 10.0
                    }
                },
                "disasters_and_accidents_shipwreck_2": {
                    "AFTER": {
                        "precision": 0.2857142857142857,
                        "recall": 0.18181818181818182,
                        "f1-score": 0.2222222222222222,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.6666666666666666,
                        "recall": 0.2222222222222222,
                        "f1-score": 0.3333333333333333,
                        "support": 9.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.19047619047619047,
                    "macro avg": {
                        "precision": 0.23809523809523808,
                        "recall": 0.10101010101010101,
                        "f1-score": 0.1388888888888889,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.43537414965986393,
                        "recall": 0.19047619047619047,
                        "f1-score": 0.25925925925925924,
                        "support": 21.0
                    }
                },
                "rail_transport_3": {
                    "AFTER": {
                        "precision": 0.25,
                        "recall": 0.2,
                        "f1-score": 0.22222222222222224,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.1,
                        "f1-score": 0.16666666666666669,
                        "support": 10.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.13333333333333333,
                        "recall": 0.13333333333333333,
                        "f1-score": 0.13333333333333333,
                        "support": 15.0
                    },
                    "macro avg": {
                        "precision": 0.1875,
                        "recall": 0.07500000000000001,
                        "f1-score": 0.09722222222222224,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.4166666666666667,
                        "recall": 0.13333333333333333,
                        "f1-score": 0.1851851851851852,
                        "support": 15.0
                    }
                },
                "weather_storms_1_extra": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    }
                },
                "health_1_extra": {
                    "AFTER": {
                        "precision": 0.23076923076923078,
                        "recall": 0.25,
                        "f1-score": 0.24000000000000002,
                        "support": 12.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 28.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 15.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.05454545454545454,
                    "macro avg": {
                        "precision": 0.057692307692307696,
                        "recall": 0.0625,
                        "f1-score": 0.060000000000000005,
                        "support": 55.0
                    },
                    "weighted avg": {
                        "precision": 0.050349650349650346,
                        "recall": 0.05454545454545454,
                        "f1-score": 0.05236363636363637,
                        "support": 55.0
                    }
                },
                "weather_floods_1": {
                    "AFTER": {
                        "precision": 0.10526315789473684,
                        "recall": 0.6666666666666666,
                        "f1-score": 0.18181818181818182,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.041666666666666664,
                        "f1-score": 0.07692307692307693,
                        "support": 24.0
                    },
                    "COEX": {
                        "precision": 1.0,
                        "recall": 0.03571428571428571,
                        "f1-score": 0.0689655172413793,
                        "support": 28.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.07272727272727272,
                    "macro avg": {
                        "precision": 0.4013157894736842,
                        "recall": 0.18601190476190474,
                        "f1-score": 0.08192669399565951,
                        "support": 55.0
                    },
                    "weighted avg": {
                        "precision": 0.7330143540669857,
                        "recall": 0.07272727272727272,
                        "f1-score": 0.07859350680667294,
                        "support": 55.0
                    }
                },
                "mining_4": {
                    "AFTER": {
                        "precision": 0.2,
                        "recall": 0.09090909090909091,
                        "f1-score": 0.12500000000000003,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 0.04,
                        "f1-score": 0.07142857142857142,
                        "support": 25.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 9.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.044444444444444446,
                    "macro avg": {
                        "precision": 0.13333333333333333,
                        "recall": 0.03272727272727273,
                        "f1-score": 0.04910714285714286,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.23407407407407405,
                        "recall": 0.044444444444444446,
                        "f1-score": 0.07023809523809524,
                        "support": 45.0
                    }
                },
                "disasters_and_accidents_volcanoes_4": {
                    "AFTER": {
                        "precision": 0.25,
                        "recall": 0.05,
                        "f1-score": 0.08333333333333334,
                        "support": 20.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 14.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.027777777777777776,
                    "macro avg": {
                        "precision": 0.0625,
                        "recall": 0.0125,
                        "f1-score": 0.020833333333333336,
                        "support": 36.0
                    },
                    "weighted avg": {
                        "precision": 0.1388888888888889,
                        "recall": 0.027777777777777776,
                        "f1-score": 0.04629629629629631,
                        "support": 36.0
                    }
                },
                "politics_and_conflicts_elections_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 1.0,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.2857142857142857,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.06666666666666667,
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.041666666666666664,
                        "f1-score": 0.07142857142857142,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.4,
                        "recall": 0.06666666666666667,
                        "f1-score": 0.11428571428571428,
                        "support": 15.0
                    }
                },
                "economy_and_business_strikes_3": {
                    "AFTER": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3,
                        "f1-score": 0.3157894736842105,
                        "support": 10.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 7.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.10714285714285714,
                    "macro avg": {
                        "precision": 0.08333333333333333,
                        "recall": 0.075,
                        "f1-score": 0.07894736842105263,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.11904761904761904,
                        "recall": 0.10714285714285714,
                        "f1-score": 0.11278195488721805,
                        "support": 28.0
                    }
                },
                "space_2": {
                    "AFTER": {
                        "precision": 0.26666666666666666,
                        "recall": 0.04,
                        "f1-score": 0.06956521739130435,
                        "support": 100.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 51.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.026143790849673203,
                    "macro avg": {
                        "precision": 0.06666666666666667,
                        "recall": 0.01,
                        "f1-score": 0.017391304347826087,
                        "support": 153.0
                    },
                    "weighted avg": {
                        "precision": 0.17429193899782136,
                        "recall": 0.026143790849673203,
                        "f1-score": 0.045467462347257744,
                        "support": 153.0
                    }
                },
                "politics_and_conflicts_resign_1": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.5,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 3.0
                    },
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.08333333333333333,
                        "f1-score": 0.125,
                        "support": 3.0
                    },
                    "weighted avg": {
                        "precision": 1.0,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.5,
                        "support": 3.0
                    }
                },
                "environment_4": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.5,
                        "f1-score": 0.5,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.13333333333333333,
                    "macro avg": {
                        "precision": 0.125,
                        "recall": 0.125,
                        "f1-score": 0.125,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.13333333333333333,
                        "recall": 0.13333333333333333,
                        "f1-score": 0.13333333333333333,
                        "support": 15.0
                    }
                },
                "space_1_extra": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.0,
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    }
                },
                "health_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 8.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.25,
                        "support": 6.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.06666666666666667,
                    "macro avg": {
                        "precision": 0.125,
                        "recall": 0.041666666666666664,
                        "f1-score": 0.0625,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.2,
                        "recall": 0.06666666666666667,
                        "f1-score": 0.1,
                        "support": 15.0
                    }
                },
                "environment_3": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.18181818181818182,
                        "f1-score": 0.3076923076923077,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.13333333333333333,
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.045454545454545456,
                        "f1-score": 0.07692307692307693,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.7333333333333333,
                        "recall": 0.13333333333333333,
                        "f1-score": 0.22564102564102567,
                        "support": 15.0
                    }
                },
                "government_and_politics_protests_3": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.25,
                        "f1-score": 0.3333333333333333,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 1.0,
                        "f1-score": 0.5,
                        "support": 1.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.3333333333333333,
                    "macro avg": {
                        "precision": 0.20833333333333331,
                        "recall": 0.3125,
                        "f1-score": 0.20833333333333331,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.3888888888888889,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3055555555555555,
                        "support": 6.0
                    }
                },
                "economy_and_business_financial_crisis_4": {
                    "AFTER": {
                        "precision": 0.2,
                        "recall": 0.08333333333333333,
                        "f1-score": 0.11764705882352941,
                        "support": 12.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.5,
                        "recall": 0.25,
                        "f1-score": 0.3333333333333333,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.09523809523809523,
                    "macro avg": {
                        "precision": 0.175,
                        "recall": 0.08333333333333333,
                        "f1-score": 0.11274509803921567,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.20952380952380953,
                        "recall": 0.09523809523809523,
                        "f1-score": 0.13071895424836602,
                        "support": 21.0
                    }
                },
                "computers_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    }
                },
                "crime_and_law_accuse_4": {
                    "AFTER": {
                        "precision": 0.6666666666666666,
                        "recall": 0.8,
                        "f1-score": 0.7272727272727272,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.4,
                        "recall": 0.4,
                        "f1-score": 0.4000000000000001,
                        "support": 10.0
                    },
                    "macro avg": {
                        "precision": 0.16666666666666666,
                        "recall": 0.2,
                        "f1-score": 0.1818181818181818,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.4,
                        "f1-score": 0.3636363636363636,
                        "support": 10.0
                    }
                },
                "culture_and_entertainment_1": {
                    "AFTER": {
                        "precision": 0.25,
                        "recall": 0.5,
                        "f1-score": 0.3333333333333333,
                        "support": 2.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.16666666666666666,
                    "macro avg": {
                        "precision": 0.0625,
                        "recall": 0.125,
                        "f1-score": 0.08333333333333333,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.08333333333333333,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.1111111111111111,
                        "support": 6.0
                    }
                },
                "internet_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.0,
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 10.0
                    }
                },
                "culture_and_entertainment_3": {
                    "AFTER": {
                        "precision": 0.3333333333333333,
                        "recall": 0.4,
                        "f1-score": 0.3636363636363636,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.13333333333333333,
                    "macro avg": {
                        "precision": 0.08333333333333333,
                        "recall": 0.1,
                        "f1-score": 0.0909090909090909,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.1111111111111111,
                        "recall": 0.13333333333333333,
                        "f1-score": 0.12121212121212119,
                        "support": 15.0
                    }
                }
            },
            "hint": {
                "government_and_politics_riots_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 12.0
                    },
                    "COEX": {
                        "precision": 0.25,
                        "recall": 0.08333333333333333,
                        "f1-score": 0.125,
                        "support": 12.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.03571428571428571,
                    "macro avg": {
                        "precision": 0.0625,
                        "recall": 0.020833333333333332,
                        "f1-score": 0.03125,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.10714285714285714,
                        "recall": 0.03571428571428571,
                        "f1-score": 0.05357142857142857,
                        "support": 28.0
                    }
                },
                "rail_transport_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "BEFORE": {
                        "precision": 0.75,
                        "recall": 0.08823529411764706,
                        "f1-score": 0.15789473684210525,
                        "support": 34.0
                    },
                    "COEX": {
                        "precision": 0.2,
                        "recall": 0.5,
                        "f1-score": 0.28571428571428575,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.1111111111111111,
                    "macro avg": {
                        "precision": 0.2375,
                        "recall": 0.14705882352941177,
                        "f1-score": 0.11090225563909775,
                        "support": 36.0
                    },
                    "weighted avg": {
                        "precision": 0.7194444444444444,
                        "recall": 0.1111111111111111,
                        "f1-score": 0.16499582289055972,
                        "support": 36.0
                    }
                },
                "politics_and_conflicts_policy_change_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    }
                },
                "politics_and_conflicts_drones_1": {
                    "AFTER": {
                        "precision": 0.16666666666666666,
                        "recall": 0.09090909090909091,
                        "f1-score": 0.11764705882352942,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 8.0
                    },
                    "COEX": {
                        "precision": 0.25,
                        "recall": 0.5,
                        "f1-score": 0.3333333333333333,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.09523809523809523,
                    "macro avg": {
                        "precision": 0.10416666666666666,
                        "recall": 0.14772727272727273,
                        "f1-score": 0.11274509803921569,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.11111111111111109,
                        "recall": 0.09523809523809523,
                        "f1-score": 0.09337068160597572,
                        "support": 21.0
                    }
                },
                "disasters_and_accidents_road_crash_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 0.09090909090909091,
                        "f1-score": 0.14285714285714288,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 10.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.047619047619047616,
                    "macro avg": {
                        "precision": 0.08333333333333333,
                        "recall": 0.022727272727272728,
                        "f1-score": 0.03571428571428572,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.1746031746031746,
                        "recall": 0.047619047619047616,
                        "f1-score": 0.07482993197278913,
                        "support": 21.0
                    }
                },
                "crime_and_law_accuse_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.0,
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 10.0
                    }
                },
                "government_and_politics_protests_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 20.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.0,
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 28.0
                    }
                },
                "politics_and_conflicts_elections_2": {
                    "AFTER": {
                        "precision": 0.2,
                        "recall": 0.045454545454545456,
                        "f1-score": 0.07407407407407407,
                        "support": 22.0
                    },
                    "BEFORE": {
                        "precision": 0.14285714285714285,
                        "recall": 0.07142857142857142,
                        "f1-score": 0.09523809523809523,
                        "support": 14.0
                    },
                    "COEX": {
                        "precision": 0.14285714285714285,
                        "recall": 0.1111111111111111,
                        "f1-score": 0.125,
                        "support": 9.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.06666666666666667,
                    "macro avg": {
                        "precision": 0.12142857142857143,
                        "recall": 0.05699855699855699,
                        "f1-score": 0.07357804232804233,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.1707936507936508,
                        "recall": 0.06666666666666667,
                        "f1-score": 0.09084362139917695,
                        "support": 45.0
                    }
                },
                "environment_2": {
                    "AFTER": {
                        "precision": 0.4,
                        "recall": 0.19047619047619047,
                        "f1-score": 0.25806451612903225,
                        "support": 21.0
                    },
                    "BEFORE": {
                        "precision": 0.3076923076923077,
                        "recall": 0.17391304347826086,
                        "f1-score": 0.2222222222222222,
                        "support": 23.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.17777777777777778,
                    "macro avg": {
                        "precision": 0.17692307692307693,
                        "recall": 0.09109730848861283,
                        "f1-score": 0.12007168458781362,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.34393162393162396,
                        "recall": 0.17777777777777778,
                        "f1-score": 0.23401035444046192,
                        "support": 45.0
                    }
                },
                "weather_floods_3": {
                    "AFTER": {
                        "precision": 0.25,
                        "recall": 0.5,
                        "f1-score": 0.3333333333333333,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.22222222222222224,
                        "support": 7.0
                    },
                    "COEX": {
                        "precision": 0.6666666666666666,
                        "recall": 0.5,
                        "f1-score": 0.5714285714285715,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.3333333333333333,
                    "macro avg": {
                        "precision": 0.35416666666666663,
                        "recall": 0.2857142857142857,
                        "f1-score": 0.28174603174603174,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.47777777777777775,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.344973544973545,
                        "support": 15.0
                    }
                },
                "sports_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    }
                },
                "health_4": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.4444444444444444,
                        "f1-score": 0.47058823529411764,
                        "support": 9.0
                    },
                    "BEFORE": {
                        "precision": 0.25,
                        "recall": 0.125,
                        "f1-score": 0.16666666666666666,
                        "support": 8.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.23809523809523808,
                    "macro avg": {
                        "precision": 0.1875,
                        "recall": 0.1423611111111111,
                        "f1-score": 0.15931372549019607,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.30952380952380953,
                        "recall": 0.23809523809523808,
                        "f1-score": 0.26517273576097106,
                        "support": 21.0
                    }
                },
                "weather_earthquakes_1": {
                    "AFTER": {
                        "precision": 0.07142857142857142,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.1,
                        "support": 6.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.09375,
                        "f1-score": 0.17142857142857143,
                        "support": 32.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 7.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.08888888888888889,
                    "macro avg": {
                        "precision": 0.26785714285714285,
                        "recall": 0.06510416666666666,
                        "f1-score": 0.06785714285714287,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.7206349206349206,
                        "recall": 0.08888888888888889,
                        "f1-score": 0.13523809523809524,
                        "support": 45.0
                    }
                },
                "space_4": {
                    "AFTER": {
                        "precision": 0.25,
                        "recall": 0.18181818181818182,
                        "f1-score": 0.2105263157894737,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 15.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.07142857142857142,
                    "macro avg": {
                        "precision": 0.0625,
                        "recall": 0.045454545454545456,
                        "f1-score": 0.052631578947368425,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.09821428571428571,
                        "recall": 0.07142857142857142,
                        "f1-score": 0.08270676691729324,
                        "support": 28.0
                    }
                },
                "economy_and_business_strikes_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.25,
                        "f1-score": 0.4,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.16666666666666666,
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.0625,
                        "f1-score": 0.1,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.6666666666666666,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.26666666666666666,
                        "support": 6.0
                    }
                },
                "politics_and_conflicts_armed_conflict_2": {
                    "AFTER": {
                        "precision": 0.25,
                        "recall": 1.0,
                        "f1-score": 0.4,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.75,
                        "recall": 0.2727272727272727,
                        "f1-score": 0.39999999999999997,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.4,
                        "recall": 0.6666666666666666,
                        "f1-score": 0.5,
                        "support": 3.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.4,
                    "macro avg": {
                        "precision": 0.35,
                        "recall": 0.48484848484848486,
                        "f1-score": 0.325,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.6466666666666666,
                        "recall": 0.4,
                        "f1-score": 0.42,
                        "support": 15.0
                    }
                },
                "infectious_disease_4": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.25,
                        "f1-score": 0.25,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    }
                },
                "health_1": {
                    "AFTER": {
                        "precision": 0.3333333333333333,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.2222222222222222,
                        "support": 6.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "COEX": {
                        "precision": 0.5,
                        "recall": 1.0,
                        "f1-score": 0.6666666666666666,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2,
                    "macro avg": {
                        "precision": 0.20833333333333331,
                        "recall": 0.2916666666666667,
                        "f1-score": 0.2222222222222222,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.25,
                        "recall": 0.2,
                        "f1-score": 0.2,
                        "support": 10.0
                    }
                },
                "disasters_and_accidents_shipwreck_2": {
                    "AFTER": {
                        "precision": 0.3,
                        "recall": 0.2727272727272727,
                        "f1-score": 0.28571428571428564,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.14285714285714285,
                        "recall": 0.1111111111111111,
                        "f1-score": 0.125,
                        "support": 9.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.19047619047619047,
                    "macro avg": {
                        "precision": 0.11071428571428571,
                        "recall": 0.09595959595959595,
                        "f1-score": 0.10267857142857141,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.2183673469387755,
                        "recall": 0.19047619047619047,
                        "f1-score": 0.20323129251700678,
                        "support": 21.0
                    }
                },
                "rail_transport_3": {
                    "AFTER": {
                        "precision": 0.16666666666666666,
                        "recall": 0.2,
                        "f1-score": 0.1818181818181818,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.1,
                        "f1-score": 0.16666666666666669,
                        "support": 10.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.13333333333333333,
                    "macro avg": {
                        "precision": 0.16666666666666666,
                        "recall": 0.07500000000000001,
                        "f1-score": 0.08712121212121213,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.3888888888888889,
                        "recall": 0.13333333333333333,
                        "f1-score": 0.17171717171717174,
                        "support": 15.0
                    }
                },
                "weather_storms_1_extra": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    }
                },
                "health_1_extra": {
                    "AFTER": {
                        "precision": 0.125,
                        "recall": 0.08333333333333333,
                        "f1-score": 0.1,
                        "support": 12.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.22222222222222224,
                        "support": 28.0
                    },
                    "COEX": {
                        "precision": 0.25,
                        "recall": 0.13333333333333333,
                        "f1-score": 0.1739130434782609,
                        "support": 15.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.12727272727272726,
                    "macro avg": {
                        "precision": 0.21875,
                        "recall": 0.08988095238095237,
                        "f1-score": 0.12403381642512079,
                        "support": 55.0
                    },
                    "weighted avg": {
                        "precision": 0.35,
                        "recall": 0.12727272727272726,
                        "f1-score": 0.18238032498902065,
                        "support": 55.0
                    }
                },
                "weather_floods_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.08333333333333333,
                        "f1-score": 0.14285714285714285,
                        "support": 24.0
                    },
                    "COEX": {
                        "precision": 0.2,
                        "recall": 0.03571428571428571,
                        "f1-score": 0.06060606060606061,
                        "support": 28.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.05454545454545454,
                    "macro avg": {
                        "precision": 0.175,
                        "recall": 0.02976190476190476,
                        "f1-score": 0.050865800865800864,
                        "support": 55.0
                    },
                    "weighted avg": {
                        "precision": 0.32,
                        "recall": 0.05454545454545454,
                        "f1-score": 0.09319165682802046,
                        "support": 55.0
                    }
                },
                "mining_4": {
                    "AFTER": {
                        "precision": 0.09090909090909091,
                        "recall": 0.09090909090909091,
                        "f1-score": 0.09090909090909091,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.04,
                        "f1-score": 0.07407407407407407,
                        "support": 25.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 9.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.044444444444444446,
                    "macro avg": {
                        "precision": 0.14772727272727273,
                        "recall": 0.03272727272727273,
                        "f1-score": 0.041245791245791245,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.3,
                        "recall": 0.044444444444444446,
                        "f1-score": 0.06337448559670782,
                        "support": 45.0
                    }
                },
                "disasters_and_accidents_volcanoes_4": {
                    "AFTER": {
                        "precision": 0.5833333333333334,
                        "recall": 0.35,
                        "f1-score": 0.4375,
                        "support": 20.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.07142857142857142,
                        "f1-score": 0.125,
                        "support": 14.0
                    },
                    "COEX": {
                        "precision": 0.25,
                        "recall": 0.5,
                        "f1-score": 0.3333333333333333,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.25,
                    "macro avg": {
                        "precision": 0.33333333333333337,
                        "recall": 0.23035714285714284,
                        "f1-score": 0.22395833333333331,
                        "support": 36.0
                    },
                    "weighted avg": {
                        "precision": 0.5324074074074074,
                        "recall": 0.25,
                        "f1-score": 0.3101851851851852,
                        "support": 36.0
                    }
                },
                "politics_and_conflicts_elections_3": {
                    "AFTER": {
                        "precision": 0.25,
                        "recall": 0.2,
                        "f1-score": 0.22222222222222224,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.25,
                        "f1-score": 0.3333333333333333,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 1.0,
                        "recall": 0.5,
                        "f1-score": 0.6666666666666666,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.3333333333333333,
                    "macro avg": {
                        "precision": 0.4375,
                        "recall": 0.2375,
                        "f1-score": 0.3055555555555556,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.6166666666666667,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.42962962962962964,
                        "support": 15.0
                    }
                },
                "economy_and_business_strikes_3": {
                    "AFTER": {
                        "precision": 0.16666666666666666,
                        "recall": 0.1,
                        "f1-score": 0.125,
                        "support": 10.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.5,
                        "recall": 0.2857142857142857,
                        "f1-score": 0.36363636363636365,
                        "support": 7.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.10714285714285714,
                    "macro avg": {
                        "precision": 0.16666666666666666,
                        "recall": 0.09642857142857142,
                        "f1-score": 0.12215909090909091,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.1845238095238095,
                        "recall": 0.10714285714285714,
                        "f1-score": 0.13555194805194806,
                        "support": 28.0
                    }
                },
                "space_2": {
                    "AFTER": {
                        "precision": 0.2857142857142857,
                        "recall": 0.04,
                        "f1-score": 0.07017543859649124,
                        "support": 100.0
                    },
                    "BEFORE": {
                        "precision": 0.26666666666666666,
                        "recall": 0.0784313725490196,
                        "f1-score": 0.1212121212121212,
                        "support": 51.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.05228758169934641,
                    "macro avg": {
                        "precision": 0.1380952380952381,
                        "recall": 0.029607843137254904,
                        "f1-score": 0.04784688995215311,
                        "support": 153.0
                    },
                    "weighted avg": {
                        "precision": 0.27563025210084036,
                        "recall": 0.05228758169934641,
                        "f1-score": 0.0862703401403092,
                        "support": 153.0
                    }
                },
                "politics_and_conflicts_resign_1": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 3.0
                    },
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.25,
                        "f1-score": 0.25,
                        "support": 3.0
                    },
                    "weighted avg": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 3.0
                    }
                },
                "environment_4": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.5,
                        "f1-score": 0.5,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.75,
                        "recall": 0.6,
                        "f1-score": 0.6666666666666665,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.3333333333333333,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.2222222222222222,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.4,
                    "macro avg": {
                        "precision": 0.3958333333333333,
                        "recall": 0.3166666666666667,
                        "f1-score": 0.3472222222222222,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.5166666666666667,
                        "recall": 0.4,
                        "f1-score": 0.44444444444444436,
                        "support": 15.0
                    }
                },
                "space_1_extra": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    }
                },
                "health_3": {
                    "AFTER": {
                        "precision": 0.25,
                        "recall": 0.125,
                        "f1-score": 0.16666666666666666,
                        "support": 8.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.06666666666666667,
                    "macro avg": {
                        "precision": 0.0625,
                        "recall": 0.03125,
                        "f1-score": 0.041666666666666664,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.13333333333333333,
                        "recall": 0.06666666666666667,
                        "f1-score": 0.08888888888888888,
                        "support": 15.0
                    }
                },
                "environment_3": {
                    "AFTER": {
                        "precision": 0.75,
                        "recall": 0.5454545454545454,
                        "f1-score": 0.631578947368421,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.4,
                    "macro avg": {
                        "precision": 0.1875,
                        "recall": 0.13636363636363635,
                        "f1-score": 0.15789473684210525,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.55,
                        "recall": 0.4,
                        "f1-score": 0.46315789473684205,
                        "support": 15.0
                    }
                },
                "government_and_politics_protests_3": {
                    "AFTER": {
                        "precision": 0.6666666666666666,
                        "recall": 0.5,
                        "f1-score": 0.5714285714285715,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "COEX": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.5,
                    "macro avg": {
                        "precision": 0.41666666666666663,
                        "recall": 0.375,
                        "f1-score": 0.3928571428571429,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.611111111111111,
                        "recall": 0.5,
                        "f1-score": 0.5476190476190477,
                        "support": 6.0
                    }
                },
                "economy_and_business_financial_crisis_4": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.4,
                        "support": 12.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.19047619047619047,
                    "macro avg": {
                        "precision": 0.125,
                        "recall": 0.08333333333333333,
                        "f1-score": 0.1,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.2857142857142857,
                        "recall": 0.19047619047619047,
                        "f1-score": 0.2285714285714286,
                        "support": 21.0
                    }
                },
                "computers_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    }
                },
                "crime_and_law_accuse_4": {
                    "AFTER": {
                        "precision": 0.3333333333333333,
                        "recall": 0.2,
                        "f1-score": 0.25,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.1,
                    "macro avg": {
                        "precision": 0.08333333333333333,
                        "recall": 0.05,
                        "f1-score": 0.0625,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.16666666666666666,
                        "recall": 0.1,
                        "f1-score": 0.125,
                        "support": 10.0
                    }
                },
                "culture_and_entertainment_1": {
                    "AFTER": {
                        "precision": 0.25,
                        "recall": 0.5,
                        "f1-score": 0.3333333333333333,
                        "support": 2.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.16666666666666666,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.16666666666666666,
                        "support": 6.0
                    },
                    "macro avg": {
                        "precision": 0.0625,
                        "recall": 0.125,
                        "f1-score": 0.08333333333333333,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.08333333333333333,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.1111111111111111,
                        "support": 6.0
                    }
                },
                "internet_2": {
                    "AFTER": {
                        "precision": 0.6666666666666666,
                        "recall": 0.4,
                        "f1-score": 0.5,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2,
                    "macro avg": {
                        "precision": 0.16666666666666666,
                        "recall": 0.1,
                        "f1-score": 0.125,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.2,
                        "f1-score": 0.25,
                        "support": 10.0
                    }
                },
                "culture_and_entertainment_3": {
                    "AFTER": {
                        "precision": 0.125,
                        "recall": 0.2,
                        "f1-score": 0.15384615384615385,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.2,
                        "recall": 0.25,
                        "f1-score": 0.22222222222222224,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.13333333333333333,
                    "macro avg": {
                        "precision": 0.08125,
                        "recall": 0.1125,
                        "f1-score": 0.09401709401709402,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.095,
                        "recall": 0.13333333333333333,
                        "f1-score": 0.11054131054131054,
                        "support": 15.0
                    }
                }
            },
            "pick": {
                "government_and_politics_riots_4": {
                    "AFTER": {
                        "precision": 0.2,
                        "recall": 0.25,
                        "f1-score": 0.22222222222222224,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.2857142857142857,
                        "support": 12.0
                    },
                    "COEX": {
                        "precision": 0.25,
                        "recall": 0.08333333333333333,
                        "f1-score": 0.125,
                        "support": 12.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.14285714285714285,
                    "macro avg": {
                        "precision": 0.3625,
                        "recall": 0.12499999999999999,
                        "f1-score": 0.15823412698412698,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.5642857142857143,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.20776643990929705,
                        "support": 28.0
                    }
                },
                "rail_transport_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "BEFORE": {
                        "precision": 0.75,
                        "recall": 0.08823529411764706,
                        "f1-score": 0.15789473684210525,
                        "support": 34.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.08333333333333333,
                    "macro avg": {
                        "precision": 0.1875,
                        "recall": 0.022058823529411766,
                        "f1-score": 0.039473684210526314,
                        "support": 36.0
                    },
                    "weighted avg": {
                        "precision": 0.7083333333333334,
                        "recall": 0.08333333333333333,
                        "f1-score": 0.14912280701754385,
                        "support": 36.0
                    }
                },
                "politics_and_conflicts_policy_change_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.0,
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    }
                },
                "politics_and_conflicts_drones_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 8.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.0,
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 21.0
                    }
                },
                "disasters_and_accidents_road_crash_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.09090909090909091,
                        "f1-score": 0.15384615384615385,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.25,
                        "recall": 0.1,
                        "f1-score": 0.14285714285714288,
                        "support": 10.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.09523809523809523,
                    "macro avg": {
                        "precision": 0.1875,
                        "recall": 0.04772727272727273,
                        "f1-score": 0.07417582417582419,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.38095238095238093,
                        "recall": 0.09523809523809523,
                        "f1-score": 0.14861329147043434,
                        "support": 21.0
                    }
                },
                "crime_and_law_accuse_3": {
                    "AFTER": {
                        "precision": 0.4,
                        "recall": 0.5,
                        "f1-score": 0.4444444444444445,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2,
                    "macro avg": {
                        "precision": 0.1,
                        "recall": 0.125,
                        "f1-score": 0.11111111111111112,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.16,
                        "recall": 0.2,
                        "f1-score": 0.17777777777777778,
                        "support": 10.0
                    }
                },
                "government_and_politics_protests_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.6666666666666666,
                        "recall": 0.1,
                        "f1-score": 0.1739130434782609,
                        "support": 20.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.07142857142857142,
                    "macro avg": {
                        "precision": 0.16666666666666666,
                        "recall": 0.025,
                        "f1-score": 0.04347826086956522,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.47619047619047616,
                        "recall": 0.07142857142857142,
                        "f1-score": 0.12422360248447206,
                        "support": 28.0
                    }
                },
                "politics_and_conflicts_elections_2": {
                    "AFTER": {
                        "precision": 0.3,
                        "recall": 0.13636363636363635,
                        "f1-score": 0.18749999999999997,
                        "support": 22.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 14.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 9.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.06666666666666667,
                    "macro avg": {
                        "precision": 0.075,
                        "recall": 0.03409090909090909,
                        "f1-score": 0.04687499999999999,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.14666666666666667,
                        "recall": 0.06666666666666667,
                        "f1-score": 0.09166666666666665,
                        "support": 45.0
                    }
                },
                "environment_2": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.4,
                        "support": 21.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 23.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.15555555555555556,
                    "macro avg": {
                        "precision": 0.125,
                        "recall": 0.08333333333333333,
                        "f1-score": 0.1,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.23333333333333334,
                        "recall": 0.15555555555555556,
                        "f1-score": 0.18666666666666668,
                        "support": 45.0
                    }
                },
                "weather_floods_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.22222222222222224,
                        "support": 7.0
                    },
                    "COEX": {
                        "precision": 0.3333333333333333,
                        "recall": 0.25,
                        "f1-score": 0.28571428571428575,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.13333333333333333,
                    "macro avg": {
                        "precision": 0.20833333333333331,
                        "recall": 0.09821428571428571,
                        "f1-score": 0.126984126984127,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.3222222222222222,
                        "recall": 0.13333333333333333,
                        "f1-score": 0.1798941798941799,
                        "support": 15.0
                    }
                },
                "sports_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.0,
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    }
                },
                "health_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 9.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 8.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.0,
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 21.0
                    }
                },
                "weather_earthquakes_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 32.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 7.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.0,
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 45.0
                    }
                },
                "space_4": {
                    "AFTER": {
                        "precision": 0.375,
                        "recall": 0.2727272727272727,
                        "f1-score": 0.3157894736842105,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 15.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.10714285714285714,
                    "macro avg": {
                        "precision": 0.09375,
                        "recall": 0.06818181818181818,
                        "f1-score": 0.07894736842105263,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.14732142857142858,
                        "recall": 0.10714285714285714,
                        "f1-score": 0.12406015037593984,
                        "support": 28.0
                    }
                },
                "economy_and_business_strikes_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.0,
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    }
                },
                "politics_and_conflicts_armed_conflict_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.09090909090909091,
                        "f1-score": 0.15384615384615385,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.06666666666666667,
                    "macro avg": {
                        "precision": 0.125,
                        "recall": 0.022727272727272728,
                        "f1-score": 0.038461538461538464,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.36666666666666664,
                        "recall": 0.06666666666666667,
                        "f1-score": 0.11282051282051284,
                        "support": 15.0
                    }
                },
                "infectious_disease_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    }
                },
                "health_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.0,
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 10.0
                    }
                },
                "disasters_and_accidents_shipwreck_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 0.1111111111111111,
                        "f1-score": 0.16666666666666666,
                        "support": 9.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.047619047619047616,
                    "macro avg": {
                        "precision": 0.08333333333333333,
                        "recall": 0.027777777777777776,
                        "f1-score": 0.041666666666666664,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.14285714285714285,
                        "recall": 0.047619047619047616,
                        "f1-score": 0.07142857142857142,
                        "support": 21.0
                    }
                },
                "rail_transport_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 10.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 15.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 15.0
                    }
                },
                "weather_storms_1_extra": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    }
                },
                "health_1_extra": {
                    "AFTER": {
                        "precision": 0.1111111111111111,
                        "recall": 0.08333333333333333,
                        "f1-score": 0.09523809523809525,
                        "support": 12.0
                    },
                    "BEFORE": {
                        "precision": 0.16666666666666666,
                        "recall": 0.03571428571428571,
                        "f1-score": 0.058823529411764705,
                        "support": 28.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 15.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.03636363636363636,
                    "macro avg": {
                        "precision": 0.06944444444444445,
                        "recall": 0.02976190476190476,
                        "f1-score": 0.03851540616246499,
                        "support": 55.0
                    },
                    "weighted avg": {
                        "precision": 0.10909090909090907,
                        "recall": 0.03636363636363636,
                        "f1-score": 0.0507257448433919,
                        "support": 55.0
                    }
                },
                "weather_floods_1": {
                    "AFTER": {
                        "precision": 0.09090909090909091,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.14285714285714288,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.08333333333333333,
                        "f1-score": 0.14285714285714285,
                        "support": 24.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 28.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.05454545454545454,
                    "macro avg": {
                        "precision": 0.14772727272727273,
                        "recall": 0.10416666666666666,
                        "f1-score": 0.07142857142857142,
                        "support": 55.0
                    },
                    "weighted avg": {
                        "precision": 0.2231404958677686,
                        "recall": 0.05454545454545454,
                        "f1-score": 0.07012987012987013,
                        "support": 55.0
                    }
                },
                "mining_4": {
                    "AFTER": {
                        "precision": 0.18181818181818182,
                        "recall": 0.18181818181818182,
                        "f1-score": 0.18181818181818182,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 25.0
                    },
                    "COEX": {
                        "precision": 0.25,
                        "recall": 0.1111111111111111,
                        "f1-score": 0.15384615384615383,
                        "support": 9.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.06666666666666667,
                    "macro avg": {
                        "precision": 0.10795454545454546,
                        "recall": 0.07323232323232323,
                        "f1-score": 0.0839160839160839,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.09444444444444444,
                        "recall": 0.06666666666666667,
                        "f1-score": 0.0752136752136752,
                        "support": 45.0
                    }
                },
                "disasters_and_accidents_volcanoes_4": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.1,
                        "f1-score": 0.16666666666666669,
                        "support": 20.0
                    },
                    "BEFORE": {
                        "precision": 0.75,
                        "recall": 0.21428571428571427,
                        "f1-score": 0.3333333333333333,
                        "support": 14.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.1388888888888889,
                    "macro avg": {
                        "precision": 0.3125,
                        "recall": 0.07857142857142857,
                        "f1-score": 0.125,
                        "support": 36.0
                    },
                    "weighted avg": {
                        "precision": 0.5694444444444444,
                        "recall": 0.1388888888888889,
                        "f1-score": 0.2222222222222222,
                        "support": 36.0
                    }
                },
                "politics_and_conflicts_elections_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.6666666666666666,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.4444444444444444,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.13333333333333333,
                    "macro avg": {
                        "precision": 0.16666666666666666,
                        "recall": 0.08333333333333333,
                        "f1-score": 0.1111111111111111,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.26666666666666666,
                        "recall": 0.13333333333333333,
                        "f1-score": 0.17777777777777776,
                        "support": 15.0
                    }
                },
                "economy_and_business_strikes_3": {
                    "AFTER": {
                        "precision": 0.16666666666666666,
                        "recall": 0.1,
                        "f1-score": 0.125,
                        "support": 10.0
                    },
                    "BEFORE": {
                        "precision": 0.2857142857142857,
                        "recall": 0.18181818181818182,
                        "f1-score": 0.2222222222222222,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.5,
                        "recall": 0.2857142857142857,
                        "f1-score": 0.36363636363636365,
                        "support": 7.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.17857142857142858,
                    "macro avg": {
                        "precision": 0.23809523809523808,
                        "recall": 0.1418831168831169,
                        "f1-score": 0.17771464646464646,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.2967687074829932,
                        "recall": 0.17857142857142858,
                        "f1-score": 0.22285353535353533,
                        "support": 28.0
                    }
                },
                "space_2": {
                    "AFTER": {
                        "precision": 0.05555555555555555,
                        "recall": 0.01,
                        "f1-score": 0.016949152542372885,
                        "support": 100.0
                    },
                    "BEFORE": {
                        "precision": 0.125,
                        "recall": 0.0196078431372549,
                        "f1-score": 0.03389830508474576,
                        "support": 51.0
                    },
                    "COEX": {
                        "precision": 0.125,
                        "recall": 0.5,
                        "f1-score": 0.2,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.0196078431372549,
                    "macro avg": {
                        "precision": 0.0763888888888889,
                        "recall": 0.13240196078431374,
                        "f1-score": 0.06271186440677967,
                        "support": 153.0
                    },
                    "weighted avg": {
                        "precision": 0.07961147421931736,
                        "recall": 0.0196078431372549,
                        "f1-score": 0.024991691591890998,
                        "support": 153.0
                    }
                },
                "politics_and_conflicts_resign_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    }
                },
                "environment_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.0,
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 15.0
                    }
                },
                "space_1_extra": {
                    "AFTER": {
                        "precision": 0.3333333333333333,
                        "recall": 1.0,
                        "f1-score": 0.5,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.2,
                        "f1-score": 0.33333333333333337,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 6.0
                    },
                    "macro avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3,
                        "f1-score": 0.20833333333333334,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.8888888888888888,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.36111111111111116,
                        "support": 6.0
                    }
                },
                "health_3": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.25,
                        "f1-score": 0.4,
                        "support": 8.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "COEX": {
                        "precision": 0.25,
                        "recall": 1.0,
                        "f1-score": 0.4,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2,
                    "macro avg": {
                        "precision": 0.3125,
                        "recall": 0.3125,
                        "f1-score": 0.2,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.55,
                        "recall": 0.2,
                        "f1-score": 0.24000000000000002,
                        "support": 15.0
                    }
                },
                "environment_3": {
                    "AFTER": {
                        "precision": 0.3333333333333333,
                        "recall": 0.09090909090909091,
                        "f1-score": 0.14285714285714288,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.06666666666666667,
                    "macro avg": {
                        "precision": 0.08333333333333333,
                        "recall": 0.022727272727272728,
                        "f1-score": 0.03571428571428572,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.24444444444444444,
                        "recall": 0.06666666666666667,
                        "f1-score": 0.10476190476190478,
                        "support": 15.0
                    }
                },
                "government_and_politics_protests_3": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.25,
                        "f1-score": 0.3333333333333333,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "COEX": {
                        "precision": 0.3333333333333333,
                        "recall": 1.0,
                        "f1-score": 0.5,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.3333333333333333,
                    "macro avg": {
                        "precision": 0.20833333333333331,
                        "recall": 0.3125,
                        "f1-score": 0.20833333333333331,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.3888888888888889,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3055555555555555,
                        "support": 6.0
                    }
                },
                "economy_and_business_financial_crisis_4": {
                    "AFTER": {
                        "precision": 0.2,
                        "recall": 0.08333333333333333,
                        "f1-score": 0.11764705882352941,
                        "support": 12.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.047619047619047616,
                    "macro avg": {
                        "precision": 0.05,
                        "recall": 0.020833333333333332,
                        "f1-score": 0.029411764705882353,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.1142857142857143,
                        "recall": 0.047619047619047616,
                        "f1-score": 0.06722689075630252,
                        "support": 21.0
                    }
                },
                "computers_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    }
                },
                "crime_and_law_accuse_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.0,
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 10.0
                    }
                },
                "culture_and_entertainment_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.5,
                        "recall": 0.5,
                        "f1-score": 0.5,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.16666666666666666,
                    "macro avg": {
                        "precision": 0.125,
                        "recall": 0.125,
                        "f1-score": 0.125,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.16666666666666666,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.16666666666666666,
                        "support": 6.0
                    }
                },
                "internet_2": {
                    "AFTER": {
                        "precision": 0.3333333333333333,
                        "recall": 0.2,
                        "f1-score": 0.25,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.1,
                    "macro avg": {
                        "precision": 0.08333333333333333,
                        "recall": 0.05,
                        "f1-score": 0.0625,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.16666666666666666,
                        "recall": 0.1,
                        "f1-score": 0.125,
                        "support": 10.0
                    }
                },
                "culture_and_entertainment_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.0,
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 15.0
                    }
                }
            }
        }
    }
}

{
    "args": {
        "batch_size": 8,
        "chunk_size": 4096,
        "dataset_name": "ctf-mrc",
        "device": "cuda",
        "dirpath_log": "log",
        "dirpath_model": null,
        "dirpath_output": "output/comparison",
        "dirpath_output_score": "output_score/comparison",
        "filepath_test": "data/preprocessed/ctf-sample/test.json",
        "filepath_dev": "data/preprocessed/ctf-sample/dev.json",
        "inference_type": "few-shot",
        "local_rank": 0,
        "marker": "eid",
        "max_new_tokens": 512,
        "model_id": "meta-llama/Llama-2-7b-chat-hf",
        "num_demonstration": 0,
        "num_gpu": 1,
        "num_cpu": 4,
        "precision_type": "bfloat16",
        "representation": "mention",
        "seed": 7,
        "temperature": 0.0,
        "dirpath_model_cache": "/data/tir/projects/tir6/general/kimihiro/.cache/huggingface/transformers",
        "top_p": 1
    },
    "average": {
        "document-and-pair-wise-scores": {
            "range": {
                "min": 0.19509803285374785,
                "median": 0.25098599130823757,
                "max": 0.3674654128690916
            },
            "individual": {
                "simple": 0.19509803285374785,
                "simple_events": 0.20278694165674285,
                "note": 0.243708001043235,
                "note_events": 0.34734447982237765,
                "qa": 0.23883806322859052,
                "qa_events": 0.2883645506685268,
                "refer": 0.2582639815732401,
                "refer_events": 0.2682339949649428,
                "hint": 0.3674654128690916,
                "pick": 0.2254868996195274
            }
        }
    },
    "individuals": {
        "document-and-pair-wise-scores": {
            "simple": {
                "government_and_politics_riots_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.25,
                        "support": 12.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 12.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.07142857142857142,
                    "macro avg": {
                        "precision": 0.125,
                        "recall": 0.041666666666666664,
                        "f1-score": 0.0625,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.21428571428571427,
                        "recall": 0.07142857142857142,
                        "f1-score": 0.10714285714285714,
                        "support": 28.0
                    }
                },
                "rail_transport_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "BEFORE": {
                        "precision": 0.6666666666666666,
                        "recall": 0.058823529411764705,
                        "f1-score": 0.10810810810810811,
                        "support": 34.0
                    },
                    "COEX": {
                        "precision": 0.16666666666666666,
                        "recall": 0.5,
                        "f1-score": 0.25,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.08333333333333333,
                    "macro avg": {
                        "precision": 0.20833333333333331,
                        "recall": 0.13970588235294118,
                        "f1-score": 0.08952702702702703,
                        "support": 36.0
                    },
                    "weighted avg": {
                        "precision": 0.6388888888888888,
                        "recall": 0.08333333333333333,
                        "f1-score": 0.11599099099099099,
                        "support": 36.0
                    }
                },
                "politics_and_conflicts_policy_change_2": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.4,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.25,
                        "recall": 1.0,
                        "f1-score": 0.4,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 6.0
                    },
                    "macro avg": {
                        "precision": 0.1875,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.2,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.2916666666666667,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.26666666666666666,
                        "support": 6.0
                    }
                },
                "politics_and_conflicts_drones_1": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.2727272727272727,
                        "f1-score": 0.42857142857142855,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.6666666666666666,
                        "recall": 0.25,
                        "f1-score": 0.36363636363636365,
                        "support": 8.0
                    },
                    "COEX": {
                        "precision": 0.2,
                        "recall": 0.5,
                        "f1-score": 0.28571428571428575,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2857142857142857,
                    "macro avg": {
                        "precision": 0.4666666666666666,
                        "recall": 0.2556818181818182,
                        "f1-score": 0.2694805194805195,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.7968253968253967,
                        "recall": 0.2857142857142857,
                        "f1-score": 0.39022881880024735,
                        "support": 21.0
                    }
                },
                "disasters_and_accidents_road_crash_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "BEFORE": {
                        "precision": 0.6,
                        "recall": 0.2727272727272727,
                        "f1-score": 0.37499999999999994,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.5,
                        "recall": 0.2,
                        "f1-score": 0.28571428571428575,
                        "support": 10.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.23809523809523808,
                    "macro avg": {
                        "precision": 0.275,
                        "recall": 0.11818181818181818,
                        "f1-score": 0.16517857142857142,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.5523809523809524,
                        "recall": 0.23809523809523808,
                        "f1-score": 0.3324829931972789,
                        "support": 21.0
                    }
                },
                "crime_and_law_accuse_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.0,
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 10.0
                    }
                },
                "government_and_politics_protests_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.1,
                        "f1-score": 0.18181818181818182,
                        "support": 20.0
                    },
                    "COEX": {
                        "precision": 0.21428571428571427,
                        "recall": 1.0,
                        "f1-score": 0.35294117647058826,
                        "support": 3.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.17857142857142858,
                    "macro avg": {
                        "precision": 0.30357142857142855,
                        "recall": 0.275,
                        "f1-score": 0.13368983957219252,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.7372448979591837,
                        "recall": 0.17857142857142858,
                        "f1-score": 0.16768525592055003,
                        "support": 28.0
                    }
                },
                "politics_and_conflicts_elections_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 22.0
                    },
                    "BEFORE": {
                        "precision": 0.2,
                        "recall": 0.07142857142857142,
                        "f1-score": 0.10526315789473682,
                        "support": 14.0
                    },
                    "COEX": {
                        "precision": 0.2222222222222222,
                        "recall": 0.2222222222222222,
                        "f1-score": 0.2222222222222222,
                        "support": 9.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.06666666666666667,
                    "macro avg": {
                        "precision": 0.10555555555555556,
                        "recall": 0.0734126984126984,
                        "f1-score": 0.08187134502923976,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.10666666666666669,
                        "recall": 0.06666666666666667,
                        "f1-score": 0.07719298245614034,
                        "support": 45.0
                    }
                },
                "environment_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 21.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 23.0
                    },
                    "COEX": {
                        "precision": 0.07142857142857142,
                        "recall": 1.0,
                        "f1-score": 0.13333333333333333,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.022222222222222223,
                    "macro avg": {
                        "precision": 0.017857142857142856,
                        "recall": 0.25,
                        "f1-score": 0.03333333333333333,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.0015873015873015873,
                        "recall": 0.022222222222222223,
                        "f1-score": 0.002962962962962963,
                        "support": 45.0
                    }
                },
                "weather_floods_3": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.25,
                        "f1-score": 0.3333333333333333,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 7.0
                    },
                    "COEX": {
                        "precision": 0.125,
                        "recall": 0.25,
                        "f1-score": 0.16666666666666666,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.13333333333333333,
                    "macro avg": {
                        "precision": 0.15625,
                        "recall": 0.125,
                        "f1-score": 0.125,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.16666666666666666,
                        "recall": 0.13333333333333333,
                        "f1-score": 0.13333333333333333,
                        "support": 15.0
                    }
                },
                "sports_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.0,
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    }
                },
                "health_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 9.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 0.125,
                        "f1-score": 0.18181818181818182,
                        "support": 8.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.047619047619047616,
                    "macro avg": {
                        "precision": 0.08333333333333333,
                        "recall": 0.03125,
                        "f1-score": 0.045454545454545456,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.12698412698412698,
                        "recall": 0.047619047619047616,
                        "f1-score": 0.06926406926406926,
                        "support": 21.0
                    }
                },
                "weather_earthquakes_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.03125,
                        "f1-score": 0.06060606060606061,
                        "support": 32.0
                    },
                    "COEX": {
                        "precision": 0.2,
                        "recall": 0.42857142857142855,
                        "f1-score": 0.27272727272727276,
                        "support": 7.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.08888888888888889,
                    "macro avg": {
                        "precision": 0.3,
                        "recall": 0.11495535714285714,
                        "f1-score": 0.08333333333333334,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.7422222222222222,
                        "recall": 0.08888888888888889,
                        "f1-score": 0.08552188552188553,
                        "support": 45.0
                    }
                },
                "space_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.75,
                        "recall": 0.2,
                        "f1-score": 0.31578947368421056,
                        "support": 15.0
                    },
                    "COEX": {
                        "precision": 0.14285714285714285,
                        "recall": 1.0,
                        "f1-score": 0.25,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.17857142857142858,
                    "macro avg": {
                        "precision": 0.2232142857142857,
                        "recall": 0.3,
                        "f1-score": 0.14144736842105265,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.4119897959183674,
                        "recall": 0.17857142857142858,
                        "f1-score": 0.18703007518796994,
                        "support": 28.0
                    }
                },
                "economy_and_business_strikes_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.25,
                        "f1-score": 0.3333333333333333,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.16666666666666666,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.16666666666666666,
                        "support": 6.0
                    },
                    "macro avg": {
                        "precision": 0.125,
                        "recall": 0.0625,
                        "f1-score": 0.08333333333333333,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.2222222222222222,
                        "support": 6.0
                    }
                },
                "politics_and_conflicts_armed_conflict_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.09090909090909091,
                        "f1-score": 0.16666666666666669,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.5,
                        "recall": 0.6666666666666666,
                        "f1-score": 0.5714285714285715,
                        "support": 3.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2,
                    "macro avg": {
                        "precision": 0.375,
                        "recall": 0.1893939393939394,
                        "f1-score": 0.18452380952380953,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.8333333333333334,
                        "recall": 0.2,
                        "f1-score": 0.23650793650793653,
                        "support": 15.0
                    }
                },
                "infectious_disease_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    }
                },
                "health_1": {
                    "AFTER": {
                        "precision": 0.6666666666666666,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.4444444444444444,
                        "support": 6.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 3.0
                    },
                    "COEX": {
                        "precision": 0.3333333333333333,
                        "recall": 1.0,
                        "f1-score": 0.5,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.4,
                    "macro avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.41666666666666663,
                        "f1-score": 0.3194444444444444,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.5333333333333333,
                        "recall": 0.4,
                        "f1-score": 0.41666666666666663,
                        "support": 10.0
                    }
                },
                "disasters_and_accidents_shipwreck_2": {
                    "AFTER": {
                        "precision": 0.4,
                        "recall": 0.18181818181818182,
                        "f1-score": 0.25000000000000006,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.1111111111111111,
                        "f1-score": 0.1818181818181818,
                        "support": 9.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.14285714285714285,
                    "macro avg": {
                        "precision": 0.225,
                        "recall": 0.07323232323232323,
                        "f1-score": 0.10795454545454547,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.4238095238095238,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.20887445887445888,
                        "support": 21.0
                    }
                },
                "rail_transport_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.2,
                        "f1-score": 0.33333333333333337,
                        "support": 10.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.13333333333333333,
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.05,
                        "f1-score": 0.08333333333333334,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.6666666666666666,
                        "recall": 0.13333333333333333,
                        "f1-score": 0.22222222222222227,
                        "support": 15.0
                    }
                },
                "weather_storms_1_extra": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    }
                },
                "health_1_extra": {
                    "AFTER": {
                        "precision": 0.4,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.23529411764705882,
                        "support": 12.0
                    },
                    "BEFORE": {
                        "precision": 0.2,
                        "recall": 0.03571428571428571,
                        "f1-score": 0.06060606060606061,
                        "support": 28.0
                    },
                    "COEX": {
                        "precision": 0.1111111111111111,
                        "recall": 0.06666666666666667,
                        "f1-score": 0.08333333333333334,
                        "support": 15.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.07272727272727272,
                    "macro avg": {
                        "precision": 0.1777777777777778,
                        "recall": 0.06726190476190476,
                        "f1-score": 0.0948083778966132,
                        "support": 55.0
                    },
                    "weighted avg": {
                        "precision": 0.21939393939393942,
                        "recall": 0.07272727272727272,
                        "f1-score": 0.10491816561335278,
                        "support": 55.0
                    }
                },
                "weather_floods_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.25,
                        "recall": 0.041666666666666664,
                        "f1-score": 0.07142857142857142,
                        "support": 24.0
                    },
                    "COEX": {
                        "precision": 0.625,
                        "recall": 0.35714285714285715,
                        "f1-score": 0.45454545454545453,
                        "support": 28.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2,
                    "macro avg": {
                        "precision": 0.21875,
                        "recall": 0.09970238095238096,
                        "f1-score": 0.1314935064935065,
                        "support": 55.0
                    },
                    "weighted avg": {
                        "precision": 0.42727272727272725,
                        "recall": 0.2,
                        "f1-score": 0.2625737898465171,
                        "support": 55.0
                    }
                },
                "mining_4": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.09090909090909091,
                        "f1-score": 0.15384615384615385,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.6666666666666666,
                        "recall": 0.08,
                        "f1-score": 0.14285714285714285,
                        "support": 25.0
                    },
                    "COEX": {
                        "precision": 0.6666666666666666,
                        "recall": 0.4444444444444444,
                        "f1-score": 0.5333333333333333,
                        "support": 9.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.15555555555555556,
                    "macro avg": {
                        "precision": 0.45833333333333326,
                        "recall": 0.15383838383838383,
                        "f1-score": 0.2075091575091575,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.6259259259259259,
                        "recall": 0.15555555555555556,
                        "f1-score": 0.22363858363858363,
                        "support": 45.0
                    }
                },
                "disasters_and_accidents_volcanoes_4": {
                    "AFTER": {
                        "precision": 0.16666666666666666,
                        "recall": 0.05,
                        "f1-score": 0.07692307692307691,
                        "support": 20.0
                    },
                    "BEFORE": {
                        "precision": 0.2,
                        "recall": 0.21428571428571427,
                        "f1-score": 0.20689655172413796,
                        "support": 14.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.1111111111111111,
                    "macro avg": {
                        "precision": 0.09166666666666667,
                        "recall": 0.06607142857142857,
                        "f1-score": 0.07095490716180372,
                        "support": 36.0
                    },
                    "weighted avg": {
                        "precision": 0.17037037037037037,
                        "recall": 0.1111111111111111,
                        "f1-score": 0.12319481284998528,
                        "support": 36.0
                    }
                },
                "politics_and_conflicts_elections_3": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.2,
                        "f1-score": 0.28571428571428575,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.06666666666666667,
                    "macro avg": {
                        "precision": 0.125,
                        "recall": 0.05,
                        "f1-score": 0.07142857142857144,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.16666666666666666,
                        "recall": 0.06666666666666667,
                        "f1-score": 0.09523809523809526,
                        "support": 15.0
                    }
                },
                "economy_and_business_strikes_3": {
                    "AFTER": {
                        "precision": 0.6666666666666666,
                        "recall": 0.2,
                        "f1-score": 0.30769230769230765,
                        "support": 10.0
                    },
                    "BEFORE": {
                        "precision": 0.25,
                        "recall": 0.09090909090909091,
                        "f1-score": 0.13333333333333333,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.25,
                        "recall": 0.2857142857142857,
                        "f1-score": 0.26666666666666666,
                        "support": 7.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.17857142857142858,
                    "macro avg": {
                        "precision": 0.29166666666666663,
                        "recall": 0.14415584415584415,
                        "f1-score": 0.1769230769230769,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.3988095238095238,
                        "recall": 0.17857142857142858,
                        "f1-score": 0.22893772893772896,
                        "support": 28.0
                    }
                },
                "space_2": {
                    "AFTER": {
                        "precision": 0.45454545454545453,
                        "recall": 0.1,
                        "f1-score": 0.16393442622950818,
                        "support": 100.0
                    },
                    "BEFORE": {
                        "precision": 0.4166666666666667,
                        "recall": 0.09803921568627451,
                        "f1-score": 0.15873015873015872,
                        "support": 51.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.09803921568627451,
                    "macro avg": {
                        "precision": 0.2178030303030303,
                        "recall": 0.04950980392156863,
                        "f1-score": 0.08066614623991672,
                        "support": 153.0
                    },
                    "weighted avg": {
                        "precision": 0.43597742127153893,
                        "recall": 0.09803921568627451,
                        "f1-score": 0.16005673672018897,
                        "support": 153.0
                    }
                },
                "politics_and_conflicts_resign_1": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.5,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 3.0
                    },
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.08333333333333333,
                        "f1-score": 0.125,
                        "support": 3.0
                    },
                    "weighted avg": {
                        "precision": 1.0,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.5,
                        "support": 3.0
                    }
                },
                "environment_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.42857142857142855,
                        "recall": 0.6,
                        "f1-score": 0.5,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.5,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.4,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.3333333333333333,
                    "macro avg": {
                        "precision": 0.23214285714285715,
                        "recall": 0.23333333333333334,
                        "f1-score": 0.225,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.3428571428571428,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3266666666666667,
                        "support": 15.0
                    }
                },
                "space_1_extra": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 1.0,
                        "f1-score": 0.6666666666666666,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.8,
                        "f1-score": 0.888888888888889,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.8333333333333334,
                        "recall": 0.8333333333333334,
                        "f1-score": 0.8333333333333334,
                        "support": 6.0
                    },
                    "macro avg": {
                        "precision": 0.375,
                        "recall": 0.45,
                        "f1-score": 0.3888888888888889,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.9166666666666666,
                        "recall": 0.8333333333333334,
                        "f1-score": 0.851851851851852,
                        "support": 6.0
                    }
                },
                "health_3": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.25,
                        "f1-score": 0.4,
                        "support": 8.0
                    },
                    "BEFORE": {
                        "precision": 0.6,
                        "recall": 0.5,
                        "f1-score": 0.5454545454545454,
                        "support": 6.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.3333333333333333,
                    "macro avg": {
                        "precision": 0.4,
                        "recall": 0.1875,
                        "f1-score": 0.23636363636363636,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.7733333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.4315151515151515,
                        "support": 15.0
                    }
                },
                "environment_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.25,
                        "recall": 1.0,
                        "f1-score": 0.4,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.13333333333333333,
                    "macro avg": {
                        "precision": 0.0625,
                        "recall": 0.25,
                        "f1-score": 0.1,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.03333333333333333,
                        "recall": 0.13333333333333333,
                        "f1-score": 0.05333333333333334,
                        "support": 15.0
                    }
                },
                "government_and_politics_protests_3": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.25,
                        "f1-score": 0.3333333333333333,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.25,
                        "recall": 1.0,
                        "f1-score": 0.4,
                        "support": 1.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 6.0
                    },
                    "macro avg": {
                        "precision": 0.1875,
                        "recall": 0.3125,
                        "f1-score": 0.18333333333333335,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.375,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.2888888888888889,
                        "support": 6.0
                    }
                },
                "economy_and_business_financial_crisis_4": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.08333333333333333,
                        "f1-score": 0.15384615384615385,
                        "support": 12.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.125,
                        "recall": 0.25,
                        "f1-score": 0.16666666666666666,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.09523809523809523,
                    "macro avg": {
                        "precision": 0.28125,
                        "recall": 0.08333333333333333,
                        "f1-score": 0.08012820512820512,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.5952380952380952,
                        "recall": 0.09523809523809523,
                        "f1-score": 0.11965811965811965,
                        "support": 21.0
                    }
                },
                "computers_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    }
                },
                "crime_and_law_accuse_4": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.2,
                        "f1-score": 0.28571428571428575,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.25,
                        "recall": 0.2,
                        "f1-score": 0.22222222222222224,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2,
                    "macro avg": {
                        "precision": 0.1875,
                        "recall": 0.1,
                        "f1-score": 0.126984126984127,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.375,
                        "recall": 0.2,
                        "f1-score": 0.253968253968254,
                        "support": 10.0
                    }
                },
                "culture_and_entertainment_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.4,
                        "recall": 1.0,
                        "f1-score": 0.5714285714285715,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.3333333333333333,
                    "macro avg": {
                        "precision": 0.1,
                        "recall": 0.25,
                        "f1-score": 0.14285714285714288,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.13333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.1904761904761905,
                        "support": 6.0
                    }
                },
                "internet_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.2,
                        "recall": 0.25,
                        "f1-score": 0.22222222222222224,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.1,
                    "macro avg": {
                        "precision": 0.05,
                        "recall": 0.0625,
                        "f1-score": 0.05555555555555556,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.08,
                        "recall": 0.1,
                        "f1-score": 0.08888888888888889,
                        "support": 10.0
                    }
                },
                "culture_and_entertainment_3": {
                    "AFTER": {
                        "precision": 0.25,
                        "recall": 0.4,
                        "f1-score": 0.3076923076923077,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.25,
                        "recall": 0.25,
                        "f1-score": 0.25,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.3333333333333333,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.2222222222222222,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.26666666666666666,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.26666666666666666,
                        "support": 15.0
                    },
                    "macro avg": {
                        "precision": 0.20833333333333331,
                        "recall": 0.20416666666666666,
                        "f1-score": 0.19497863247863248,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.2833333333333333,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.2581196581196581,
                        "support": 15.0
                    }
                }
            },
            "simple_events": {
                "government_and_politics_riots_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 12.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 12.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.0,
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 28.0
                    }
                },
                "rail_transport_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 34.0
                    },
                    "COEX": {
                        "precision": 0.14285714285714285,
                        "recall": 0.5,
                        "f1-score": 0.22222222222222224,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.027777777777777776,
                    "macro avg": {
                        "precision": 0.03571428571428571,
                        "recall": 0.125,
                        "f1-score": 0.05555555555555556,
                        "support": 36.0
                    },
                    "weighted avg": {
                        "precision": 0.007936507936507936,
                        "recall": 0.027777777777777776,
                        "f1-score": 0.01234567901234568,
                        "support": 36.0
                    }
                },
                "politics_and_conflicts_policy_change_2": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.5,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.25,
                        "recall": 1.0,
                        "f1-score": 0.4,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.3333333333333333,
                    "macro avg": {
                        "precision": 0.3125,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.225,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.5416666666666666,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.31666666666666665,
                        "support": 6.0
                    }
                },
                "politics_and_conflicts_drones_1": {
                    "AFTER": {
                        "precision": 0.3333333333333333,
                        "recall": 0.18181818181818182,
                        "f1-score": 0.23529411764705885,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 8.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.09523809523809523,
                    "macro avg": {
                        "precision": 0.08333333333333333,
                        "recall": 0.045454545454545456,
                        "f1-score": 0.05882352941176471,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.1746031746031746,
                        "recall": 0.09523809523809523,
                        "f1-score": 0.12324929971988796,
                        "support": 21.0
                    }
                },
                "disasters_and_accidents_road_crash_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.09090909090909091,
                        "f1-score": 0.16666666666666669,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.42857142857142855,
                        "recall": 0.3,
                        "f1-score": 0.3529411764705882,
                        "support": 10.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.19047619047619047,
                    "macro avg": {
                        "precision": 0.35714285714285715,
                        "recall": 0.09772727272727272,
                        "f1-score": 0.1299019607843137,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.727891156462585,
                        "recall": 0.19047619047619047,
                        "f1-score": 0.25536881419234364,
                        "support": 21.0
                    }
                },
                "crime_and_law_accuse_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.2857142857142857,
                        "support": 6.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.1,
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.041666666666666664,
                        "f1-score": 0.07142857142857142,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.6,
                        "recall": 0.1,
                        "f1-score": 0.17142857142857143,
                        "support": 10.0
                    }
                },
                "government_and_politics_protests_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 20.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.0,
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 28.0
                    }
                },
                "politics_and_conflicts_elections_2": {
                    "AFTER": {
                        "precision": 0.5714285714285714,
                        "recall": 0.18181818181818182,
                        "f1-score": 0.27586206896551724,
                        "support": 22.0
                    },
                    "BEFORE": {
                        "precision": 0.6666666666666666,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.23529411764705882,
                        "support": 14.0
                    },
                    "COEX": {
                        "precision": 0.1875,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.24000000000000005,
                        "support": 9.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2,
                    "macro avg": {
                        "precision": 0.35639880952380953,
                        "recall": 0.16450216450216448,
                        "f1-score": 0.187789046653144,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.5242724867724868,
                        "recall": 0.2,
                        "f1-score": 0.25606851476222675,
                        "support": 45.0
                    }
                },
                "environment_2": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.25,
                        "support": 21.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 23.0
                    },
                    "COEX": {
                        "precision": 0.09090909090909091,
                        "recall": 1.0,
                        "f1-score": 0.16666666666666669,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.08888888888888889,
                    "macro avg": {
                        "precision": 0.2727272727272727,
                        "recall": 0.2857142857142857,
                        "f1-score": 0.10416666666666667,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.46868686868686865,
                        "recall": 0.08888888888888889,
                        "f1-score": 0.12037037037037038,
                        "support": 45.0
                    }
                },
                "weather_floods_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 7.0
                    },
                    "COEX": {
                        "precision": 0.26666666666666666,
                        "recall": 1.0,
                        "f1-score": 0.4210526315789474,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.26666666666666666,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.26666666666666666,
                        "support": 15.0
                    },
                    "macro avg": {
                        "precision": 0.06666666666666667,
                        "recall": 0.25,
                        "f1-score": 0.10526315789473685,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.07111111111111111,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.11228070175438597,
                        "support": 15.0
                    }
                },
                "sports_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    }
                },
                "health_4": {
                    "AFTER": {
                        "precision": 0.6666666666666666,
                        "recall": 0.2222222222222222,
                        "f1-score": 0.3333333333333333,
                        "support": 9.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 8.0
                    },
                    "COEX": {
                        "precision": 0.15384615384615385,
                        "recall": 0.5,
                        "f1-score": 0.23529411764705882,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.19047619047619047,
                    "macro avg": {
                        "precision": 0.20512820512820512,
                        "recall": 0.18055555555555555,
                        "f1-score": 0.14215686274509803,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.315018315018315,
                        "recall": 0.19047619047619047,
                        "f1-score": 0.1876750700280112,
                        "support": 21.0
                    }
                },
                "weather_earthquakes_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 32.0
                    },
                    "COEX": {
                        "precision": 0.5,
                        "recall": 0.5714285714285714,
                        "f1-score": 0.5333333333333333,
                        "support": 7.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.08888888888888889,
                    "macro avg": {
                        "precision": 0.125,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.13333333333333333,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.07777777777777778,
                        "recall": 0.08888888888888889,
                        "f1-score": 0.08296296296296296,
                        "support": 45.0
                    }
                },
                "space_4": {
                    "AFTER": {
                        "precision": 0.6666666666666666,
                        "recall": 0.18181818181818182,
                        "f1-score": 0.28571428571428575,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 15.0
                    },
                    "COEX": {
                        "precision": 0.08333333333333333,
                        "recall": 0.5,
                        "f1-score": 0.14285714285714285,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.10714285714285714,
                    "macro avg": {
                        "precision": 0.1875,
                        "recall": 0.17045454545454547,
                        "f1-score": 0.10714285714285715,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.26785714285714285,
                        "recall": 0.10714285714285714,
                        "f1-score": 0.12244897959183675,
                        "support": 28.0
                    }
                },
                "economy_and_business_strikes_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.3333333333333333,
                        "recall": 1.0,
                        "f1-score": 0.5,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.16666666666666666,
                    "macro avg": {
                        "precision": 0.08333333333333333,
                        "recall": 0.25,
                        "f1-score": 0.125,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.05555555555555555,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.08333333333333333,
                        "support": 6.0
                    }
                },
                "politics_and_conflicts_armed_conflict_2": {
                    "AFTER": {
                        "precision": 0.2,
                        "recall": 1.0,
                        "f1-score": 0.33333333333333337,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.09090909090909091,
                        "f1-score": 0.16666666666666669,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.6666666666666666,
                        "recall": 0.6666666666666666,
                        "f1-score": 0.6666666666666666,
                        "support": 3.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.26666666666666666,
                    "macro avg": {
                        "precision": 0.4666666666666667,
                        "recall": 0.43939393939393934,
                        "f1-score": 0.29166666666666663,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.88,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.2777777777777778,
                        "support": 15.0
                    }
                },
                "infectious_disease_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    }
                },
                "health_1": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.2857142857142857,
                        "support": 6.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "COEX": {
                        "precision": 0.14285714285714285,
                        "recall": 1.0,
                        "f1-score": 0.25,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2,
                    "macro avg": {
                        "precision": 0.2857142857142857,
                        "recall": 0.2916666666666667,
                        "f1-score": 0.13392857142857142,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.6142857142857143,
                        "recall": 0.2,
                        "f1-score": 0.19642857142857142,
                        "support": 10.0
                    }
                },
                "disasters_and_accidents_shipwreck_2": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.09090909090909091,
                        "f1-score": 0.16666666666666669,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 9.0
                    },
                    "COEX": {
                        "precision": 0.07692307692307693,
                        "recall": 1.0,
                        "f1-score": 0.14285714285714288,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.09523809523809523,
                    "macro avg": {
                        "precision": 0.2692307692307692,
                        "recall": 0.2727272727272727,
                        "f1-score": 0.07738095238095238,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.5274725274725275,
                        "recall": 0.09523809523809523,
                        "f1-score": 0.09410430839002268,
                        "support": 21.0
                    }
                },
                "rail_transport_3": {
                    "AFTER": {
                        "precision": 0.25,
                        "recall": 0.2,
                        "f1-score": 0.22222222222222224,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 10.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.06666666666666667,
                    "macro avg": {
                        "precision": 0.0625,
                        "recall": 0.05,
                        "f1-score": 0.05555555555555556,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.08333333333333333,
                        "recall": 0.06666666666666667,
                        "f1-score": 0.07407407407407408,
                        "support": 15.0
                    }
                },
                "weather_storms_1_extra": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.25,
                        "f1-score": 0.25,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    }
                },
                "health_1_extra": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.25,
                        "support": 12.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 28.0
                    },
                    "COEX": {
                        "precision": 0.25,
                        "recall": 0.2,
                        "f1-score": 0.22222222222222224,
                        "support": 15.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.09090909090909091,
                    "macro avg": {
                        "precision": 0.1875,
                        "recall": 0.09166666666666667,
                        "f1-score": 0.11805555555555555,
                        "support": 55.0
                    },
                    "weighted avg": {
                        "precision": 0.17727272727272728,
                        "recall": 0.09090909090909091,
                        "f1-score": 0.11515151515151516,
                        "support": 55.0
                    }
                },
                "weather_floods_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 24.0
                    },
                    "COEX": {
                        "precision": 0.7857142857142857,
                        "recall": 0.39285714285714285,
                        "f1-score": 0.5238095238095237,
                        "support": 28.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2,
                    "macro avg": {
                        "precision": 0.19642857142857142,
                        "recall": 0.09821428571428571,
                        "f1-score": 0.13095238095238093,
                        "support": 55.0
                    },
                    "weighted avg": {
                        "precision": 0.4,
                        "recall": 0.2,
                        "f1-score": 0.2666666666666666,
                        "support": 55.0
                    }
                },
                "mining_4": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.2727272727272727,
                        "f1-score": 0.42857142857142855,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 25.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 9.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.06666666666666667,
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.06818181818181818,
                        "f1-score": 0.10714285714285714,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.24444444444444444,
                        "recall": 0.06666666666666667,
                        "f1-score": 0.10476190476190476,
                        "support": 45.0
                    }
                },
                "disasters_and_accidents_volcanoes_4": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.2,
                        "f1-score": 0.33333333333333337,
                        "support": 20.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 14.0
                    },
                    "COEX": {
                        "precision": 0.08333333333333333,
                        "recall": 1.0,
                        "f1-score": 0.15384615384615385,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.16666666666666666,
                    "macro avg": {
                        "precision": 0.2708333333333333,
                        "recall": 0.3,
                        "f1-score": 0.1217948717948718,
                        "support": 36.0
                    },
                    "weighted avg": {
                        "precision": 0.5601851851851852,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.19373219373219375,
                        "support": 36.0
                    }
                },
                "politics_and_conflicts_elections_3": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.2,
                        "f1-score": 0.28571428571428575,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.5,
                        "recall": 1.0,
                        "f1-score": 0.6666666666666666,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.4666666666666667,
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.3,
                        "f1-score": 0.23809523809523808,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.36666666666666664,
                        "recall": 0.4666666666666667,
                        "f1-score": 0.3619047619047619,
                        "support": 15.0
                    }
                },
                "economy_and_business_strikes_3": {
                    "AFTER": {
                        "precision": 0.2857142857142857,
                        "recall": 0.2,
                        "f1-score": 0.23529411764705882,
                        "support": 10.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.3333333333333333,
                        "recall": 0.2857142857142857,
                        "f1-score": 0.30769230769230765,
                        "support": 7.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.14285714285714285,
                    "macro avg": {
                        "precision": 0.15476190476190477,
                        "recall": 0.12142857142857143,
                        "f1-score": 0.13574660633484162,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.18537414965986393,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.16095669036845509,
                        "support": 28.0
                    }
                },
                "space_2": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.11,
                        "f1-score": 0.19819819819819817,
                        "support": 100.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 51.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.0718954248366013,
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.0275,
                        "f1-score": 0.04954954954954954,
                        "support": 153.0
                    },
                    "weighted avg": {
                        "precision": 0.6535947712418301,
                        "recall": 0.0718954248366013,
                        "f1-score": 0.12954130601189423,
                        "support": 153.0
                    }
                },
                "politics_and_conflicts_resign_1": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.5,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 3.0
                    },
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.08333333333333333,
                        "f1-score": 0.125,
                        "support": 3.0
                    },
                    "weighted avg": {
                        "precision": 1.0,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.5,
                        "support": 3.0
                    }
                },
                "environment_4": {
                    "AFTER": {
                        "precision": 0.3333333333333333,
                        "recall": 0.25,
                        "f1-score": 0.28571428571428575,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.5,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.25,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.13333333333333333,
                    "macro avg": {
                        "precision": 0.20833333333333331,
                        "recall": 0.10416666666666666,
                        "f1-score": 0.13392857142857145,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.28888888888888886,
                        "recall": 0.13333333333333333,
                        "f1-score": 0.1761904761904762,
                        "support": 15.0
                    }
                },
                "space_1_extra": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.0,
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    }
                },
                "health_3": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.375,
                        "f1-score": 0.5454545454545454,
                        "support": 8.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2,
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.09375,
                        "f1-score": 0.13636363636363635,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.5333333333333333,
                        "recall": 0.2,
                        "f1-score": 0.2909090909090909,
                        "support": 15.0
                    }
                },
                "environment_3": {
                    "AFTER": {
                        "precision": 0.6666666666666666,
                        "recall": 0.18181818181818182,
                        "f1-score": 0.28571428571428575,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.13333333333333333,
                    "macro avg": {
                        "precision": 0.16666666666666666,
                        "recall": 0.045454545454545456,
                        "f1-score": 0.07142857142857144,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.4888888888888889,
                        "recall": 0.13333333333333333,
                        "f1-score": 0.20952380952380956,
                        "support": 15.0
                    }
                },
                "government_and_politics_protests_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "COEX": {
                        "precision": 0.25,
                        "recall": 1.0,
                        "f1-score": 0.4,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.16666666666666666,
                    "macro avg": {
                        "precision": 0.0625,
                        "recall": 0.25,
                        "f1-score": 0.1,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.041666666666666664,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.06666666666666667,
                        "support": 6.0
                    }
                },
                "economy_and_business_financial_crisis_4": {
                    "AFTER": {
                        "precision": 0.3333333333333333,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.2222222222222222,
                        "support": 12.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.3333333333333333,
                        "recall": 0.5,
                        "f1-score": 0.4,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.19047619047619047,
                    "macro avg": {
                        "precision": 0.16666666666666666,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.15555555555555556,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.25396825396825395,
                        "recall": 0.19047619047619047,
                        "f1-score": 0.20317460317460317,
                        "support": 21.0
                    }
                },
                "computers_2": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.25,
                        "f1-score": 0.25,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    }
                },
                "crime_and_law_accuse_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.0,
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 10.0
                    }
                },
                "culture_and_entertainment_1": {
                    "AFTER": {
                        "precision": 0.6666666666666666,
                        "recall": 1.0,
                        "f1-score": 0.8,
                        "support": 2.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.3333333333333333,
                    "macro avg": {
                        "precision": 0.16666666666666666,
                        "recall": 0.25,
                        "f1-score": 0.2,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.2222222222222222,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.26666666666666666,
                        "support": 6.0
                    }
                },
                "internet_2": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.4,
                        "f1-score": 0.5714285714285715,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2,
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.1,
                        "f1-score": 0.14285714285714288,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.5,
                        "recall": 0.2,
                        "f1-score": 0.28571428571428575,
                        "support": 10.0
                    }
                },
                "culture_and_entertainment_3": {
                    "AFTER": {
                        "precision": 0.4,
                        "recall": 0.4,
                        "f1-score": 0.4000000000000001,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.5,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.4,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.26666666666666666,
                    "macro avg": {
                        "precision": 0.225,
                        "recall": 0.18333333333333335,
                        "f1-score": 0.2,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.29333333333333333,
                        "support": 15.0
                    }
                }
            },
            "note": {
                "government_and_politics_riots_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.08333333333333333,
                        "f1-score": 0.14285714285714285,
                        "support": 12.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 12.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.03571428571428571,
                    "macro avg": {
                        "precision": 0.125,
                        "recall": 0.020833333333333332,
                        "f1-score": 0.03571428571428571,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.21428571428571427,
                        "recall": 0.03571428571428571,
                        "f1-score": 0.061224489795918366,
                        "support": 28.0
                    }
                },
                "rail_transport_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.029411764705882353,
                        "f1-score": 0.05714285714285715,
                        "support": 34.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.027777777777777776,
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.007352941176470588,
                        "f1-score": 0.014285714285714287,
                        "support": 36.0
                    },
                    "weighted avg": {
                        "precision": 0.9444444444444444,
                        "recall": 0.027777777777777776,
                        "f1-score": 0.05396825396825397,
                        "support": 36.0
                    }
                },
                "politics_and_conflicts_policy_change_2": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.4,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.5,
                        "f1-score": 0.5,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 6.0
                    },
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.20833333333333331,
                        "f1-score": 0.225,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.4166666666666667,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3666666666666667,
                        "support": 6.0
                    }
                },
                "politics_and_conflicts_drones_1": {
                    "AFTER": {
                        "precision": 0.42857142857142855,
                        "recall": 0.2727272727272727,
                        "f1-score": 0.33333333333333326,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 8.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.14285714285714285,
                    "macro avg": {
                        "precision": 0.10714285714285714,
                        "recall": 0.06818181818181818,
                        "f1-score": 0.08333333333333331,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.22448979591836735,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.17460317460317457,
                        "support": 21.0
                    }
                },
                "disasters_and_accidents_road_crash_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.3333333333333333,
                        "recall": 0.1,
                        "f1-score": 0.15384615384615383,
                        "support": 10.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.047619047619047616,
                    "macro avg": {
                        "precision": 0.08333333333333333,
                        "recall": 0.025,
                        "f1-score": 0.03846153846153846,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.15873015873015872,
                        "recall": 0.047619047619047616,
                        "f1-score": 0.07326007326007325,
                        "support": 21.0
                    }
                },
                "crime_and_law_accuse_3": {
                    "AFTER": {
                        "precision": 0.2857142857142857,
                        "recall": 0.5,
                        "f1-score": 0.36363636363636365,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.25,
                        "support": 6.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.3,
                        "recall": 0.3,
                        "f1-score": 0.3,
                        "support": 10.0
                    },
                    "macro avg": {
                        "precision": 0.19642857142857142,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.1534090909090909,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.41428571428571426,
                        "recall": 0.3,
                        "f1-score": 0.29545454545454547,
                        "support": 10.0
                    }
                },
                "government_and_politics_protests_2": {
                    "AFTER": {
                        "precision": 0.2,
                        "recall": 0.4,
                        "f1-score": 0.26666666666666666,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.05,
                        "f1-score": 0.09523809523809523,
                        "support": 20.0
                    },
                    "COEX": {
                        "precision": 0.06666666666666667,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.1111111111111111,
                        "support": 3.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.14285714285714285,
                    "macro avg": {
                        "precision": 0.31666666666666665,
                        "recall": 0.19583333333333333,
                        "f1-score": 0.11825396825396825,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.7571428571428571,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.12755102040816327,
                        "support": 28.0
                    }
                },
                "politics_and_conflicts_elections_2": {
                    "AFTER": {
                        "precision": 0.25,
                        "recall": 0.045454545454545456,
                        "f1-score": 0.07692307692307693,
                        "support": 22.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.07142857142857142,
                        "f1-score": 0.125,
                        "support": 14.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 9.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.044444444444444446,
                    "macro avg": {
                        "precision": 0.1875,
                        "recall": 0.02922077922077922,
                        "f1-score": 0.05048076923076923,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.2777777777777778,
                        "recall": 0.044444444444444446,
                        "f1-score": 0.0764957264957265,
                        "support": 45.0
                    }
                },
                "environment_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 21.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 23.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.0,
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 45.0
                    }
                },
                "weather_floods_3": {
                    "AFTER": {
                        "precision": 0.2,
                        "recall": 0.25,
                        "f1-score": 0.22222222222222224,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.22222222222222224,
                        "support": 7.0
                    },
                    "COEX": {
                        "precision": 0.3333333333333333,
                        "recall": 0.25,
                        "f1-score": 0.28571428571428575,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2,
                    "macro avg": {
                        "precision": 0.2583333333333333,
                        "recall": 0.1607142857142857,
                        "f1-score": 0.18253968253968256,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.37555555555555553,
                        "recall": 0.2,
                        "f1-score": 0.2391534391534392,
                        "support": 15.0
                    }
                },
                "sports_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    }
                },
                "health_4": {
                    "AFTER": {
                        "precision": 0.25,
                        "recall": 0.1111111111111111,
                        "f1-score": 0.15384615384615383,
                        "support": 9.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 0.125,
                        "f1-score": 0.18181818181818182,
                        "support": 8.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.09523809523809523,
                    "macro avg": {
                        "precision": 0.14583333333333331,
                        "recall": 0.059027777777777776,
                        "f1-score": 0.0839160839160839,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.2341269841269841,
                        "recall": 0.09523809523809523,
                        "f1-score": 0.1351981351981352,
                        "support": 21.0
                    }
                },
                "weather_earthquakes_1": {
                    "AFTER": {
                        "precision": 0.16666666666666666,
                        "recall": 0.5,
                        "f1-score": 0.25,
                        "support": 6.0
                    },
                    "BEFORE": {
                        "precision": 0.8333333333333334,
                        "recall": 0.15625,
                        "f1-score": 0.2631578947368421,
                        "support": 32.0
                    },
                    "COEX": {
                        "precision": 0.25,
                        "recall": 0.42857142857142855,
                        "f1-score": 0.3157894736842105,
                        "support": 7.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.24444444444444444,
                    "macro avg": {
                        "precision": 0.3125,
                        "recall": 0.27120535714285715,
                        "f1-score": 0.20723684210526314,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.6537037037037037,
                        "recall": 0.24444444444444444,
                        "f1-score": 0.2695906432748538,
                        "support": 45.0
                    }
                },
                "space_4": {
                    "AFTER": {
                        "precision": 0.3333333333333333,
                        "recall": 0.36363636363636365,
                        "f1-score": 0.34782608695652173,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.25,
                        "recall": 0.13333333333333333,
                        "f1-score": 0.1739130434782609,
                        "support": 15.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.21428571428571427,
                    "macro avg": {
                        "precision": 0.14583333333333331,
                        "recall": 0.12424242424242424,
                        "f1-score": 0.13043478260869565,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.2648809523809524,
                        "recall": 0.21428571428571427,
                        "f1-score": 0.2298136645962733,
                        "support": 28.0
                    }
                },
                "economy_and_business_strikes_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.3333333333333333,
                        "recall": 1.0,
                        "f1-score": 0.5,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.16666666666666666,
                    "macro avg": {
                        "precision": 0.08333333333333333,
                        "recall": 0.25,
                        "f1-score": 0.125,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.05555555555555555,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.08333333333333333,
                        "support": 6.0
                    }
                },
                "politics_and_conflicts_armed_conflict_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.18181818181818182,
                        "f1-score": 0.3076923076923077,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.13333333333333333,
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.045454545454545456,
                        "f1-score": 0.07692307692307693,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.7333333333333333,
                        "recall": 0.13333333333333333,
                        "f1-score": 0.22564102564102567,
                        "support": 15.0
                    }
                },
                "infectious_disease_4": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.25,
                        "f1-score": 0.25,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    }
                },
                "health_1": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.4,
                        "support": 6.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2,
                    "macro avg": {
                        "precision": 0.125,
                        "recall": 0.08333333333333333,
                        "f1-score": 0.1,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.3,
                        "recall": 0.2,
                        "f1-score": 0.24000000000000005,
                        "support": 10.0
                    }
                },
                "disasters_and_accidents_shipwreck_2": {
                    "AFTER": {
                        "precision": 0.2,
                        "recall": 0.09090909090909091,
                        "f1-score": 0.12500000000000003,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.25,
                        "recall": 0.1111111111111111,
                        "f1-score": 0.15384615384615383,
                        "support": 9.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.09523809523809523,
                    "macro avg": {
                        "precision": 0.1125,
                        "recall": 0.050505050505050504,
                        "f1-score": 0.06971153846153846,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.2119047619047619,
                        "recall": 0.09523809523809523,
                        "f1-score": 0.13141025641025642,
                        "support": 21.0
                    }
                },
                "rail_transport_3": {
                    "AFTER": {
                        "precision": 0.2,
                        "recall": 0.2,
                        "f1-score": 0.20000000000000004,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.2,
                        "f1-score": 0.28571428571428575,
                        "support": 10.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2,
                    "macro avg": {
                        "precision": 0.175,
                        "recall": 0.1,
                        "f1-score": 0.12142857142857144,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.4,
                        "recall": 0.2,
                        "f1-score": 0.2571428571428572,
                        "support": 15.0
                    }
                },
                "weather_storms_1_extra": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.25,
                        "f1-score": 0.25,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    }
                },
                "health_1_extra": {
                    "AFTER": {
                        "precision": 0.14285714285714285,
                        "recall": 0.08333333333333333,
                        "f1-score": 0.10526315789473685,
                        "support": 12.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 28.0
                    },
                    "COEX": {
                        "precision": 0.19047619047619047,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.2222222222222222,
                        "support": 15.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.09090909090909091,
                    "macro avg": {
                        "precision": 0.08333333333333333,
                        "recall": 0.0875,
                        "f1-score": 0.08187134502923976,
                        "support": 55.0
                    },
                    "weighted avg": {
                        "precision": 0.08311688311688312,
                        "recall": 0.09090909090909091,
                        "f1-score": 0.0835725677830941,
                        "support": 55.0
                    }
                },
                "weather_floods_1": {
                    "AFTER": {
                        "precision": 0.09090909090909091,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.14285714285714288,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.25,
                        "recall": 0.08333333333333333,
                        "f1-score": 0.125,
                        "support": 24.0
                    },
                    "COEX": {
                        "precision": 0.9,
                        "recall": 0.32142857142857145,
                        "f1-score": 0.4736842105263158,
                        "support": 28.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.21818181818181817,
                    "macro avg": {
                        "precision": 0.31022727272727274,
                        "recall": 0.18452380952380953,
                        "f1-score": 0.18538533834586468,
                        "support": 55.0
                    },
                    "weighted avg": {
                        "precision": 0.5722314049586776,
                        "recall": 0.21818181818181817,
                        "f1-score": 0.3034859876965141,
                        "support": 55.0
                    }
                },
                "mining_4": {
                    "AFTER": {
                        "precision": 0.21428571428571427,
                        "recall": 0.2727272727272727,
                        "f1-score": 0.23999999999999996,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.5833333333333334,
                        "recall": 0.28,
                        "f1-score": 0.3783783783783784,
                        "support": 25.0
                    },
                    "COEX": {
                        "precision": 0.25,
                        "recall": 0.1111111111111111,
                        "f1-score": 0.15384615384615383,
                        "support": 9.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.24444444444444444,
                    "macro avg": {
                        "precision": 0.2619047619047619,
                        "recall": 0.16595959595959597,
                        "f1-score": 0.19305613305613306,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.4264550264550264,
                        "recall": 0.24444444444444444,
                        "f1-score": 0.29964610764610766,
                        "support": 45.0
                    }
                },
                "disasters_and_accidents_volcanoes_4": {
                    "AFTER": {
                        "precision": 0.75,
                        "recall": 0.15,
                        "f1-score": 0.24999999999999997,
                        "support": 20.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 0.07142857142857142,
                        "f1-score": 0.11764705882352941,
                        "support": 14.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.1111111111111111,
                    "macro avg": {
                        "precision": 0.2708333333333333,
                        "recall": 0.055357142857142855,
                        "f1-score": 0.09191176470588235,
                        "support": 36.0
                    },
                    "weighted avg": {
                        "precision": 0.5462962962962963,
                        "recall": 0.1111111111111111,
                        "f1-score": 0.18464052287581698,
                        "support": 36.0
                    }
                },
                "politics_and_conflicts_elections_3": {
                    "AFTER": {
                        "precision": 0.16666666666666666,
                        "recall": 0.2,
                        "f1-score": 0.1818181818181818,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.06666666666666667,
                    "macro avg": {
                        "precision": 0.041666666666666664,
                        "recall": 0.05,
                        "f1-score": 0.04545454545454545,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.05555555555555555,
                        "recall": 0.06666666666666667,
                        "f1-score": 0.060606060606060594,
                        "support": 15.0
                    }
                },
                "economy_and_business_strikes_3": {
                    "AFTER": {
                        "precision": 0.1875,
                        "recall": 0.3,
                        "f1-score": 0.23076923076923075,
                        "support": 10.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 0.09090909090909091,
                        "f1-score": 0.14285714285714288,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.16666666666666666,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.15384615384615383,
                        "support": 7.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.17857142857142858,
                    "macro avg": {
                        "precision": 0.17187499999999997,
                        "recall": 0.13344155844155842,
                        "f1-score": 0.13186813186813187,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.2395833333333333,
                        "recall": 0.17857142857142858,
                        "f1-score": 0.1770015698587127,
                        "support": 28.0
                    }
                },
                "space_2": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.02,
                        "f1-score": 0.038461538461538464,
                        "support": 100.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.0196078431372549,
                        "f1-score": 0.03773584905660377,
                        "support": 51.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.0196078431372549,
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.009901960784313726,
                        "f1-score": 0.019049346879535557,
                        "support": 153.0
                    },
                    "weighted avg": {
                        "precision": 0.4934640522875817,
                        "recall": 0.0196078431372549,
                        "f1-score": 0.037716876784579335,
                        "support": 153.0
                    }
                },
                "politics_and_conflicts_resign_1": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.5,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 3.0
                    },
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.08333333333333333,
                        "f1-score": 0.125,
                        "support": 3.0
                    },
                    "weighted avg": {
                        "precision": 1.0,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.5,
                        "support": 3.0
                    }
                },
                "environment_4": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.25,
                        "f1-score": 0.4,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 0.2,
                        "f1-score": 0.25,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 1.0,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.2857142857142857,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2,
                    "macro avg": {
                        "precision": 0.5833333333333333,
                        "recall": 0.15416666666666667,
                        "f1-score": 0.23392857142857143,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.7777777777777778,
                        "recall": 0.2,
                        "f1-score": 0.30428571428571427,
                        "support": 15.0
                    }
                },
                "space_1_extra": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.2,
                        "f1-score": 0.33333333333333337,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.16666666666666666,
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.05,
                        "f1-score": 0.08333333333333334,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.8333333333333334,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.27777777777777785,
                        "support": 6.0
                    }
                },
                "health_3": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.25,
                        "f1-score": 0.3333333333333333,
                        "support": 8.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.13333333333333333,
                    "macro avg": {
                        "precision": 0.125,
                        "recall": 0.0625,
                        "f1-score": 0.08333333333333333,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.26666666666666666,
                        "recall": 0.13333333333333333,
                        "f1-score": 0.17777777777777776,
                        "support": 15.0
                    }
                },
                "environment_3": {
                    "AFTER": {
                        "precision": 0.8333333333333334,
                        "recall": 0.45454545454545453,
                        "f1-score": 0.5882352941176471,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.5,
                        "f1-score": 0.5,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.4,
                    "macro avg": {
                        "precision": 0.33333333333333337,
                        "recall": 0.23863636363636365,
                        "f1-score": 0.2720588235294118,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.6777777777777778,
                        "recall": 0.4,
                        "f1-score": 0.4980392156862745,
                        "support": 15.0
                    }
                },
                "government_and_politics_protests_3": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.25,
                        "f1-score": 0.4,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.16666666666666666,
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.0625,
                        "f1-score": 0.1,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.6666666666666666,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.26666666666666666,
                        "support": 6.0
                    }
                },
                "economy_and_business_financial_crisis_4": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.4166666666666667,
                        "f1-score": 0.45454545454545453,
                        "support": 12.0
                    },
                    "BEFORE": {
                        "precision": 0.25,
                        "recall": 0.2,
                        "f1-score": 0.22222222222222224,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.3333333333333333,
                        "recall": 0.25,
                        "f1-score": 0.28571428571428575,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.3333333333333333,
                    "macro avg": {
                        "precision": 0.2708333333333333,
                        "recall": 0.21666666666666667,
                        "f1-score": 0.24062049062049062,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.4087301587301588,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3670720813577957,
                        "support": 21.0
                    }
                },
                "computers_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    }
                },
                "crime_and_law_accuse_4": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.2,
                        "f1-score": 0.33333333333333337,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.2,
                        "f1-score": 0.28571428571428575,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2,
                    "macro avg": {
                        "precision": 0.375,
                        "recall": 0.1,
                        "f1-score": 0.15476190476190477,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.75,
                        "recall": 0.2,
                        "f1-score": 0.3095238095238096,
                        "support": 10.0
                    }
                },
                "culture_and_entertainment_1": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.5,
                        "f1-score": 0.6666666666666666,
                        "support": 2.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.5,
                        "recall": 1.0,
                        "f1-score": 0.6666666666666666,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.5,
                    "macro avg": {
                        "precision": 0.375,
                        "recall": 0.375,
                        "f1-score": 0.3333333333333333,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.5,
                        "recall": 0.5,
                        "f1-score": 0.4444444444444444,
                        "support": 6.0
                    }
                },
                "internet_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.0,
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 10.0
                    }
                },
                "culture_and_entertainment_3": {
                    "AFTER": {
                        "precision": 0.42857142857142855,
                        "recall": 0.6,
                        "f1-score": 0.5,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.25,
                        "f1-score": 0.3333333333333333,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.5,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.4,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.4,
                    "macro avg": {
                        "precision": 0.35714285714285715,
                        "recall": 0.29583333333333334,
                        "f1-score": 0.30833333333333335,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.47619047619047616,
                        "recall": 0.4,
                        "f1-score": 0.41555555555555557,
                        "support": 15.0
                    }
                }
            },
            "note_events": {
                "government_and_politics_riots_4": {
                    "AFTER": {
                        "precision": 0.18181818181818182,
                        "recall": 0.5,
                        "f1-score": 0.26666666666666666,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 12.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 12.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.07142857142857142,
                    "macro avg": {
                        "precision": 0.045454545454545456,
                        "recall": 0.125,
                        "f1-score": 0.06666666666666667,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.025974025974025976,
                        "recall": 0.07142857142857142,
                        "f1-score": 0.03809523809523809,
                        "support": 28.0
                    }
                },
                "rail_transport_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "BEFORE": {
                        "precision": 0.8333333333333334,
                        "recall": 0.14705882352941177,
                        "f1-score": 0.25,
                        "support": 34.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.1388888888888889,
                    "macro avg": {
                        "precision": 0.20833333333333334,
                        "recall": 0.03676470588235294,
                        "f1-score": 0.0625,
                        "support": 36.0
                    },
                    "weighted avg": {
                        "precision": 0.7870370370370371,
                        "recall": 0.1388888888888889,
                        "f1-score": 0.2361111111111111,
                        "support": 36.0
                    }
                },
                "politics_and_conflicts_policy_change_2": {
                    "AFTER": {
                        "precision": 0.75,
                        "recall": 1.0,
                        "f1-score": 0.8571428571428571,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.5,
                    "macro avg": {
                        "precision": 0.1875,
                        "recall": 0.25,
                        "f1-score": 0.21428571428571427,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.375,
                        "recall": 0.5,
                        "f1-score": 0.42857142857142855,
                        "support": 6.0
                    }
                },
                "politics_and_conflicts_drones_1": {
                    "AFTER": {
                        "precision": 0.25,
                        "recall": 0.18181818181818182,
                        "f1-score": 0.2105263157894737,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 8.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.09523809523809523,
                    "macro avg": {
                        "precision": 0.0625,
                        "recall": 0.045454545454545456,
                        "f1-score": 0.052631578947368425,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.13095238095238096,
                        "recall": 0.09523809523809523,
                        "f1-score": 0.11027568922305765,
                        "support": 21.0
                    }
                },
                "disasters_and_accidents_road_crash_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "BEFORE": {
                        "precision": 0.6666666666666666,
                        "recall": 0.18181818181818182,
                        "f1-score": 0.28571428571428575,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.4,
                        "recall": 0.2,
                        "f1-score": 0.26666666666666666,
                        "support": 10.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.19047619047619047,
                    "macro avg": {
                        "precision": 0.26666666666666666,
                        "recall": 0.09545454545454546,
                        "f1-score": 0.1380952380952381,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.5396825396825397,
                        "recall": 0.19047619047619047,
                        "f1-score": 0.27664399092970526,
                        "support": 21.0
                    }
                },
                "crime_and_law_accuse_3": {
                    "AFTER": {
                        "precision": 0.2857142857142857,
                        "recall": 0.5,
                        "f1-score": 0.36363636363636365,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.2,
                        "recall": 0.2,
                        "f1-score": 0.20000000000000004,
                        "support": 10.0
                    },
                    "macro avg": {
                        "precision": 0.07142857142857142,
                        "recall": 0.125,
                        "f1-score": 0.09090909090909091,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.11428571428571428,
                        "recall": 0.2,
                        "f1-score": 0.14545454545454545,
                        "support": 10.0
                    }
                },
                "government_and_politics_protests_2": {
                    "AFTER": {
                        "precision": 0.16666666666666666,
                        "recall": 0.4,
                        "f1-score": 0.23529411764705882,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.25,
                        "f1-score": 0.4,
                        "support": 20.0
                    },
                    "COEX": {
                        "precision": 0.2,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.25,
                        "support": 3.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2857142857142857,
                    "macro avg": {
                        "precision": 0.3416666666666667,
                        "recall": 0.24583333333333335,
                        "f1-score": 0.2213235294117647,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.7654761904761905,
                        "recall": 0.2857142857142857,
                        "f1-score": 0.35451680672268904,
                        "support": 28.0
                    }
                },
                "politics_and_conflicts_elections_2": {
                    "AFTER": {
                        "precision": 0.47619047619047616,
                        "recall": 0.45454545454545453,
                        "f1-score": 0.46511627906976744,
                        "support": 22.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 0.07142857142857142,
                        "f1-score": 0.11764705882352941,
                        "support": 14.0
                    },
                    "COEX": {
                        "precision": 0.14285714285714285,
                        "recall": 0.1111111111111111,
                        "f1-score": 0.125,
                        "support": 9.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.26666666666666666,
                    "macro avg": {
                        "precision": 0.23809523809523808,
                        "recall": 0.15927128427128429,
                        "f1-score": 0.1769408344733242,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.36507936507936506,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.28899148806809544,
                        "support": 45.0
                    }
                },
                "environment_2": {
                    "AFTER": {
                        "precision": 0.5333333333333333,
                        "recall": 0.38095238095238093,
                        "f1-score": 0.4444444444444444,
                        "support": 21.0
                    },
                    "BEFORE": {
                        "precision": 0.4,
                        "recall": 0.08695652173913043,
                        "f1-score": 0.14285714285714285,
                        "support": 23.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2222222222222222,
                    "macro avg": {
                        "precision": 0.23333333333333334,
                        "recall": 0.11697722567287784,
                        "f1-score": 0.1468253968253968,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.4533333333333333,
                        "recall": 0.2222222222222222,
                        "f1-score": 0.28042328042328035,
                        "support": 45.0
                    }
                },
                "weather_floods_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 7.0
                    },
                    "COEX": {
                        "precision": 0.16666666666666666,
                        "recall": 0.25,
                        "f1-score": 0.2,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.06666666666666667,
                    "macro avg": {
                        "precision": 0.041666666666666664,
                        "recall": 0.0625,
                        "f1-score": 0.05,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.04444444444444444,
                        "recall": 0.06666666666666667,
                        "f1-score": 0.05333333333333334,
                        "support": 15.0
                    }
                },
                "sports_1": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 2.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.6666666666666666,
                        "recall": 0.6666666666666666,
                        "f1-score": 0.6666666666666666,
                        "support": 3.0
                    },
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.25,
                        "f1-score": 0.25,
                        "support": 3.0
                    },
                    "weighted avg": {
                        "precision": 0.6666666666666666,
                        "recall": 0.6666666666666666,
                        "f1-score": 0.6666666666666666,
                        "support": 3.0
                    }
                },
                "health_4": {
                    "AFTER": {
                        "precision": 0.7777777777777778,
                        "recall": 0.7777777777777778,
                        "f1-score": 0.7777777777777778,
                        "support": 9.0
                    },
                    "BEFORE": {
                        "precision": 0.6666666666666666,
                        "recall": 0.25,
                        "f1-score": 0.36363636363636365,
                        "support": 8.0
                    },
                    "COEX": {
                        "precision": 0.14285714285714285,
                        "recall": 0.25,
                        "f1-score": 0.18181818181818182,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.47619047619047616,
                    "macro avg": {
                        "precision": 0.3968253968253968,
                        "recall": 0.3194444444444444,
                        "f1-score": 0.33080808080808083,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.6145124716553287,
                        "recall": 0.47619047619047616,
                        "f1-score": 0.5064935064935066,
                        "support": 21.0
                    }
                },
                "weather_earthquakes_1": {
                    "AFTER": {
                        "precision": 0.07692307692307693,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.10526315789473684,
                        "support": 6.0
                    },
                    "BEFORE": {
                        "precision": 0.75,
                        "recall": 0.1875,
                        "f1-score": 0.3,
                        "support": 32.0
                    },
                    "COEX": {
                        "precision": 0.2222222222222222,
                        "recall": 0.2857142857142857,
                        "f1-score": 0.25,
                        "support": 7.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2,
                    "macro avg": {
                        "precision": 0.26228632478632474,
                        "recall": 0.15997023809523808,
                        "f1-score": 0.1638157894736842,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.5781576448243115,
                        "recall": 0.2,
                        "f1-score": 0.26625730994152047,
                        "support": 45.0
                    }
                },
                "space_4": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.7272727272727273,
                        "f1-score": 0.5925925925925926,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.06666666666666667,
                        "f1-score": 0.11764705882352941,
                        "support": 15.0
                    },
                    "COEX": {
                        "precision": 0.1111111111111111,
                        "recall": 0.5,
                        "f1-score": 0.1818181818181818,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.35714285714285715,
                    "macro avg": {
                        "precision": 0.2777777777777778,
                        "recall": 0.3234848484848485,
                        "f1-score": 0.22301445830857594,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.4722222222222222,
                        "recall": 0.35714285714285715,
                        "f1-score": 0.3088164558752794,
                        "support": 28.0
                    }
                },
                "economy_and_business_strikes_2": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 1.0,
                        "f1-score": 0.6666666666666666,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.16666666666666666,
                    "macro avg": {
                        "precision": 0.125,
                        "recall": 0.25,
                        "f1-score": 0.16666666666666666,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.08333333333333333,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.1111111111111111,
                        "support": 6.0
                    }
                },
                "politics_and_conflicts_armed_conflict_2": {
                    "AFTER": {
                        "precision": 0.1111111111111111,
                        "recall": 1.0,
                        "f1-score": 0.19999999999999998,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.2727272727272727,
                        "f1-score": 0.42857142857142855,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 1.0,
                        "recall": 0.6666666666666666,
                        "f1-score": 0.8,
                        "support": 3.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.4,
                    "macro avg": {
                        "precision": 0.5277777777777778,
                        "recall": 0.48484848484848486,
                        "f1-score": 0.35714285714285715,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.9407407407407408,
                        "recall": 0.4,
                        "f1-score": 0.4876190476190477,
                        "support": 15.0
                    }
                },
                "infectious_disease_4": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.25,
                        "f1-score": 0.25,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    }
                },
                "health_1": {
                    "AFTER": {
                        "precision": 0.75,
                        "recall": 0.5,
                        "f1-score": 0.6,
                        "support": 6.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.3,
                    "macro avg": {
                        "precision": 0.1875,
                        "recall": 0.125,
                        "f1-score": 0.15,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.45,
                        "recall": 0.3,
                        "f1-score": 0.36,
                        "support": 10.0
                    }
                },
                "disasters_and_accidents_shipwreck_2": {
                    "AFTER": {
                        "precision": 0.6666666666666666,
                        "recall": 0.36363636363636365,
                        "f1-score": 0.4705882352941177,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 9.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.19047619047619047,
                    "macro avg": {
                        "precision": 0.16666666666666666,
                        "recall": 0.09090909090909091,
                        "f1-score": 0.11764705882352942,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.3492063492063492,
                        "recall": 0.19047619047619047,
                        "f1-score": 0.24649859943977592,
                        "support": 21.0
                    }
                },
                "rail_transport_3": {
                    "AFTER": {
                        "precision": 0.3333333333333333,
                        "recall": 0.4,
                        "f1-score": 0.3636363636363636,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 10.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.13333333333333333,
                    "macro avg": {
                        "precision": 0.08333333333333333,
                        "recall": 0.1,
                        "f1-score": 0.0909090909090909,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.1111111111111111,
                        "recall": 0.13333333333333333,
                        "f1-score": 0.12121212121212119,
                        "support": 15.0
                    }
                },
                "weather_storms_1_extra": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.25,
                        "f1-score": 0.25,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    }
                },
                "health_1_extra": {
                    "AFTER": {
                        "precision": 0.17857142857142858,
                        "recall": 0.4166666666666667,
                        "f1-score": 0.25,
                        "support": 12.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.25,
                        "support": 28.0
                    },
                    "COEX": {
                        "precision": 0.5,
                        "recall": 0.13333333333333333,
                        "f1-score": 0.2105263157894737,
                        "support": 15.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2,
                    "macro avg": {
                        "precision": 0.41964285714285715,
                        "recall": 0.1732142857142857,
                        "f1-score": 0.17763157894736842,
                        "support": 55.0
                    },
                    "weighted avg": {
                        "precision": 0.6844155844155844,
                        "recall": 0.2,
                        "f1-score": 0.23923444976076558,
                        "support": 55.0
                    }
                },
                "weather_floods_1": {
                    "AFTER": {
                        "precision": 0.05263157894736842,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.09090909090909091,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 0.08333333333333333,
                        "f1-score": 0.13333333333333333,
                        "support": 24.0
                    },
                    "COEX": {
                        "precision": 0.8571428571428571,
                        "recall": 0.21428571428571427,
                        "f1-score": 0.34285714285714286,
                        "support": 28.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.16363636363636364,
                    "macro avg": {
                        "precision": 0.3107769423558897,
                        "recall": 0.15773809523809523,
                        "f1-score": 0.14177489177489178,
                        "support": 55.0
                    },
                    "weighted avg": {
                        "precision": 0.5846889952153109,
                        "recall": 0.16363636363636364,
                        "f1-score": 0.23768595041322313,
                        "support": 55.0
                    }
                },
                "mining_4": {
                    "AFTER": {
                        "precision": 0.5294117647058824,
                        "recall": 0.8181818181818182,
                        "f1-score": 0.6428571428571428,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 25.0
                    },
                    "COEX": {
                        "precision": 0.4,
                        "recall": 0.2222222222222222,
                        "f1-score": 0.2857142857142857,
                        "support": 9.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.24444444444444444,
                    "macro avg": {
                        "precision": 0.2323529411764706,
                        "recall": 0.2601010101010101,
                        "f1-score": 0.23214285714285712,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.20941176470588235,
                        "recall": 0.24444444444444444,
                        "f1-score": 0.21428571428571427,
                        "support": 45.0
                    }
                },
                "disasters_and_accidents_volcanoes_4": {
                    "AFTER": {
                        "precision": 0.5714285714285714,
                        "recall": 0.4,
                        "f1-score": 0.47058823529411764,
                        "support": 20.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.21428571428571427,
                        "f1-score": 0.35294117647058826,
                        "support": 14.0
                    },
                    "COEX": {
                        "precision": 0.2,
                        "recall": 0.5,
                        "f1-score": 0.28571428571428575,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.3333333333333333,
                    "macro avg": {
                        "precision": 0.44285714285714284,
                        "recall": 0.2785714285714286,
                        "f1-score": 0.2773109243697479,
                        "support": 36.0
                    },
                    "weighted avg": {
                        "precision": 0.7174603174603174,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.41456582633053224,
                        "support": 36.0
                    }
                },
                "politics_and_conflicts_elections_3": {
                    "AFTER": {
                        "precision": 0.4,
                        "recall": 0.4,
                        "f1-score": 0.4000000000000001,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.5714285714285714,
                        "recall": 0.6666666666666666,
                        "f1-score": 0.6153846153846153,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.4,
                    "macro avg": {
                        "precision": 0.24285714285714285,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.25384615384615383,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.3619047619047619,
                        "recall": 0.4,
                        "f1-score": 0.3794871794871794,
                        "support": 15.0
                    }
                },
                "economy_and_business_strikes_3": {
                    "AFTER": {
                        "precision": 0.1111111111111111,
                        "recall": 0.1,
                        "f1-score": 0.10526315789473685,
                        "support": 10.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.3333333333333333,
                        "recall": 0.2857142857142857,
                        "f1-score": 0.30769230769230765,
                        "support": 7.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.10714285714285714,
                    "macro avg": {
                        "precision": 0.1111111111111111,
                        "recall": 0.09642857142857142,
                        "f1-score": 0.10323886639676112,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.12301587301587301,
                        "recall": 0.10714285714285714,
                        "f1-score": 0.11451706188548294,
                        "support": 28.0
                    }
                },
                "space_2": {
                    "AFTER": {
                        "precision": 0.42857142857142855,
                        "recall": 0.12,
                        "f1-score": 0.1875,
                        "support": 100.0
                    },
                    "BEFORE": {
                        "precision": 0.4117647058823529,
                        "recall": 0.13725490196078433,
                        "f1-score": 0.20588235294117646,
                        "support": 51.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.12418300653594772,
                    "macro avg": {
                        "precision": 0.21008403361344535,
                        "recall": 0.06431372549019608,
                        "f1-score": 0.09834558823529412,
                        "support": 153.0
                    },
                    "weighted avg": {
                        "precision": 0.41736694677871145,
                        "recall": 0.12418300653594772,
                        "f1-score": 0.19117647058823528,
                        "support": 153.0
                    }
                },
                "politics_and_conflicts_resign_1": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.6666666666666666,
                        "f1-score": 0.8,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.6666666666666666,
                        "recall": 0.6666666666666666,
                        "f1-score": 0.6666666666666666,
                        "support": 3.0
                    },
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.2,
                        "support": 3.0
                    },
                    "weighted avg": {
                        "precision": 1.0,
                        "recall": 0.6666666666666666,
                        "f1-score": 0.8000000000000002,
                        "support": 3.0
                    }
                },
                "environment_4": {
                    "AFTER": {
                        "precision": 0.2857142857142857,
                        "recall": 0.5,
                        "f1-score": 0.36363636363636365,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.2,
                        "f1-score": 0.33333333333333337,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.3333333333333333,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.2222222222222222,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.26666666666666666,
                    "macro avg": {
                        "precision": 0.4047619047619047,
                        "recall": 0.21666666666666665,
                        "f1-score": 0.2297979797979798,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.5428571428571428,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.296969696969697,
                        "support": 15.0
                    }
                },
                "space_1_extra": {
                    "AFTER": {
                        "precision": 0.3333333333333333,
                        "recall": 1.0,
                        "f1-score": 0.5,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.16666666666666666,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.16666666666666666,
                        "support": 6.0
                    },
                    "macro avg": {
                        "precision": 0.08333333333333333,
                        "recall": 0.25,
                        "f1-score": 0.125,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.05555555555555555,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.08333333333333333,
                        "support": 6.0
                    }
                },
                "health_3": {
                    "AFTER": {
                        "precision": 0.75,
                        "recall": 0.375,
                        "f1-score": 0.5,
                        "support": 8.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2,
                    "macro avg": {
                        "precision": 0.1875,
                        "recall": 0.09375,
                        "f1-score": 0.125,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.4,
                        "recall": 0.2,
                        "f1-score": 0.26666666666666666,
                        "support": 15.0
                    }
                },
                "environment_3": {
                    "AFTER": {
                        "precision": 0.6666666666666666,
                        "recall": 0.36363636363636365,
                        "f1-score": 0.4705882352941177,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.26666666666666666,
                    "macro avg": {
                        "precision": 0.16666666666666666,
                        "recall": 0.09090909090909091,
                        "f1-score": 0.11764705882352942,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.4888888888888889,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.34509803921568627,
                        "support": 15.0
                    }
                },
                "government_and_politics_protests_3": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.25,
                        "f1-score": 0.3333333333333333,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "COEX": {
                        "precision": 0.3333333333333333,
                        "recall": 1.0,
                        "f1-score": 0.5,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.3333333333333333,
                    "macro avg": {
                        "precision": 0.20833333333333331,
                        "recall": 0.3125,
                        "f1-score": 0.20833333333333331,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.3888888888888889,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3055555555555555,
                        "support": 6.0
                    }
                },
                "economy_and_business_financial_crisis_4": {
                    "AFTER": {
                        "precision": 0.25,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.2,
                        "support": 12.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 0.2,
                        "f1-score": 0.25,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.14285714285714285,
                    "macro avg": {
                        "precision": 0.14583333333333331,
                        "recall": 0.09166666666666667,
                        "f1-score": 0.1125,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.22222222222222218,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.17380952380952383,
                        "support": 21.0
                    }
                },
                "computers_2": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.25,
                        "f1-score": 0.25,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    }
                },
                "crime_and_law_accuse_4": {
                    "AFTER": {
                        "precision": 0.2857142857142857,
                        "recall": 0.4,
                        "f1-score": 0.3333333333333333,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2,
                    "macro avg": {
                        "precision": 0.07142857142857142,
                        "recall": 0.1,
                        "f1-score": 0.08333333333333333,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.14285714285714285,
                        "recall": 0.2,
                        "f1-score": 0.16666666666666666,
                        "support": 10.0
                    }
                },
                "culture_and_entertainment_1": {
                    "AFTER": {
                        "precision": 0.6666666666666666,
                        "recall": 1.0,
                        "f1-score": 0.8,
                        "support": 2.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.3333333333333333,
                        "recall": 0.5,
                        "f1-score": 0.4,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.5,
                        "recall": 0.5,
                        "f1-score": 0.5,
                        "support": 6.0
                    },
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.375,
                        "f1-score": 0.30000000000000004,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.5,
                        "f1-score": 0.4000000000000001,
                        "support": 6.0
                    }
                },
                "internet_2": {
                    "AFTER": {
                        "precision": 0.75,
                        "recall": 0.6,
                        "f1-score": 0.6666666666666665,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.3333333333333333,
                        "recall": 1.0,
                        "f1-score": 0.5,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.4,
                    "macro avg": {
                        "precision": 0.2708333333333333,
                        "recall": 0.4,
                        "f1-score": 0.29166666666666663,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.4083333333333333,
                        "recall": 0.4,
                        "f1-score": 0.38333333333333325,
                        "support": 10.0
                    }
                },
                "culture_and_entertainment_3": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.4,
                        "f1-score": 0.4444444444444445,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.75,
                        "recall": 0.75,
                        "f1-score": 0.75,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.5714285714285714,
                        "recall": 0.6666666666666666,
                        "f1-score": 0.6153846153846153,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.6,
                        "recall": 0.6,
                        "f1-score": 0.6,
                        "support": 15.0
                    },
                    "macro avg": {
                        "precision": 0.45535714285714285,
                        "recall": 0.4541666666666666,
                        "f1-score": 0.4524572649572649,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.5952380952380952,
                        "recall": 0.6,
                        "f1-score": 0.5943019943019944,
                        "support": 15.0
                    }
                }
            },
            "qa": {
                "government_and_politics_riots_4": {
                    "AFTER": {
                        "precision": 0.3333333333333333,
                        "recall": 0.25,
                        "f1-score": 0.28571428571428575,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.08333333333333333,
                        "f1-score": 0.15384615384615385,
                        "support": 12.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 12.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.07142857142857142,
                    "macro avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.08333333333333333,
                        "f1-score": 0.1098901098901099,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.4761904761904762,
                        "recall": 0.07142857142857142,
                        "f1-score": 0.10675039246467818,
                        "support": 28.0
                    }
                },
                "rail_transport_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.20588235294117646,
                        "f1-score": 0.34146341463414637,
                        "support": 34.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.19444444444444445,
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.051470588235294115,
                        "f1-score": 0.08536585365853659,
                        "support": 36.0
                    },
                    "weighted avg": {
                        "precision": 0.9444444444444444,
                        "recall": 0.19444444444444445,
                        "f1-score": 0.32249322493224936,
                        "support": 36.0
                    }
                },
                "politics_and_conflicts_policy_change_2": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.5,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.5,
                    "macro avg": {
                        "precision": 0.5,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.375,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.8333333333333334,
                        "recall": 0.5,
                        "f1-score": 0.5833333333333334,
                        "support": 6.0
                    }
                },
                "politics_and_conflicts_drones_1": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.18181818181818182,
                        "f1-score": 0.26666666666666666,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.125,
                        "f1-score": 0.2,
                        "support": 8.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.14285714285714285,
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.07670454545454546,
                        "f1-score": 0.11666666666666667,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.4523809523809524,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.21587301587301586,
                        "support": 21.0
                    }
                },
                "disasters_and_accidents_road_crash_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.09090909090909091,
                        "f1-score": 0.15384615384615385,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 1.0,
                        "recall": 0.1,
                        "f1-score": 0.18181818181818182,
                        "support": 10.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.09523809523809523,
                    "macro avg": {
                        "precision": 0.375,
                        "recall": 0.04772727272727273,
                        "f1-score": 0.08391608391608392,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.7380952380952381,
                        "recall": 0.09523809523809523,
                        "f1-score": 0.1671661671661672,
                        "support": 21.0
                    }
                },
                "crime_and_law_accuse_3": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.5,
                        "f1-score": 0.5,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.75,
                        "recall": 0.5,
                        "f1-score": 0.6,
                        "support": 6.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.5,
                        "recall": 0.5,
                        "f1-score": 0.5,
                        "support": 10.0
                    },
                    "macro avg": {
                        "precision": 0.3125,
                        "recall": 0.25,
                        "f1-score": 0.275,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.65,
                        "recall": 0.5,
                        "f1-score": 0.5599999999999999,
                        "support": 10.0
                    }
                },
                "government_and_politics_protests_2": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.2,
                        "f1-score": 0.33333333333333337,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.05,
                        "f1-score": 0.09523809523809523,
                        "support": 20.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.07142857142857142,
                    "macro avg": {
                        "precision": 0.5,
                        "recall": 0.0625,
                        "f1-score": 0.10714285714285715,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.8928571428571429,
                        "recall": 0.07142857142857142,
                        "f1-score": 0.12755102040816327,
                        "support": 28.0
                    }
                },
                "politics_and_conflicts_elections_2": {
                    "AFTER": {
                        "precision": 0.4,
                        "recall": 0.09090909090909091,
                        "f1-score": 0.14814814814814814,
                        "support": 22.0
                    },
                    "BEFORE": {
                        "precision": 0.25,
                        "recall": 0.07142857142857142,
                        "f1-score": 0.11111111111111112,
                        "support": 14.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 9.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.06666666666666667,
                    "macro avg": {
                        "precision": 0.1625,
                        "recall": 0.040584415584415584,
                        "f1-score": 0.06481481481481481,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.2733333333333334,
                        "recall": 0.06666666666666667,
                        "f1-score": 0.10699588477366255,
                        "support": 45.0
                    }
                },
                "environment_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 21.0
                    },
                    "BEFORE": {
                        "precision": 0.4,
                        "recall": 0.08695652173913043,
                        "f1-score": 0.14285714285714285,
                        "support": 23.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.044444444444444446,
                    "macro avg": {
                        "precision": 0.1,
                        "recall": 0.021739130434782608,
                        "f1-score": 0.03571428571428571,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.20444444444444446,
                        "recall": 0.044444444444444446,
                        "f1-score": 0.073015873015873,
                        "support": 45.0
                    }
                },
                "weather_floods_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.75,
                        "recall": 0.42857142857142855,
                        "f1-score": 0.5454545454545454,
                        "support": 7.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2,
                    "macro avg": {
                        "precision": 0.1875,
                        "recall": 0.10714285714285714,
                        "f1-score": 0.13636363636363635,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.35,
                        "recall": 0.2,
                        "f1-score": 0.2545454545454545,
                        "support": 15.0
                    }
                },
                "sports_1": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.5,
                        "f1-score": 0.5,
                        "support": 2.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 3.0
                    },
                    "macro avg": {
                        "precision": 0.125,
                        "recall": 0.125,
                        "f1-score": 0.125,
                        "support": 3.0
                    },
                    "weighted avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 3.0
                    }
                },
                "health_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 9.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 8.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.0,
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 21.0
                    }
                },
                "weather_earthquakes_1": {
                    "AFTER": {
                        "precision": 0.3333333333333333,
                        "recall": 0.5,
                        "f1-score": 0.4,
                        "support": 6.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.125,
                        "f1-score": 0.2,
                        "support": 32.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 7.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.15555555555555556,
                    "macro avg": {
                        "precision": 0.20833333333333331,
                        "recall": 0.15625,
                        "f1-score": 0.15000000000000002,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.4,
                        "recall": 0.15555555555555556,
                        "f1-score": 0.19555555555555557,
                        "support": 45.0
                    }
                },
                "space_4": {
                    "AFTER": {
                        "precision": 0.36363636363636365,
                        "recall": 0.36363636363636365,
                        "f1-score": 0.36363636363636365,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 0.13333333333333333,
                        "f1-score": 0.19047619047619044,
                        "support": 15.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.21428571428571427,
                    "macro avg": {
                        "precision": 0.17424242424242425,
                        "recall": 0.12424242424242424,
                        "f1-score": 0.13852813852813853,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.32142857142857145,
                        "recall": 0.21428571428571427,
                        "f1-score": 0.24489795918367346,
                        "support": 28.0
                    }
                },
                "economy_and_business_strikes_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.75,
                        "f1-score": 0.8571428571428571,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.5,
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.1875,
                        "f1-score": 0.21428571428571427,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.6666666666666666,
                        "recall": 0.5,
                        "f1-score": 0.5714285714285714,
                        "support": 6.0
                    }
                },
                "politics_and_conflicts_armed_conflict_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.2727272727272727,
                        "f1-score": 0.42857142857142855,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2,
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.06818181818181818,
                        "f1-score": 0.10714285714285714,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.7333333333333333,
                        "recall": 0.2,
                        "f1-score": 0.3142857142857143,
                        "support": 15.0
                    }
                },
                "infectious_disease_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    }
                },
                "health_1": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.5,
                        "support": 6.0
                    },
                    "BEFORE": {
                        "precision": 0.25,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.28571428571428575,
                        "support": 3.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.3,
                    "macro avg": {
                        "precision": 0.3125,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.19642857142857145,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.675,
                        "recall": 0.3,
                        "f1-score": 0.38571428571428573,
                        "support": 10.0
                    }
                },
                "disasters_and_accidents_shipwreck_2": {
                    "AFTER": {
                        "precision": 0.3333333333333333,
                        "recall": 0.09090909090909091,
                        "f1-score": 0.14285714285714288,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.2,
                        "recall": 0.1111111111111111,
                        "f1-score": 0.14285714285714285,
                        "support": 9.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.09523809523809523,
                    "macro avg": {
                        "precision": 0.13333333333333333,
                        "recall": 0.050505050505050504,
                        "f1-score": 0.07142857142857142,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.26031746031746034,
                        "recall": 0.09523809523809523,
                        "f1-score": 0.1360544217687075,
                        "support": 21.0
                    }
                },
                "rail_transport_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.6666666666666666,
                        "recall": 0.2,
                        "f1-score": 0.30769230769230765,
                        "support": 10.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.13333333333333333,
                        "recall": 0.13333333333333333,
                        "f1-score": 0.13333333333333333,
                        "support": 15.0
                    },
                    "macro avg": {
                        "precision": 0.16666666666666666,
                        "recall": 0.05,
                        "f1-score": 0.07692307692307691,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.4444444444444444,
                        "recall": 0.13333333333333333,
                        "f1-score": 0.20512820512820512,
                        "support": 15.0
                    }
                },
                "weather_storms_1_extra": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    }
                },
                "health_1_extra": {
                    "AFTER": {
                        "precision": 0.1,
                        "recall": 0.08333333333333333,
                        "f1-score": 0.0909090909090909,
                        "support": 12.0
                    },
                    "BEFORE": {
                        "precision": 0.5454545454545454,
                        "recall": 0.21428571428571427,
                        "f1-score": 0.30769230769230765,
                        "support": 28.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 15.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.12727272727272726,
                    "macro avg": {
                        "precision": 0.16136363636363635,
                        "recall": 0.0744047619047619,
                        "f1-score": 0.09965034965034963,
                        "support": 55.0
                    },
                    "weighted avg": {
                        "precision": 0.299504132231405,
                        "recall": 0.12727272727272726,
                        "f1-score": 0.1764780673871583,
                        "support": 55.0
                    }
                },
                "weather_floods_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.5555555555555556,
                        "recall": 0.20833333333333334,
                        "f1-score": 0.30303030303030304,
                        "support": 24.0
                    },
                    "COEX": {
                        "precision": 0.5,
                        "recall": 0.10714285714285714,
                        "f1-score": 0.17647058823529413,
                        "support": 28.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.14545454545454545,
                    "macro avg": {
                        "precision": 0.2638888888888889,
                        "recall": 0.07886904761904762,
                        "f1-score": 0.11987522281639929,
                        "support": 55.0
                    },
                    "weighted avg": {
                        "precision": 0.496969696969697,
                        "recall": 0.14545454545454545,
                        "f1-score": 0.22207097715119106,
                        "support": 55.0
                    }
                },
                "mining_4": {
                    "AFTER": {
                        "precision": 0.3333333333333333,
                        "recall": 0.09090909090909091,
                        "f1-score": 0.14285714285714288,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.75,
                        "recall": 0.24,
                        "f1-score": 0.36363636363636365,
                        "support": 25.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 9.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.15555555555555556,
                    "macro avg": {
                        "precision": 0.2708333333333333,
                        "recall": 0.08272727272727273,
                        "f1-score": 0.12662337662337664,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.4981481481481482,
                        "recall": 0.15555555555555556,
                        "f1-score": 0.23694083694083695,
                        "support": 45.0
                    }
                },
                "disasters_and_accidents_volcanoes_4": {
                    "AFTER": {
                        "precision": 0.3333333333333333,
                        "recall": 0.05,
                        "f1-score": 0.08695652173913045,
                        "support": 20.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.2,
                        "support": 14.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.08333333333333333,
                    "macro avg": {
                        "precision": 0.16666666666666666,
                        "recall": 0.04821428571428571,
                        "f1-score": 0.07173913043478261,
                        "support": 36.0
                    },
                    "weighted avg": {
                        "precision": 0.31481481481481477,
                        "recall": 0.08333333333333333,
                        "f1-score": 0.12608695652173915,
                        "support": 36.0
                    }
                },
                "politics_and_conflicts_elections_3": {
                    "AFTER": {
                        "precision": 0.2,
                        "recall": 0.2,
                        "f1-score": 0.20000000000000004,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.4,
                        "recall": 0.5,
                        "f1-score": 0.4444444444444445,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2,
                    "macro avg": {
                        "precision": 0.15000000000000002,
                        "recall": 0.175,
                        "f1-score": 0.16111111111111112,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.17333333333333334,
                        "recall": 0.2,
                        "f1-score": 0.1851851851851852,
                        "support": 15.0
                    }
                },
                "economy_and_business_strikes_3": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.2,
                        "f1-score": 0.33333333333333337,
                        "support": 10.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 7.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.07142857142857142,
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.05,
                        "f1-score": 0.08333333333333334,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.35714285714285715,
                        "recall": 0.07142857142857142,
                        "f1-score": 0.11904761904761907,
                        "support": 28.0
                    }
                },
                "space_2": {
                    "AFTER": {
                        "precision": 0.6111111111111112,
                        "recall": 0.11,
                        "f1-score": 0.1864406779661017,
                        "support": 100.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 0.1568627450980392,
                        "f1-score": 0.21333333333333332,
                        "support": 51.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.12418300653594772,
                    "macro avg": {
                        "precision": 0.2361111111111111,
                        "recall": 0.0667156862745098,
                        "f1-score": 0.09994350282485875,
                        "support": 153.0
                    },
                    "weighted avg": {
                        "precision": 0.5105301379811183,
                        "recall": 0.12418300653594772,
                        "f1-score": 0.19296776337653704,
                        "support": 153.0
                    }
                },
                "politics_and_conflicts_resign_1": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.5,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 3.0
                    },
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.08333333333333333,
                        "f1-score": 0.125,
                        "support": 3.0
                    },
                    "weighted avg": {
                        "precision": 1.0,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.5,
                        "support": 3.0
                    }
                },
                "environment_4": {
                    "AFTER": {
                        "precision": 0.3333333333333333,
                        "recall": 0.25,
                        "f1-score": 0.28571428571428575,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.4,
                        "recall": 0.4,
                        "f1-score": 0.4000000000000001,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 1.0,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.2857142857142857,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.26666666666666666,
                    "macro avg": {
                        "precision": 0.43333333333333335,
                        "recall": 0.20416666666666666,
                        "f1-score": 0.24285714285714288,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.6222222222222221,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.3238095238095238,
                        "support": 15.0
                    }
                },
                "space_1_extra": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 1.0,
                        "f1-score": 0.6666666666666666,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.4,
                        "f1-score": 0.5714285714285715,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.5,
                        "recall": 0.5,
                        "f1-score": 0.5,
                        "support": 6.0
                    },
                    "macro avg": {
                        "precision": 0.375,
                        "recall": 0.35,
                        "f1-score": 0.30952380952380953,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.9166666666666666,
                        "recall": 0.5,
                        "f1-score": 0.5873015873015873,
                        "support": 6.0
                    }
                },
                "health_3": {
                    "AFTER": {
                        "precision": 0.2,
                        "recall": 0.125,
                        "f1-score": 0.15384615384615385,
                        "support": 8.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.25,
                        "support": 6.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.13333333333333333,
                    "macro avg": {
                        "precision": 0.175,
                        "recall": 0.07291666666666666,
                        "f1-score": 0.10096153846153846,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.30666666666666664,
                        "recall": 0.13333333333333333,
                        "f1-score": 0.18205128205128204,
                        "support": 15.0
                    }
                },
                "environment_3": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.36363636363636365,
                        "f1-score": 0.5333333333333333,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.26666666666666666,
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.09090909090909091,
                        "f1-score": 0.13333333333333333,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.7333333333333333,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.3911111111111111,
                        "support": 15.0
                    }
                },
                "government_and_politics_protests_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.0,
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    }
                },
                "economy_and_business_financial_crisis_4": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.25,
                        "support": 12.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.09523809523809523,
                    "macro avg": {
                        "precision": 0.125,
                        "recall": 0.041666666666666664,
                        "f1-score": 0.0625,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.2857142857142857,
                        "recall": 0.09523809523809523,
                        "f1-score": 0.14285714285714285,
                        "support": 21.0
                    }
                },
                "computers_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    }
                },
                "crime_and_law_accuse_4": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.4,
                        "f1-score": 0.5714285714285715,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.4,
                        "f1-score": 0.5714285714285715,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.4,
                    "macro avg": {
                        "precision": 0.5,
                        "recall": 0.2,
                        "f1-score": 0.28571428571428575,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 1.0,
                        "recall": 0.4,
                        "f1-score": 0.5714285714285715,
                        "support": 10.0
                    }
                },
                "culture_and_entertainment_1": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.5,
                        "f1-score": 0.6666666666666666,
                        "support": 2.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.16666666666666666,
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.125,
                        "f1-score": 0.16666666666666666,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.2222222222222222,
                        "support": 6.0
                    }
                },
                "internet_2": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.4,
                        "f1-score": 0.5714285714285715,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2,
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.1,
                        "f1-score": 0.14285714285714288,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.5,
                        "recall": 0.2,
                        "f1-score": 0.28571428571428575,
                        "support": 10.0
                    }
                },
                "culture_and_entertainment_3": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.2,
                        "f1-score": 0.28571428571428575,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.25,
                        "f1-score": 0.3333333333333333,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.13333333333333333,
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.1125,
                        "f1-score": 0.15476190476190477,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.3,
                        "recall": 0.13333333333333333,
                        "f1-score": 0.1841269841269841,
                        "support": 15.0
                    }
                }
            },
            "qa_events": {
                "government_and_politics_riots_4": {
                    "AFTER": {
                        "precision": 0.16666666666666666,
                        "recall": 0.25,
                        "f1-score": 0.2,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 12.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 12.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.03571428571428571,
                    "macro avg": {
                        "precision": 0.041666666666666664,
                        "recall": 0.0625,
                        "f1-score": 0.05,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.023809523809523808,
                        "recall": 0.03571428571428571,
                        "f1-score": 0.028571428571428574,
                        "support": 28.0
                    }
                },
                "rail_transport_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.14705882352941177,
                        "f1-score": 0.25641025641025644,
                        "support": 34.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.1388888888888889,
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.03676470588235294,
                        "f1-score": 0.06410256410256411,
                        "support": 36.0
                    },
                    "weighted avg": {
                        "precision": 0.9444444444444444,
                        "recall": 0.1388888888888889,
                        "f1-score": 0.24216524216524218,
                        "support": 36.0
                    }
                },
                "politics_and_conflicts_policy_change_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.5,
                        "f1-score": 0.5,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.16666666666666666,
                    "macro avg": {
                        "precision": 0.125,
                        "recall": 0.125,
                        "f1-score": 0.125,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.16666666666666666,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.16666666666666666,
                        "support": 6.0
                    }
                },
                "politics_and_conflicts_drones_1": {
                    "AFTER": {
                        "precision": 0.7142857142857143,
                        "recall": 0.45454545454545453,
                        "f1-score": 0.5555555555555556,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.6666666666666666,
                        "recall": 0.5,
                        "f1-score": 0.5714285714285715,
                        "support": 8.0
                    },
                    "COEX": {
                        "precision": 1.0,
                        "recall": 0.5,
                        "f1-score": 0.6666666666666666,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.47619047619047616,
                    "macro avg": {
                        "precision": 0.5952380952380952,
                        "recall": 0.36363636363636365,
                        "f1-score": 0.4484126984126984,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.7233560090702947,
                        "recall": 0.47619047619047616,
                        "f1-score": 0.5721844293272865,
                        "support": 21.0
                    }
                },
                "disasters_and_accidents_road_crash_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "BEFORE": {
                        "precision": 0.6666666666666666,
                        "recall": 0.18181818181818182,
                        "f1-score": 0.28571428571428575,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 1.0,
                        "recall": 0.2,
                        "f1-score": 0.33333333333333337,
                        "support": 10.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.19047619047619047,
                    "macro avg": {
                        "precision": 0.41666666666666663,
                        "recall": 0.09545454545454546,
                        "f1-score": 0.15476190476190477,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.8253968253968254,
                        "recall": 0.19047619047619047,
                        "f1-score": 0.308390022675737,
                        "support": 21.0
                    }
                },
                "crime_and_law_accuse_3": {
                    "AFTER": {
                        "precision": 0.4,
                        "recall": 0.5,
                        "f1-score": 0.4444444444444445,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.2857142857142857,
                        "support": 6.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.3,
                    "macro avg": {
                        "precision": 0.35,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.18253968253968256,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.76,
                        "recall": 0.3,
                        "f1-score": 0.3492063492063492,
                        "support": 10.0
                    }
                },
                "government_and_politics_protests_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.3,
                        "f1-score": 0.4615384615384615,
                        "support": 20.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.21428571428571427,
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.075,
                        "f1-score": 0.11538461538461538,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.7142857142857143,
                        "recall": 0.21428571428571427,
                        "f1-score": 0.32967032967032966,
                        "support": 28.0
                    }
                },
                "politics_and_conflicts_elections_2": {
                    "AFTER": {
                        "precision": 0.42857142857142855,
                        "recall": 0.13636363636363635,
                        "f1-score": 0.20689655172413793,
                        "support": 22.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 14.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 9.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.06666666666666667,
                    "macro avg": {
                        "precision": 0.10714285714285714,
                        "recall": 0.03409090909090909,
                        "f1-score": 0.05172413793103448,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.20952380952380953,
                        "recall": 0.06666666666666667,
                        "f1-score": 0.10114942528735632,
                        "support": 45.0
                    }
                },
                "environment_2": {
                    "AFTER": {
                        "precision": 0.6666666666666666,
                        "recall": 0.2857142857142857,
                        "f1-score": 0.4,
                        "support": 21.0
                    },
                    "BEFORE": {
                        "precision": 0.4,
                        "recall": 0.08695652173913043,
                        "f1-score": 0.14285714285714285,
                        "support": 23.0
                    },
                    "COEX": {
                        "precision": 0.09090909090909091,
                        "recall": 1.0,
                        "f1-score": 0.16666666666666669,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2,
                    "macro avg": {
                        "precision": 0.28939393939393937,
                        "recall": 0.34316770186335405,
                        "f1-score": 0.17738095238095242,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.5175757575757576,
                        "recall": 0.2,
                        "f1-score": 0.2633862433862434,
                        "support": 45.0
                    }
                },
                "weather_floods_3": {
                    "AFTER": {
                        "precision": 0.3333333333333333,
                        "recall": 0.5,
                        "f1-score": 0.4,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.2857142857142857,
                        "f1-score": 0.36363636363636365,
                        "support": 7.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.26666666666666666,
                    "macro avg": {
                        "precision": 0.20833333333333331,
                        "recall": 0.19642857142857142,
                        "f1-score": 0.19090909090909092,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.3222222222222222,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.27636363636363637,
                        "support": 15.0
                    }
                },
                "sports_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    }
                },
                "health_4": {
                    "AFTER": {
                        "precision": 0.8,
                        "recall": 0.4444444444444444,
                        "f1-score": 0.5714285714285714,
                        "support": 9.0
                    },
                    "BEFORE": {
                        "precision": 0.25,
                        "recall": 0.125,
                        "f1-score": 0.16666666666666666,
                        "support": 8.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.23809523809523808,
                    "macro avg": {
                        "precision": 0.2625,
                        "recall": 0.1423611111111111,
                        "f1-score": 0.1845238095238095,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.43809523809523804,
                        "recall": 0.23809523809523808,
                        "f1-score": 0.3083900226757369,
                        "support": 21.0
                    }
                },
                "weather_earthquakes_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "BEFORE": {
                        "precision": 0.7,
                        "recall": 0.21875,
                        "f1-score": 0.3333333333333333,
                        "support": 32.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 7.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.15555555555555556,
                    "macro avg": {
                        "precision": 0.175,
                        "recall": 0.0546875,
                        "f1-score": 0.08333333333333333,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.49777777777777776,
                        "recall": 0.15555555555555556,
                        "f1-score": 0.23703703703703702,
                        "support": 45.0
                    }
                },
                "space_4": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.2727272727272727,
                        "f1-score": 0.3529411764705882,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.13333333333333333,
                        "f1-score": 0.2105263157894737,
                        "support": 15.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.17857142857142858,
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.1015151515151515,
                        "f1-score": 0.14086687306501547,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.4642857142857143,
                        "recall": 0.17857142857142858,
                        "f1-score": 0.251437417072092,
                        "support": 28.0
                    }
                },
                "economy_and_business_strikes_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.5,
                        "f1-score": 0.5,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 6.0
                    },
                    "macro avg": {
                        "precision": 0.125,
                        "recall": 0.125,
                        "f1-score": 0.125,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 6.0
                    }
                },
                "politics_and_conflicts_armed_conflict_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.09090909090909091,
                        "f1-score": 0.16666666666666669,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.06666666666666667,
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.022727272727272728,
                        "f1-score": 0.04166666666666667,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.7333333333333333,
                        "recall": 0.06666666666666667,
                        "f1-score": 0.12222222222222223,
                        "support": 15.0
                    }
                },
                "infectious_disease_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    }
                },
                "health_1": {
                    "AFTER": {
                        "precision": 0.6666666666666666,
                        "recall": 0.6666666666666666,
                        "f1-score": 0.6666666666666666,
                        "support": 6.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.4,
                    "macro avg": {
                        "precision": 0.16666666666666666,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.16666666666666666,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.4,
                        "recall": 0.4,
                        "f1-score": 0.4,
                        "support": 10.0
                    }
                },
                "disasters_and_accidents_shipwreck_2": {
                    "AFTER": {
                        "precision": 0.3333333333333333,
                        "recall": 0.09090909090909091,
                        "f1-score": 0.14285714285714288,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.42857142857142855,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.375,
                        "support": 9.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.19047619047619047,
                    "macro avg": {
                        "precision": 0.19047619047619047,
                        "recall": 0.10606060606060605,
                        "f1-score": 0.12946428571428573,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.3582766439909297,
                        "recall": 0.19047619047619047,
                        "f1-score": 0.23554421768707481,
                        "support": 21.0
                    }
                },
                "rail_transport_3": {
                    "AFTER": {
                        "precision": 0.3333333333333333,
                        "recall": 0.4,
                        "f1-score": 0.3636363636363636,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 10.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.13333333333333333,
                        "recall": 0.13333333333333333,
                        "f1-score": 0.13333333333333333,
                        "support": 15.0
                    },
                    "macro avg": {
                        "precision": 0.08333333333333333,
                        "recall": 0.1,
                        "f1-score": 0.0909090909090909,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.1111111111111111,
                        "recall": 0.13333333333333333,
                        "f1-score": 0.12121212121212119,
                        "support": 15.0
                    }
                },
                "weather_storms_1_extra": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.25,
                        "f1-score": 0.25,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    }
                },
                "health_1_extra": {
                    "AFTER": {
                        "precision": 0.14285714285714285,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.15384615384615383,
                        "support": 12.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.21428571428571427,
                        "f1-score": 0.3,
                        "support": 28.0
                    },
                    "COEX": {
                        "precision": 0.6666666666666666,
                        "recall": 0.13333333333333333,
                        "f1-score": 0.2222222222222222,
                        "support": 15.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.18181818181818182,
                    "macro avg": {
                        "precision": 0.32738095238095233,
                        "recall": 0.12857142857142856,
                        "f1-score": 0.169017094017094,
                        "support": 55.0
                    },
                    "weighted avg": {
                        "precision": 0.4675324675324676,
                        "recall": 0.18181818181818182,
                        "f1-score": 0.24689976689976686,
                        "support": 55.0
                    }
                },
                "weather_floods_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 24.0
                    },
                    "COEX": {
                        "precision": 0.16666666666666666,
                        "recall": 0.07142857142857142,
                        "f1-score": 0.1,
                        "support": 28.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.03636363636363636,
                    "macro avg": {
                        "precision": 0.041666666666666664,
                        "recall": 0.017857142857142856,
                        "f1-score": 0.025,
                        "support": 55.0
                    },
                    "weighted avg": {
                        "precision": 0.08484848484848484,
                        "recall": 0.03636363636363636,
                        "f1-score": 0.05090909090909091,
                        "support": 55.0
                    }
                },
                "mining_4": {
                    "AFTER": {
                        "precision": 0.125,
                        "recall": 0.09090909090909091,
                        "f1-score": 0.10526315789473685,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.12,
                        "f1-score": 0.21428571428571425,
                        "support": 25.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 9.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.08888888888888889,
                    "macro avg": {
                        "precision": 0.28125,
                        "recall": 0.05272727272727273,
                        "f1-score": 0.07988721804511277,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.5861111111111111,
                        "recall": 0.08888888888888889,
                        "f1-score": 0.1447786131996658,
                        "support": 45.0
                    }
                },
                "disasters_and_accidents_volcanoes_4": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.15,
                        "f1-score": 0.23076923076923075,
                        "support": 20.0
                    },
                    "BEFORE": {
                        "precision": 0.2727272727272727,
                        "recall": 0.21428571428571427,
                        "f1-score": 0.23999999999999996,
                        "support": 14.0
                    },
                    "COEX": {
                        "precision": 0.25,
                        "recall": 0.5,
                        "f1-score": 0.3333333333333333,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.19444444444444445,
                    "macro avg": {
                        "precision": 0.2556818181818182,
                        "recall": 0.21607142857142858,
                        "f1-score": 0.20102564102564102,
                        "support": 36.0
                    },
                    "weighted avg": {
                        "precision": 0.3977272727272727,
                        "recall": 0.19444444444444445,
                        "f1-score": 0.24005698005698,
                        "support": 36.0
                    }
                },
                "politics_and_conflicts_elections_3": {
                    "AFTER": {
                        "precision": 0.16666666666666666,
                        "recall": 0.2,
                        "f1-score": 0.1818181818181818,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.2,
                        "recall": 0.25,
                        "f1-score": 0.22222222222222224,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.13333333333333333,
                    "macro avg": {
                        "precision": 0.09166666666666667,
                        "recall": 0.1125,
                        "f1-score": 0.10101010101010101,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.10888888888888888,
                        "recall": 0.13333333333333333,
                        "f1-score": 0.11986531986531987,
                        "support": 15.0
                    }
                },
                "economy_and_business_strikes_3": {
                    "AFTER": {
                        "precision": 0.3333333333333333,
                        "recall": 0.1,
                        "f1-score": 0.15384615384615383,
                        "support": 10.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 0.09090909090909091,
                        "f1-score": 0.14285714285714288,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.3333333333333333,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.2,
                        "support": 7.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.10714285714285714,
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.08344155844155844,
                        "f1-score": 0.12417582417582418,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.10714285714285714,
                        "f1-score": 0.16106750392464678,
                        "support": 28.0
                    }
                },
                "space_2": {
                    "AFTER": {
                        "precision": 0.8181818181818182,
                        "recall": 0.18,
                        "f1-score": 0.29508196721311475,
                        "support": 100.0
                    },
                    "BEFORE": {
                        "precision": 0.32142857142857145,
                        "recall": 0.17647058823529413,
                        "f1-score": 0.2278481012658228,
                        "support": 51.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.17647058823529413,
                    "macro avg": {
                        "precision": 0.28490259740259744,
                        "recall": 0.08911764705882352,
                        "f1-score": 0.13073251711973438,
                        "support": 153.0
                    },
                    "weighted avg": {
                        "precision": 0.6419022154316272,
                        "recall": 0.17647058823529413,
                        "f1-score": 0.2688133979468525,
                        "support": 153.0
                    }
                },
                "politics_and_conflicts_resign_1": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.6666666666666666,
                        "f1-score": 0.8,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.6666666666666666,
                        "recall": 0.6666666666666666,
                        "f1-score": 0.6666666666666666,
                        "support": 3.0
                    },
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.2,
                        "support": 3.0
                    },
                    "weighted avg": {
                        "precision": 1.0,
                        "recall": 0.6666666666666666,
                        "f1-score": 0.8000000000000002,
                        "support": 3.0
                    }
                },
                "environment_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.25,
                        "recall": 0.4,
                        "f1-score": 0.3076923076923077,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 1.0,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.2857142857142857,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2,
                    "macro avg": {
                        "precision": 0.3125,
                        "recall": 0.14166666666666666,
                        "f1-score": 0.14835164835164835,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.48333333333333334,
                        "recall": 0.2,
                        "f1-score": 0.21684981684981686,
                        "support": 15.0
                    }
                },
                "space_1_extra": {
                    "AFTER": {
                        "precision": 0.3333333333333333,
                        "recall": 1.0,
                        "f1-score": 0.5,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.6,
                        "f1-score": 0.7499999999999999,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.6666666666666666,
                        "recall": 0.6666666666666666,
                        "f1-score": 0.6666666666666666,
                        "support": 6.0
                    },
                    "macro avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.4,
                        "f1-score": 0.3125,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.8888888888888888,
                        "recall": 0.6666666666666666,
                        "f1-score": 0.7083333333333334,
                        "support": 6.0
                    }
                },
                "health_3": {
                    "AFTER": {
                        "precision": 0.4,
                        "recall": 0.25,
                        "f1-score": 0.3076923076923077,
                        "support": 8.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.2222222222222222,
                        "support": 6.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2,
                    "macro avg": {
                        "precision": 0.18333333333333335,
                        "recall": 0.10416666666666666,
                        "f1-score": 0.13247863247863248,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.3466666666666667,
                        "recall": 0.2,
                        "f1-score": 0.252991452991453,
                        "support": 15.0
                    }
                },
                "environment_3": {
                    "AFTER": {
                        "precision": 0.6666666666666666,
                        "recall": 0.36363636363636365,
                        "f1-score": 0.4705882352941177,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 1.0,
                        "recall": 0.5,
                        "f1-score": 0.6666666666666666,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.3333333333333333,
                    "macro avg": {
                        "precision": 0.41666666666666663,
                        "recall": 0.2159090909090909,
                        "f1-score": 0.28431372549019607,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.6222222222222221,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.4339869281045752,
                        "support": 15.0
                    }
                },
                "government_and_politics_protests_3": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.25,
                        "f1-score": 0.3333333333333333,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.16666666666666666,
                    "macro avg": {
                        "precision": 0.125,
                        "recall": 0.0625,
                        "f1-score": 0.08333333333333333,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.2222222222222222,
                        "support": 6.0
                    }
                },
                "economy_and_business_financial_crisis_4": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.08333333333333333,
                        "f1-score": 0.15384615384615385,
                        "support": 12.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.6,
                        "f1-score": 0.5454545454545454,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 1.0,
                        "recall": 0.25,
                        "f1-score": 0.4,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.23809523809523808,
                    "macro avg": {
                        "precision": 0.625,
                        "recall": 0.23333333333333334,
                        "f1-score": 0.2748251748251748,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.8809523809523809,
                        "recall": 0.23809523809523808,
                        "f1-score": 0.29397269397269393,
                        "support": 21.0
                    }
                },
                "computers_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    }
                },
                "crime_and_law_accuse_4": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.6,
                        "f1-score": 0.7499999999999999,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.6666666666666666,
                        "recall": 0.4,
                        "f1-score": 0.5,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.5,
                        "recall": 0.5,
                        "f1-score": 0.5,
                        "support": 10.0
                    },
                    "macro avg": {
                        "precision": 0.41666666666666663,
                        "recall": 0.25,
                        "f1-score": 0.3125,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.8333333333333333,
                        "recall": 0.5,
                        "f1-score": 0.625,
                        "support": 10.0
                    }
                },
                "culture_and_entertainment_1": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.5,
                        "f1-score": 0.5,
                        "support": 2.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 0.5,
                        "f1-score": 0.4,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.3333333333333333,
                    "macro avg": {
                        "precision": 0.20833333333333331,
                        "recall": 0.25,
                        "f1-score": 0.225,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.27777777777777773,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3,
                        "support": 6.0
                    }
                },
                "internet_2": {
                    "AFTER": {
                        "precision": 0.75,
                        "recall": 0.6,
                        "f1-score": 0.6666666666666665,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.6666666666666666,
                        "recall": 0.5,
                        "f1-score": 0.5714285714285715,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.5,
                    "macro avg": {
                        "precision": 0.35416666666666663,
                        "recall": 0.275,
                        "f1-score": 0.30952380952380953,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.6416666666666666,
                        "recall": 0.5,
                        "f1-score": 0.5619047619047619,
                        "support": 10.0
                    }
                },
                "culture_and_entertainment_3": {
                    "AFTER": {
                        "precision": 0.4,
                        "recall": 0.4,
                        "f1-score": 0.4000000000000001,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.25,
                        "f1-score": 0.4,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2,
                    "macro avg": {
                        "precision": 0.35,
                        "recall": 0.1625,
                        "f1-score": 0.2,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.4,
                        "recall": 0.2,
                        "f1-score": 0.24000000000000005,
                        "support": 15.0
                    }
                }
            },
            "refer": {
                "government_and_politics_riots_4": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.25,
                        "f1-score": 0.3333333333333333,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.25,
                        "support": 12.0
                    },
                    "COEX": {
                        "precision": 0.16666666666666666,
                        "recall": 0.08333333333333333,
                        "f1-score": 0.1111111111111111,
                        "support": 12.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.14285714285714285,
                    "macro avg": {
                        "precision": 0.2916666666666667,
                        "recall": 0.12499999999999999,
                        "f1-score": 0.1736111111111111,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.35714285714285715,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.20238095238095236,
                        "support": 28.0
                    }
                },
                "rail_transport_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.17647058823529413,
                        "f1-score": 0.3,
                        "support": 34.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.16666666666666666,
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.04411764705882353,
                        "f1-score": 0.075,
                        "support": 36.0
                    },
                    "weighted avg": {
                        "precision": 0.9444444444444444,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.2833333333333333,
                        "support": 36.0
                    }
                },
                "politics_and_conflicts_policy_change_2": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.6666666666666666,
                        "f1-score": 0.8,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.5,
                        "f1-score": 0.5,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.5,
                    "macro avg": {
                        "precision": 0.375,
                        "recall": 0.29166666666666663,
                        "f1-score": 0.325,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.6666666666666666,
                        "recall": 0.5,
                        "f1-score": 0.5666666666666668,
                        "support": 6.0
                    }
                },
                "politics_and_conflicts_drones_1": {
                    "AFTER": {
                        "precision": 0.6,
                        "recall": 0.2727272727272727,
                        "f1-score": 0.37499999999999994,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 8.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.14285714285714285,
                    "macro avg": {
                        "precision": 0.15,
                        "recall": 0.06818181818181818,
                        "f1-score": 0.09374999999999999,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.3142857142857143,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.1964285714285714,
                        "support": 21.0
                    }
                },
                "disasters_and_accidents_road_crash_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.09090909090909091,
                        "f1-score": 0.15384615384615385,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.25,
                        "recall": 0.1,
                        "f1-score": 0.14285714285714288,
                        "support": 10.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.09523809523809523,
                    "macro avg": {
                        "precision": 0.1875,
                        "recall": 0.04772727272727273,
                        "f1-score": 0.07417582417582419,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.38095238095238093,
                        "recall": 0.09523809523809523,
                        "f1-score": 0.14861329147043434,
                        "support": 21.0
                    }
                },
                "crime_and_law_accuse_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.25,
                        "support": 6.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.1,
                    "macro avg": {
                        "precision": 0.125,
                        "recall": 0.041666666666666664,
                        "f1-score": 0.0625,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.3,
                        "recall": 0.1,
                        "f1-score": 0.15,
                        "support": 10.0
                    }
                },
                "government_and_politics_protests_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.75,
                        "recall": 0.15,
                        "f1-score": 0.24999999999999997,
                        "support": 20.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.10714285714285714,
                    "macro avg": {
                        "precision": 0.1875,
                        "recall": 0.0375,
                        "f1-score": 0.06249999999999999,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.5357142857142857,
                        "recall": 0.10714285714285714,
                        "f1-score": 0.17857142857142855,
                        "support": 28.0
                    }
                },
                "politics_and_conflicts_elections_2": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.13636363636363635,
                        "f1-score": 0.21428571428571427,
                        "support": 22.0
                    },
                    "BEFORE": {
                        "precision": 0.6666666666666666,
                        "recall": 0.2857142857142857,
                        "f1-score": 0.4,
                        "support": 14.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 9.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.15555555555555556,
                    "macro avg": {
                        "precision": 0.29166666666666663,
                        "recall": 0.10551948051948051,
                        "f1-score": 0.15357142857142858,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.45185185185185184,
                        "recall": 0.15555555555555556,
                        "f1-score": 0.22920634920634922,
                        "support": 45.0
                    }
                },
                "environment_2": {
                    "AFTER": {
                        "precision": 0.3333333333333333,
                        "recall": 0.09523809523809523,
                        "f1-score": 0.14814814814814814,
                        "support": 21.0
                    },
                    "BEFORE": {
                        "precision": 0.7777777777777778,
                        "recall": 0.30434782608695654,
                        "f1-score": 0.43750000000000006,
                        "support": 23.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2,
                    "macro avg": {
                        "precision": 0.2777777777777778,
                        "recall": 0.09989648033126294,
                        "f1-score": 0.14641203703703703,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.5530864197530865,
                        "recall": 0.2,
                        "f1-score": 0.29274691358024696,
                        "support": 45.0
                    }
                },
                "weather_floods_3": {
                    "AFTER": {
                        "precision": 0.25,
                        "recall": 0.25,
                        "f1-score": 0.25,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.2,
                        "support": 7.0
                    },
                    "COEX": {
                        "precision": 1.0,
                        "recall": 0.25,
                        "f1-score": 0.4,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2,
                    "macro avg": {
                        "precision": 0.3958333333333333,
                        "recall": 0.1607142857142857,
                        "f1-score": 0.21250000000000002,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.4888888888888889,
                        "recall": 0.2,
                        "f1-score": 0.26666666666666666,
                        "support": 15.0
                    }
                },
                "sports_1": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.5,
                        "f1-score": 0.6666666666666666,
                        "support": 2.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 3.0
                    },
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.125,
                        "f1-score": 0.16666666666666666,
                        "support": 3.0
                    },
                    "weighted avg": {
                        "precision": 0.6666666666666666,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.4444444444444444,
                        "support": 3.0
                    }
                },
                "health_4": {
                    "AFTER": {
                        "precision": 0.6666666666666666,
                        "recall": 0.2222222222222222,
                        "f1-score": 0.3333333333333333,
                        "support": 9.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 0.25,
                        "f1-score": 0.28571428571428575,
                        "support": 8.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.19047619047619047,
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.11805555555555555,
                        "f1-score": 0.15476190476190477,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.4126984126984127,
                        "recall": 0.19047619047619047,
                        "f1-score": 0.2517006802721089,
                        "support": 21.0
                    }
                },
                "weather_earthquakes_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 32.0
                    },
                    "COEX": {
                        "precision": 0.1,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.11764705882352941,
                        "support": 7.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.022222222222222223,
                    "macro avg": {
                        "precision": 0.025,
                        "recall": 0.03571428571428571,
                        "f1-score": 0.029411764705882353,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.015555555555555557,
                        "recall": 0.022222222222222223,
                        "f1-score": 0.01830065359477124,
                        "support": 45.0
                    }
                },
                "space_4": {
                    "AFTER": {
                        "precision": 0.7142857142857143,
                        "recall": 0.45454545454545453,
                        "f1-score": 0.5555555555555556,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.6,
                        "recall": 0.2,
                        "f1-score": 0.3,
                        "support": 15.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2857142857142857,
                    "macro avg": {
                        "precision": 0.32857142857142857,
                        "recall": 0.16363636363636364,
                        "f1-score": 0.2138888888888889,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.6020408163265306,
                        "recall": 0.2857142857142857,
                        "f1-score": 0.37896825396825395,
                        "support": 28.0
                    }
                },
                "economy_and_business_strikes_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.25,
                        "f1-score": 0.4,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.16666666666666666,
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.0625,
                        "f1-score": 0.1,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.6666666666666666,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.26666666666666666,
                        "support": 6.0
                    }
                },
                "politics_and_conflicts_armed_conflict_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.09090909090909091,
                        "f1-score": 0.16666666666666669,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.5,
                        "recall": 0.6666666666666666,
                        "f1-score": 0.5714285714285715,
                        "support": 3.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2,
                    "macro avg": {
                        "precision": 0.375,
                        "recall": 0.1893939393939394,
                        "f1-score": 0.18452380952380953,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.8333333333333334,
                        "recall": 0.2,
                        "f1-score": 0.23650793650793653,
                        "support": 15.0
                    }
                },
                "infectious_disease_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    }
                },
                "health_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "BEFORE": {
                        "precision": 0.25,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.28571428571428575,
                        "support": 3.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.1,
                    "macro avg": {
                        "precision": 0.0625,
                        "recall": 0.08333333333333333,
                        "f1-score": 0.07142857142857144,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.075,
                        "recall": 0.1,
                        "f1-score": 0.08571428571428572,
                        "support": 10.0
                    }
                },
                "disasters_and_accidents_shipwreck_2": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.09090909090909091,
                        "f1-score": 0.15384615384615385,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 0.1111111111111111,
                        "f1-score": 0.16666666666666666,
                        "support": 9.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.09523809523809523,
                    "macro avg": {
                        "precision": 0.20833333333333331,
                        "recall": 0.050505050505050504,
                        "f1-score": 0.08012820512820512,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.40476190476190477,
                        "recall": 0.09523809523809523,
                        "f1-score": 0.15201465201465203,
                        "support": 21.0
                    }
                },
                "rail_transport_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.6,
                        "f1-score": 0.7499999999999999,
                        "support": 10.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.4,
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.15,
                        "f1-score": 0.18749999999999997,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.6666666666666666,
                        "recall": 0.4,
                        "f1-score": 0.49999999999999994,
                        "support": 15.0
                    }
                },
                "weather_storms_1_extra": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    }
                },
                "health_1_extra": {
                    "AFTER": {
                        "precision": 0.3333333333333333,
                        "recall": 0.25,
                        "f1-score": 0.28571428571428575,
                        "support": 12.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.07142857142857142,
                        "f1-score": 0.13333333333333333,
                        "support": 28.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 15.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.09090909090909091,
                    "macro avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.08035714285714285,
                        "f1-score": 0.10476190476190478,
                        "support": 55.0
                    },
                    "weighted avg": {
                        "precision": 0.5818181818181818,
                        "recall": 0.09090909090909091,
                        "f1-score": 0.13021645021645023,
                        "support": 55.0
                    }
                },
                "weather_floods_1": {
                    "AFTER": {
                        "precision": 0.09090909090909091,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.14285714285714288,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.125,
                        "f1-score": 0.2,
                        "support": 24.0
                    },
                    "COEX": {
                        "precision": 0.8,
                        "recall": 0.5714285714285714,
                        "f1-score": 0.6666666666666666,
                        "support": 28.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.36363636363636365,
                    "macro avg": {
                        "precision": 0.3477272727272728,
                        "recall": 0.25744047619047616,
                        "f1-score": 0.2523809523809524,
                        "support": 55.0
                    },
                    "weighted avg": {
                        "precision": 0.6304132231404959,
                        "recall": 0.36363636363636365,
                        "f1-score": 0.4344588744588744,
                        "support": 55.0
                    }
                },
                "mining_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.75,
                        "recall": 0.12,
                        "f1-score": 0.20689655172413793,
                        "support": 25.0
                    },
                    "COEX": {
                        "precision": 0.16666666666666666,
                        "recall": 0.1111111111111111,
                        "f1-score": 0.13333333333333333,
                        "support": 9.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.08888888888888889,
                    "macro avg": {
                        "precision": 0.22916666666666666,
                        "recall": 0.057777777777777775,
                        "f1-score": 0.08505747126436781,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.45,
                        "recall": 0.08888888888888889,
                        "f1-score": 0.14160919540229885,
                        "support": 45.0
                    }
                },
                "disasters_and_accidents_volcanoes_4": {
                    "AFTER": {
                        "precision": 0.6666666666666666,
                        "recall": 0.3,
                        "f1-score": 0.41379310344827586,
                        "support": 20.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.25,
                        "support": 14.0
                    },
                    "COEX": {
                        "precision": 0.09090909090909091,
                        "recall": 0.5,
                        "f1-score": 0.15384615384615385,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.25,
                    "macro avg": {
                        "precision": 0.43939393939393934,
                        "recall": 0.2357142857142857,
                        "f1-score": 0.2044098143236074,
                        "support": 36.0
                    },
                    "weighted avg": {
                        "precision": 0.7643097643097643,
                        "recall": 0.25,
                        "f1-score": 0.33565428824049515,
                        "support": 36.0
                    }
                },
                "politics_and_conflicts_elections_3": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.6,
                        "f1-score": 0.5454545454545454,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2,
                    "macro avg": {
                        "precision": 0.125,
                        "recall": 0.15,
                        "f1-score": 0.13636363636363635,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.16666666666666666,
                        "recall": 0.2,
                        "f1-score": 0.1818181818181818,
                        "support": 15.0
                    }
                },
                "economy_and_business_strikes_3": {
                    "AFTER": {
                        "precision": 0.2222222222222222,
                        "recall": 0.2,
                        "f1-score": 0.2105263157894737,
                        "support": 10.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.18181818181818182,
                        "f1-score": 0.3076923076923077,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.375,
                        "recall": 0.42857142857142855,
                        "f1-score": 0.39999999999999997,
                        "support": 7.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.25,
                    "macro avg": {
                        "precision": 0.3993055555555556,
                        "recall": 0.2025974025974026,
                        "f1-score": 0.22955465587044532,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.5659722222222222,
                        "recall": 0.25,
                        "f1-score": 0.29606709080393295,
                        "support": 28.0
                    }
                },
                "space_2": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.05,
                        "f1-score": 0.09090909090909091,
                        "support": 100.0
                    },
                    "BEFORE": {
                        "precision": 0.2,
                        "recall": 0.0392156862745098,
                        "f1-score": 0.06557377049180327,
                        "support": 51.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.0457516339869281,
                    "macro avg": {
                        "precision": 0.175,
                        "recall": 0.02230392156862745,
                        "f1-score": 0.039120715350223545,
                        "support": 153.0
                    },
                    "weighted avg": {
                        "precision": 0.39346405228758174,
                        "recall": 0.0457516339869281,
                        "f1-score": 0.08127562997379777,
                        "support": 153.0
                    }
                },
                "politics_and_conflicts_resign_1": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.6666666666666666,
                        "f1-score": 0.8,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.6666666666666666,
                        "recall": 0.6666666666666666,
                        "f1-score": 0.6666666666666666,
                        "support": 3.0
                    },
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.2,
                        "support": 3.0
                    },
                    "weighted avg": {
                        "precision": 1.0,
                        "recall": 0.6666666666666666,
                        "f1-score": 0.8000000000000002,
                        "support": 3.0
                    }
                },
                "environment_4": {
                    "AFTER": {
                        "precision": 0.25,
                        "recall": 0.25,
                        "f1-score": 0.25,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 0.2,
                        "f1-score": 0.25,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.25,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.2,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2,
                    "macro avg": {
                        "precision": 0.20833333333333331,
                        "recall": 0.15416666666666667,
                        "f1-score": 0.175,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.27777777777777773,
                        "recall": 0.2,
                        "f1-score": 0.23,
                        "support": 15.0
                    }
                },
                "space_1_extra": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.2,
                        "f1-score": 0.28571428571428575,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.16666666666666666,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.16666666666666666,
                        "support": 6.0
                    },
                    "macro avg": {
                        "precision": 0.125,
                        "recall": 0.05,
                        "f1-score": 0.07142857142857144,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.4166666666666667,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.23809523809523814,
                        "support": 6.0
                    }
                },
                "health_3": {
                    "AFTER": {
                        "precision": 0.8,
                        "recall": 0.5,
                        "f1-score": 0.6153846153846154,
                        "support": 8.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.2857142857142857,
                        "support": 6.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.3333333333333333,
                    "macro avg": {
                        "precision": 0.45,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.22527472527472528,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.8266666666666667,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.44249084249084253,
                        "support": 15.0
                    }
                },
                "environment_3": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.09090909090909091,
                        "f1-score": 0.15384615384615385,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.2,
                        "recall": 0.5,
                        "f1-score": 0.28571428571428575,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.3333333333333333,
                        "recall": 0.5,
                        "f1-score": 0.4,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2,
                    "macro avg": {
                        "precision": 0.2583333333333333,
                        "recall": 0.2727272727272727,
                        "f1-score": 0.20989010989010992,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.4377777777777778,
                        "recall": 0.2,
                        "f1-score": 0.2042490842490843,
                        "support": 15.0
                    }
                },
                "government_and_politics_protests_3": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.5,
                        "f1-score": 0.6666666666666666,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 1.0,
                        "f1-score": 0.6666666666666666,
                        "support": 1.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.5,
                        "recall": 0.5,
                        "f1-score": 0.5,
                        "support": 6.0
                    },
                    "macro avg": {
                        "precision": 0.375,
                        "recall": 0.375,
                        "f1-score": 0.3333333333333333,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.75,
                        "recall": 0.5,
                        "f1-score": 0.5555555555555555,
                        "support": 6.0
                    }
                },
                "economy_and_business_financial_crisis_4": {
                    "AFTER": {
                        "precision": 0.6666666666666666,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.4444444444444444,
                        "support": 12.0
                    },
                    "BEFORE": {
                        "precision": 0.6666666666666666,
                        "recall": 0.4,
                        "f1-score": 0.5,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.25,
                        "recall": 0.25,
                        "f1-score": 0.25,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.3333333333333333,
                    "macro avg": {
                        "precision": 0.3958333333333333,
                        "recall": 0.24583333333333335,
                        "f1-score": 0.2986111111111111,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.5873015873015872,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.4206349206349206,
                        "support": 21.0
                    }
                },
                "computers_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    }
                },
                "crime_and_law_accuse_4": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.2,
                        "f1-score": 0.28571428571428575,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.1,
                    "macro avg": {
                        "precision": 0.125,
                        "recall": 0.05,
                        "f1-score": 0.07142857142857144,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.25,
                        "recall": 0.1,
                        "f1-score": 0.14285714285714288,
                        "support": 10.0
                    }
                },
                "culture_and_entertainment_1": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.5,
                        "f1-score": 0.5,
                        "support": 2.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.16666666666666666,
                    "macro avg": {
                        "precision": 0.125,
                        "recall": 0.125,
                        "f1-score": 0.125,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.16666666666666666,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.16666666666666666,
                        "support": 6.0
                    }
                },
                "internet_2": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.6,
                        "f1-score": 0.7499999999999999,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.3,
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.15,
                        "f1-score": 0.18749999999999997,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.5,
                        "recall": 0.3,
                        "f1-score": 0.37499999999999994,
                        "support": 10.0
                    }
                },
                "culture_and_entertainment_3": {
                    "AFTER": {
                        "precision": 0.3333333333333333,
                        "recall": 0.2,
                        "f1-score": 0.25,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 0.25,
                        "f1-score": 0.28571428571428575,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.4,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3636363636363636,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.26666666666666666,
                    "macro avg": {
                        "precision": 0.26666666666666666,
                        "recall": 0.19583333333333333,
                        "f1-score": 0.22483766233766234,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.36000000000000004,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.304978354978355,
                        "support": 15.0
                    }
                }
            },
            "refer_events": {
                "government_and_politics_riots_4": {
                    "AFTER": {
                        "precision": 0.10526315789473684,
                        "recall": 0.5,
                        "f1-score": 0.17391304347826086,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.16666666666666666,
                        "recall": 0.08333333333333333,
                        "f1-score": 0.1111111111111111,
                        "support": 12.0
                    },
                    "COEX": {
                        "precision": 0.3333333333333333,
                        "recall": 0.08333333333333333,
                        "f1-score": 0.13333333333333333,
                        "support": 12.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.14285714285714285,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.14285714285714285,
                        "support": 28.0
                    },
                    "macro avg": {
                        "precision": 0.15131578947368418,
                        "recall": 0.16666666666666669,
                        "f1-score": 0.10458937198067633,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.22932330827067668,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.12960662525879918,
                        "support": 28.0
                    }
                },
                "rail_transport_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "BEFORE": {
                        "precision": 0.875,
                        "recall": 0.20588235294117646,
                        "f1-score": 0.33333333333333337,
                        "support": 34.0
                    },
                    "COEX": {
                        "precision": 0.08333333333333333,
                        "recall": 0.5,
                        "f1-score": 0.14285714285714285,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2222222222222222,
                    "macro avg": {
                        "precision": 0.23958333333333334,
                        "recall": 0.1764705882352941,
                        "f1-score": 0.11904761904761905,
                        "support": 36.0
                    },
                    "weighted avg": {
                        "precision": 0.8310185185185186,
                        "recall": 0.2222222222222222,
                        "f1-score": 0.3227513227513228,
                        "support": 36.0
                    }
                },
                "politics_and_conflicts_policy_change_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.2,
                        "recall": 1.0,
                        "f1-score": 0.33333333333333337,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.16666666666666666,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.16666666666666666,
                        "support": 6.0
                    },
                    "macro avg": {
                        "precision": 0.05,
                        "recall": 0.25,
                        "f1-score": 0.08333333333333334,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.03333333333333333,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.05555555555555556,
                        "support": 6.0
                    }
                },
                "politics_and_conflicts_drones_1": {
                    "AFTER": {
                        "precision": 0.5833333333333334,
                        "recall": 0.6363636363636364,
                        "f1-score": 0.6086956521739131,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 8.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 21.0
                    },
                    "macro avg": {
                        "precision": 0.14583333333333334,
                        "recall": 0.1590909090909091,
                        "f1-score": 0.15217391304347827,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.3055555555555556,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.31884057971014496,
                        "support": 21.0
                    }
                },
                "disasters_and_accidents_road_crash_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 0.09090909090909091,
                        "f1-score": 0.14285714285714288,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.4444444444444444,
                        "recall": 0.4,
                        "f1-score": 0.4210526315789474,
                        "support": 10.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.23809523809523808,
                        "recall": 0.23809523809523808,
                        "f1-score": 0.23809523809523808,
                        "support": 21.0
                    },
                    "macro avg": {
                        "precision": 0.19444444444444442,
                        "recall": 0.12272727272727274,
                        "f1-score": 0.14097744360902256,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.3862433862433862,
                        "recall": 0.23809523809523808,
                        "f1-score": 0.2753311851056212,
                        "support": 21.0
                    }
                },
                "crime_and_law_accuse_3": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.5,
                        "f1-score": 0.5,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.25,
                        "support": 6.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.3,
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.1875,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.5,
                        "recall": 0.3,
                        "f1-score": 0.35,
                        "support": 10.0
                    }
                },
                "government_and_politics_protests_2": {
                    "AFTER": {
                        "precision": 0.08333333333333333,
                        "recall": 0.2,
                        "f1-score": 0.11764705882352941,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.25,
                        "f1-score": 0.4,
                        "support": 20.0
                    },
                    "COEX": {
                        "precision": 0.18181818181818182,
                        "recall": 0.6666666666666666,
                        "f1-score": 0.28571428571428575,
                        "support": 3.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.2857142857142857,
                        "recall": 0.2857142857142857,
                        "f1-score": 0.2857142857142857,
                        "support": 28.0
                    },
                    "macro avg": {
                        "precision": 0.3162878787878788,
                        "recall": 0.2791666666666667,
                        "f1-score": 0.2008403361344538,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.7486471861471863,
                        "recall": 0.2857142857142857,
                        "f1-score": 0.33733493397358943,
                        "support": 28.0
                    }
                },
                "politics_and_conflicts_elections_2": {
                    "AFTER": {
                        "precision": 0.5714285714285714,
                        "recall": 0.5454545454545454,
                        "f1-score": 0.5581395348837208,
                        "support": 22.0
                    },
                    "BEFORE": {
                        "precision": 0.36363636363636365,
                        "recall": 0.2857142857142857,
                        "f1-score": 0.32,
                        "support": 14.0
                    },
                    "COEX": {
                        "precision": 0.2,
                        "recall": 0.2222222222222222,
                        "f1-score": 0.2105263157894737,
                        "support": 9.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.4,
                    "macro avg": {
                        "precision": 0.2837662337662338,
                        "recall": 0.26334776334776333,
                        "f1-score": 0.27216646266829864,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.43249639249639255,
                        "recall": 0.4,
                        "f1-score": 0.4145290357677138,
                        "support": 45.0
                    }
                },
                "environment_2": {
                    "AFTER": {
                        "precision": 0.5142857142857142,
                        "recall": 0.8571428571428571,
                        "f1-score": 0.6428571428571428,
                        "support": 21.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 23.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.4,
                        "recall": 0.4,
                        "f1-score": 0.4000000000000001,
                        "support": 45.0
                    },
                    "macro avg": {
                        "precision": 0.12857142857142856,
                        "recall": 0.21428571428571427,
                        "f1-score": 0.1607142857142857,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.23999999999999996,
                        "recall": 0.4,
                        "f1-score": 0.29999999999999993,
                        "support": 45.0
                    }
                },
                "weather_floods_3": {
                    "AFTER": {
                        "precision": 0.2,
                        "recall": 0.5,
                        "f1-score": 0.28571428571428575,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 7.0
                    },
                    "COEX": {
                        "precision": 0.6666666666666666,
                        "recall": 0.5,
                        "f1-score": 0.5714285714285715,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.26666666666666666,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.26666666666666666,
                        "support": 15.0
                    },
                    "macro avg": {
                        "precision": 0.21666666666666667,
                        "recall": 0.25,
                        "f1-score": 0.2142857142857143,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.23111111111111113,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.2285714285714286,
                        "support": 15.0
                    }
                },
                "sports_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    }
                },
                "health_4": {
                    "AFTER": {
                        "precision": 0.46153846153846156,
                        "recall": 0.6666666666666666,
                        "f1-score": 0.5454545454545455,
                        "support": 9.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.125,
                        "f1-score": 0.2,
                        "support": 8.0
                    },
                    "COEX": {
                        "precision": 0.3333333333333333,
                        "recall": 0.5,
                        "f1-score": 0.4,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.42857142857142855,
                        "recall": 0.42857142857142855,
                        "f1-score": 0.42857142857142855,
                        "support": 21.0
                    },
                    "macro avg": {
                        "precision": 0.32371794871794873,
                        "recall": 0.32291666666666663,
                        "f1-score": 0.2863636363636364,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.4517704517704518,
                        "recall": 0.42857142857142855,
                        "f1-score": 0.3861471861471862,
                        "support": 21.0
                    }
                },
                "weather_earthquakes_1": {
                    "AFTER": {
                        "precision": 0.09090909090909091,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.14285714285714288,
                        "support": 6.0
                    },
                    "BEFORE": {
                        "precision": 0.8181818181818182,
                        "recall": 0.28125,
                        "f1-score": 0.41860465116279066,
                        "support": 32.0
                    },
                    "COEX": {
                        "precision": 0.36363636363636365,
                        "recall": 0.5714285714285714,
                        "f1-score": 0.4444444444444444,
                        "support": 7.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.3333333333333333,
                    "macro avg": {
                        "precision": 0.31818181818181823,
                        "recall": 0.29650297619047616,
                        "f1-score": 0.2514765596160945,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.6505050505050506,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.385857840121406,
                        "support": 45.0
                    }
                },
                "space_4": {
                    "AFTER": {
                        "precision": 0.2777777777777778,
                        "recall": 0.45454545454545453,
                        "f1-score": 0.3448275862068966,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 0.13333333333333333,
                        "f1-score": 0.19047619047619044,
                        "support": 15.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.25,
                        "recall": 0.25,
                        "f1-score": 0.25,
                        "support": 28.0
                    },
                    "macro avg": {
                        "precision": 0.1527777777777778,
                        "recall": 0.14696969696969697,
                        "f1-score": 0.13382594417077176,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.2876984126984127,
                        "recall": 0.25,
                        "f1-score": 0.2375087966220971,
                        "support": 28.0
                    }
                },
                "economy_and_business_strikes_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.25,
                        "f1-score": 0.3333333333333333,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.16666666666666666,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.16666666666666666,
                        "support": 6.0
                    },
                    "macro avg": {
                        "precision": 0.125,
                        "recall": 0.0625,
                        "f1-score": 0.08333333333333333,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.2222222222222222,
                        "support": 6.0
                    }
                },
                "politics_and_conflicts_armed_conflict_2": {
                    "AFTER": {
                        "precision": 0.16666666666666666,
                        "recall": 1.0,
                        "f1-score": 0.2857142857142857,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.125,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.18181818181818182,
                        "support": 3.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.13333333333333333,
                        "recall": 0.13333333333333333,
                        "f1-score": 0.13333333333333333,
                        "support": 15.0
                    },
                    "macro avg": {
                        "precision": 0.07291666666666666,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.11688311688311688,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.03611111111111111,
                        "recall": 0.13333333333333333,
                        "f1-score": 0.055411255411255404,
                        "support": 15.0
                    }
                },
                "infectious_disease_4": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.25,
                        "f1-score": 0.25,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    }
                },
                "health_1": {
                    "AFTER": {
                        "precision": 0.6666666666666666,
                        "recall": 0.6666666666666666,
                        "f1-score": 0.6666666666666666,
                        "support": 6.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "COEX": {
                        "precision": 0.5,
                        "recall": 1.0,
                        "f1-score": 0.6666666666666666,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.5,
                        "recall": 0.5,
                        "f1-score": 0.5,
                        "support": 10.0
                    },
                    "macro avg": {
                        "precision": 0.29166666666666663,
                        "recall": 0.41666666666666663,
                        "f1-score": 0.3333333333333333,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.45,
                        "recall": 0.5,
                        "f1-score": 0.4666666666666667,
                        "support": 10.0
                    }
                },
                "disasters_and_accidents_shipwreck_2": {
                    "AFTER": {
                        "precision": 0.2,
                        "recall": 0.09090909090909091,
                        "f1-score": 0.12500000000000003,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 9.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.047619047619047616,
                        "recall": 0.047619047619047616,
                        "f1-score": 0.047619047619047616,
                        "support": 21.0
                    },
                    "macro avg": {
                        "precision": 0.05,
                        "recall": 0.022727272727272728,
                        "f1-score": 0.03125000000000001,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.10476190476190476,
                        "recall": 0.047619047619047616,
                        "f1-score": 0.0654761904761905,
                        "support": 21.0
                    }
                },
                "rail_transport_3": {
                    "AFTER": {
                        "precision": 0.4444444444444444,
                        "recall": 0.8,
                        "f1-score": 0.5714285714285714,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.3,
                        "f1-score": 0.4615384615384615,
                        "support": 10.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.4666666666666667,
                        "recall": 0.4666666666666667,
                        "f1-score": 0.4666666666666667,
                        "support": 15.0
                    },
                    "macro avg": {
                        "precision": 0.3611111111111111,
                        "recall": 0.275,
                        "f1-score": 0.2582417582417582,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.8148148148148148,
                        "recall": 0.4666666666666667,
                        "f1-score": 0.4981684981684981,
                        "support": 15.0
                    }
                },
                "weather_storms_1_extra": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    }
                },
                "health_1_extra": {
                    "AFTER": {
                        "precision": 0.16666666666666666,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.2222222222222222,
                        "support": 12.0
                    },
                    "BEFORE": {
                        "precision": 0.35294117647058826,
                        "recall": 0.21428571428571427,
                        "f1-score": 0.26666666666666666,
                        "support": 28.0
                    },
                    "COEX": {
                        "precision": 0.2727272727272727,
                        "recall": 0.2,
                        "f1-score": 0.23076923076923075,
                        "support": 15.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.23636363636363636,
                    "macro avg": {
                        "precision": 0.1980837789661319,
                        "recall": 0.1869047619047619,
                        "f1-score": 0.1799145299145299,
                        "support": 55.0
                    },
                    "weighted avg": {
                        "precision": 0.2904229460379193,
                        "recall": 0.23636363636363636,
                        "f1-score": 0.24717948717948718,
                        "support": 55.0
                    }
                },
                "weather_floods_1": {
                    "AFTER": {
                        "precision": 0.0967741935483871,
                        "recall": 1.0,
                        "f1-score": 0.17647058823529413,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 0.125,
                        "f1-score": 0.18181818181818182,
                        "support": 24.0
                    },
                    "COEX": {
                        "precision": 0.5555555555555556,
                        "recall": 0.17857142857142858,
                        "f1-score": 0.2702702702702703,
                        "support": 28.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2,
                    "macro avg": {
                        "precision": 0.246415770609319,
                        "recall": 0.32589285714285715,
                        "f1-score": 0.15713976008093655,
                        "support": 55.0
                    },
                    "weighted avg": {
                        "precision": 0.43356142065819486,
                        "recall": 0.2,
                        "f1-score": 0.22655664901654207,
                        "support": 55.0
                    }
                },
                "mining_4": {
                    "AFTER": {
                        "precision": 0.20689655172413793,
                        "recall": 0.5454545454545454,
                        "f1-score": 0.3,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.625,
                        "recall": 0.2,
                        "f1-score": 0.30303030303030304,
                        "support": 25.0
                    },
                    "COEX": {
                        "precision": 0.125,
                        "recall": 0.1111111111111111,
                        "f1-score": 0.11764705882352941,
                        "support": 9.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.26666666666666666,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.26666666666666666,
                        "support": 45.0
                    },
                    "macro avg": {
                        "precision": 0.23922413793103448,
                        "recall": 0.21414141414141413,
                        "f1-score": 0.18016934046345812,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.42279693486590036,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.2652129134482075,
                        "support": 45.0
                    }
                },
                "disasters_and_accidents_volcanoes_4": {
                    "AFTER": {
                        "precision": 0.6111111111111112,
                        "recall": 0.55,
                        "f1-score": 0.5789473684210527,
                        "support": 20.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.2,
                        "support": 14.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.3611111111111111,
                        "recall": 0.3611111111111111,
                        "f1-score": 0.3611111111111111,
                        "support": 36.0
                    },
                    "macro avg": {
                        "precision": 0.2361111111111111,
                        "recall": 0.1732142857142857,
                        "f1-score": 0.19473684210526315,
                        "support": 36.0
                    },
                    "weighted avg": {
                        "precision": 0.46913580246913583,
                        "recall": 0.3611111111111111,
                        "f1-score": 0.3994152046783626,
                        "support": 36.0
                    }
                },
                "politics_and_conflicts_elections_3": {
                    "AFTER": {
                        "precision": 0.5714285714285714,
                        "recall": 0.8,
                        "f1-score": 0.6666666666666666,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.5714285714285714,
                        "recall": 0.6666666666666666,
                        "f1-score": 0.6153846153846153,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.5333333333333333,
                    "macro avg": {
                        "precision": 0.2857142857142857,
                        "recall": 0.3666666666666667,
                        "f1-score": 0.3205128205128205,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.419047619047619,
                        "recall": 0.5333333333333333,
                        "f1-score": 0.4683760683760683,
                        "support": 15.0
                    }
                },
                "economy_and_business_strikes_3": {
                    "AFTER": {
                        "precision": 0.3125,
                        "recall": 0.5,
                        "f1-score": 0.38461538461538464,
                        "support": 10.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.5,
                        "recall": 0.5714285714285714,
                        "f1-score": 0.5333333333333333,
                        "support": 7.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.32142857142857145,
                        "recall": 0.32142857142857145,
                        "f1-score": 0.32142857142857145,
                        "support": 28.0
                    },
                    "macro avg": {
                        "precision": 0.203125,
                        "recall": 0.26785714285714285,
                        "f1-score": 0.2294871794871795,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.23660714285714285,
                        "recall": 0.32142857142857145,
                        "f1-score": 0.2706959706959707,
                        "support": 28.0
                    }
                },
                "space_2": {
                    "AFTER": {
                        "precision": 0.4909090909090909,
                        "recall": 0.27,
                        "f1-score": 0.34838709677419355,
                        "support": 100.0
                    },
                    "BEFORE": {
                        "precision": 0.06666666666666667,
                        "recall": 0.0784313725490196,
                        "f1-score": 0.07207207207207207,
                        "support": 51.0
                    },
                    "COEX": {
                        "precision": 0.05714285714285714,
                        "recall": 1.0,
                        "f1-score": 0.1081081081081081,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.21568627450980393,
                    "macro avg": {
                        "precision": 0.1536796536796537,
                        "recall": 0.3371078431372549,
                        "f1-score": 0.13214181923859342,
                        "support": 153.0
                    },
                    "weighted avg": {
                        "precision": 0.34382480264833204,
                        "recall": 0.21568627450980393,
                        "f1-score": 0.2531411867275245,
                        "support": 153.0
                    }
                },
                "politics_and_conflicts_resign_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    }
                },
                "environment_4": {
                    "AFTER": {
                        "precision": 0.25,
                        "recall": 0.75,
                        "f1-score": 0.375,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.5,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.25,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.26666666666666666,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.26666666666666666,
                        "support": 15.0
                    },
                    "macro avg": {
                        "precision": 0.1875,
                        "recall": 0.22916666666666666,
                        "f1-score": 0.15625,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.26666666666666666,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.2,
                        "support": 15.0
                    }
                },
                "space_1_extra": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    }
                },
                "health_3": {
                    "AFTER": {
                        "precision": 0.6666666666666666,
                        "recall": 0.5,
                        "f1-score": 0.5714285714285715,
                        "support": 8.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.5,
                        "support": 6.0
                    },
                    "COEX": {
                        "precision": 0.14285714285714285,
                        "recall": 1.0,
                        "f1-score": 0.25,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.4666666666666667,
                        "recall": 0.4666666666666667,
                        "f1-score": 0.4666666666666667,
                        "support": 15.0
                    },
                    "macro avg": {
                        "precision": 0.45238095238095233,
                        "recall": 0.4583333333333333,
                        "f1-score": 0.3303571428571429,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.7650793650793649,
                        "recall": 0.4666666666666667,
                        "f1-score": 0.5214285714285715,
                        "support": 15.0
                    }
                },
                "environment_3": {
                    "AFTER": {
                        "precision": 0.7142857142857143,
                        "recall": 0.45454545454545453,
                        "f1-score": 0.5555555555555556,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.3333333333333333,
                    "macro avg": {
                        "precision": 0.17857142857142858,
                        "recall": 0.11363636363636363,
                        "f1-score": 0.1388888888888889,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.5238095238095238,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.40740740740740744,
                        "support": 15.0
                    }
                },
                "government_and_politics_protests_3": {
                    "AFTER": {
                        "precision": 0.3333333333333333,
                        "recall": 0.25,
                        "f1-score": 0.28571428571428575,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.16666666666666666,
                    "macro avg": {
                        "precision": 0.08333333333333333,
                        "recall": 0.0625,
                        "f1-score": 0.07142857142857144,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.2222222222222222,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.1904761904761905,
                        "support": 6.0
                    }
                },
                "economy_and_business_financial_crisis_4": {
                    "AFTER": {
                        "precision": 0.4444444444444444,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.380952380952381,
                        "support": 12.0
                    },
                    "BEFORE": {
                        "precision": 0.4,
                        "recall": 0.4,
                        "f1-score": 0.4000000000000001,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.14285714285714285,
                        "recall": 0.25,
                        "f1-score": 0.18181818181818182,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 21.0
                    },
                    "macro avg": {
                        "precision": 0.24682539682539684,
                        "recall": 0.24583333333333335,
                        "f1-score": 0.24069264069264074,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.37641723356009066,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3475572047000619,
                        "support": 21.0
                    }
                },
                "computers_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    }
                },
                "crime_and_law_accuse_4": {
                    "AFTER": {
                        "precision": 0.2,
                        "recall": 0.2,
                        "f1-score": 0.20000000000000004,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.1,
                        "recall": 0.1,
                        "f1-score": 0.10000000000000002,
                        "support": 10.0
                    },
                    "macro avg": {
                        "precision": 0.05,
                        "recall": 0.05,
                        "f1-score": 0.05000000000000001,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.1,
                        "recall": 0.1,
                        "f1-score": 0.10000000000000002,
                        "support": 10.0
                    }
                },
                "culture_and_entertainment_1": {
                    "AFTER": {
                        "precision": 0.25,
                        "recall": 0.5,
                        "f1-score": 0.3333333333333333,
                        "support": 2.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.16666666666666666,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.16666666666666666,
                        "support": 6.0
                    },
                    "macro avg": {
                        "precision": 0.0625,
                        "recall": 0.125,
                        "f1-score": 0.08333333333333333,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.08333333333333333,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.1111111111111111,
                        "support": 6.0
                    }
                },
                "internet_2": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.6,
                        "f1-score": 0.5454545454545454,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.25,
                        "f1-score": 0.4,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.4,
                        "recall": 0.4,
                        "f1-score": 0.4000000000000001,
                        "support": 10.0
                    },
                    "macro avg": {
                        "precision": 0.375,
                        "recall": 0.2125,
                        "f1-score": 0.23636363636363636,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.65,
                        "recall": 0.4,
                        "f1-score": 0.43272727272727274,
                        "support": 10.0
                    }
                },
                "culture_and_entertainment_3": {
                    "AFTER": {
                        "precision": 0.2,
                        "recall": 0.2,
                        "f1-score": 0.20000000000000004,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.375,
                        "recall": 0.5,
                        "f1-score": 0.42857142857142855,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.26666666666666666,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.26666666666666666,
                        "support": 15.0
                    },
                    "macro avg": {
                        "precision": 0.14375,
                        "recall": 0.175,
                        "f1-score": 0.15714285714285714,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.21666666666666667,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.23809523809523808,
                        "support": 15.0
                    }
                }
            },
            "hint": {
                "government_and_politics_riots_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.25,
                        "support": 12.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 12.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.07142857142857142,
                    "macro avg": {
                        "precision": 0.125,
                        "recall": 0.041666666666666664,
                        "f1-score": 0.0625,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.21428571428571427,
                        "recall": 0.07142857142857142,
                        "f1-score": 0.10714285714285714,
                        "support": 28.0
                    }
                },
                "rail_transport_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "BEFORE": {
                        "precision": 0.8888888888888888,
                        "recall": 0.23529411764705882,
                        "f1-score": 0.3720930232558139,
                        "support": 34.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2222222222222222,
                    "macro avg": {
                        "precision": 0.2222222222222222,
                        "recall": 0.058823529411764705,
                        "f1-score": 0.09302325581395347,
                        "support": 36.0
                    },
                    "weighted avg": {
                        "precision": 0.8395061728395061,
                        "recall": 0.2222222222222222,
                        "f1-score": 0.3514211886304909,
                        "support": 36.0
                    }
                },
                "politics_and_conflicts_policy_change_2": {
                    "AFTER": {
                        "precision": 0.6666666666666666,
                        "recall": 0.6666666666666666,
                        "f1-score": 0.6666666666666666,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 0.5,
                        "f1-score": 0.4,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.5,
                        "recall": 0.5,
                        "f1-score": 0.5,
                        "support": 6.0
                    },
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.29166666666666663,
                        "f1-score": 0.26666666666666666,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.4444444444444444,
                        "recall": 0.5,
                        "f1-score": 0.4666666666666666,
                        "support": 6.0
                    }
                },
                "politics_and_conflicts_drones_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.42857142857142855,
                        "recall": 0.375,
                        "f1-score": 0.39999999999999997,
                        "support": 8.0
                    },
                    "COEX": {
                        "precision": 0.3333333333333333,
                        "recall": 0.5,
                        "f1-score": 0.4,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.19047619047619047,
                    "macro avg": {
                        "precision": 0.19047619047619047,
                        "recall": 0.21875,
                        "f1-score": 0.2,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.1950113378684807,
                        "recall": 0.19047619047619047,
                        "f1-score": 0.19047619047619047,
                        "support": 21.0
                    }
                },
                "disasters_and_accidents_road_crash_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.18181818181818182,
                        "f1-score": 0.26666666666666666,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.3333333333333333,
                        "recall": 0.1,
                        "f1-score": 0.15384615384615383,
                        "support": 10.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.14285714285714285,
                    "macro avg": {
                        "precision": 0.20833333333333331,
                        "recall": 0.07045454545454546,
                        "f1-score": 0.10512820512820512,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.4206349206349206,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.21294261294261294,
                        "support": 21.0
                    }
                },
                "crime_and_law_accuse_3": {
                    "AFTER": {
                        "precision": 0.25,
                        "recall": 0.25,
                        "f1-score": 0.25,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.2222222222222222,
                        "support": 6.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2,
                    "macro avg": {
                        "precision": 0.14583333333333331,
                        "recall": 0.10416666666666666,
                        "f1-score": 0.11805555555555555,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.3,
                        "recall": 0.2,
                        "f1-score": 0.2333333333333333,
                        "support": 10.0
                    }
                },
                "government_and_politics_protests_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.4444444444444444,
                        "recall": 0.2,
                        "f1-score": 0.2758620689655173,
                        "support": 20.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.14285714285714285,
                    "macro avg": {
                        "precision": 0.1111111111111111,
                        "recall": 0.05,
                        "f1-score": 0.06896551724137932,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.3174603174603175,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.1970443349753695,
                        "support": 28.0
                    }
                },
                "politics_and_conflicts_elections_2": {
                    "AFTER": {
                        "precision": 0.625,
                        "recall": 0.45454545454545453,
                        "f1-score": 0.5263157894736842,
                        "support": 22.0
                    },
                    "BEFORE": {
                        "precision": 0.25,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.18181818181818182,
                        "support": 14.0
                    },
                    "COEX": {
                        "precision": 0.25,
                        "recall": 0.1111111111111111,
                        "f1-score": 0.15384615384615383,
                        "support": 9.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.28888888888888886,
                    "macro avg": {
                        "precision": 0.28125,
                        "recall": 0.17712842712842713,
                        "f1-score": 0.21549503128450495,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.43333333333333335,
                        "recall": 0.28888888888888886,
                        "f1-score": 0.34464482885535513,
                        "support": 45.0
                    }
                },
                "environment_2": {
                    "AFTER": {
                        "precision": 0.3333333333333333,
                        "recall": 0.19047619047619047,
                        "f1-score": 0.24242424242424246,
                        "support": 21.0
                    },
                    "BEFORE": {
                        "precision": 0.36363636363636365,
                        "recall": 0.17391304347826086,
                        "f1-score": 0.2352941176470588,
                        "support": 23.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.17777777777777778,
                    "macro avg": {
                        "precision": 0.17424242424242425,
                        "recall": 0.09109730848861283,
                        "f1-score": 0.11942959001782531,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.3414141414141414,
                        "recall": 0.17777777777777778,
                        "f1-score": 0.2333927510398099,
                        "support": 45.0
                    }
                },
                "weather_floods_3": {
                    "AFTER": {
                        "precision": 0.42857142857142855,
                        "recall": 0.75,
                        "f1-score": 0.5454545454545454,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.6666666666666666,
                        "recall": 0.5714285714285714,
                        "f1-score": 0.6153846153846153,
                        "support": 7.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.4666666666666667,
                    "macro avg": {
                        "precision": 0.2738095238095238,
                        "recall": 0.33035714285714285,
                        "f1-score": 0.2902097902097902,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.4253968253968254,
                        "recall": 0.4666666666666667,
                        "f1-score": 0.4326340326340326,
                        "support": 15.0
                    }
                },
                "sports_1": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.5,
                        "f1-score": 0.5,
                        "support": 2.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 3.0
                    },
                    "macro avg": {
                        "precision": 0.125,
                        "recall": 0.125,
                        "f1-score": 0.125,
                        "support": 3.0
                    },
                    "weighted avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 3.0
                    }
                },
                "health_4": {
                    "AFTER": {
                        "precision": 0.4,
                        "recall": 0.4444444444444444,
                        "f1-score": 0.4210526315789474,
                        "support": 9.0
                    },
                    "BEFORE": {
                        "precision": 0.5555555555555556,
                        "recall": 0.625,
                        "f1-score": 0.5882352941176471,
                        "support": 8.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.42857142857142855,
                    "macro avg": {
                        "precision": 0.2388888888888889,
                        "recall": 0.2673611111111111,
                        "f1-score": 0.25232198142414863,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.38306878306878306,
                        "recall": 0.42857142857142855,
                        "f1-score": 0.40454076367389064,
                        "support": 21.0
                    }
                },
                "weather_earthquakes_1": {
                    "AFTER": {
                        "precision": 0.1111111111111111,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.13333333333333333,
                        "support": 6.0
                    },
                    "BEFORE": {
                        "precision": 0.9090909090909091,
                        "recall": 0.3125,
                        "f1-score": 0.4651162790697674,
                        "support": 32.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 7.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.24444444444444444,
                    "macro avg": {
                        "precision": 0.255050505050505,
                        "recall": 0.11979166666666666,
                        "f1-score": 0.14961240310077517,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.6612794612794612,
                        "recall": 0.24444444444444444,
                        "f1-score": 0.3485271317829457,
                        "support": 45.0
                    }
                },
                "space_4": {
                    "AFTER": {
                        "precision": 0.5555555555555556,
                        "recall": 0.45454545454545453,
                        "f1-score": 0.5,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.6,
                        "recall": 0.4,
                        "f1-score": 0.48,
                        "support": 15.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.39285714285714285,
                    "macro avg": {
                        "precision": 0.28888888888888886,
                        "recall": 0.21363636363636362,
                        "f1-score": 0.245,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.5396825396825397,
                        "recall": 0.39285714285714285,
                        "f1-score": 0.45357142857142857,
                        "support": 28.0
                    }
                },
                "economy_and_business_strikes_2": {
                    "AFTER": {
                        "precision": 0.3333333333333333,
                        "recall": 1.0,
                        "f1-score": 0.5,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.5,
                        "f1-score": 0.6666666666666666,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.5,
                        "recall": 0.5,
                        "f1-score": 0.5,
                        "support": 6.0
                    },
                    "macro avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.375,
                        "f1-score": 0.29166666666666663,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.7222222222222222,
                        "recall": 0.5,
                        "f1-score": 0.5277777777777778,
                        "support": 6.0
                    }
                },
                "politics_and_conflicts_armed_conflict_2": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 1.0,
                        "f1-score": 0.6666666666666666,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.2727272727272727,
                        "f1-score": 0.42857142857142855,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.26666666666666666,
                    "macro avg": {
                        "precision": 0.375,
                        "recall": 0.3181818181818182,
                        "f1-score": 0.2738095238095238,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.7666666666666667,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.35873015873015873,
                        "support": 15.0
                    }
                },
                "infectious_disease_4": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.25,
                        "f1-score": 0.25,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    }
                },
                "health_1": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.25,
                        "support": 6.0
                    },
                    "BEFORE": {
                        "precision": 0.6666666666666666,
                        "recall": 0.6666666666666666,
                        "f1-score": 0.6666666666666666,
                        "support": 3.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.3,
                    "macro avg": {
                        "precision": 0.29166666666666663,
                        "recall": 0.20833333333333331,
                        "f1-score": 0.22916666666666666,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.5,
                        "recall": 0.3,
                        "f1-score": 0.35,
                        "support": 10.0
                    }
                },
                "disasters_and_accidents_shipwreck_2": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.45454545454545453,
                        "f1-score": 0.47619047619047616,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 0.2222222222222222,
                        "f1-score": 0.26666666666666666,
                        "support": 9.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.3333333333333333,
                    "macro avg": {
                        "precision": 0.20833333333333331,
                        "recall": 0.16919191919191917,
                        "f1-score": 0.18571428571428572,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.40476190476190477,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.363718820861678,
                        "support": 21.0
                    }
                },
                "rail_transport_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.6,
                        "recall": 0.3,
                        "f1-score": 0.4,
                        "support": 10.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2,
                    "macro avg": {
                        "precision": 0.15,
                        "recall": 0.075,
                        "f1-score": 0.1,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.4,
                        "recall": 0.2,
                        "f1-score": 0.26666666666666666,
                        "support": 15.0
                    }
                },
                "weather_storms_1_extra": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.25,
                        "f1-score": 0.25,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    }
                },
                "health_1_extra": {
                    "AFTER": {
                        "precision": 0.14285714285714285,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.15384615384615383,
                        "support": 12.0
                    },
                    "BEFORE": {
                        "precision": 0.4,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.21052631578947364,
                        "support": 28.0
                    },
                    "COEX": {
                        "precision": 0.4,
                        "recall": 0.13333333333333333,
                        "f1-score": 0.2,
                        "support": 15.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.14545454545454545,
                    "macro avg": {
                        "precision": 0.23571428571428574,
                        "recall": 0.11071428571428571,
                        "f1-score": 0.14109311740890687,
                        "support": 55.0
                    },
                    "weighted avg": {
                        "precision": 0.3438961038961039,
                        "recall": 0.14545454545454545,
                        "f1-score": 0.19528892160471104,
                        "support": 55.0
                    }
                },
                "weather_floods_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.5833333333333334,
                        "recall": 0.2916666666666667,
                        "f1-score": 0.38888888888888895,
                        "support": 24.0
                    },
                    "COEX": {
                        "precision": 0.6,
                        "recall": 0.21428571428571427,
                        "f1-score": 0.3157894736842105,
                        "support": 28.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.23636363636363636,
                    "macro avg": {
                        "precision": 0.29583333333333334,
                        "recall": 0.12648809523809523,
                        "f1-score": 0.17616959064327486,
                        "support": 55.0
                    },
                    "weighted avg": {
                        "precision": 0.56,
                        "recall": 0.23636363636363636,
                        "f1-score": 0.3304625199362042,
                        "support": 55.0
                    }
                },
                "mining_4": {
                    "AFTER": {
                        "precision": 0.25,
                        "recall": 0.18181818181818182,
                        "f1-score": 0.2105263157894737,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.25,
                        "recall": 0.08,
                        "f1-score": 0.12121212121212122,
                        "support": 25.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 9.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.08888888888888889,
                    "macro avg": {
                        "precision": 0.125,
                        "recall": 0.06545454545454546,
                        "f1-score": 0.08293460925039872,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.2,
                        "recall": 0.08888888888888889,
                        "f1-score": 0.11880205564416091,
                        "support": 45.0
                    }
                },
                "disasters_and_accidents_volcanoes_4": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.2,
                        "f1-score": 0.28571428571428575,
                        "support": 20.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 0.2857142857142857,
                        "f1-score": 0.30769230769230765,
                        "support": 14.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2222222222222222,
                    "macro avg": {
                        "precision": 0.20833333333333331,
                        "recall": 0.12142857142857143,
                        "f1-score": 0.14835164835164835,
                        "support": 36.0
                    },
                    "weighted avg": {
                        "precision": 0.4074074074074074,
                        "recall": 0.2222222222222222,
                        "f1-score": 0.2783882783882784,
                        "support": 36.0
                    }
                },
                "politics_and_conflicts_elections_3": {
                    "AFTER": {
                        "precision": 0.3333333333333333,
                        "recall": 0.2,
                        "f1-score": 0.25,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.3,
                        "recall": 0.75,
                        "f1-score": 0.4285714285714285,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.26666666666666666,
                    "macro avg": {
                        "precision": 0.15833333333333333,
                        "recall": 0.2375,
                        "f1-score": 0.16964285714285712,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.1911111111111111,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.1976190476190476,
                        "support": 15.0
                    }
                },
                "economy_and_business_strikes_3": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.4,
                        "f1-score": 0.4444444444444445,
                        "support": 10.0
                    },
                    "BEFORE": {
                        "precision": 0.16666666666666666,
                        "recall": 0.09090909090909091,
                        "f1-score": 0.11764705882352942,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.25,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.18181818181818182,
                        "support": 7.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.21428571428571427,
                    "macro avg": {
                        "precision": 0.22916666666666666,
                        "recall": 0.15844155844155844,
                        "f1-score": 0.18597742127153893,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.306547619047619,
                        "recall": 0.21428571428571427,
                        "f1-score": 0.2504031915796622,
                        "support": 28.0
                    }
                },
                "space_2": {
                    "AFTER": {
                        "precision": 0.6923076923076923,
                        "recall": 0.18,
                        "f1-score": 0.28571428571428575,
                        "support": 100.0
                    },
                    "BEFORE": {
                        "precision": 0.2,
                        "recall": 0.09803921568627451,
                        "f1-score": 0.13157894736842105,
                        "support": 51.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.1503267973856209,
                    "macro avg": {
                        "precision": 0.22307692307692306,
                        "recall": 0.06950980392156862,
                        "f1-score": 0.1043233082706767,
                        "support": 153.0
                    },
                    "weighted avg": {
                        "precision": 0.5191553544494721,
                        "recall": 0.1503267973856209,
                        "f1-score": 0.2306010123347585,
                        "support": 153.0
                    }
                },
                "politics_and_conflicts_resign_1": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.6666666666666666,
                        "f1-score": 0.8,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.6666666666666666,
                        "recall": 0.6666666666666666,
                        "f1-score": 0.6666666666666666,
                        "support": 3.0
                    },
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.2,
                        "support": 3.0
                    },
                    "weighted avg": {
                        "precision": 1.0,
                        "recall": 0.6666666666666666,
                        "f1-score": 0.8000000000000002,
                        "support": 3.0
                    }
                },
                "environment_4": {
                    "AFTER": {
                        "precision": 0.2,
                        "recall": 0.25,
                        "f1-score": 0.22222222222222224,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.25,
                        "recall": 0.2,
                        "f1-score": 0.22222222222222224,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.13333333333333333,
                    "macro avg": {
                        "precision": 0.1125,
                        "recall": 0.1125,
                        "f1-score": 0.11111111111111112,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.13666666666666666,
                        "recall": 0.13333333333333333,
                        "f1-score": 0.13333333333333333,
                        "support": 15.0
                    }
                },
                "space_1_extra": {
                    "AFTER": {
                        "precision": 0.3333333333333333,
                        "recall": 1.0,
                        "f1-score": 0.5,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.4,
                        "f1-score": 0.5714285714285715,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.5,
                        "recall": 0.5,
                        "f1-score": 0.5,
                        "support": 6.0
                    },
                    "macro avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.35,
                        "f1-score": 0.2678571428571429,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.8888888888888888,
                        "recall": 0.5,
                        "f1-score": 0.5595238095238096,
                        "support": 6.0
                    }
                },
                "health_3": {
                    "AFTER": {
                        "precision": 0.6,
                        "recall": 0.375,
                        "f1-score": 0.4615384615384615,
                        "support": 8.0
                    },
                    "BEFORE": {
                        "precision": 0.4,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3636363636363636,
                        "support": 6.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.3333333333333333,
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.17708333333333331,
                        "f1-score": 0.20629370629370627,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.48000000000000004,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.39160839160839156,
                        "support": 15.0
                    }
                },
                "environment_3": {
                    "AFTER": {
                        "precision": 0.8333333333333334,
                        "recall": 0.45454545454545453,
                        "f1-score": 0.5882352941176471,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.4,
                        "recall": 1.0,
                        "f1-score": 0.5714285714285715,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.4666666666666667,
                    "macro avg": {
                        "precision": 0.30833333333333335,
                        "recall": 0.36363636363636365,
                        "f1-score": 0.28991596638655465,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.6644444444444446,
                        "recall": 0.4666666666666667,
                        "f1-score": 0.5075630252100841,
                        "support": 15.0
                    }
                },
                "government_and_politics_protests_3": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.25,
                        "f1-score": 0.3333333333333333,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.16666666666666666,
                    "macro avg": {
                        "precision": 0.125,
                        "recall": 0.0625,
                        "f1-score": 0.08333333333333333,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.2222222222222222,
                        "support": 6.0
                    }
                },
                "economy_and_business_financial_crisis_4": {
                    "AFTER": {
                        "precision": 0.5555555555555556,
                        "recall": 0.4166666666666667,
                        "f1-score": 0.4761904761904762,
                        "support": 12.0
                    },
                    "BEFORE": {
                        "precision": 0.4,
                        "recall": 0.4,
                        "f1-score": 0.4000000000000001,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.3333333333333333,
                    "macro avg": {
                        "precision": 0.2388888888888889,
                        "recall": 0.20416666666666666,
                        "f1-score": 0.21904761904761907,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.41269841269841273,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3673469387755103,
                        "support": 21.0
                    }
                },
                "computers_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    }
                },
                "crime_and_law_accuse_4": {
                    "AFTER": {
                        "precision": 0.75,
                        "recall": 0.6,
                        "f1-score": 0.6666666666666665,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.75,
                        "recall": 0.6,
                        "f1-score": 0.6666666666666665,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.6,
                        "recall": 0.6,
                        "f1-score": 0.6,
                        "support": 10.0
                    },
                    "macro avg": {
                        "precision": 0.375,
                        "recall": 0.3,
                        "f1-score": 0.33333333333333326,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.75,
                        "recall": 0.6,
                        "f1-score": 0.6666666666666665,
                        "support": 10.0
                    }
                },
                "culture_and_entertainment_1": {
                    "AFTER": {
                        "precision": 0.6666666666666666,
                        "recall": 1.0,
                        "f1-score": 0.8,
                        "support": 2.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.5,
                        "f1-score": 0.5,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.5,
                    "macro avg": {
                        "precision": 0.29166666666666663,
                        "recall": 0.375,
                        "f1-score": 0.325,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.38888888888888884,
                        "recall": 0.5,
                        "f1-score": 0.43333333333333335,
                        "support": 6.0
                    }
                },
                "internet_2": {
                    "AFTER": {
                        "precision": 0.6666666666666666,
                        "recall": 0.4,
                        "f1-score": 0.5,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.6,
                        "recall": 0.75,
                        "f1-score": 0.6666666666666665,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.5,
                    "macro avg": {
                        "precision": 0.31666666666666665,
                        "recall": 0.2875,
                        "f1-score": 0.29166666666666663,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.5733333333333333,
                        "recall": 0.5,
                        "f1-score": 0.5166666666666666,
                        "support": 10.0
                    }
                },
                "culture_and_entertainment_3": {
                    "AFTER": {
                        "precision": 0.5714285714285714,
                        "recall": 0.8,
                        "f1-score": 0.6666666666666666,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.5,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.25,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.3333333333333333,
                    "macro avg": {
                        "precision": 0.26785714285714285,
                        "recall": 0.24166666666666667,
                        "f1-score": 0.22916666666666666,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.3904761904761905,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3222222222222222,
                        "support": 15.0
                    }
                }
            },
            "pick": {
                "government_and_politics_riots_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 12.0
                    },
                    "COEX": {
                        "precision": 0.14285714285714285,
                        "recall": 0.08333333333333333,
                        "f1-score": 0.10526315789473685,
                        "support": 12.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.03571428571428571,
                    "macro avg": {
                        "precision": 0.03571428571428571,
                        "recall": 0.020833333333333332,
                        "f1-score": 0.026315789473684213,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.061224489795918366,
                        "recall": 0.03571428571428571,
                        "f1-score": 0.04511278195488722,
                        "support": 28.0
                    }
                },
                "rail_transport_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.08823529411764706,
                        "f1-score": 0.1621621621621622,
                        "support": 34.0
                    },
                    "COEX": {
                        "precision": 0.09523809523809523,
                        "recall": 1.0,
                        "f1-score": 0.17391304347826084,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.1388888888888889,
                    "macro avg": {
                        "precision": 0.27380952380952384,
                        "recall": 0.27205882352941174,
                        "f1-score": 0.08401880141010576,
                        "support": 36.0
                    },
                    "weighted avg": {
                        "precision": 0.9497354497354498,
                        "recall": 0.1388888888888889,
                        "f1-score": 0.16281498890194546,
                        "support": 36.0
                    }
                },
                "politics_and_conflicts_policy_change_2": {
                    "AFTER": {
                        "precision": 0.6666666666666666,
                        "recall": 0.6666666666666666,
                        "f1-score": 0.6666666666666666,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.5,
                        "recall": 1.0,
                        "f1-score": 0.6666666666666666,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.5,
                    "macro avg": {
                        "precision": 0.29166666666666663,
                        "recall": 0.41666666666666663,
                        "f1-score": 0.3333333333333333,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.4166666666666667,
                        "recall": 0.5,
                        "f1-score": 0.4444444444444444,
                        "support": 6.0
                    }
                },
                "politics_and_conflicts_drones_1": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.2727272727272727,
                        "f1-score": 0.3529411764705882,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 8.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.14285714285714285,
                    "macro avg": {
                        "precision": 0.125,
                        "recall": 0.06818181818181818,
                        "f1-score": 0.08823529411764705,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.2619047619047619,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.18487394957983191,
                        "support": 21.0
                    }
                },
                "disasters_and_accidents_road_crash_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 0.09090909090909091,
                        "f1-score": 0.14285714285714288,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.5,
                        "recall": 0.2,
                        "f1-score": 0.28571428571428575,
                        "support": 10.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.14285714285714285,
                    "macro avg": {
                        "precision": 0.20833333333333331,
                        "recall": 0.07272727272727272,
                        "f1-score": 0.10714285714285715,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.4126984126984127,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.2108843537414966,
                        "support": 21.0
                    }
                },
                "crime_and_law_accuse_3": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.25,
                        "f1-score": 0.4,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.1,
                        "recall": 0.1,
                        "f1-score": 0.10000000000000002,
                        "support": 10.0
                    },
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.0625,
                        "f1-score": 0.1,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.4,
                        "recall": 0.1,
                        "f1-score": 0.16,
                        "support": 10.0
                    }
                },
                "government_and_politics_protests_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 20.0
                    },
                    "COEX": {
                        "precision": 0.2,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.25,
                        "support": 3.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.03571428571428571,
                    "macro avg": {
                        "precision": 0.05,
                        "recall": 0.08333333333333333,
                        "f1-score": 0.0625,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.021428571428571432,
                        "recall": 0.03571428571428571,
                        "f1-score": 0.026785714285714284,
                        "support": 28.0
                    }
                },
                "politics_and_conflicts_elections_2": {
                    "AFTER": {
                        "precision": 0.6363636363636364,
                        "recall": 0.3181818181818182,
                        "f1-score": 0.4242424242424242,
                        "support": 22.0
                    },
                    "BEFORE": {
                        "precision": 0.2,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.16666666666666666,
                        "support": 14.0
                    },
                    "COEX": {
                        "precision": 0.2631578947368421,
                        "recall": 0.5555555555555556,
                        "f1-score": 0.35714285714285715,
                        "support": 9.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.3111111111111111,
                    "macro avg": {
                        "precision": 0.2748803827751196,
                        "recall": 0.2541486291486291,
                        "f1-score": 0.237012987012987,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.42596491228070177,
                        "recall": 0.3111111111111111,
                        "f1-score": 0.33068783068783064,
                        "support": 45.0
                    }
                },
                "environment_2": {
                    "AFTER": {
                        "precision": 0.9375,
                        "recall": 0.7142857142857143,
                        "f1-score": 0.8108108108108109,
                        "support": 21.0
                    },
                    "BEFORE": {
                        "precision": 0.8181818181818182,
                        "recall": 0.391304347826087,
                        "f1-score": 0.5294117647058824,
                        "support": 23.0
                    },
                    "COEX": {
                        "precision": 0.08333333333333333,
                        "recall": 1.0,
                        "f1-score": 0.15384615384615385,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.5555555555555556,
                    "macro avg": {
                        "precision": 0.4597537878787879,
                        "recall": 0.5263975155279503,
                        "f1-score": 0.37351718234071174,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.8575336700336701,
                        "recall": 0.5555555555555556,
                        "f1-score": 0.6523854170912995,
                        "support": 45.0
                    }
                },
                "weather_floods_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 7.0
                    },
                    "COEX": {
                        "precision": 0.2222222222222222,
                        "recall": 0.5,
                        "f1-score": 0.30769230769230765,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.13333333333333333,
                    "macro avg": {
                        "precision": 0.05555555555555555,
                        "recall": 0.125,
                        "f1-score": 0.07692307692307691,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.059259259259259255,
                        "recall": 0.13333333333333333,
                        "f1-score": 0.08205128205128204,
                        "support": 15.0
                    }
                },
                "sports_1": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 2.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.6666666666666666,
                        "recall": 0.6666666666666666,
                        "f1-score": 0.6666666666666666,
                        "support": 3.0
                    },
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.25,
                        "f1-score": 0.25,
                        "support": 3.0
                    },
                    "weighted avg": {
                        "precision": 0.6666666666666666,
                        "recall": 0.6666666666666666,
                        "f1-score": 0.6666666666666666,
                        "support": 3.0
                    }
                },
                "health_4": {
                    "AFTER": {
                        "precision": 0.6666666666666666,
                        "recall": 0.2222222222222222,
                        "f1-score": 0.3333333333333333,
                        "support": 9.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 8.0
                    },
                    "COEX": {
                        "precision": 0.2222222222222222,
                        "recall": 0.5,
                        "f1-score": 0.30769230769230765,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.19047619047619047,
                    "macro avg": {
                        "precision": 0.2222222222222222,
                        "recall": 0.18055555555555555,
                        "f1-score": 0.16025641025641024,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.3280423280423281,
                        "recall": 0.19047619047619047,
                        "f1-score": 0.20146520146520147,
                        "support": 21.0
                    }
                },
                "weather_earthquakes_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.125,
                        "f1-score": 0.2222222222222222,
                        "support": 32.0
                    },
                    "COEX": {
                        "precision": 0.11538461538461539,
                        "recall": 0.42857142857142855,
                        "f1-score": 0.18181818181818182,
                        "support": 7.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.15555555555555556,
                    "macro avg": {
                        "precision": 0.27884615384615385,
                        "recall": 0.13839285714285715,
                        "f1-score": 0.10101010101010101,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.729059829059829,
                        "recall": 0.15555555555555556,
                        "f1-score": 0.186307519640853,
                        "support": 45.0
                    }
                },
                "space_4": {
                    "AFTER": {
                        "precision": 0.6,
                        "recall": 0.2727272727272727,
                        "f1-score": 0.37499999999999994,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 15.0
                    },
                    "COEX": {
                        "precision": 0.09090909090909091,
                        "recall": 0.5,
                        "f1-score": 0.15384615384615385,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.14285714285714285,
                    "macro avg": {
                        "precision": 0.17272727272727273,
                        "recall": 0.19318181818181818,
                        "f1-score": 0.13221153846153844,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.24220779220779218,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.15831043956043953,
                        "support": 28.0
                    }
                },
                "economy_and_business_strikes_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.5,
                        "recall": 1.0,
                        "f1-score": 0.6666666666666666,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.16666666666666666,
                    "macro avg": {
                        "precision": 0.125,
                        "recall": 0.25,
                        "f1-score": 0.16666666666666666,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.08333333333333333,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.1111111111111111,
                        "support": 6.0
                    }
                },
                "politics_and_conflicts_armed_conflict_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.0,
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 15.0
                    }
                },
                "infectious_disease_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    }
                },
                "health_1": {
                    "AFTER": {
                        "precision": 0.75,
                        "recall": 0.5,
                        "f1-score": 0.6,
                        "support": 6.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.3,
                    "macro avg": {
                        "precision": 0.1875,
                        "recall": 0.125,
                        "f1-score": 0.15,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.45,
                        "recall": 0.3,
                        "f1-score": 0.36,
                        "support": 10.0
                    }
                },
                "disasters_and_accidents_shipwreck_2": {
                    "AFTER": {
                        "precision": 0.6666666666666666,
                        "recall": 0.18181818181818182,
                        "f1-score": 0.28571428571428575,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 9.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.09523809523809523,
                    "macro avg": {
                        "precision": 0.16666666666666666,
                        "recall": 0.045454545454545456,
                        "f1-score": 0.07142857142857144,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.3492063492063492,
                        "recall": 0.09523809523809523,
                        "f1-score": 0.14965986394557826,
                        "support": 21.0
                    }
                },
                "rail_transport_3": {
                    "AFTER": {
                        "precision": 0.25,
                        "recall": 0.2,
                        "f1-score": 0.22222222222222224,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 10.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.06666666666666667,
                    "macro avg": {
                        "precision": 0.0625,
                        "recall": 0.05,
                        "f1-score": 0.05555555555555556,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.08333333333333333,
                        "recall": 0.06666666666666667,
                        "f1-score": 0.07407407407407408,
                        "support": 15.0
                    }
                },
                "weather_storms_1_extra": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.25,
                        "f1-score": 0.25,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    }
                },
                "health_1_extra": {
                    "AFTER": {
                        "precision": 0.058823529411764705,
                        "recall": 0.08333333333333333,
                        "f1-score": 0.06896551724137931,
                        "support": 12.0
                    },
                    "BEFORE": {
                        "precision": 0.4166666666666667,
                        "recall": 0.17857142857142858,
                        "f1-score": 0.25,
                        "support": 28.0
                    },
                    "COEX": {
                        "precision": 0.2,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.2285714285714286,
                        "support": 15.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.18181818181818182,
                    "macro avg": {
                        "precision": 0.16887254901960785,
                        "recall": 0.13214285714285715,
                        "f1-score": 0.13688423645320197,
                        "support": 55.0
                    },
                    "weighted avg": {
                        "precision": 0.27950089126559713,
                        "recall": 0.18181818181818182,
                        "f1-score": 0.20465741155396328,
                        "support": 55.0
                    }
                },
                "weather_floods_1": {
                    "AFTER": {
                        "precision": 0.125,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.18181818181818182,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.25,
                        "recall": 0.041666666666666664,
                        "f1-score": 0.07142857142857142,
                        "support": 24.0
                    },
                    "COEX": {
                        "precision": 0.5833333333333334,
                        "recall": 0.25,
                        "f1-score": 0.35000000000000003,
                        "support": 28.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.16363636363636364,
                    "macro avg": {
                        "precision": 0.23958333333333334,
                        "recall": 0.15625,
                        "f1-score": 0.15081168831168834,
                        "support": 55.0
                    },
                    "weighted avg": {
                        "precision": 0.4128787878787879,
                        "recall": 0.16363636363636364,
                        "f1-score": 0.21926800472255017,
                        "support": 55.0
                    }
                },
                "mining_4": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.6363636363636364,
                        "f1-score": 0.7777777777777778,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 25.0
                    },
                    "COEX": {
                        "precision": 0.23809523809523808,
                        "recall": 0.5555555555555556,
                        "f1-score": 0.33333333333333326,
                        "support": 9.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.26666666666666666,
                    "macro avg": {
                        "precision": 0.30952380952380953,
                        "recall": 0.297979797979798,
                        "f1-score": 0.2777777777777778,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.292063492063492,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.2567901234567901,
                        "support": 45.0
                    }
                },
                "disasters_and_accidents_volcanoes_4": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.5,
                        "f1-score": 0.6666666666666666,
                        "support": 20.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 14.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2777777777777778,
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.125,
                        "f1-score": 0.16666666666666666,
                        "support": 36.0
                    },
                    "weighted avg": {
                        "precision": 0.5555555555555556,
                        "recall": 0.2777777777777778,
                        "f1-score": 0.37037037037037035,
                        "support": 36.0
                    }
                },
                "politics_and_conflicts_elections_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.6666666666666666,
                        "recall": 0.6666666666666666,
                        "f1-score": 0.6666666666666666,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.26666666666666666,
                    "macro avg": {
                        "precision": 0.16666666666666666,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.16666666666666666,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.26666666666666666,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.26666666666666666,
                        "support": 15.0
                    }
                },
                "economy_and_business_strikes_3": {
                    "AFTER": {
                        "precision": 0.2857142857142857,
                        "recall": 0.2,
                        "f1-score": 0.23529411764705882,
                        "support": 10.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.5,
                        "recall": 0.42857142857142855,
                        "f1-score": 0.4615384615384615,
                        "support": 7.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.17857142857142858,
                    "macro avg": {
                        "precision": 0.19642857142857142,
                        "recall": 0.15714285714285714,
                        "f1-score": 0.17420814479638008,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.2270408163265306,
                        "recall": 0.17857142857142858,
                        "f1-score": 0.19941822882999352,
                        "support": 28.0
                    }
                },
                "space_2": {
                    "AFTER": {
                        "precision": 0.6,
                        "recall": 0.18,
                        "f1-score": 0.2769230769230769,
                        "support": 100.0
                    },
                    "BEFORE": {
                        "precision": 0.2631578947368421,
                        "recall": 0.19607843137254902,
                        "f1-score": 0.2247191011235955,
                        "support": 51.0
                    },
                    "COEX": {
                        "precision": 0.04878048780487805,
                        "recall": 1.0,
                        "f1-score": 0.09302325581395349,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.19607843137254902,
                    "macro avg": {
                        "precision": 0.22798459563543005,
                        "recall": 0.34401960784313723,
                        "f1-score": 0.14866635846515647,
                        "support": 153.0
                    },
                    "weighted avg": {
                        "precision": 0.48051381442606994,
                        "recall": 0.19607843137254902,
                        "f1-score": 0.25711783242639846,
                        "support": 153.0
                    }
                },
                "politics_and_conflicts_resign_1": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.5,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 3.0
                    },
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.08333333333333333,
                        "f1-score": 0.125,
                        "support": 3.0
                    },
                    "weighted avg": {
                        "precision": 1.0,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.5,
                        "support": 3.0
                    }
                },
                "environment_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.25,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.2,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.06666666666666667,
                    "macro avg": {
                        "precision": 0.0625,
                        "recall": 0.041666666666666664,
                        "f1-score": 0.05,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.1,
                        "recall": 0.06666666666666667,
                        "f1-score": 0.08000000000000002,
                        "support": 15.0
                    }
                },
                "space_1_extra": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    }
                },
                "health_3": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.375,
                        "f1-score": 0.5454545454545454,
                        "support": 8.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2,
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.09375,
                        "f1-score": 0.13636363636363635,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.5333333333333333,
                        "recall": 0.2,
                        "f1-score": 0.2909090909090909,
                        "support": 15.0
                    }
                },
                "environment_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.14285714285714285,
                        "recall": 0.5,
                        "f1-score": 0.22222222222222224,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.06666666666666667,
                    "macro avg": {
                        "precision": 0.03571428571428571,
                        "recall": 0.125,
                        "f1-score": 0.05555555555555556,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.019047619047619046,
                        "recall": 0.06666666666666667,
                        "f1-score": 0.02962962962962963,
                        "support": 15.0
                    }
                },
                "government_and_politics_protests_3": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.25,
                        "f1-score": 0.4,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "COEX": {
                        "precision": 0.5,
                        "recall": 1.0,
                        "f1-score": 0.6666666666666666,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.3333333333333333,
                    "macro avg": {
                        "precision": 0.375,
                        "recall": 0.3125,
                        "f1-score": 0.26666666666666666,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.75,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.37777777777777777,
                        "support": 6.0
                    }
                },
                "economy_and_business_financial_crisis_4": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.25,
                        "support": 12.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.14285714285714285,
                        "recall": 0.25,
                        "f1-score": 0.18181818181818182,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.14285714285714285,
                    "macro avg": {
                        "precision": 0.1607142857142857,
                        "recall": 0.10416666666666666,
                        "f1-score": 0.10795454545454546,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.3129251700680272,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.1774891774891775,
                        "support": 21.0
                    }
                },
                "computers_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    }
                },
                "crime_and_law_accuse_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.0,
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 10.0
                    }
                },
                "culture_and_entertainment_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.0,
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    }
                },
                "internet_2": {
                    "AFTER": {
                        "precision": 0.75,
                        "recall": 0.6,
                        "f1-score": 0.6666666666666665,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.3,
                    "macro avg": {
                        "precision": 0.1875,
                        "recall": 0.15,
                        "f1-score": 0.16666666666666663,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.375,
                        "recall": 0.3,
                        "f1-score": 0.33333333333333326,
                        "support": 10.0
                    }
                },
                "culture_and_entertainment_3": {
                    "AFTER": {
                        "precision": 0.3333333333333333,
                        "recall": 0.2,
                        "f1-score": 0.25,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 0.25,
                        "f1-score": 0.28571428571428575,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.3333333333333333,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.2222222222222222,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2,
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.15416666666666667,
                        "f1-score": 0.189484126984127,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.2,
                        "f1-score": 0.24841269841269842,
                        "support": 15.0
                    }
                }
            }
        }
    }
}

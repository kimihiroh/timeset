{
    "args": {
        "batch_size": 4,
        "dataset_name": "ctf-mrc",
        "device": "cuda",
        "dirpath_log": "log",
        "dirpath_model": null,
        "dirpath_output": "output/comparison",
        "dirpath_output_score": "output_score/comparison",
        "filepath_test": "data/preprocessed/ctf-sample/test.json",
        "filepath_dev": "data/preprocessed/ctf-sample/dev.json",
        "inference_type": "few-shot",
        "local_rank": 0,
        "marker": "eid",
        "max_new_tokens": 512,
        "model_id": "t5-3b",
        "num_demonstration": 0,
        "num_gpu": 1,
        "num_cpu": 4,
        "peft_model_path": null,
        "precision_type": "bfloat16",
        "representation": "mention",
        "seed": 7,
        "temperature": 0.0,
        "dirpath_model_cache": "/data/tir/projects/tir6/general/kimihiro/.cache/huggingface/transformers"
    },
    "average": {
        "document-and-pair-wise-scores": {
            "range": {
                "min": 0.2850170602900846,
                "median": 0.3194048358035668,
                "max": 0.4380055373941848
            },
            "individual": {
                "simple": 0.322104608647194,
                "simple_events": 0.4242539796850283,
                "note": 0.2850170602900846,
                "note_events": 0.4380055373941848,
                "qa": 0.3167050629599397,
                "qa_events": 0.3084601229215689,
                "refer": 0.2884378577903568,
                "refer_events": 0.3694696477549182,
                "hint": 0.2877777597408818,
                "pick": 0.3635663752985237
            }
        }
    },
    "individuals": {
        "document-and-pair-wise-scores": {
            "simple": {
                "government_and_politics_riots_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.6666666666666666,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.26666666666666666,
                        "support": 12.0
                    },
                    "COEX": {
                        "precision": 0.2,
                        "recall": 0.08333333333333333,
                        "f1-score": 0.11764705882352941,
                        "support": 12.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.10714285714285714,
                    "macro avg": {
                        "precision": 0.21666666666666667,
                        "recall": 0.0625,
                        "f1-score": 0.09607843137254901,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.37142857142857144,
                        "recall": 0.10714285714285714,
                        "f1-score": 0.16470588235294117,
                        "support": 28.0
                    }
                },
                "rail_transport_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "BEFORE": {
                        "precision": 0.875,
                        "recall": 0.20588235294117646,
                        "f1-score": 0.33333333333333337,
                        "support": 34.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.19444444444444445,
                    "macro avg": {
                        "precision": 0.21875,
                        "recall": 0.051470588235294115,
                        "f1-score": 0.08333333333333334,
                        "support": 36.0
                    },
                    "weighted avg": {
                        "precision": 0.8263888888888888,
                        "recall": 0.19444444444444445,
                        "f1-score": 0.3148148148148148,
                        "support": 36.0
                    }
                },
                "politics_and_conflicts_policy_change_2": {
                    "AFTER": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 0.5,
                        "f1-score": 0.4,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 6.0
                    },
                    "macro avg": {
                        "precision": 0.16666666666666666,
                        "recall": 0.20833333333333331,
                        "f1-score": 0.18333333333333335,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.27777777777777773,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3,
                        "support": 6.0
                    }
                },
                "politics_and_conflicts_drones_1": {
                    "AFTER": {
                        "precision": 0.42857142857142855,
                        "recall": 0.2727272727272727,
                        "f1-score": 0.33333333333333326,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.4,
                        "recall": 0.25,
                        "f1-score": 0.3076923076923077,
                        "support": 8.0
                    },
                    "COEX": {
                        "precision": 0.14285714285714285,
                        "recall": 0.5,
                        "f1-score": 0.22222222222222224,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2857142857142857,
                    "macro avg": {
                        "precision": 0.24285714285714283,
                        "recall": 0.2556818181818182,
                        "f1-score": 0.2158119658119658,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.39047619047619053,
                        "recall": 0.2857142857142857,
                        "f1-score": 0.31298331298331294,
                        "support": 21.0
                    }
                },
                "disasters_and_accidents_road_crash_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.36363636363636365,
                        "f1-score": 0.4210526315789474,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 10.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.19047619047619047,
                    "macro avg": {
                        "precision": 0.125,
                        "recall": 0.09090909090909091,
                        "f1-score": 0.10526315789473685,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.2619047619047619,
                        "recall": 0.19047619047619047,
                        "f1-score": 0.2205513784461153,
                        "support": 21.0
                    }
                },
                "crime_and_law_accuse_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.5,
                        "f1-score": 0.5,
                        "support": 6.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.3,
                    "macro avg": {
                        "precision": 0.125,
                        "recall": 0.125,
                        "f1-score": 0.125,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.3,
                        "recall": 0.3,
                        "f1-score": 0.3,
                        "support": 10.0
                    }
                },
                "government_and_politics_protests_2": {
                    "AFTER": {
                        "precision": 0.3,
                        "recall": 0.6,
                        "f1-score": 0.4,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.6666666666666666,
                        "recall": 0.2,
                        "f1-score": 0.30769230769230765,
                        "support": 20.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.25,
                    "macro avg": {
                        "precision": 0.24166666666666664,
                        "recall": 0.2,
                        "f1-score": 0.1769230769230769,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.5297619047619048,
                        "recall": 0.25,
                        "f1-score": 0.2912087912087912,
                        "support": 28.0
                    }
                },
                "politics_and_conflicts_elections_2": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.18181818181818182,
                        "f1-score": 0.26666666666666666,
                        "support": 22.0
                    },
                    "BEFORE": {
                        "precision": 0.25,
                        "recall": 0.21428571428571427,
                        "f1-score": 0.23076923076923075,
                        "support": 14.0
                    },
                    "COEX": {
                        "precision": 0.125,
                        "recall": 0.1111111111111111,
                        "f1-score": 0.11764705882352941,
                        "support": 9.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.17777777777777778,
                    "macro avg": {
                        "precision": 0.21875,
                        "recall": 0.1268037518037518,
                        "f1-score": 0.15377073906485672,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.3472222222222222,
                        "recall": 0.17777777777777778,
                        "f1-score": 0.22569465392994803,
                        "support": 45.0
                    }
                },
                "environment_2": {
                    "AFTER": {
                        "precision": 0.36363636363636365,
                        "recall": 0.19047619047619047,
                        "f1-score": 0.25,
                        "support": 21.0
                    },
                    "BEFORE": {
                        "precision": 0.38461538461538464,
                        "recall": 0.21739130434782608,
                        "f1-score": 0.27777777777777773,
                        "support": 23.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2,
                    "macro avg": {
                        "precision": 0.18706293706293708,
                        "recall": 0.10196687370600413,
                        "f1-score": 0.13194444444444442,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.3662781662781663,
                        "recall": 0.2,
                        "f1-score": 0.25864197530864197,
                        "support": 45.0
                    }
                },
                "weather_floods_3": {
                    "AFTER": {
                        "precision": 0.3333333333333333,
                        "recall": 0.75,
                        "f1-score": 0.46153846153846156,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.75,
                        "recall": 0.42857142857142855,
                        "f1-score": 0.5454545454545454,
                        "support": 7.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.4,
                    "macro avg": {
                        "precision": 0.2708333333333333,
                        "recall": 0.29464285714285715,
                        "f1-score": 0.2517482517482518,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.4388888888888889,
                        "recall": 0.4,
                        "f1-score": 0.3776223776223776,
                        "support": 15.0
                    }
                },
                "sports_1": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.5,
                        "f1-score": 0.5,
                        "support": 2.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 3.0
                    },
                    "macro avg": {
                        "precision": 0.125,
                        "recall": 0.125,
                        "f1-score": 0.125,
                        "support": 3.0
                    },
                    "weighted avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 3.0
                    }
                },
                "health_4": {
                    "AFTER": {
                        "precision": 0.42857142857142855,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.375,
                        "support": 9.0
                    },
                    "BEFORE": {
                        "precision": 0.75,
                        "recall": 0.375,
                        "f1-score": 0.5,
                        "support": 8.0
                    },
                    "COEX": {
                        "precision": 0.14285714285714285,
                        "recall": 0.25,
                        "f1-score": 0.18181818181818182,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.3333333333333333,
                    "macro avg": {
                        "precision": 0.33035714285714285,
                        "recall": 0.23958333333333331,
                        "f1-score": 0.26420454545454547,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.4965986394557823,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3858225108225108,
                        "support": 21.0
                    }
                },
                "weather_earthquakes_1": {
                    "AFTER": {
                        "precision": 0.15384615384615385,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.21052631578947367,
                        "support": 6.0
                    },
                    "BEFORE": {
                        "precision": 0.9090909090909091,
                        "recall": 0.3125,
                        "f1-score": 0.4651162790697674,
                        "support": 32.0
                    },
                    "COEX": {
                        "precision": 0.3076923076923077,
                        "recall": 0.5714285714285714,
                        "f1-score": 0.4,
                        "support": 7.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.35555555555555557,
                    "macro avg": {
                        "precision": 0.34265734265734266,
                        "recall": 0.30431547619047616,
                        "f1-score": 0.2689106487148103,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.7148407148407148,
                        "recall": 0.35555555555555557,
                        "f1-score": 0.4210417516659867,
                        "support": 45.0
                    }
                },
                "space_4": {
                    "AFTER": {
                        "precision": 0.3333333333333333,
                        "recall": 0.18181818181818182,
                        "f1-score": 0.23529411764705885,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.375,
                        "recall": 0.2,
                        "f1-score": 0.26086956521739135,
                        "support": 15.0
                    },
                    "COEX": {
                        "precision": 0.25,
                        "recall": 1.0,
                        "f1-score": 0.4,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.25,
                    "macro avg": {
                        "precision": 0.23958333333333331,
                        "recall": 0.34545454545454546,
                        "f1-score": 0.22404092071611256,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.34970238095238093,
                        "recall": 0.25,
                        "f1-score": 0.26075995615637565,
                        "support": 28.0
                    }
                },
                "economy_and_business_strikes_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.6666666666666666,
                        "recall": 0.5,
                        "f1-score": 0.5714285714285715,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.3333333333333333,
                    "macro avg": {
                        "precision": 0.16666666666666666,
                        "recall": 0.125,
                        "f1-score": 0.14285714285714288,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.4444444444444444,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.380952380952381,
                        "support": 6.0
                    }
                },
                "politics_and_conflicts_armed_conflict_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.8,
                        "recall": 0.36363636363636365,
                        "f1-score": 0.5000000000000001,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.26666666666666666,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.26666666666666666,
                        "support": 15.0
                    },
                    "macro avg": {
                        "precision": 0.2,
                        "recall": 0.09090909090909091,
                        "f1-score": 0.12500000000000003,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.5866666666666667,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.36666666666666675,
                        "support": 15.0
                    }
                },
                "infectious_disease_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    }
                },
                "health_1": {
                    "AFTER": {
                        "precision": 0.75,
                        "recall": 0.5,
                        "f1-score": 0.6,
                        "support": 6.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.4,
                        "support": 3.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.4,
                    "macro avg": {
                        "precision": 0.3125,
                        "recall": 0.20833333333333331,
                        "f1-score": 0.25,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.6,
                        "recall": 0.4,
                        "f1-score": 0.48,
                        "support": 10.0
                    }
                },
                "disasters_and_accidents_shipwreck_2": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.18181818181818182,
                        "f1-score": 0.26666666666666666,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.5714285714285714,
                        "recall": 0.4444444444444444,
                        "f1-score": 0.5,
                        "support": 9.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2857142857142857,
                    "macro avg": {
                        "precision": 0.26785714285714285,
                        "recall": 0.15656565656565657,
                        "f1-score": 0.19166666666666665,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.5068027210884354,
                        "recall": 0.2857142857142857,
                        "f1-score": 0.353968253968254,
                        "support": 21.0
                    }
                },
                "rail_transport_3": {
                    "AFTER": {
                        "precision": 0.3333333333333333,
                        "recall": 0.2,
                        "f1-score": 0.25,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.2,
                        "f1-score": 0.28571428571428575,
                        "support": 10.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.2,
                        "recall": 0.2,
                        "f1-score": 0.20000000000000004,
                        "support": 15.0
                    },
                    "macro avg": {
                        "precision": 0.20833333333333331,
                        "recall": 0.1,
                        "f1-score": 0.13392857142857145,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.4444444444444444,
                        "recall": 0.2,
                        "f1-score": 0.27380952380952384,
                        "support": 15.0
                    }
                },
                "weather_storms_1_extra": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    }
                },
                "health_1_extra": {
                    "AFTER": {
                        "precision": 0.14285714285714285,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.15384615384615383,
                        "support": 12.0
                    },
                    "BEFORE": {
                        "precision": 0.5833333333333334,
                        "recall": 0.25,
                        "f1-score": 0.35000000000000003,
                        "support": 28.0
                    },
                    "COEX": {
                        "precision": 0.125,
                        "recall": 0.13333333333333333,
                        "f1-score": 0.12903225806451615,
                        "support": 15.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2,
                    "macro avg": {
                        "precision": 0.21279761904761907,
                        "recall": 0.13749999999999998,
                        "f1-score": 0.1582196029776675,
                        "support": 55.0
                    },
                    "weighted avg": {
                        "precision": 0.3622294372294373,
                        "recall": 0.2,
                        "f1-score": 0.2469388675840289,
                        "support": 55.0
                    }
                },
                "weather_floods_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.36363636363636365,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.2285714285714286,
                        "support": 24.0
                    },
                    "COEX": {
                        "precision": 0.4117647058823529,
                        "recall": 0.25,
                        "f1-score": 0.3111111111111111,
                        "support": 28.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2,
                    "macro avg": {
                        "precision": 0.19385026737967914,
                        "recall": 0.10416666666666666,
                        "f1-score": 0.13492063492063494,
                        "support": 55.0
                    },
                    "weighted avg": {
                        "precision": 0.3683033543996111,
                        "recall": 0.2,
                        "f1-score": 0.25812409812409814,
                        "support": 55.0
                    }
                },
                "mining_4": {
                    "AFTER": {
                        "precision": 0.23076923076923078,
                        "recall": 0.2727272727272727,
                        "f1-score": 0.24999999999999994,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.4166666666666667,
                        "recall": 0.2,
                        "f1-score": 0.2702702702702703,
                        "support": 25.0
                    },
                    "COEX": {
                        "precision": 0.2727272727272727,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3,
                        "support": 9.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.24444444444444444,
                    "macro avg": {
                        "precision": 0.23004079254079254,
                        "recall": 0.2015151515151515,
                        "f1-score": 0.20506756756756755,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.34243719243719245,
                        "recall": 0.24444444444444444,
                        "f1-score": 0.2712612612612612,
                        "support": 45.0
                    }
                },
                "disasters_and_accidents_volcanoes_4": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.2,
                        "f1-score": 0.28571428571428575,
                        "support": 20.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.22222222222222224,
                        "support": 14.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.16666666666666666,
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.08571428571428572,
                        "f1-score": 0.126984126984127,
                        "support": 36.0
                    },
                    "weighted avg": {
                        "precision": 0.4722222222222222,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.2451499118165785,
                        "support": 36.0
                    }
                },
                "politics_and_conflicts_elections_3": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.2,
                        "f1-score": 0.28571428571428575,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.2857142857142857,
                        "recall": 0.5,
                        "f1-score": 0.36363636363636365,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2,
                    "macro avg": {
                        "precision": 0.19642857142857142,
                        "recall": 0.175,
                        "f1-score": 0.16233766233766234,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.24285714285714285,
                        "recall": 0.2,
                        "f1-score": 0.19220779220779222,
                        "support": 15.0
                    }
                },
                "economy_and_business_strikes_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 10.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.45454545454545453,
                        "f1-score": 0.47619047619047616,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.3333333333333333,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.2,
                        "support": 7.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.21428571428571427,
                    "macro avg": {
                        "precision": 0.20833333333333331,
                        "recall": 0.14935064935064934,
                        "f1-score": 0.16904761904761906,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.27976190476190477,
                        "recall": 0.21428571428571427,
                        "f1-score": 0.2370748299319728,
                        "support": 28.0
                    }
                },
                "space_2": {
                    "AFTER": {
                        "precision": 0.7692307692307693,
                        "recall": 0.2,
                        "f1-score": 0.31746031746031744,
                        "support": 100.0
                    },
                    "BEFORE": {
                        "precision": 0.3448275862068966,
                        "recall": 0.19607843137254902,
                        "f1-score": 0.25,
                        "support": 51.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.19607843137254902,
                    "macro avg": {
                        "precision": 0.2785145888594165,
                        "recall": 0.09901960784313726,
                        "f1-score": 0.14186507936507936,
                        "support": 153.0
                    },
                    "weighted avg": {
                        "precision": 0.6177077373831938,
                        "recall": 0.19607843137254902,
                        "f1-score": 0.2908237369021683,
                        "support": 153.0
                    }
                },
                "politics_and_conflicts_resign_1": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.5,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 3.0
                    },
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.08333333333333333,
                        "f1-score": 0.125,
                        "support": 3.0
                    },
                    "weighted avg": {
                        "precision": 1.0,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.5,
                        "support": 3.0
                    }
                },
                "environment_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.25,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.2,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.06666666666666667,
                    "macro avg": {
                        "precision": 0.0625,
                        "recall": 0.041666666666666664,
                        "f1-score": 0.05,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.1,
                        "recall": 0.06666666666666667,
                        "f1-score": 0.08000000000000002,
                        "support": 15.0
                    }
                },
                "space_1_extra": {
                    "AFTER": {
                        "precision": 0.3333333333333333,
                        "recall": 1.0,
                        "f1-score": 0.5,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.4,
                        "f1-score": 0.5714285714285715,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.5,
                        "recall": 0.5,
                        "f1-score": 0.5,
                        "support": 6.0
                    },
                    "macro avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.35,
                        "f1-score": 0.2678571428571429,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.8888888888888888,
                        "recall": 0.5,
                        "f1-score": 0.5595238095238096,
                        "support": 6.0
                    }
                },
                "health_3": {
                    "AFTER": {
                        "precision": 0.6,
                        "recall": 0.375,
                        "f1-score": 0.4615384615384615,
                        "support": 8.0
                    },
                    "BEFORE": {
                        "precision": 0.6666666666666666,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.4444444444444444,
                        "support": 6.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 15.0
                    },
                    "macro avg": {
                        "precision": 0.31666666666666665,
                        "recall": 0.17708333333333331,
                        "f1-score": 0.22649572649572647,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.5866666666666667,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.4239316239316239,
                        "support": 15.0
                    }
                },
                "environment_3": {
                    "AFTER": {
                        "precision": 0.6666666666666666,
                        "recall": 0.36363636363636365,
                        "f1-score": 0.4705882352941177,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 0.5,
                        "f1-score": 0.4,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.25,
                        "recall": 0.5,
                        "f1-score": 0.3333333333333333,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.4,
                    "macro avg": {
                        "precision": 0.3125,
                        "recall": 0.34090909090909094,
                        "f1-score": 0.30098039215686273,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.5666666666666667,
                        "recall": 0.4,
                        "f1-score": 0.44287581699346407,
                        "support": 15.0
                    }
                },
                "government_and_politics_protests_3": {
                    "AFTER": {
                        "precision": 0.75,
                        "recall": 0.75,
                        "f1-score": 0.75,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.5,
                        "recall": 0.5,
                        "f1-score": 0.5,
                        "support": 6.0
                    },
                    "macro avg": {
                        "precision": 0.1875,
                        "recall": 0.1875,
                        "f1-score": 0.1875,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.5,
                        "recall": 0.5,
                        "f1-score": 0.5,
                        "support": 6.0
                    }
                },
                "economy_and_business_financial_crisis_4": {
                    "AFTER": {
                        "precision": 0.6,
                        "recall": 0.25,
                        "f1-score": 0.35294117647058826,
                        "support": 12.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 0.6,
                        "f1-score": 0.42857142857142855,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.5,
                        "recall": 0.25,
                        "f1-score": 0.3333333333333333,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.3333333333333333,
                    "macro avg": {
                        "precision": 0.35833333333333334,
                        "recall": 0.275,
                        "f1-score": 0.27871148459383754,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.5174603174603174,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.36721355208750167,
                        "support": 21.0
                    }
                },
                "computers_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    }
                },
                "crime_and_law_accuse_4": {
                    "AFTER": {
                        "precision": 0.75,
                        "recall": 0.6,
                        "f1-score": 0.6666666666666665,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.6,
                        "f1-score": 0.7499999999999999,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.6,
                        "recall": 0.6,
                        "f1-score": 0.6,
                        "support": 10.0
                    },
                    "macro avg": {
                        "precision": 0.4375,
                        "recall": 0.3,
                        "f1-score": 0.35416666666666663,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.875,
                        "recall": 0.6,
                        "f1-score": 0.7083333333333333,
                        "support": 10.0
                    }
                },
                "culture_and_entertainment_1": {
                    "AFTER": {
                        "precision": 0.3333333333333333,
                        "recall": 0.5,
                        "f1-score": 0.4,
                        "support": 2.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.5,
                        "f1-score": 0.5,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 1.0,
                        "recall": 0.5,
                        "f1-score": 0.6666666666666666,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.5,
                        "recall": 0.5,
                        "f1-score": 0.5,
                        "support": 6.0
                    },
                    "macro avg": {
                        "precision": 0.4583333333333333,
                        "recall": 0.375,
                        "f1-score": 0.39166666666666666,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.611111111111111,
                        "recall": 0.5,
                        "f1-score": 0.5222222222222223,
                        "support": 6.0
                    }
                },
                "internet_2": {
                    "AFTER": {
                        "precision": 0.6666666666666666,
                        "recall": 0.4,
                        "f1-score": 0.5,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.4,
                        "recall": 0.5,
                        "f1-score": 0.4444444444444445,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.5,
                        "recall": 1.0,
                        "f1-score": 0.6666666666666666,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.5,
                        "recall": 0.5,
                        "f1-score": 0.5,
                        "support": 10.0
                    },
                    "macro avg": {
                        "precision": 0.39166666666666666,
                        "recall": 0.475,
                        "f1-score": 0.4027777777777778,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.5433333333333333,
                        "recall": 0.5,
                        "f1-score": 0.49444444444444446,
                        "support": 10.0
                    }
                },
                "culture_and_entertainment_3": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.4,
                        "f1-score": 0.4444444444444445,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.16666666666666666,
                        "recall": 0.25,
                        "f1-score": 0.2,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 1.0,
                        "recall": 0.6666666666666666,
                        "f1-score": 0.8,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.4666666666666667,
                    "macro avg": {
                        "precision": 0.41666666666666663,
                        "recall": 0.32916666666666666,
                        "f1-score": 0.36111111111111116,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.611111111111111,
                        "recall": 0.4666666666666667,
                        "f1-score": 0.5214814814814815,
                        "support": 15.0
                    }
                }
            },
            "simple_events": {
                "government_and_politics_riots_4": {
                    "AFTER": {
                        "precision": 0.3,
                        "recall": 0.75,
                        "f1-score": 0.4285714285714285,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.375,
                        "recall": 0.25,
                        "f1-score": 0.3,
                        "support": 12.0
                    },
                    "COEX": {
                        "precision": 0.6,
                        "recall": 0.5,
                        "f1-score": 0.5454545454545454,
                        "support": 12.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.42857142857142855,
                        "recall": 0.42857142857142855,
                        "f1-score": 0.42857142857142855,
                        "support": 28.0
                    },
                    "macro avg": {
                        "precision": 0.31875,
                        "recall": 0.375,
                        "f1-score": 0.31850649350649346,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.4607142857142857,
                        "recall": 0.42857142857142855,
                        "f1-score": 0.42356215213358067,
                        "support": 28.0
                    }
                },
                "rail_transport_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "BEFORE": {
                        "precision": 0.7777777777777778,
                        "recall": 0.20588235294117646,
                        "f1-score": 0.3255813953488372,
                        "support": 34.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.19444444444444445,
                    "macro avg": {
                        "precision": 0.19444444444444445,
                        "recall": 0.051470588235294115,
                        "f1-score": 0.0813953488372093,
                        "support": 36.0
                    },
                    "weighted avg": {
                        "precision": 0.7345679012345679,
                        "recall": 0.19444444444444445,
                        "f1-score": 0.30749354005167956,
                        "support": 36.0
                    }
                },
                "politics_and_conflicts_policy_change_2": {
                    "AFTER": {
                        "precision": 0.6666666666666666,
                        "recall": 0.6666666666666666,
                        "f1-score": 0.6666666666666666,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.5,
                        "recall": 1.0,
                        "f1-score": 0.6666666666666666,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.5,
                        "recall": 0.5,
                        "f1-score": 0.5,
                        "support": 6.0
                    },
                    "macro avg": {
                        "precision": 0.29166666666666663,
                        "recall": 0.41666666666666663,
                        "f1-score": 0.3333333333333333,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.4166666666666667,
                        "recall": 0.5,
                        "f1-score": 0.4444444444444444,
                        "support": 6.0
                    }
                },
                "politics_and_conflicts_drones_1": {
                    "AFTER": {
                        "precision": 0.16666666666666666,
                        "recall": 0.09090909090909091,
                        "f1-score": 0.11764705882352942,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.4,
                        "recall": 0.5,
                        "f1-score": 0.4444444444444445,
                        "support": 8.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.23809523809523808,
                        "recall": 0.23809523809523808,
                        "f1-score": 0.23809523809523808,
                        "support": 21.0
                    },
                    "macro avg": {
                        "precision": 0.14166666666666666,
                        "recall": 0.14772727272727273,
                        "f1-score": 0.14052287581699346,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.23968253968253966,
                        "recall": 0.23809523809523808,
                        "f1-score": 0.2309368191721133,
                        "support": 21.0
                    }
                },
                "disasters_and_accidents_road_crash_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "BEFORE": {
                        "precision": 0.7142857142857143,
                        "recall": 0.45454545454545453,
                        "f1-score": 0.5555555555555556,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 1.0,
                        "recall": 0.1,
                        "f1-score": 0.18181818181818182,
                        "support": 10.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2857142857142857,
                    "macro avg": {
                        "precision": 0.4285714285714286,
                        "recall": 0.13863636363636364,
                        "f1-score": 0.18434343434343436,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.8503401360544218,
                        "recall": 0.2857142857142857,
                        "f1-score": 0.37758537758537764,
                        "support": 21.0
                    }
                },
                "crime_and_law_accuse_3": {
                    "AFTER": {
                        "precision": 0.3333333333333333,
                        "recall": 0.5,
                        "f1-score": 0.4,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.4,
                        "support": 6.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.4,
                        "recall": 0.4,
                        "f1-score": 0.4000000000000001,
                        "support": 10.0
                    },
                    "macro avg": {
                        "precision": 0.20833333333333331,
                        "recall": 0.20833333333333331,
                        "f1-score": 0.2,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.4333333333333333,
                        "recall": 0.4,
                        "f1-score": 0.4,
                        "support": 10.0
                    }
                },
                "government_and_politics_protests_2": {
                    "AFTER": {
                        "precision": 0.375,
                        "recall": 0.6,
                        "f1-score": 0.4615384615384615,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.75,
                        "recall": 0.45,
                        "f1-score": 0.5625000000000001,
                        "support": 20.0
                    },
                    "COEX": {
                        "precision": 0.25,
                        "recall": 0.6666666666666666,
                        "f1-score": 0.36363636363636365,
                        "support": 3.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.5,
                        "recall": 0.5,
                        "f1-score": 0.5,
                        "support": 28.0
                    },
                    "macro avg": {
                        "precision": 0.34375,
                        "recall": 0.4291666666666667,
                        "f1-score": 0.34691870629370636,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.6294642857142857,
                        "recall": 0.5,
                        "f1-score": 0.5231643356643357,
                        "support": 28.0
                    }
                },
                "politics_and_conflicts_elections_2": {
                    "AFTER": {
                        "precision": 0.4375,
                        "recall": 0.3181818181818182,
                        "f1-score": 0.3684210526315789,
                        "support": 22.0
                    },
                    "BEFORE": {
                        "precision": 0.1875,
                        "recall": 0.21428571428571427,
                        "f1-score": 0.19999999999999998,
                        "support": 14.0
                    },
                    "COEX": {
                        "precision": 0.15384615384615385,
                        "recall": 0.2222222222222222,
                        "f1-score": 0.18181818181818185,
                        "support": 9.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.26666666666666666,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.26666666666666666,
                        "support": 45.0
                    },
                    "macro avg": {
                        "precision": 0.19471153846153846,
                        "recall": 0.18867243867243866,
                        "f1-score": 0.1875598086124402,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.302991452991453,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.27870281765018606,
                        "support": 45.0
                    }
                },
                "environment_2": {
                    "AFTER": {
                        "precision": 0.3333333333333333,
                        "recall": 0.23809523809523808,
                        "f1-score": 0.2777777777777778,
                        "support": 21.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 0.17391304347826086,
                        "f1-score": 0.22857142857142854,
                        "support": 23.0
                    },
                    "COEX": {
                        "precision": 0.058823529411764705,
                        "recall": 1.0,
                        "f1-score": 0.1111111111111111,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2222222222222222,
                    "macro avg": {
                        "precision": 0.18137254901960784,
                        "recall": 0.3530020703933747,
                        "f1-score": 0.15436507936507937,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.32723311546840955,
                        "recall": 0.2222222222222222,
                        "f1-score": 0.24892416225749558,
                        "support": 45.0
                    }
                },
                "weather_floods_3": {
                    "AFTER": {
                        "precision": 0.25,
                        "recall": 0.5,
                        "f1-score": 0.3333333333333333,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.6,
                        "recall": 0.42857142857142855,
                        "f1-score": 0.5,
                        "support": 7.0
                    },
                    "COEX": {
                        "precision": 0.5,
                        "recall": 0.25,
                        "f1-score": 0.3333333333333333,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.4,
                        "recall": 0.4,
                        "f1-score": 0.4000000000000001,
                        "support": 15.0
                    },
                    "macro avg": {
                        "precision": 0.3375,
                        "recall": 0.29464285714285715,
                        "f1-score": 0.29166666666666663,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.48000000000000004,
                        "recall": 0.4,
                        "f1-score": 0.4111111111111111,
                        "support": 15.0
                    }
                },
                "sports_1": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.5,
                        "f1-score": 0.6666666666666666,
                        "support": 2.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 1.0,
                        "f1-score": 0.6666666666666666,
                        "support": 1.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.6666666666666666,
                        "recall": 0.6666666666666666,
                        "f1-score": 0.6666666666666666,
                        "support": 3.0
                    },
                    "macro avg": {
                        "precision": 0.375,
                        "recall": 0.375,
                        "f1-score": 0.3333333333333333,
                        "support": 3.0
                    },
                    "weighted avg": {
                        "precision": 0.8333333333333334,
                        "recall": 0.6666666666666666,
                        "f1-score": 0.6666666666666666,
                        "support": 3.0
                    }
                },
                "health_4": {
                    "AFTER": {
                        "precision": 0.4166666666666667,
                        "recall": 0.5555555555555556,
                        "f1-score": 0.4761904761904762,
                        "support": 9.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 0.25,
                        "f1-score": 0.28571428571428575,
                        "support": 8.0
                    },
                    "COEX": {
                        "precision": 0.5,
                        "recall": 0.25,
                        "f1-score": 0.3333333333333333,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.38095238095238093,
                    "macro avg": {
                        "precision": 0.3125,
                        "recall": 0.2638888888888889,
                        "f1-score": 0.27380952380952384,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.40079365079365076,
                        "recall": 0.38095238095238093,
                        "f1-score": 0.37641723356009066,
                        "support": 21.0
                    }
                },
                "weather_earthquakes_1": {
                    "AFTER": {
                        "precision": 0.15,
                        "recall": 0.5,
                        "f1-score": 0.23076923076923075,
                        "support": 6.0
                    },
                    "BEFORE": {
                        "precision": 0.7368421052631579,
                        "recall": 0.4375,
                        "f1-score": 0.5490196078431372,
                        "support": 32.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 7.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.37777777777777777,
                    "macro avg": {
                        "precision": 0.22171052631578947,
                        "recall": 0.234375,
                        "f1-score": 0.19494720965309198,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.5439766081871344,
                        "recall": 0.37777777777777777,
                        "f1-score": 0.4211831741243505,
                        "support": 45.0
                    }
                },
                "space_4": {
                    "AFTER": {
                        "precision": 0.4,
                        "recall": 0.18181818181818182,
                        "f1-score": 0.25000000000000006,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 15.0
                    },
                    "COEX": {
                        "precision": 0.16666666666666666,
                        "recall": 1.0,
                        "f1-score": 0.2857142857142857,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.14285714285714285,
                    "macro avg": {
                        "precision": 0.14166666666666666,
                        "recall": 0.29545454545454547,
                        "f1-score": 0.13392857142857145,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.16904761904761906,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.11862244897959186,
                        "support": 28.0
                    }
                },
                "economy_and_business_strikes_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.25,
                        "f1-score": 0.3333333333333333,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.16666666666666666,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.16666666666666666,
                        "support": 6.0
                    },
                    "macro avg": {
                        "precision": 0.125,
                        "recall": 0.0625,
                        "f1-score": 0.08333333333333333,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.2222222222222222,
                        "support": 6.0
                    }
                },
                "politics_and_conflicts_armed_conflict_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.7777777777777778,
                        "recall": 0.6363636363636364,
                        "f1-score": 0.7000000000000001,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.4666666666666667,
                        "recall": 0.4666666666666667,
                        "f1-score": 0.4666666666666667,
                        "support": 15.0
                    },
                    "macro avg": {
                        "precision": 0.19444444444444445,
                        "recall": 0.1590909090909091,
                        "f1-score": 0.17500000000000002,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.5703703703703703,
                        "recall": 0.4666666666666667,
                        "f1-score": 0.5133333333333334,
                        "support": 15.0
                    }
                },
                "infectious_disease_4": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.25,
                        "f1-score": 0.25,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    }
                },
                "health_1": {
                    "AFTER": {
                        "precision": 0.3333333333333333,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.2222222222222222,
                        "support": 6.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.6666666666666666,
                        "f1-score": 0.5714285714285715,
                        "support": 3.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.3,
                        "recall": 0.3,
                        "f1-score": 0.3,
                        "support": 10.0
                    },
                    "macro avg": {
                        "precision": 0.20833333333333331,
                        "recall": 0.20833333333333331,
                        "f1-score": 0.19841269841269843,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.35,
                        "recall": 0.3,
                        "f1-score": 0.30476190476190473,
                        "support": 10.0
                    }
                },
                "disasters_and_accidents_shipwreck_2": {
                    "AFTER": {
                        "precision": 0.25,
                        "recall": 0.18181818181818182,
                        "f1-score": 0.2105263157894737,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.2727272727272727,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3,
                        "support": 9.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.23809523809523808,
                        "recall": 0.23809523809523808,
                        "f1-score": 0.23809523809523808,
                        "support": 21.0
                    },
                    "macro avg": {
                        "precision": 0.13068181818181818,
                        "recall": 0.12878787878787878,
                        "f1-score": 0.12763157894736843,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.24783549783549783,
                        "recall": 0.23809523809523808,
                        "f1-score": 0.2388471177944862,
                        "support": 21.0
                    }
                },
                "rail_transport_3": {
                    "AFTER": {
                        "precision": 0.25,
                        "recall": 0.6,
                        "f1-score": 0.35294117647058826,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 0.1,
                        "f1-score": 0.15384615384615383,
                        "support": 10.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.26666666666666666,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.26666666666666666,
                        "support": 15.0
                    },
                    "macro avg": {
                        "precision": 0.14583333333333331,
                        "recall": 0.175,
                        "f1-score": 0.12669683257918551,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.3055555555555555,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.22021116138763197,
                        "support": 15.0
                    }
                },
                "weather_storms_1_extra": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.25,
                        "f1-score": 0.25,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    }
                },
                "health_1_extra": {
                    "AFTER": {
                        "precision": 0.34615384615384615,
                        "recall": 0.75,
                        "f1-score": 0.4736842105263157,
                        "support": 12.0
                    },
                    "BEFORE": {
                        "precision": 0.631578947368421,
                        "recall": 0.42857142857142855,
                        "f1-score": 0.5106382978723404,
                        "support": 28.0
                    },
                    "COEX": {
                        "precision": 0.5714285714285714,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.36363636363636365,
                        "support": 15.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.45454545454545453,
                    "macro avg": {
                        "precision": 0.38729034123770967,
                        "recall": 0.3613095238095238,
                        "f1-score": 0.33698971800875493,
                        "support": 55.0
                    },
                    "weighted avg": {
                        "precision": 0.5528997318471002,
                        "recall": 0.45454545454545453,
                        "f1-score": 0.4624841512961232,
                        "support": 55.0
                    }
                },
                "weather_floods_1": {
                    "AFTER": {
                        "precision": 0.043478260869565216,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.07692307692307691,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.5454545454545454,
                        "recall": 0.5,
                        "f1-score": 0.5217391304347826,
                        "support": 24.0
                    },
                    "COEX": {
                        "precision": 0.8333333333333334,
                        "recall": 0.17857142857142858,
                        "f1-score": 0.29411764705882354,
                        "support": 28.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.32727272727272727,
                    "macro avg": {
                        "precision": 0.35556653491436097,
                        "recall": 0.25297619047619047,
                        "f1-score": 0.22319496360417074,
                        "support": 55.0
                    },
                    "weighted avg": {
                        "precision": 0.6646304946700204,
                        "recall": 0.32727272727272727,
                        "f1-score": 0.3815964087063831,
                        "support": 55.0
                    }
                },
                "mining_4": {
                    "AFTER": {
                        "precision": 0.42857142857142855,
                        "recall": 0.2727272727272727,
                        "f1-score": 0.33333333333333326,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.5454545454545454,
                        "recall": 0.24,
                        "f1-score": 0.3333333333333333,
                        "support": 25.0
                    },
                    "COEX": {
                        "precision": 0.2857142857142857,
                        "recall": 0.6666666666666666,
                        "f1-score": 0.4,
                        "support": 9.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.3333333333333333,
                    "macro avg": {
                        "precision": 0.31493506493506496,
                        "recall": 0.2948484848484848,
                        "f1-score": 0.2666666666666666,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.46493506493506487,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3466666666666666,
                        "support": 45.0
                    }
                },
                "disasters_and_accidents_volcanoes_4": {
                    "AFTER": {
                        "precision": 0.5882352941176471,
                        "recall": 0.5,
                        "f1-score": 0.5405405405405405,
                        "support": 20.0
                    },
                    "BEFORE": {
                        "precision": 0.4,
                        "recall": 0.2857142857142857,
                        "f1-score": 0.3333333333333333,
                        "support": 14.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.3888888888888889,
                    "macro avg": {
                        "precision": 0.24705882352941178,
                        "recall": 0.19642857142857142,
                        "f1-score": 0.21846846846846846,
                        "support": 36.0
                    },
                    "weighted avg": {
                        "precision": 0.48235294117647065,
                        "recall": 0.3888888888888889,
                        "f1-score": 0.42992992992992984,
                        "support": 36.0
                    }
                },
                "politics_and_conflicts_elections_3": {
                    "AFTER": {
                        "precision": 0.375,
                        "recall": 0.6,
                        "f1-score": 0.4615384615384615,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.2,
                        "recall": 0.2,
                        "f1-score": 0.20000000000000004,
                        "support": 15.0
                    },
                    "macro avg": {
                        "precision": 0.09375,
                        "recall": 0.15,
                        "f1-score": 0.11538461538461538,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.125,
                        "recall": 0.2,
                        "f1-score": 0.15384615384615383,
                        "support": 15.0
                    }
                },
                "economy_and_business_strikes_3": {
                    "AFTER": {
                        "precision": 0.36363636363636365,
                        "recall": 0.4,
                        "f1-score": 0.380952380952381,
                        "support": 10.0
                    },
                    "BEFORE": {
                        "precision": 0.2727272727272727,
                        "recall": 0.2727272727272727,
                        "f1-score": 0.2727272727272727,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 7.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.25,
                        "recall": 0.25,
                        "f1-score": 0.25,
                        "support": 28.0
                    },
                    "macro avg": {
                        "precision": 0.1590909090909091,
                        "recall": 0.16818181818181818,
                        "f1-score": 0.1634199134199134,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.23701298701298704,
                        "recall": 0.25,
                        "f1-score": 0.24319727891156465,
                        "support": 28.0
                    }
                },
                "space_2": {
                    "AFTER": {
                        "precision": 0.64,
                        "recall": 0.16,
                        "f1-score": 0.256,
                        "support": 100.0
                    },
                    "BEFORE": {
                        "precision": 0.3235294117647059,
                        "recall": 0.21568627450980393,
                        "f1-score": 0.2588235294117647,
                        "support": 51.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.17647058823529413,
                    "macro avg": {
                        "precision": 0.2408823529411765,
                        "recall": 0.09392156862745099,
                        "f1-score": 0.12870588235294117,
                        "support": 153.0
                    },
                    "weighted avg": {
                        "precision": 0.5261437908496732,
                        "recall": 0.17647058823529413,
                        "f1-score": 0.25359477124183005,
                        "support": 153.0
                    }
                },
                "politics_and_conflicts_resign_1": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.6666666666666666,
                        "f1-score": 0.8,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.6666666666666666,
                        "recall": 0.6666666666666666,
                        "f1-score": 0.6666666666666666,
                        "support": 3.0
                    },
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.2,
                        "support": 3.0
                    },
                    "weighted avg": {
                        "precision": 1.0,
                        "recall": 0.6666666666666666,
                        "f1-score": 0.8000000000000002,
                        "support": 3.0
                    }
                },
                "environment_4": {
                    "AFTER": {
                        "precision": 0.4,
                        "recall": 0.5,
                        "f1-score": 0.4444444444444445,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.8,
                        "recall": 0.8,
                        "f1-score": 0.8000000000000002,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.4,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3636363636363636,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.5333333333333333,
                        "recall": 0.5333333333333333,
                        "f1-score": 0.5333333333333333,
                        "support": 15.0
                    },
                    "macro avg": {
                        "precision": 0.4,
                        "recall": 0.4083333333333333,
                        "f1-score": 0.40202020202020206,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.5333333333333333,
                        "recall": 0.5333333333333333,
                        "f1-score": 0.5306397306397307,
                        "support": 15.0
                    }
                },
                "space_1_extra": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.2,
                        "f1-score": 0.33333333333333337,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.16666666666666666,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.16666666666666666,
                        "support": 6.0
                    },
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.05,
                        "f1-score": 0.08333333333333334,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.8333333333333334,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.27777777777777785,
                        "support": 6.0
                    }
                },
                "health_3": {
                    "AFTER": {
                        "precision": 0.7142857142857143,
                        "recall": 0.625,
                        "f1-score": 0.6666666666666666,
                        "support": 8.0
                    },
                    "BEFORE": {
                        "precision": 0.8333333333333334,
                        "recall": 0.8333333333333334,
                        "f1-score": 0.8333333333333334,
                        "support": 6.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.6666666666666666,
                        "recall": 0.6666666666666666,
                        "f1-score": 0.6666666666666666,
                        "support": 15.0
                    },
                    "macro avg": {
                        "precision": 0.3869047619047619,
                        "recall": 0.36458333333333337,
                        "f1-score": 0.375,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.7142857142857143,
                        "recall": 0.6666666666666666,
                        "f1-score": 0.6888888888888888,
                        "support": 15.0
                    }
                },
                "environment_3": {
                    "AFTER": {
                        "precision": 0.6666666666666666,
                        "recall": 0.36363636363636365,
                        "f1-score": 0.4705882352941177,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.14285714285714285,
                        "recall": 0.5,
                        "f1-score": 0.22222222222222224,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 15.0
                    },
                    "macro avg": {
                        "precision": 0.20238095238095238,
                        "recall": 0.2159090909090909,
                        "f1-score": 0.173202614379085,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.5079365079365079,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.37472766884531594,
                        "support": 15.0
                    }
                },
                "government_and_politics_protests_3": {
                    "AFTER": {
                        "precision": 0.6666666666666666,
                        "recall": 0.5,
                        "f1-score": 0.5714285714285715,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 1.0,
                        "f1-score": 0.6666666666666666,
                        "support": 1.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.5,
                        "recall": 0.5,
                        "f1-score": 0.5,
                        "support": 6.0
                    },
                    "macro avg": {
                        "precision": 0.29166666666666663,
                        "recall": 0.375,
                        "f1-score": 0.30952380952380953,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.5277777777777778,
                        "recall": 0.5,
                        "f1-score": 0.4920634920634921,
                        "support": 6.0
                    }
                },
                "economy_and_business_financial_crisis_4": {
                    "AFTER": {
                        "precision": 0.6363636363636364,
                        "recall": 0.5833333333333334,
                        "f1-score": 0.6086956521739131,
                        "support": 12.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.3333333333333333,
                    "macro avg": {
                        "precision": 0.1590909090909091,
                        "recall": 0.14583333333333334,
                        "f1-score": 0.15217391304347827,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.36363636363636365,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3478260869565218,
                        "support": 21.0
                    }
                },
                "computers_2": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.25,
                        "f1-score": 0.25,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    }
                },
                "crime_and_law_accuse_4": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.4,
                        "f1-score": 0.4444444444444445,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.4,
                        "recall": 0.4,
                        "f1-score": 0.4000000000000001,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.4,
                        "recall": 0.4,
                        "f1-score": 0.4000000000000001,
                        "support": 10.0
                    },
                    "macro avg": {
                        "precision": 0.225,
                        "recall": 0.2,
                        "f1-score": 0.21111111111111114,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.45,
                        "recall": 0.4,
                        "f1-score": 0.42222222222222233,
                        "support": 10.0
                    }
                },
                "culture_and_entertainment_1": {
                    "AFTER": {
                        "precision": 0.3333333333333333,
                        "recall": 0.5,
                        "f1-score": 0.4,
                        "support": 2.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.5,
                        "recall": 0.5,
                        "f1-score": 0.5,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 6.0
                    },
                    "macro avg": {
                        "precision": 0.20833333333333331,
                        "recall": 0.25,
                        "f1-score": 0.225,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.27777777777777773,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3,
                        "support": 6.0
                    }
                },
                "internet_2": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.4,
                        "f1-score": 0.4444444444444445,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.6,
                        "recall": 0.75,
                        "f1-score": 0.6666666666666665,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.5,
                        "recall": 0.5,
                        "f1-score": 0.5,
                        "support": 10.0
                    },
                    "macro avg": {
                        "precision": 0.275,
                        "recall": 0.2875,
                        "f1-score": 0.27777777777777773,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.49000000000000005,
                        "recall": 0.5,
                        "f1-score": 0.4888888888888888,
                        "support": 10.0
                    }
                },
                "culture_and_entertainment_3": {
                    "AFTER": {
                        "precision": 0.4,
                        "recall": 0.4,
                        "f1-score": 0.4000000000000001,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.25,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.28571428571428575,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.26666666666666666,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.26666666666666666,
                        "support": 15.0
                    },
                    "macro avg": {
                        "precision": 0.1625,
                        "recall": 0.18333333333333335,
                        "f1-score": 0.17142857142857146,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.23333333333333334,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.24761904761904766,
                        "support": 15.0
                    }
                }
            },
            "note": {
                "government_and_politics_riots_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.4,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.23529411764705882,
                        "support": 12.0
                    },
                    "COEX": {
                        "precision": 0.4,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.23529411764705882,
                        "support": 12.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.14285714285714285,
                    "macro avg": {
                        "precision": 0.2,
                        "recall": 0.08333333333333333,
                        "f1-score": 0.11764705882352941,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.3428571428571429,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.20168067226890754,
                        "support": 28.0
                    }
                },
                "rail_transport_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "BEFORE": {
                        "precision": 0.8571428571428571,
                        "recall": 0.17647058823529413,
                        "f1-score": 0.29268292682926833,
                        "support": 34.0
                    },
                    "COEX": {
                        "precision": 0.2,
                        "recall": 0.5,
                        "f1-score": 0.28571428571428575,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.19444444444444445,
                    "macro avg": {
                        "precision": 0.2642857142857143,
                        "recall": 0.16911764705882354,
                        "f1-score": 0.14459930313588854,
                        "support": 36.0
                    },
                    "weighted avg": {
                        "precision": 0.8206349206349206,
                        "recall": 0.19444444444444445,
                        "f1-score": 0.2922957801006582,
                        "support": 36.0
                    }
                },
                "politics_and_conflicts_policy_change_2": {
                    "AFTER": {
                        "precision": 0.6666666666666666,
                        "recall": 0.6666666666666666,
                        "f1-score": 0.6666666666666666,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 0.5,
                        "f1-score": 0.4,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.5,
                        "recall": 0.5,
                        "f1-score": 0.5,
                        "support": 6.0
                    },
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.29166666666666663,
                        "f1-score": 0.26666666666666666,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.4444444444444444,
                        "recall": 0.5,
                        "f1-score": 0.4666666666666666,
                        "support": 6.0
                    }
                },
                "politics_and_conflicts_drones_1": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.36363636363636365,
                        "f1-score": 0.4210526315789474,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 0.125,
                        "f1-score": 0.18181818181818182,
                        "support": 8.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.23809523809523808,
                    "macro avg": {
                        "precision": 0.20833333333333331,
                        "recall": 0.12215909090909091,
                        "f1-score": 0.1507177033492823,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.38888888888888884,
                        "recall": 0.23809523809523808,
                        "f1-score": 0.2898154477101846,
                        "support": 21.0
                    }
                },
                "disasters_and_accidents_road_crash_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.09090909090909091,
                        "f1-score": 0.15384615384615385,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.2857142857142857,
                        "recall": 0.2,
                        "f1-score": 0.23529411764705882,
                        "support": 10.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.14285714285714285,
                    "macro avg": {
                        "precision": 0.19642857142857142,
                        "recall": 0.07272727272727272,
                        "f1-score": 0.09728506787330317,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.3979591836734694,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.19263089851325144,
                        "support": 21.0
                    }
                },
                "crime_and_law_accuse_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.6,
                        "recall": 0.5,
                        "f1-score": 0.5454545454545454,
                        "support": 6.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.3,
                    "macro avg": {
                        "precision": 0.15,
                        "recall": 0.125,
                        "f1-score": 0.13636363636363635,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.36,
                        "recall": 0.3,
                        "f1-score": 0.32727272727272727,
                        "support": 10.0
                    }
                },
                "government_and_politics_protests_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.15,
                        "f1-score": 0.23076923076923075,
                        "support": 20.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.10714285714285714,
                    "macro avg": {
                        "precision": 0.125,
                        "recall": 0.0375,
                        "f1-score": 0.05769230769230769,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.35714285714285715,
                        "recall": 0.10714285714285714,
                        "f1-score": 0.16483516483516483,
                        "support": 28.0
                    }
                },
                "politics_and_conflicts_elections_2": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.2727272727272727,
                        "f1-score": 0.3529411764705882,
                        "support": 22.0
                    },
                    "BEFORE": {
                        "precision": 0.16666666666666666,
                        "recall": 0.07142857142857142,
                        "f1-score": 0.1,
                        "support": 14.0
                    },
                    "COEX": {
                        "precision": 0.2727272727272727,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3,
                        "support": 9.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2222222222222222,
                    "macro avg": {
                        "precision": 0.23484848484848483,
                        "recall": 0.16937229437229434,
                        "f1-score": 0.18823529411764706,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.3508417508417508,
                        "recall": 0.2222222222222222,
                        "f1-score": 0.2636601307189542,
                        "support": 45.0
                    }
                },
                "environment_2": {
                    "AFTER": {
                        "precision": 0.45454545454545453,
                        "recall": 0.23809523809523808,
                        "f1-score": 0.31249999999999994,
                        "support": 21.0
                    },
                    "BEFORE": {
                        "precision": 0.4,
                        "recall": 0.17391304347826086,
                        "f1-score": 0.24242424242424243,
                        "support": 23.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2,
                    "macro avg": {
                        "precision": 0.21363636363636362,
                        "recall": 0.10300207039337474,
                        "f1-score": 0.1387310606060606,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.4165656565656566,
                        "recall": 0.2,
                        "f1-score": 0.2697390572390572,
                        "support": 45.0
                    }
                },
                "weather_floods_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 7.0
                    },
                    "COEX": {
                        "precision": 0.5,
                        "recall": 0.5,
                        "f1-score": 0.5,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.13333333333333333,
                    "macro avg": {
                        "precision": 0.125,
                        "recall": 0.125,
                        "f1-score": 0.125,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.13333333333333333,
                        "recall": 0.13333333333333333,
                        "f1-score": 0.13333333333333333,
                        "support": 15.0
                    }
                },
                "sports_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    }
                },
                "health_4": {
                    "AFTER": {
                        "precision": 0.4,
                        "recall": 0.2222222222222222,
                        "f1-score": 0.2857142857142857,
                        "support": 9.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.25,
                        "f1-score": 0.3333333333333333,
                        "support": 8.0
                    },
                    "COEX": {
                        "precision": 0.3333333333333333,
                        "recall": 0.5,
                        "f1-score": 0.4,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2857142857142857,
                    "macro avg": {
                        "precision": 0.30833333333333335,
                        "recall": 0.24305555555555555,
                        "f1-score": 0.25476190476190474,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.4253968253968254,
                        "recall": 0.2857142857142857,
                        "f1-score": 0.3256235827664399,
                        "support": 21.0
                    }
                },
                "weather_earthquakes_1": {
                    "AFTER": {
                        "precision": 0.1111111111111111,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.13333333333333333,
                        "support": 6.0
                    },
                    "BEFORE": {
                        "precision": 0.6666666666666666,
                        "recall": 0.25,
                        "f1-score": 0.36363636363636365,
                        "support": 32.0
                    },
                    "COEX": {
                        "precision": 0.3076923076923077,
                        "recall": 0.5714285714285714,
                        "f1-score": 0.4,
                        "support": 7.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.28888888888888886,
                    "macro avg": {
                        "precision": 0.27136752136752135,
                        "recall": 0.2470238095238095,
                        "f1-score": 0.22424242424242424,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.5367521367521367,
                        "recall": 0.28888888888888886,
                        "f1-score": 0.3385858585858586,
                        "support": 45.0
                    }
                },
                "space_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.4444444444444444,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.33333333333333337,
                        "support": 15.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.14285714285714285,
                    "macro avg": {
                        "precision": 0.1111111111111111,
                        "recall": 0.06666666666666667,
                        "f1-score": 0.08333333333333334,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.23809523809523808,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.1785714285714286,
                        "support": 28.0
                    }
                },
                "economy_and_business_strikes_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.6666666666666666,
                        "recall": 0.5,
                        "f1-score": 0.5714285714285715,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.3333333333333333,
                    "macro avg": {
                        "precision": 0.16666666666666666,
                        "recall": 0.125,
                        "f1-score": 0.14285714285714288,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.4444444444444444,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.380952380952381,
                        "support": 6.0
                    }
                },
                "politics_and_conflicts_armed_conflict_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.18181818181818182,
                        "f1-score": 0.3076923076923077,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.13333333333333333,
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.045454545454545456,
                        "f1-score": 0.07692307692307693,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.7333333333333333,
                        "recall": 0.13333333333333333,
                        "f1-score": 0.22564102564102567,
                        "support": 15.0
                    }
                },
                "infectious_disease_4": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.25,
                        "f1-score": 0.25,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    }
                },
                "health_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.0,
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 10.0
                    }
                },
                "disasters_and_accidents_shipwreck_2": {
                    "AFTER": {
                        "precision": 0.3333333333333333,
                        "recall": 0.18181818181818182,
                        "f1-score": 0.23529411764705885,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.5714285714285714,
                        "recall": 0.4444444444444444,
                        "f1-score": 0.5,
                        "support": 9.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2857142857142857,
                    "macro avg": {
                        "precision": 0.22619047619047616,
                        "recall": 0.15656565656565657,
                        "f1-score": 0.18382352941176472,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.419501133786848,
                        "recall": 0.2857142857142857,
                        "f1-score": 0.3375350140056022,
                        "support": 21.0
                    }
                },
                "rail_transport_3": {
                    "AFTER": {
                        "precision": 0.2,
                        "recall": 0.2,
                        "f1-score": 0.20000000000000004,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 10.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.06666666666666667,
                    "macro avg": {
                        "precision": 0.05,
                        "recall": 0.05,
                        "f1-score": 0.05000000000000001,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.06666666666666667,
                        "recall": 0.06666666666666667,
                        "f1-score": 0.06666666666666668,
                        "support": 15.0
                    }
                },
                "weather_storms_1_extra": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.25,
                        "f1-score": 0.25,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    }
                },
                "health_1_extra": {
                    "AFTER": {
                        "precision": 0.4,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3636363636363636,
                        "support": 12.0
                    },
                    "BEFORE": {
                        "precision": 0.625,
                        "recall": 0.17857142857142858,
                        "f1-score": 0.2777777777777778,
                        "support": 28.0
                    },
                    "COEX": {
                        "precision": 0.4444444444444444,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.33333333333333337,
                        "support": 15.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.23636363636363636,
                    "macro avg": {
                        "precision": 0.3673611111111111,
                        "recall": 0.19464285714285712,
                        "f1-score": 0.2436868686868687,
                        "support": 55.0
                    },
                    "weighted avg": {
                        "precision": 0.5266666666666667,
                        "recall": 0.23636363636363636,
                        "f1-score": 0.3116620752984389,
                        "support": 55.0
                    }
                },
                "weather_floods_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.46153846153846156,
                        "recall": 0.25,
                        "f1-score": 0.32432432432432434,
                        "support": 24.0
                    },
                    "COEX": {
                        "precision": 0.5,
                        "recall": 0.2857142857142857,
                        "f1-score": 0.36363636363636365,
                        "support": 28.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2545454545454545,
                    "macro avg": {
                        "precision": 0.2403846153846154,
                        "recall": 0.13392857142857142,
                        "f1-score": 0.171990171990172,
                        "support": 55.0
                    },
                    "weighted avg": {
                        "precision": 0.45594405594405596,
                        "recall": 0.2545454545454545,
                        "f1-score": 0.3266473084654903,
                        "support": 55.0
                    }
                },
                "mining_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 25.0
                    },
                    "COEX": {
                        "precision": 0.14285714285714285,
                        "recall": 0.1111111111111111,
                        "f1-score": 0.125,
                        "support": 9.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.022222222222222223,
                    "macro avg": {
                        "precision": 0.03571428571428571,
                        "recall": 0.027777777777777776,
                        "f1-score": 0.03125,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.028571428571428567,
                        "recall": 0.022222222222222223,
                        "f1-score": 0.025,
                        "support": 45.0
                    }
                },
                "disasters_and_accidents_volcanoes_4": {
                    "AFTER": {
                        "precision": 0.45454545454545453,
                        "recall": 0.25,
                        "f1-score": 0.3225806451612903,
                        "support": 20.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 0.2857142857142857,
                        "f1-score": 0.30769230769230765,
                        "support": 14.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.25,
                    "macro avg": {
                        "precision": 0.19696969696969696,
                        "recall": 0.13392857142857142,
                        "f1-score": 0.1575682382133995,
                        "support": 36.0
                    },
                    "weighted avg": {
                        "precision": 0.38215488215488214,
                        "recall": 0.25,
                        "f1-score": 0.2988695891921698,
                        "support": 36.0
                    }
                },
                "politics_and_conflicts_elections_3": {
                    "AFTER": {
                        "precision": 0.4,
                        "recall": 0.4,
                        "f1-score": 0.4000000000000001,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.2,
                        "recall": 0.25,
                        "f1-score": 0.22222222222222224,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.2,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.1818181818181818,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.26666666666666666,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.26666666666666666,
                        "support": 15.0
                    },
                    "macro avg": {
                        "precision": 0.2,
                        "recall": 0.20416666666666666,
                        "f1-score": 0.20101010101010103,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.26666666666666666,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.26531986531986534,
                        "support": 15.0
                    }
                },
                "economy_and_business_strikes_3": {
                    "AFTER": {
                        "precision": 0.2,
                        "recall": 0.1,
                        "f1-score": 0.13333333333333333,
                        "support": 10.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.09090909090909091,
                        "f1-score": 0.15384615384615385,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.2,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.16666666666666666,
                        "support": 7.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.10714285714285714,
                    "macro avg": {
                        "precision": 0.22499999999999998,
                        "recall": 0.08344155844155844,
                        "f1-score": 0.11346153846153845,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.3178571428571429,
                        "recall": 0.10714285714285714,
                        "f1-score": 0.1497252747252747,
                        "support": 28.0
                    }
                },
                "space_2": {
                    "AFTER": {
                        "precision": 0.6190476190476191,
                        "recall": 0.13,
                        "f1-score": 0.21487603305785125,
                        "support": 100.0
                    },
                    "BEFORE": {
                        "precision": 0.3103448275862069,
                        "recall": 0.17647058823529413,
                        "f1-score": 0.22500000000000003,
                        "support": 51.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.1437908496732026,
                    "macro avg": {
                        "precision": 0.23234811165845648,
                        "recall": 0.07661764705882354,
                        "f1-score": 0.10996900826446282,
                        "support": 153.0
                    },
                    "weighted avg": {
                        "precision": 0.5080545628212971,
                        "recall": 0.1437908496732026,
                        "f1-score": 0.2154418516717982,
                        "support": 153.0
                    }
                },
                "politics_and_conflicts_resign_1": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.5,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 3.0
                    },
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.08333333333333333,
                        "f1-score": 0.125,
                        "support": 3.0
                    },
                    "weighted avg": {
                        "precision": 1.0,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.5,
                        "support": 3.0
                    }
                },
                "environment_4": {
                    "AFTER": {
                        "precision": 0.25,
                        "recall": 0.25,
                        "f1-score": 0.25,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.16666666666666666,
                        "recall": 0.2,
                        "f1-score": 0.1818181818181818,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.13333333333333333,
                    "macro avg": {
                        "precision": 0.10416666666666666,
                        "recall": 0.1125,
                        "f1-score": 0.10795454545454544,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.12222222222222222,
                        "recall": 0.13333333333333333,
                        "f1-score": 0.12727272727272726,
                        "support": 15.0
                    }
                },
                "space_1_extra": {
                    "AFTER": {
                        "precision": 0.3333333333333333,
                        "recall": 1.0,
                        "f1-score": 0.5,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.4,
                        "f1-score": 0.5714285714285715,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.5,
                        "recall": 0.5,
                        "f1-score": 0.5,
                        "support": 6.0
                    },
                    "macro avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.35,
                        "f1-score": 0.2678571428571429,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.8888888888888888,
                        "recall": 0.5,
                        "f1-score": 0.5595238095238096,
                        "support": 6.0
                    }
                },
                "health_3": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.25,
                        "f1-score": 0.4,
                        "support": 8.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.13333333333333333,
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.0625,
                        "f1-score": 0.1,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.5333333333333333,
                        "recall": 0.13333333333333333,
                        "f1-score": 0.21333333333333335,
                        "support": 15.0
                    }
                },
                "environment_3": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.2727272727272727,
                        "f1-score": 0.42857142857142855,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.16666666666666666,
                        "recall": 0.5,
                        "f1-score": 0.25,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.26666666666666666,
                    "macro avg": {
                        "precision": 0.2916666666666667,
                        "recall": 0.19318181818181818,
                        "f1-score": 0.16964285714285715,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.7555555555555556,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.3476190476190476,
                        "support": 15.0
                    }
                },
                "government_and_politics_protests_3": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.5,
                        "f1-score": 0.5,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.3333333333333333,
                    "macro avg": {
                        "precision": 0.125,
                        "recall": 0.125,
                        "f1-score": 0.125,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 6.0
                    }
                },
                "economy_and_business_financial_crisis_4": {
                    "AFTER": {
                        "precision": 0.2222222222222222,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.1904761904761905,
                        "support": 12.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.09523809523809523,
                    "macro avg": {
                        "precision": 0.05555555555555555,
                        "recall": 0.041666666666666664,
                        "f1-score": 0.04761904761904762,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.12698412698412698,
                        "recall": 0.09523809523809523,
                        "f1-score": 0.108843537414966,
                        "support": 21.0
                    }
                },
                "computers_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    }
                },
                "crime_and_law_accuse_4": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.6,
                        "f1-score": 0.5454545454545454,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.4,
                        "f1-score": 0.4444444444444445,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.5,
                        "recall": 0.5,
                        "f1-score": 0.5,
                        "support": 10.0
                    },
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.25,
                        "f1-score": 0.24747474747474746,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.5,
                        "recall": 0.5,
                        "f1-score": 0.494949494949495,
                        "support": 10.0
                    }
                },
                "culture_and_entertainment_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    }
                },
                "internet_2": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.2,
                        "f1-score": 0.33333333333333337,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.1,
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.05,
                        "f1-score": 0.08333333333333334,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.5,
                        "recall": 0.1,
                        "f1-score": 0.16666666666666669,
                        "support": 10.0
                    }
                },
                "culture_and_entertainment_3": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.4,
                        "f1-score": 0.4444444444444445,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.25,
                        "f1-score": 0.4,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.5714285714285714,
                        "recall": 0.6666666666666666,
                        "f1-score": 0.6153846153846153,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.4666666666666667,
                    "macro avg": {
                        "precision": 0.5178571428571428,
                        "recall": 0.32916666666666666,
                        "f1-score": 0.364957264957265,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.6619047619047619,
                        "recall": 0.4666666666666667,
                        "f1-score": 0.500968660968661,
                        "support": 15.0
                    }
                }
            },
            "note_events": {
                "government_and_politics_riots_4": {
                    "AFTER": {
                        "precision": 0.25,
                        "recall": 0.5,
                        "f1-score": 0.3333333333333333,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.4166666666666667,
                        "recall": 0.4166666666666667,
                        "f1-score": 0.4166666666666667,
                        "support": 12.0
                    },
                    "COEX": {
                        "precision": 0.625,
                        "recall": 0.4166666666666667,
                        "f1-score": 0.5,
                        "support": 12.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.42857142857142855,
                        "recall": 0.42857142857142855,
                        "f1-score": 0.42857142857142855,
                        "support": 28.0
                    },
                    "macro avg": {
                        "precision": 0.3229166666666667,
                        "recall": 0.33333333333333337,
                        "f1-score": 0.3125,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.48214285714285715,
                        "recall": 0.42857142857142855,
                        "f1-score": 0.4404761904761904,
                        "support": 28.0
                    }
                },
                "rail_transport_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.3235294117647059,
                        "f1-score": 0.48888888888888893,
                        "support": 34.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.3055555555555556,
                        "recall": 0.3055555555555556,
                        "f1-score": 0.3055555555555556,
                        "support": 36.0
                    },
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.08088235294117647,
                        "f1-score": 0.12222222222222223,
                        "support": 36.0
                    },
                    "weighted avg": {
                        "precision": 0.9444444444444444,
                        "recall": 0.3055555555555556,
                        "f1-score": 0.4617283950617284,
                        "support": 36.0
                    }
                },
                "politics_and_conflicts_policy_change_2": {
                    "AFTER": {
                        "precision": 0.75,
                        "recall": 1.0,
                        "f1-score": 0.8571428571428571,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.5,
                        "recall": 1.0,
                        "f1-score": 0.6666666666666666,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.6666666666666666,
                        "recall": 0.6666666666666666,
                        "f1-score": 0.6666666666666666,
                        "support": 6.0
                    },
                    "macro avg": {
                        "precision": 0.3125,
                        "recall": 0.5,
                        "f1-score": 0.38095238095238093,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.4583333333333333,
                        "recall": 0.6666666666666666,
                        "f1-score": 0.5396825396825397,
                        "support": 6.0
                    }
                },
                "politics_and_conflicts_drones_1": {
                    "AFTER": {
                        "precision": 0.75,
                        "recall": 0.2727272727272727,
                        "f1-score": 0.39999999999999997,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 0.25,
                        "f1-score": 0.28571428571428575,
                        "support": 8.0
                    },
                    "COEX": {
                        "precision": 0.18181818181818182,
                        "recall": 1.0,
                        "f1-score": 0.3076923076923077,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 21.0
                    },
                    "macro avg": {
                        "precision": 0.3162878787878788,
                        "recall": 0.3806818181818182,
                        "f1-score": 0.24835164835164836,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.5371572871572872,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.34767137624280475,
                        "support": 21.0
                    }
                },
                "disasters_and_accidents_road_crash_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 0.18181818181818182,
                        "f1-score": 0.23529411764705885,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.5,
                        "recall": 0.2,
                        "f1-score": 0.28571428571428575,
                        "support": 10.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.19047619047619047,
                        "recall": 0.19047619047619047,
                        "f1-score": 0.19047619047619047,
                        "support": 21.0
                    },
                    "macro avg": {
                        "precision": 0.20833333333333331,
                        "recall": 0.09545454545454546,
                        "f1-score": 0.13025210084033614,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.4126984126984127,
                        "recall": 0.19047619047619047,
                        "f1-score": 0.25930372148859543,
                        "support": 21.0
                    }
                },
                "crime_and_law_accuse_3": {
                    "AFTER": {
                        "precision": 0.3333333333333333,
                        "recall": 0.5,
                        "f1-score": 0.4,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.2857142857142857,
                        "support": 6.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.3,
                        "recall": 0.3,
                        "f1-score": 0.3,
                        "support": 10.0
                    },
                    "macro avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.17142857142857143,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.7333333333333333,
                        "recall": 0.3,
                        "f1-score": 0.3314285714285714,
                        "support": 10.0
                    }
                },
                "government_and_politics_protests_2": {
                    "AFTER": {
                        "precision": 0.2222222222222222,
                        "recall": 0.4,
                        "f1-score": 0.2857142857142857,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.6923076923076923,
                        "recall": 0.45,
                        "f1-score": 0.5454545454545455,
                        "support": 20.0
                    },
                    "COEX": {
                        "precision": 0.16666666666666666,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.2222222222222222,
                        "support": 3.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.42857142857142855,
                        "recall": 0.42857142857142855,
                        "f1-score": 0.42857142857142855,
                        "support": 28.0
                    },
                    "macro avg": {
                        "precision": 0.2702991452991453,
                        "recall": 0.29583333333333334,
                        "f1-score": 0.26334776334776333,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.5520451770451771,
                        "recall": 0.42857142857142855,
                        "f1-score": 0.4644403215831788,
                        "support": 28.0
                    }
                },
                "politics_and_conflicts_elections_2": {
                    "AFTER": {
                        "precision": 0.47058823529411764,
                        "recall": 0.36363636363636365,
                        "f1-score": 0.41025641025641024,
                        "support": 22.0
                    },
                    "BEFORE": {
                        "precision": 0.14285714285714285,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.14285714285714285,
                        "support": 14.0
                    },
                    "COEX": {
                        "precision": 0.18181818181818182,
                        "recall": 0.2222222222222222,
                        "f1-score": 0.19999999999999998,
                        "support": 9.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.26666666666666666,
                    "macro avg": {
                        "precision": 0.1988158899923606,
                        "recall": 0.1821789321789322,
                        "f1-score": 0.18827838827838828,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.310873440285205,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.28501424501424505,
                        "support": 45.0
                    }
                },
                "environment_2": {
                    "AFTER": {
                        "precision": 0.5384615384615384,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.41176470588235287,
                        "support": 21.0
                    },
                    "BEFORE": {
                        "precision": 0.5238095238095238,
                        "recall": 0.4782608695652174,
                        "f1-score": 0.5,
                        "support": 23.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.4,
                        "recall": 0.4,
                        "f1-score": 0.4000000000000001,
                        "support": 45.0
                    },
                    "macro avg": {
                        "precision": 0.26556776556776557,
                        "recall": 0.2028985507246377,
                        "f1-score": 0.2279411764705882,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.519006919006919,
                        "recall": 0.4,
                        "f1-score": 0.44771241830065356,
                        "support": 45.0
                    }
                },
                "weather_floods_3": {
                    "AFTER": {
                        "precision": 0.3333333333333333,
                        "recall": 0.5,
                        "f1-score": 0.4,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.6666666666666666,
                        "recall": 0.2857142857142857,
                        "f1-score": 0.4,
                        "support": 7.0
                    },
                    "COEX": {
                        "precision": 0.5,
                        "recall": 0.75,
                        "f1-score": 0.6,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.4666666666666667,
                        "recall": 0.4666666666666667,
                        "f1-score": 0.4666666666666667,
                        "support": 15.0
                    },
                    "macro avg": {
                        "precision": 0.375,
                        "recall": 0.3839285714285714,
                        "f1-score": 0.35,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.5333333333333333,
                        "recall": 0.4666666666666667,
                        "f1-score": 0.45333333333333337,
                        "support": 15.0
                    }
                },
                "sports_1": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.5,
                        "f1-score": 0.5,
                        "support": 2.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 3.0
                    },
                    "macro avg": {
                        "precision": 0.125,
                        "recall": 0.125,
                        "f1-score": 0.125,
                        "support": 3.0
                    },
                    "weighted avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 3.0
                    }
                },
                "health_4": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.7777777777777778,
                        "f1-score": 0.6086956521739131,
                        "support": 9.0
                    },
                    "BEFORE": {
                        "precision": 0.6666666666666666,
                        "recall": 0.25,
                        "f1-score": 0.36363636363636365,
                        "support": 8.0
                    },
                    "COEX": {
                        "precision": 0.25,
                        "recall": 0.25,
                        "f1-score": 0.25,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.47619047619047616,
                        "recall": 0.47619047619047616,
                        "f1-score": 0.47619047619047616,
                        "support": 21.0
                    },
                    "macro avg": {
                        "precision": 0.35416666666666663,
                        "recall": 0.3194444444444444,
                        "f1-score": 0.3055830039525692,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.5158730158730158,
                        "recall": 0.47619047619047616,
                        "f1-score": 0.44701675136457747,
                        "support": 21.0
                    }
                },
                "weather_earthquakes_1": {
                    "AFTER": {
                        "precision": 0.125,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.18181818181818182,
                        "support": 6.0
                    },
                    "BEFORE": {
                        "precision": 0.75,
                        "recall": 0.375,
                        "f1-score": 0.5,
                        "support": 32.0
                    },
                    "COEX": {
                        "precision": 0.15384615384615385,
                        "recall": 0.2857142857142857,
                        "f1-score": 0.2,
                        "support": 7.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.35555555555555557,
                        "recall": 0.35555555555555557,
                        "f1-score": 0.35555555555555557,
                        "support": 45.0
                    },
                    "macro avg": {
                        "precision": 0.25721153846153844,
                        "recall": 0.24851190476190474,
                        "f1-score": 0.22045454545454546,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.5739316239316239,
                        "recall": 0.35555555555555557,
                        "f1-score": 0.41090909090909084,
                        "support": 45.0
                    }
                },
                "space_4": {
                    "AFTER": {
                        "precision": 0.3333333333333333,
                        "recall": 0.2727272727272727,
                        "f1-score": 0.3,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.46153846153846156,
                        "recall": 0.4,
                        "f1-score": 0.42857142857142855,
                        "support": 15.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.32142857142857145,
                        "recall": 0.32142857142857145,
                        "f1-score": 0.32142857142857145,
                        "support": 28.0
                    },
                    "macro avg": {
                        "precision": 0.19871794871794873,
                        "recall": 0.16818181818181818,
                        "f1-score": 0.18214285714285713,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.3782051282051282,
                        "recall": 0.32142857142857145,
                        "f1-score": 0.3474489795918367,
                        "support": 28.0
                    }
                },
                "economy_and_business_strikes_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.25,
                        "f1-score": 0.3333333333333333,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.16666666666666666,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.16666666666666666,
                        "support": 6.0
                    },
                    "macro avg": {
                        "precision": 0.125,
                        "recall": 0.0625,
                        "f1-score": 0.08333333333333333,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.2222222222222222,
                        "support": 6.0
                    }
                },
                "politics_and_conflicts_armed_conflict_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.18181818181818182,
                        "f1-score": 0.26666666666666666,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.13333333333333333,
                        "recall": 0.13333333333333333,
                        "f1-score": 0.13333333333333333,
                        "support": 15.0
                    },
                    "macro avg": {
                        "precision": 0.125,
                        "recall": 0.045454545454545456,
                        "f1-score": 0.06666666666666667,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.36666666666666664,
                        "recall": 0.13333333333333333,
                        "f1-score": 0.19555555555555554,
                        "support": 15.0
                    }
                },
                "infectious_disease_4": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.25,
                        "f1-score": 0.25,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    }
                },
                "health_1": {
                    "AFTER": {
                        "precision": 0.8333333333333334,
                        "recall": 0.8333333333333334,
                        "f1-score": 0.8333333333333334,
                        "support": 6.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.6666666666666666,
                        "f1-score": 0.8,
                        "support": 3.0
                    },
                    "COEX": {
                        "precision": 0.5,
                        "recall": 1.0,
                        "f1-score": 0.6666666666666666,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.8,
                        "recall": 0.8,
                        "f1-score": 0.8000000000000002,
                        "support": 10.0
                    },
                    "macro avg": {
                        "precision": 0.5833333333333334,
                        "recall": 0.625,
                        "f1-score": 0.575,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.85,
                        "recall": 0.8,
                        "f1-score": 0.8066666666666666,
                        "support": 10.0
                    }
                },
                "disasters_and_accidents_shipwreck_2": {
                    "AFTER": {
                        "precision": 0.6666666666666666,
                        "recall": 0.7272727272727273,
                        "f1-score": 0.6956521739130435,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.7142857142857143,
                        "recall": 0.5555555555555556,
                        "f1-score": 0.6250000000000001,
                        "support": 9.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.6190476190476191,
                        "recall": 0.6190476190476191,
                        "f1-score": 0.6190476190476191,
                        "support": 21.0
                    },
                    "macro avg": {
                        "precision": 0.34523809523809523,
                        "recall": 0.3207070707070707,
                        "f1-score": 0.33016304347826086,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.655328798185941,
                        "recall": 0.6190476190476191,
                        "f1-score": 0.6322463768115943,
                        "support": 21.0
                    }
                },
                "rail_transport_3": {
                    "AFTER": {
                        "precision": 0.3333333333333333,
                        "recall": 0.4,
                        "f1-score": 0.3636363636363636,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.6666666666666666,
                        "recall": 0.2,
                        "f1-score": 0.30769230769230765,
                        "support": 10.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.26666666666666666,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.26666666666666666,
                        "support": 15.0
                    },
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.15000000000000002,
                        "f1-score": 0.1678321678321678,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.5555555555555555,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.32634032634032634,
                        "support": 15.0
                    }
                },
                "weather_storms_1_extra": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.25,
                        "f1-score": 0.25,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    }
                },
                "health_1_extra": {
                    "AFTER": {
                        "precision": 0.21428571428571427,
                        "recall": 0.5,
                        "f1-score": 0.3,
                        "support": 12.0
                    },
                    "BEFORE": {
                        "precision": 0.631578947368421,
                        "recall": 0.42857142857142855,
                        "f1-score": 0.5106382978723404,
                        "support": 28.0
                    },
                    "COEX": {
                        "precision": 0.2,
                        "recall": 0.06666666666666667,
                        "f1-score": 0.1,
                        "support": 15.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.34545454545454546,
                    "macro avg": {
                        "precision": 0.26146616541353385,
                        "recall": 0.2488095238095238,
                        "f1-score": 0.22765957446808507,
                        "support": 55.0
                    },
                    "weighted avg": {
                        "precision": 0.4228298017771701,
                        "recall": 0.34545454545454546,
                        "f1-score": 0.3526885880077369,
                        "support": 55.0
                    }
                },
                "weather_floods_1": {
                    "AFTER": {
                        "precision": 0.125,
                        "recall": 1.0,
                        "f1-score": 0.2222222222222222,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.45454545454545453,
                        "recall": 0.20833333333333334,
                        "f1-score": 0.28571428571428575,
                        "support": 24.0
                    },
                    "COEX": {
                        "precision": 0.6,
                        "recall": 0.32142857142857145,
                        "f1-score": 0.41860465116279066,
                        "support": 28.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.3090909090909091,
                    "macro avg": {
                        "precision": 0.29488636363636367,
                        "recall": 0.38244047619047616,
                        "f1-score": 0.23163528977482464,
                        "support": 55.0
                    },
                    "weighted avg": {
                        "precision": 0.5106198347107438,
                        "recall": 0.3090909090909091,
                        "f1-score": 0.34990435920668483,
                        "support": 55.0
                    }
                },
                "mining_4": {
                    "AFTER": {
                        "precision": 0.15384615384615385,
                        "recall": 0.18181818181818182,
                        "f1-score": 0.16666666666666669,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.6666666666666666,
                        "recall": 0.4,
                        "f1-score": 0.5,
                        "support": 25.0
                    },
                    "COEX": {
                        "precision": 0.3125,
                        "recall": 0.5555555555555556,
                        "f1-score": 0.39999999999999997,
                        "support": 9.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.37777777777777777,
                    "macro avg": {
                        "precision": 0.2832532051282051,
                        "recall": 0.28434343434343434,
                        "f1-score": 0.26666666666666666,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.47047720797720793,
                        "recall": 0.37777777777777777,
                        "f1-score": 0.39851851851851855,
                        "support": 45.0
                    }
                },
                "disasters_and_accidents_volcanoes_4": {
                    "AFTER": {
                        "precision": 0.6666666666666666,
                        "recall": 0.4,
                        "f1-score": 0.5,
                        "support": 20.0
                    },
                    "BEFORE": {
                        "precision": 0.42857142857142855,
                        "recall": 0.42857142857142855,
                        "f1-score": 0.42857142857142855,
                        "support": 14.0
                    },
                    "COEX": {
                        "precision": 0.1,
                        "recall": 0.5,
                        "f1-score": 0.16666666666666669,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.4166666666666667,
                        "recall": 0.4166666666666667,
                        "f1-score": 0.4166666666666667,
                        "support": 36.0
                    },
                    "macro avg": {
                        "precision": 0.2988095238095238,
                        "recall": 0.33214285714285713,
                        "f1-score": 0.27380952380952384,
                        "support": 36.0
                    },
                    "weighted avg": {
                        "precision": 0.5425925925925925,
                        "recall": 0.4166666666666667,
                        "f1-score": 0.45370370370370366,
                        "support": 36.0
                    }
                },
                "politics_and_conflicts_elections_3": {
                    "AFTER": {
                        "precision": 0.2,
                        "recall": 0.2,
                        "f1-score": 0.20000000000000004,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 0.5,
                        "f1-score": 0.4,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.3333333333333333,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.2222222222222222,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.26666666666666666,
                    "macro avg": {
                        "precision": 0.21666666666666667,
                        "recall": 0.21666666666666665,
                        "f1-score": 0.20555555555555557,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.28888888888888886,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.26222222222222225,
                        "support": 15.0
                    }
                },
                "economy_and_business_strikes_3": {
                    "AFTER": {
                        "precision": 0.4444444444444444,
                        "recall": 0.4,
                        "f1-score": 0.4210526315789474,
                        "support": 10.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 0.2727272727272727,
                        "f1-score": 0.3,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.2,
                        "recall": 0.2857142857142857,
                        "f1-score": 0.23529411764705882,
                        "support": 7.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.32142857142857145,
                        "recall": 0.32142857142857145,
                        "f1-score": 0.32142857142857145,
                        "support": 28.0
                    },
                    "macro avg": {
                        "precision": 0.2444444444444444,
                        "recall": 0.2396103896103896,
                        "f1-score": 0.23908668730650157,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.3396825396825397,
                        "recall": 0.32142857142857145,
                        "f1-score": 0.32705661211853165,
                        "support": 28.0
                    }
                },
                "space_2": {
                    "AFTER": {
                        "precision": 0.6585365853658537,
                        "recall": 0.27,
                        "f1-score": 0.3829787234042553,
                        "support": 100.0
                    },
                    "BEFORE": {
                        "precision": 0.2033898305084746,
                        "recall": 0.23529411764705882,
                        "f1-score": 0.2181818181818182,
                        "support": 51.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2549019607843137,
                    "macro avg": {
                        "precision": 0.21548160396858207,
                        "recall": 0.12632352941176472,
                        "f1-score": 0.15029013539651837,
                        "support": 153.0
                    },
                    "weighted avg": {
                        "precision": 0.4982126790360626,
                        "recall": 0.2549019607843137,
                        "f1-score": 0.32304016384116513,
                        "support": 153.0
                    }
                },
                "politics_and_conflicts_resign_1": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.5,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 3.0
                    },
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.08333333333333333,
                        "f1-score": 0.125,
                        "support": 3.0
                    },
                    "weighted avg": {
                        "precision": 1.0,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.5,
                        "support": 3.0
                    }
                },
                "environment_4": {
                    "AFTER": {
                        "precision": 0.6666666666666666,
                        "recall": 1.0,
                        "f1-score": 0.8,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.2,
                        "f1-score": 0.28571428571428575,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.42857142857142855,
                        "recall": 0.5,
                        "f1-score": 0.4615384615384615,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.5333333333333333,
                        "recall": 0.5333333333333333,
                        "f1-score": 0.5333333333333333,
                        "support": 15.0
                    },
                    "macro avg": {
                        "precision": 0.3988095238095238,
                        "recall": 0.425,
                        "f1-score": 0.3868131868131868,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.5158730158730158,
                        "recall": 0.5333333333333333,
                        "f1-score": 0.49318681318681323,
                        "support": 15.0
                    }
                },
                "space_1_extra": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.2,
                        "f1-score": 0.33333333333333337,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.16666666666666666,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.16666666666666666,
                        "support": 6.0
                    },
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.05,
                        "f1-score": 0.08333333333333334,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.8333333333333334,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.27777777777777785,
                        "support": 6.0
                    }
                },
                "health_3": {
                    "AFTER": {
                        "precision": 0.5555555555555556,
                        "recall": 0.625,
                        "f1-score": 0.5882352941176471,
                        "support": 8.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 15.0
                    },
                    "macro avg": {
                        "precision": 0.1388888888888889,
                        "recall": 0.15625,
                        "f1-score": 0.14705882352941177,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.29629629629629634,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3137254901960784,
                        "support": 15.0
                    }
                },
                "environment_3": {
                    "AFTER": {
                        "precision": 0.8888888888888888,
                        "recall": 0.7272727272727273,
                        "f1-score": 0.7999999999999999,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.25,
                        "recall": 0.5,
                        "f1-score": 0.3333333333333333,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.6,
                        "recall": 0.6,
                        "f1-score": 0.6,
                        "support": 15.0
                    },
                    "macro avg": {
                        "precision": 0.2847222222222222,
                        "recall": 0.3068181818181818,
                        "f1-score": 0.2833333333333333,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.6851851851851851,
                        "recall": 0.6,
                        "f1-score": 0.631111111111111,
                        "support": 15.0
                    }
                },
                "government_and_politics_protests_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "COEX": {
                        "precision": 0.5,
                        "recall": 1.0,
                        "f1-score": 0.6666666666666666,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.16666666666666666,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.16666666666666666,
                        "support": 6.0
                    },
                    "macro avg": {
                        "precision": 0.125,
                        "recall": 0.25,
                        "f1-score": 0.16666666666666666,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.08333333333333333,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.1111111111111111,
                        "support": 6.0
                    }
                },
                "economy_and_business_financial_crisis_4": {
                    "AFTER": {
                        "precision": 0.6666666666666666,
                        "recall": 0.5,
                        "f1-score": 0.5714285714285715,
                        "support": 12.0
                    },
                    "BEFORE": {
                        "precision": 0.42857142857142855,
                        "recall": 0.6,
                        "f1-score": 0.5,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.25,
                        "recall": 0.25,
                        "f1-score": 0.25,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.47619047619047616,
                    "macro avg": {
                        "precision": 0.3363095238095238,
                        "recall": 0.3375,
                        "f1-score": 0.3303571428571429,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.5306122448979591,
                        "recall": 0.47619047619047616,
                        "f1-score": 0.4931972789115647,
                        "support": 21.0
                    }
                },
                "computers_2": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.25,
                        "f1-score": 0.25,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    }
                },
                "crime_and_law_accuse_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 0.4,
                        "f1-score": 0.3636363636363636,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.2,
                        "recall": 0.2,
                        "f1-score": 0.20000000000000004,
                        "support": 10.0
                    },
                    "macro avg": {
                        "precision": 0.08333333333333333,
                        "recall": 0.1,
                        "f1-score": 0.0909090909090909,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.16666666666666666,
                        "recall": 0.2,
                        "f1-score": 0.1818181818181818,
                        "support": 10.0
                    }
                },
                "culture_and_entertainment_1": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.5,
                        "f1-score": 0.6666666666666666,
                        "support": 2.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 0.5,
                        "f1-score": 0.4,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.5,
                        "recall": 0.5,
                        "f1-score": 0.5,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.5,
                        "recall": 0.5,
                        "f1-score": 0.5,
                        "support": 6.0
                    },
                    "macro avg": {
                        "precision": 0.4583333333333333,
                        "recall": 0.375,
                        "f1-score": 0.39166666666666666,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.611111111111111,
                        "recall": 0.5,
                        "f1-score": 0.5222222222222223,
                        "support": 6.0
                    }
                },
                "internet_2": {
                    "AFTER": {
                        "precision": 0.75,
                        "recall": 0.6,
                        "f1-score": 0.6666666666666665,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 0.25,
                        "f1-score": 0.28571428571428575,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.3333333333333333,
                        "recall": 1.0,
                        "f1-score": 0.5,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.5,
                        "recall": 0.5,
                        "f1-score": 0.5,
                        "support": 10.0
                    },
                    "macro avg": {
                        "precision": 0.35416666666666663,
                        "recall": 0.4625,
                        "f1-score": 0.3630952380952381,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.5416666666666666,
                        "recall": 0.5,
                        "f1-score": 0.4976190476190475,
                        "support": 10.0
                    }
                },
                "culture_and_entertainment_3": {
                    "AFTER": {
                        "precision": 0.4,
                        "recall": 0.4,
                        "f1-score": 0.4000000000000001,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.4,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3636363636363636,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.26666666666666666,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.26666666666666666,
                        "support": 15.0
                    },
                    "macro avg": {
                        "precision": 0.2,
                        "recall": 0.18333333333333335,
                        "f1-score": 0.19090909090909092,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.29333333333333333,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.27878787878787875,
                        "support": 15.0
                    }
                }
            },
            "qa": {
                "government_and_politics_riots_4": {
                    "AFTER": {
                        "precision": 0.2857142857142857,
                        "recall": 0.5,
                        "f1-score": 0.36363636363636365,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.4,
                        "support": 12.0
                    },
                    "COEX": {
                        "precision": 0.5384615384615384,
                        "recall": 0.5833333333333334,
                        "f1-score": 0.5599999999999999,
                        "support": 12.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.4642857142857143,
                        "recall": 0.4642857142857143,
                        "f1-score": 0.4642857142857143,
                        "support": 28.0
                    },
                    "macro avg": {
                        "precision": 0.33104395604395603,
                        "recall": 0.35416666666666663,
                        "f1-score": 0.33090909090909093,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.48587127158555726,
                        "recall": 0.4642857142857143,
                        "f1-score": 0.4633766233766234,
                        "support": 28.0
                    }
                },
                "rail_transport_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.2647058823529412,
                        "f1-score": 0.4186046511627907,
                        "support": 34.0
                    },
                    "COEX": {
                        "precision": 0.07142857142857142,
                        "recall": 0.5,
                        "f1-score": 0.125,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2777777777777778,
                    "macro avg": {
                        "precision": 0.26785714285714285,
                        "recall": 0.19117647058823528,
                        "f1-score": 0.1359011627906977,
                        "support": 36.0
                    },
                    "weighted avg": {
                        "precision": 0.9484126984126985,
                        "recall": 0.2777777777777778,
                        "f1-score": 0.4022932816537468,
                        "support": 36.0
                    }
                },
                "politics_and_conflicts_policy_change_2": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.4,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.5,
                        "f1-score": 0.6666666666666666,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 6.0
                    },
                    "macro avg": {
                        "precision": 0.375,
                        "recall": 0.20833333333333331,
                        "f1-score": 0.26666666666666666,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.5833333333333334,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.4222222222222222,
                        "support": 6.0
                    }
                },
                "politics_and_conflicts_drones_1": {
                    "AFTER": {
                        "precision": 0.6666666666666666,
                        "recall": 0.36363636363636365,
                        "f1-score": 0.4705882352941177,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.5714285714285714,
                        "recall": 0.5,
                        "f1-score": 0.5333333333333333,
                        "support": 8.0
                    },
                    "COEX": {
                        "precision": 0.125,
                        "recall": 0.5,
                        "f1-score": 0.2,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.42857142857142855,
                        "recall": 0.42857142857142855,
                        "f1-score": 0.42857142857142855,
                        "support": 21.0
                    },
                    "macro avg": {
                        "precision": 0.34077380952380953,
                        "recall": 0.34090909090909094,
                        "f1-score": 0.30098039215686273,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.5787981859410432,
                        "recall": 0.42857142857142855,
                        "f1-score": 0.46872082166199813,
                        "support": 21.0
                    }
                },
                "disasters_and_accidents_road_crash_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "BEFORE": {
                        "precision": 0.6666666666666666,
                        "recall": 0.18181818181818182,
                        "f1-score": 0.28571428571428575,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.2857142857142857,
                        "recall": 0.2,
                        "f1-score": 0.23529411764705882,
                        "support": 10.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.19047619047619047,
                        "recall": 0.19047619047619047,
                        "f1-score": 0.19047619047619047,
                        "support": 21.0
                    },
                    "macro avg": {
                        "precision": 0.23809523809523808,
                        "recall": 0.09545454545454546,
                        "f1-score": 0.13025210084033614,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.48526077097505665,
                        "recall": 0.19047619047619047,
                        "f1-score": 0.2617046818727491,
                        "support": 21.0
                    }
                },
                "crime_and_law_accuse_3": {
                    "AFTER": {
                        "precision": 0.3333333333333333,
                        "recall": 0.25,
                        "f1-score": 0.28571428571428575,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.25,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.2,
                        "support": 6.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.2,
                        "recall": 0.2,
                        "f1-score": 0.20000000000000004,
                        "support": 10.0
                    },
                    "macro avg": {
                        "precision": 0.14583333333333331,
                        "recall": 0.10416666666666666,
                        "f1-score": 0.12142857142857144,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.2833333333333333,
                        "recall": 0.2,
                        "f1-score": 0.23428571428571435,
                        "support": 10.0
                    }
                },
                "government_and_politics_protests_2": {
                    "AFTER": {
                        "precision": 0.4,
                        "recall": 0.4,
                        "f1-score": 0.4000000000000001,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.6,
                        "recall": 0.3,
                        "f1-score": 0.4,
                        "support": 20.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2857142857142857,
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.175,
                        "f1-score": 0.2,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.5,
                        "recall": 0.2857142857142857,
                        "f1-score": 0.35714285714285715,
                        "support": 28.0
                    }
                },
                "politics_and_conflicts_elections_2": {
                    "AFTER": {
                        "precision": 0.4375,
                        "recall": 0.3181818181818182,
                        "f1-score": 0.3684210526315789,
                        "support": 22.0
                    },
                    "BEFORE": {
                        "precision": 0.2222222222222222,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.17391304347826086,
                        "support": 14.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 9.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2,
                    "macro avg": {
                        "precision": 0.16493055555555555,
                        "recall": 0.11525974025974026,
                        "f1-score": 0.13558352402745993,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.28302469135802466,
                        "recall": 0.2,
                        "f1-score": 0.2342232392575642,
                        "support": 45.0
                    }
                },
                "environment_2": {
                    "AFTER": {
                        "precision": 0.6666666666666666,
                        "recall": 0.38095238095238093,
                        "f1-score": 0.4848484848484849,
                        "support": 21.0
                    },
                    "BEFORE": {
                        "precision": 0.6,
                        "recall": 0.2608695652173913,
                        "f1-score": 0.36363636363636365,
                        "support": 23.0
                    },
                    "COEX": {
                        "precision": 0.05555555555555555,
                        "recall": 1.0,
                        "f1-score": 0.10526315789473684,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.3333333333333333,
                    "macro avg": {
                        "precision": 0.33055555555555555,
                        "recall": 0.41045548654244307,
                        "f1-score": 0.23843700159489636,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.6190123456790123,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.41446039340776186,
                        "support": 45.0
                    }
                },
                "weather_floods_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.4,
                        "recall": 0.2857142857142857,
                        "f1-score": 0.3333333333333333,
                        "support": 7.0
                    },
                    "COEX": {
                        "precision": 0.6,
                        "recall": 0.75,
                        "f1-score": 0.6666666666666665,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.3333333333333333,
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.2589285714285714,
                        "f1-score": 0.24999999999999994,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.3466666666666667,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.33333333333333326,
                        "support": 15.0
                    }
                },
                "sports_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 1.0,
                        "f1-score": 0.5,
                        "support": 1.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 3.0
                    },
                    "macro avg": {
                        "precision": 0.08333333333333333,
                        "recall": 0.25,
                        "f1-score": 0.125,
                        "support": 3.0
                    },
                    "weighted avg": {
                        "precision": 0.1111111111111111,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.16666666666666666,
                        "support": 3.0
                    }
                },
                "health_4": {
                    "AFTER": {
                        "precision": 0.16666666666666666,
                        "recall": 0.1111111111111111,
                        "f1-score": 0.13333333333333333,
                        "support": 9.0
                    },
                    "BEFORE": {
                        "precision": 0.2222222222222222,
                        "recall": 0.25,
                        "f1-score": 0.23529411764705882,
                        "support": 8.0
                    },
                    "COEX": {
                        "precision": 1.0,
                        "recall": 0.25,
                        "f1-score": 0.4,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.19047619047619047,
                    "macro avg": {
                        "precision": 0.3472222222222222,
                        "recall": 0.1527777777777778,
                        "f1-score": 0.19215686274509805,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.34656084656084657,
                        "recall": 0.19047619047619047,
                        "f1-score": 0.22296918767506999,
                        "support": 21.0
                    }
                },
                "weather_earthquakes_1": {
                    "AFTER": {
                        "precision": 0.09090909090909091,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.11764705882352942,
                        "support": 6.0
                    },
                    "BEFORE": {
                        "precision": 0.5384615384615384,
                        "recall": 0.21875,
                        "f1-score": 0.3111111111111111,
                        "support": 32.0
                    },
                    "COEX": {
                        "precision": 0.05555555555555555,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.08,
                        "support": 7.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2,
                    "macro avg": {
                        "precision": 0.17123154623154624,
                        "recall": 0.13206845238095238,
                        "f1-score": 0.12718954248366013,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.40366917033583705,
                        "recall": 0.2,
                        "f1-score": 0.24936528685548293,
                        "support": 45.0
                    }
                },
                "space_4": {
                    "AFTER": {
                        "precision": 0.4444444444444444,
                        "recall": 0.36363636363636365,
                        "f1-score": 0.39999999999999997,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.4444444444444444,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.33333333333333337,
                        "support": 15.0
                    },
                    "COEX": {
                        "precision": 0.1111111111111111,
                        "recall": 0.5,
                        "f1-score": 0.1818181818181818,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.32142857142857145,
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.2825757575757576,
                        "f1-score": 0.2287878787878788,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.42063492063492053,
                        "recall": 0.32142857142857145,
                        "f1-score": 0.3487012987012987,
                        "support": 28.0
                    }
                },
                "economy_and_business_strikes_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.6666666666666666,
                        "recall": 0.5,
                        "f1-score": 0.5714285714285715,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.3333333333333333,
                        "recall": 1.0,
                        "f1-score": 0.5,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.5,
                        "recall": 0.5,
                        "f1-score": 0.5,
                        "support": 6.0
                    },
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.375,
                        "f1-score": 0.2678571428571429,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.5,
                        "recall": 0.5,
                        "f1-score": 0.46428571428571436,
                        "support": 6.0
                    }
                },
                "politics_and_conflicts_armed_conflict_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.6,
                        "recall": 0.2727272727272727,
                        "f1-score": 0.37499999999999994,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.2,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.25,
                        "support": 3.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.26666666666666666,
                    "macro avg": {
                        "precision": 0.2,
                        "recall": 0.1515151515151515,
                        "f1-score": 0.15625,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.4799999999999999,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.32499999999999996,
                        "support": 15.0
                    }
                },
                "infectious_disease_4": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.25,
                        "f1-score": 0.25,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    }
                },
                "health_1": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.5,
                        "f1-score": 0.6666666666666666,
                        "support": 6.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.3,
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.125,
                        "f1-score": 0.16666666666666666,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.6,
                        "recall": 0.3,
                        "f1-score": 0.4,
                        "support": 10.0
                    }
                },
                "disasters_and_accidents_shipwreck_2": {
                    "AFTER": {
                        "precision": 0.8,
                        "recall": 0.36363636363636365,
                        "f1-score": 0.5000000000000001,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.25,
                        "recall": 0.2222222222222222,
                        "f1-score": 0.23529411764705882,
                        "support": 9.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2857142857142857,
                    "macro avg": {
                        "precision": 0.2625,
                        "recall": 0.14646464646464646,
                        "f1-score": 0.18382352941176472,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.5261904761904762,
                        "recall": 0.2857142857142857,
                        "f1-score": 0.36274509803921573,
                        "support": 21.0
                    }
                },
                "rail_transport_3": {
                    "AFTER": {
                        "precision": 0.2857142857142857,
                        "recall": 0.4,
                        "f1-score": 0.3333333333333333,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.5714285714285714,
                        "recall": 0.4,
                        "f1-score": 0.47058823529411764,
                        "support": 10.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.4,
                        "recall": 0.4,
                        "f1-score": 0.4000000000000001,
                        "support": 15.0
                    },
                    "macro avg": {
                        "precision": 0.21428571428571427,
                        "recall": 0.2,
                        "f1-score": 0.20098039215686275,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.47619047619047616,
                        "recall": 0.4,
                        "f1-score": 0.4248366013071896,
                        "support": 15.0
                    }
                },
                "weather_storms_1_extra": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    }
                },
                "health_1_extra": {
                    "AFTER": {
                        "precision": 0.2777777777777778,
                        "recall": 0.4166666666666667,
                        "f1-score": 0.33333333333333337,
                        "support": 12.0
                    },
                    "BEFORE": {
                        "precision": 0.4666666666666667,
                        "recall": 0.25,
                        "f1-score": 0.32558139534883723,
                        "support": 28.0
                    },
                    "COEX": {
                        "precision": 0.5,
                        "recall": 0.4,
                        "f1-score": 0.4444444444444445,
                        "support": 15.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.32727272727272727,
                    "macro avg": {
                        "precision": 0.3111111111111111,
                        "recall": 0.2666666666666667,
                        "f1-score": 0.27583979328165376,
                        "support": 55.0
                    },
                    "weighted avg": {
                        "precision": 0.4345454545454545,
                        "recall": 0.32727272727272727,
                        "f1-score": 0.35968992248062015,
                        "support": 55.0
                    }
                },
                "weather_floods_1": {
                    "AFTER": {
                        "precision": 0.11764705882352941,
                        "recall": 0.6666666666666666,
                        "f1-score": 0.2,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.25,
                        "recall": 0.125,
                        "f1-score": 0.16666666666666666,
                        "support": 24.0
                    },
                    "COEX": {
                        "precision": 0.42857142857142855,
                        "recall": 0.10714285714285714,
                        "f1-score": 0.17142857142857143,
                        "support": 28.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.14545454545454545,
                    "macro avg": {
                        "precision": 0.1990546218487395,
                        "recall": 0.22470238095238093,
                        "f1-score": 0.13452380952380955,
                        "support": 55.0
                    },
                    "weighted avg": {
                        "precision": 0.3336898395721925,
                        "recall": 0.14545454545454545,
                        "f1-score": 0.17090909090909087,
                        "support": 55.0
                    }
                },
                "mining_4": {
                    "AFTER": {
                        "precision": 0.09090909090909091,
                        "recall": 0.09090909090909091,
                        "f1-score": 0.09090909090909091,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.5882352941176471,
                        "recall": 0.4,
                        "f1-score": 0.4761904761904762,
                        "support": 25.0
                    },
                    "COEX": {
                        "precision": 0.21428571428571427,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.2608695652173913,
                        "support": 9.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.3111111111111111,
                    "macro avg": {
                        "precision": 0.22335752482811308,
                        "recall": 0.20606060606060606,
                        "f1-score": 0.20699228307923961,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.3918767507002801,
                        "recall": 0.3111111111111111,
                        "f1-score": 0.338946399815965,
                        "support": 45.0
                    }
                },
                "disasters_and_accidents_volcanoes_4": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.25,
                        "f1-score": 0.4,
                        "support": 20.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 14.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.1388888888888889,
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.0625,
                        "f1-score": 0.1,
                        "support": 36.0
                    },
                    "weighted avg": {
                        "precision": 0.5555555555555556,
                        "recall": 0.1388888888888889,
                        "f1-score": 0.2222222222222222,
                        "support": 36.0
                    }
                },
                "politics_and_conflicts_elections_3": {
                    "AFTER": {
                        "precision": 0.42857142857142855,
                        "recall": 0.6,
                        "f1-score": 0.5,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.5,
                        "f1-score": 0.5,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.5,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.4,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.4666666666666667,
                        "recall": 0.4666666666666667,
                        "f1-score": 0.4666666666666667,
                        "support": 15.0
                    },
                    "macro avg": {
                        "precision": 0.35714285714285715,
                        "recall": 0.35833333333333334,
                        "f1-score": 0.35,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.47619047619047616,
                        "recall": 0.4666666666666667,
                        "f1-score": 0.46,
                        "support": 15.0
                    }
                },
                "economy_and_business_strikes_3": {
                    "AFTER": {
                        "precision": 0.4,
                        "recall": 0.4,
                        "f1-score": 0.4000000000000001,
                        "support": 10.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.2727272727272727,
                        "f1-score": 0.3529411764705882,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.2,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.16666666666666666,
                        "support": 7.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2857142857142857,
                    "macro avg": {
                        "precision": 0.275,
                        "recall": 0.2038961038961039,
                        "f1-score": 0.2299019607843137,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.3892857142857143,
                        "recall": 0.2857142857142857,
                        "f1-score": 0.3231792717086835,
                        "support": 28.0
                    }
                },
                "space_2": {
                    "AFTER": {
                        "precision": 0.5238095238095238,
                        "recall": 0.11,
                        "f1-score": 0.18181818181818182,
                        "support": 100.0
                    },
                    "BEFORE": {
                        "precision": 0.2,
                        "recall": 0.0784313725490196,
                        "f1-score": 0.11267605633802816,
                        "support": 51.0
                    },
                    "COEX": {
                        "precision": 0.025,
                        "recall": 0.5,
                        "f1-score": 0.047619047619047616,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.10457516339869281,
                    "macro avg": {
                        "precision": 0.18720238095238098,
                        "recall": 0.1721078431372549,
                        "f1-score": 0.0855283214438144,
                        "support": 153.0
                    },
                    "weighted avg": {
                        "precision": 0.4093526299408653,
                        "recall": 0.10457516339869281,
                        "f1-score": 0.15701656960977592,
                        "support": 153.0
                    }
                },
                "politics_and_conflicts_resign_1": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.5,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 3.0
                    },
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.08333333333333333,
                        "f1-score": 0.125,
                        "support": 3.0
                    },
                    "weighted avg": {
                        "precision": 1.0,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.5,
                        "support": 3.0
                    }
                },
                "environment_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 0.4,
                        "f1-score": 0.3636363636363636,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.26666666666666666,
                    "macro avg": {
                        "precision": 0.16666666666666666,
                        "recall": 0.18333333333333335,
                        "f1-score": 0.17424242424242423,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.24444444444444444,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.2545454545454545,
                        "support": 15.0
                    }
                },
                "space_1_extra": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.6666666666666666,
                        "recall": 0.4,
                        "f1-score": 0.5,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 6.0
                    },
                    "macro avg": {
                        "precision": 0.16666666666666666,
                        "recall": 0.1,
                        "f1-score": 0.125,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.5555555555555555,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.4166666666666667,
                        "support": 6.0
                    }
                },
                "health_3": {
                    "AFTER": {
                        "precision": 0.2,
                        "recall": 0.125,
                        "f1-score": 0.15384615384615385,
                        "support": 8.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "COEX": {
                        "precision": 0.2,
                        "recall": 1.0,
                        "f1-score": 0.33333333333333337,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.13333333333333333,
                    "macro avg": {
                        "precision": 0.1,
                        "recall": 0.28125,
                        "f1-score": 0.1217948717948718,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.12000000000000001,
                        "recall": 0.13333333333333333,
                        "f1-score": 0.10427350427350429,
                        "support": 15.0
                    }
                },
                "environment_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.0,
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 15.0
                    }
                },
                "government_and_politics_protests_3": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.25,
                        "f1-score": 0.4,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 1.0,
                        "f1-score": 0.5,
                        "support": 1.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 6.0
                    },
                    "macro avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3125,
                        "f1-score": 0.225,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.7222222222222222,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.35000000000000003,
                        "support": 6.0
                    }
                },
                "economy_and_business_financial_crisis_4": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.4,
                        "support": 12.0
                    },
                    "BEFORE": {
                        "precision": 0.2,
                        "recall": 0.4,
                        "f1-score": 0.26666666666666666,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2857142857142857,
                    "macro avg": {
                        "precision": 0.175,
                        "recall": 0.18333333333333335,
                        "f1-score": 0.16666666666666669,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.2857142857142857,
                        "f1-score": 0.2920634920634921,
                        "support": 21.0
                    }
                },
                "computers_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    }
                },
                "crime_and_law_accuse_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.16666666666666666,
                        "recall": 0.2,
                        "f1-score": 0.1818181818181818,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.1,
                        "recall": 0.1,
                        "f1-score": 0.10000000000000002,
                        "support": 10.0
                    },
                    "macro avg": {
                        "precision": 0.041666666666666664,
                        "recall": 0.05,
                        "f1-score": 0.04545454545454545,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.08333333333333333,
                        "recall": 0.1,
                        "f1-score": 0.0909090909090909,
                        "support": 10.0
                    }
                },
                "culture_and_entertainment_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 0.5,
                        "f1-score": 0.4,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.3333333333333333,
                        "recall": 0.5,
                        "f1-score": 0.4,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 6.0
                    },
                    "macro avg": {
                        "precision": 0.16666666666666666,
                        "recall": 0.25,
                        "f1-score": 0.2,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.2222222222222222,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.26666666666666666,
                        "support": 6.0
                    }
                },
                "internet_2": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.2,
                        "f1-score": 0.33333333333333337,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.4,
                        "recall": 0.5,
                        "f1-score": 0.4444444444444445,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.3,
                        "recall": 0.3,
                        "f1-score": 0.3,
                        "support": 10.0
                    },
                    "macro avg": {
                        "precision": 0.35,
                        "recall": 0.175,
                        "f1-score": 0.19444444444444448,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.6599999999999999,
                        "recall": 0.3,
                        "f1-score": 0.34444444444444444,
                        "support": 10.0
                    }
                },
                "culture_and_entertainment_3": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.6,
                        "f1-score": 0.5454545454545454,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.4,
                        "recall": 0.5,
                        "f1-score": 0.4444444444444445,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.5,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.4,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.4666666666666667,
                        "recall": 0.4666666666666667,
                        "f1-score": 0.4666666666666667,
                        "support": 15.0
                    },
                    "macro avg": {
                        "precision": 0.35,
                        "recall": 0.35833333333333334,
                        "f1-score": 0.3474747474747475,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.47333333333333333,
                        "recall": 0.4666666666666667,
                        "f1-score": 0.4603367003367004,
                        "support": 15.0
                    }
                }
            },
            "qa_events": {
                "government_and_politics_riots_4": {
                    "AFTER": {
                        "precision": 0.14285714285714285,
                        "recall": 0.5,
                        "f1-score": 0.22222222222222224,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.4,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.23529411764705882,
                        "support": 12.0
                    },
                    "COEX": {
                        "precision": 0.3333333333333333,
                        "recall": 0.25,
                        "f1-score": 0.28571428571428575,
                        "support": 12.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.25,
                        "recall": 0.25,
                        "f1-score": 0.25,
                        "support": 28.0
                    },
                    "macro avg": {
                        "precision": 0.21904761904761905,
                        "recall": 0.22916666666666666,
                        "f1-score": 0.1858076563958917,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.3346938775510204,
                        "recall": 0.25,
                        "f1-score": 0.25503534747232226,
                        "support": 28.0
                    }
                },
                "rail_transport_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "BEFORE": {
                        "precision": 0.6666666666666666,
                        "recall": 0.11764705882352941,
                        "f1-score": 0.2,
                        "support": 34.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.1111111111111111,
                    "macro avg": {
                        "precision": 0.16666666666666666,
                        "recall": 0.029411764705882353,
                        "f1-score": 0.05,
                        "support": 36.0
                    },
                    "weighted avg": {
                        "precision": 0.6296296296296295,
                        "recall": 0.1111111111111111,
                        "f1-score": 0.1888888888888889,
                        "support": 36.0
                    }
                },
                "politics_and_conflicts_policy_change_2": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.6666666666666666,
                        "f1-score": 0.8,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.3333333333333333,
                        "recall": 1.0,
                        "f1-score": 0.5,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.5,
                        "recall": 0.5,
                        "f1-score": 0.5,
                        "support": 6.0
                    },
                    "macro avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.41666666666666663,
                        "f1-score": 0.325,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.5555555555555556,
                        "recall": 0.5,
                        "f1-score": 0.4833333333333334,
                        "support": 6.0
                    }
                },
                "politics_and_conflicts_drones_1": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.36363636363636365,
                        "f1-score": 0.5333333333333333,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.75,
                        "f1-score": 0.6,
                        "support": 8.0
                    },
                    "COEX": {
                        "precision": 0.2,
                        "recall": 0.5,
                        "f1-score": 0.28571428571428575,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.5238095238095238,
                        "recall": 0.5238095238095238,
                        "f1-score": 0.5238095238095238,
                        "support": 21.0
                    },
                    "macro avg": {
                        "precision": 0.425,
                        "recall": 0.40340909090909094,
                        "f1-score": 0.3547619047619048,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.7333333333333334,
                        "recall": 0.5238095238095238,
                        "f1-score": 0.5351473922902494,
                        "support": 21.0
                    }
                },
                "disasters_and_accidents_road_crash_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "BEFORE": {
                        "precision": 0.5833333333333334,
                        "recall": 0.6363636363636364,
                        "f1-score": 0.6086956521739131,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 1.0,
                        "recall": 0.3,
                        "f1-score": 0.4615384615384615,
                        "support": 10.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.47619047619047616,
                        "recall": 0.47619047619047616,
                        "f1-score": 0.47619047619047616,
                        "support": 21.0
                    },
                    "macro avg": {
                        "precision": 0.39583333333333337,
                        "recall": 0.23409090909090907,
                        "f1-score": 0.26755852842809363,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.7817460317460319,
                        "recall": 0.47619047619047616,
                        "f1-score": 0.5386207994903648,
                        "support": 21.0
                    }
                },
                "crime_and_law_accuse_3": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.5,
                        "f1-score": 0.5,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.2222222222222222,
                        "support": 6.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.3,
                        "recall": 0.3,
                        "f1-score": 0.3,
                        "support": 10.0
                    },
                    "macro avg": {
                        "precision": 0.20833333333333331,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.18055555555555555,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.4,
                        "recall": 0.3,
                        "f1-score": 0.3333333333333333,
                        "support": 10.0
                    }
                },
                "government_and_politics_protests_2": {
                    "AFTER": {
                        "precision": 0.16666666666666666,
                        "recall": 0.2,
                        "f1-score": 0.1818181818181818,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.6,
                        "recall": 0.15,
                        "f1-score": 0.24,
                        "support": 20.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.14285714285714285,
                    "macro avg": {
                        "precision": 0.19166666666666665,
                        "recall": 0.0875,
                        "f1-score": 0.10545454545454544,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.45833333333333337,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.20389610389610388,
                        "support": 28.0
                    }
                },
                "politics_and_conflicts_elections_2": {
                    "AFTER": {
                        "precision": 0.6666666666666666,
                        "recall": 0.36363636363636365,
                        "f1-score": 0.4705882352941177,
                        "support": 22.0
                    },
                    "BEFORE": {
                        "precision": 0.2,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.16666666666666666,
                        "support": 14.0
                    },
                    "COEX": {
                        "precision": 0.2857142857142857,
                        "recall": 0.2222222222222222,
                        "f1-score": 0.25,
                        "support": 9.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.26666666666666666,
                    "macro avg": {
                        "precision": 0.28809523809523807,
                        "recall": 0.1821789321789322,
                        "f1-score": 0.2218137254901961,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.4452910052910053,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.33191721132897606,
                        "support": 45.0
                    }
                },
                "environment_2": {
                    "AFTER": {
                        "precision": 0.3684210526315789,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.35,
                        "support": 21.0
                    },
                    "BEFORE": {
                        "precision": 0.2727272727272727,
                        "recall": 0.13043478260869565,
                        "f1-score": 0.1764705882352941,
                        "support": 23.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2222222222222222,
                    "macro avg": {
                        "precision": 0.16028708133971292,
                        "recall": 0.11594202898550723,
                        "f1-score": 0.1316176470588235,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.3113237639553429,
                        "recall": 0.2222222222222222,
                        "f1-score": 0.2535294117647059,
                        "support": 45.0
                    }
                },
                "weather_floods_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.6666666666666666,
                        "recall": 0.2857142857142857,
                        "f1-score": 0.4,
                        "support": 7.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.13333333333333333,
                    "macro avg": {
                        "precision": 0.16666666666666666,
                        "recall": 0.07142857142857142,
                        "f1-score": 0.1,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.31111111111111106,
                        "recall": 0.13333333333333333,
                        "f1-score": 0.18666666666666668,
                        "support": 15.0
                    }
                },
                "sports_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    }
                },
                "health_4": {
                    "AFTER": {
                        "precision": 0.75,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.46153846153846156,
                        "support": 9.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.375,
                        "f1-score": 0.5454545454545454,
                        "support": 8.0
                    },
                    "COEX": {
                        "precision": 0.3333333333333333,
                        "recall": 0.5,
                        "f1-score": 0.4,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.38095238095238093,
                    "macro avg": {
                        "precision": 0.5208333333333334,
                        "recall": 0.3020833333333333,
                        "f1-score": 0.35174825174825175,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.7658730158730158,
                        "recall": 0.38095238095238093,
                        "f1-score": 0.4817848817848817,
                        "support": 21.0
                    }
                },
                "weather_earthquakes_1": {
                    "AFTER": {
                        "precision": 0.1,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.125,
                        "support": 6.0
                    },
                    "BEFORE": {
                        "precision": 0.6923076923076923,
                        "recall": 0.28125,
                        "f1-score": 0.4,
                        "support": 32.0
                    },
                    "COEX": {
                        "precision": 0.1111111111111111,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.125,
                        "support": 7.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.24444444444444444,
                    "macro avg": {
                        "precision": 0.22585470085470083,
                        "recall": 0.14769345238095238,
                        "f1-score": 0.1625,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.5229249762583096,
                        "recall": 0.24444444444444444,
                        "f1-score": 0.3205555555555556,
                        "support": 45.0
                    }
                },
                "space_4": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.18181818181818182,
                        "f1-score": 0.26666666666666666,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.4444444444444444,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.33333333333333337,
                        "support": 15.0
                    },
                    "COEX": {
                        "precision": 0.3333333333333333,
                        "recall": 0.5,
                        "f1-score": 0.4,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.25,
                    "macro avg": {
                        "precision": 0.3194444444444444,
                        "recall": 0.23712121212121212,
                        "f1-score": 0.25,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.4583333333333333,
                        "recall": 0.25,
                        "f1-score": 0.31190476190476196,
                        "support": 28.0
                    }
                },
                "economy_and_business_strikes_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.6666666666666666,
                        "recall": 0.5,
                        "f1-score": 0.5714285714285715,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 6.0
                    },
                    "macro avg": {
                        "precision": 0.16666666666666666,
                        "recall": 0.125,
                        "f1-score": 0.14285714285714288,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.4444444444444444,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.380952380952381,
                        "support": 6.0
                    }
                },
                "politics_and_conflicts_armed_conflict_2": {
                    "AFTER": {
                        "precision": 0.1111111111111111,
                        "recall": 1.0,
                        "f1-score": 0.19999999999999998,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.09090909090909091,
                        "f1-score": 0.16666666666666669,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.13333333333333333,
                    "macro avg": {
                        "precision": 0.2777777777777778,
                        "recall": 0.2727272727272727,
                        "f1-score": 0.09166666666666667,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.7407407407407407,
                        "recall": 0.13333333333333333,
                        "f1-score": 0.13555555555555557,
                        "support": 15.0
                    }
                },
                "infectious_disease_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    }
                },
                "health_1": {
                    "AFTER": {
                        "precision": 0.6666666666666666,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.4444444444444444,
                        "support": 6.0
                    },
                    "BEFORE": {
                        "precision": 0.25,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.28571428571428575,
                        "support": 3.0
                    },
                    "COEX": {
                        "precision": 0.5,
                        "recall": 1.0,
                        "f1-score": 0.6666666666666666,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.4,
                    "macro avg": {
                        "precision": 0.35416666666666663,
                        "recall": 0.41666666666666663,
                        "f1-score": 0.3492063492063492,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.525,
                        "recall": 0.4,
                        "f1-score": 0.41904761904761906,
                        "support": 10.0
                    }
                },
                "disasters_and_accidents_shipwreck_2": {
                    "AFTER": {
                        "precision": 0.6,
                        "recall": 0.2727272727272727,
                        "f1-score": 0.37499999999999994,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.5555555555555556,
                        "recall": 0.5555555555555556,
                        "f1-score": 0.5555555555555556,
                        "support": 9.0
                    },
                    "COEX": {
                        "precision": 0.3333333333333333,
                        "recall": 1.0,
                        "f1-score": 0.5,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.42857142857142855,
                    "macro avg": {
                        "precision": 0.3722222222222222,
                        "recall": 0.45707070707070707,
                        "f1-score": 0.3576388888888889,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.5682539682539682,
                        "recall": 0.42857142857142855,
                        "f1-score": 0.4583333333333333,
                        "support": 21.0
                    }
                },
                "rail_transport_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.3,
                        "f1-score": 0.4615384615384615,
                        "support": 10.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2,
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.075,
                        "f1-score": 0.11538461538461538,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.6666666666666666,
                        "recall": 0.2,
                        "f1-score": 0.30769230769230765,
                        "support": 15.0
                    }
                },
                "weather_storms_1_extra": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    }
                },
                "health_1_extra": {
                    "AFTER": {
                        "precision": 0.1,
                        "recall": 0.08333333333333333,
                        "f1-score": 0.0909090909090909,
                        "support": 12.0
                    },
                    "BEFORE": {
                        "precision": 0.4444444444444444,
                        "recall": 0.2857142857142857,
                        "f1-score": 0.34782608695652173,
                        "support": 28.0
                    },
                    "COEX": {
                        "precision": 0.29411764705882354,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3125,
                        "support": 15.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2545454545454545,
                    "macro avg": {
                        "precision": 0.20964052287581697,
                        "recall": 0.17559523809523808,
                        "f1-score": 0.18780879446640314,
                        "support": 55.0
                    },
                    "weighted avg": {
                        "precision": 0.3282947118241235,
                        "recall": 0.2545454545454545,
                        "f1-score": 0.2821370822853036,
                        "support": 55.0
                    }
                },
                "weather_floods_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.375,
                        "recall": 0.25,
                        "f1-score": 0.3,
                        "support": 24.0
                    },
                    "COEX": {
                        "precision": 0.6666666666666666,
                        "recall": 0.2857142857142857,
                        "f1-score": 0.4,
                        "support": 28.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2545454545454545,
                    "macro avg": {
                        "precision": 0.26041666666666663,
                        "recall": 0.13392857142857142,
                        "f1-score": 0.175,
                        "support": 55.0
                    },
                    "weighted avg": {
                        "precision": 0.5030303030303029,
                        "recall": 0.2545454545454545,
                        "f1-score": 0.33454545454545453,
                        "support": 55.0
                    }
                },
                "mining_4": {
                    "AFTER": {
                        "precision": 0.1,
                        "recall": 0.09090909090909091,
                        "f1-score": 0.09523809523809525,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.5454545454545454,
                        "recall": 0.24,
                        "f1-score": 0.3333333333333333,
                        "support": 25.0
                    },
                    "COEX": {
                        "precision": 0.15789473684210525,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.21428571428571427,
                        "support": 9.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2222222222222222,
                    "macro avg": {
                        "precision": 0.20083732057416265,
                        "recall": 0.16606060606060608,
                        "f1-score": 0.1607142857142857,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.3590536948431685,
                        "recall": 0.2222222222222222,
                        "f1-score": 0.2513227513227513,
                        "support": 45.0
                    }
                },
                "disasters_and_accidents_volcanoes_4": {
                    "AFTER": {
                        "precision": 0.8333333333333334,
                        "recall": 0.5,
                        "f1-score": 0.625,
                        "support": 20.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 0.2857142857142857,
                        "f1-score": 0.30769230769230765,
                        "support": 14.0
                    },
                    "COEX": {
                        "precision": 0.16666666666666666,
                        "recall": 0.5,
                        "f1-score": 0.25,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.4166666666666667,
                    "macro avg": {
                        "precision": 0.33333333333333337,
                        "recall": 0.3214285714285714,
                        "f1-score": 0.2956730769230769,
                        "support": 36.0
                    },
                    "weighted avg": {
                        "precision": 0.6018518518518519,
                        "recall": 0.4166666666666667,
                        "f1-score": 0.4807692307692307,
                        "support": 36.0
                    }
                },
                "politics_and_conflicts_elections_3": {
                    "AFTER": {
                        "precision": 0.2857142857142857,
                        "recall": 0.4,
                        "f1-score": 0.3333333333333333,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.4,
                        "recall": 0.5,
                        "f1-score": 0.4444444444444445,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.3333333333333333,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.2222222222222222,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 15.0
                    },
                    "macro avg": {
                        "precision": 0.25476190476190474,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.25,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.3352380952380952,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.31851851851851853,
                        "support": 15.0
                    }
                },
                "economy_and_business_strikes_3": {
                    "AFTER": {
                        "precision": 0.25,
                        "recall": 0.1,
                        "f1-score": 0.14285714285714288,
                        "support": 10.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.2727272727272727,
                        "f1-score": 0.3529411764705882,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.2,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.16666666666666666,
                        "support": 7.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.17857142857142858,
                    "macro avg": {
                        "precision": 0.2375,
                        "recall": 0.1288961038961039,
                        "f1-score": 0.16561624649859943,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.33571428571428574,
                        "recall": 0.17857142857142858,
                        "f1-score": 0.23134253701480592,
                        "support": 28.0
                    }
                },
                "space_2": {
                    "AFTER": {
                        "precision": 0.5217391304347826,
                        "recall": 0.12,
                        "f1-score": 0.19512195121951217,
                        "support": 100.0
                    },
                    "BEFORE": {
                        "precision": 0.34615384615384615,
                        "recall": 0.17647058823529413,
                        "f1-score": 0.23376623376623376,
                        "support": 51.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.13725490196078433,
                    "macro avg": {
                        "precision": 0.21697324414715718,
                        "recall": 0.07411764705882354,
                        "f1-score": 0.10722204624643648,
                        "support": 153.0
                    },
                    "weighted avg": {
                        "precision": 0.45639058298904844,
                        "recall": 0.13725490196078433,
                        "f1-score": 0.2054527649936545,
                        "support": 153.0
                    }
                },
                "politics_and_conflicts_resign_1": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.6666666666666666,
                        "f1-score": 0.8,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.6666666666666666,
                        "recall": 0.6666666666666666,
                        "f1-score": 0.6666666666666666,
                        "support": 3.0
                    },
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.2,
                        "support": 3.0
                    },
                    "weighted avg": {
                        "precision": 1.0,
                        "recall": 0.6666666666666666,
                        "f1-score": 0.8000000000000002,
                        "support": 3.0
                    }
                },
                "environment_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 0.4,
                        "f1-score": 0.3636363636363636,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.13333333333333333,
                    "macro avg": {
                        "precision": 0.08333333333333333,
                        "recall": 0.1,
                        "f1-score": 0.0909090909090909,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.1111111111111111,
                        "recall": 0.13333333333333333,
                        "f1-score": 0.12121212121212119,
                        "support": 15.0
                    }
                },
                "space_1_extra": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.6,
                        "f1-score": 0.7499999999999999,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.5,
                        "recall": 0.5,
                        "f1-score": 0.5,
                        "support": 6.0
                    },
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.15,
                        "f1-score": 0.18749999999999997,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.8333333333333334,
                        "recall": 0.5,
                        "f1-score": 0.6249999999999999,
                        "support": 6.0
                    }
                },
                "health_3": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.125,
                        "f1-score": 0.2222222222222222,
                        "support": 8.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "COEX": {
                        "precision": 0.14285714285714285,
                        "recall": 1.0,
                        "f1-score": 0.25,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.13333333333333333,
                    "macro avg": {
                        "precision": 0.2857142857142857,
                        "recall": 0.28125,
                        "f1-score": 0.11805555555555555,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.5428571428571428,
                        "recall": 0.13333333333333333,
                        "f1-score": 0.13518518518518519,
                        "support": 15.0
                    }
                },
                "environment_3": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.36363636363636365,
                        "f1-score": 0.5333333333333333,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.26666666666666666,
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.09090909090909091,
                        "f1-score": 0.13333333333333333,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.7333333333333333,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.3911111111111111,
                        "support": 15.0
                    }
                },
                "government_and_politics_protests_3": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.5,
                        "f1-score": 0.6666666666666666,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 1.0,
                        "f1-score": 0.5,
                        "support": 1.0
                    },
                    "COEX": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.6666666666666666,
                        "recall": 0.6666666666666666,
                        "f1-score": 0.6666666666666666,
                        "support": 6.0
                    },
                    "macro avg": {
                        "precision": 0.5833333333333333,
                        "recall": 0.625,
                        "f1-score": 0.5416666666666666,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.8888888888888888,
                        "recall": 0.6666666666666666,
                        "f1-score": 0.6944444444444443,
                        "support": 6.0
                    }
                },
                "economy_and_business_financial_crisis_4": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.25,
                        "f1-score": 0.3333333333333333,
                        "support": 12.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.2857142857142857,
                        "recall": 0.5,
                        "f1-score": 0.36363636363636365,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.23809523809523808,
                    "macro avg": {
                        "precision": 0.19642857142857142,
                        "recall": 0.1875,
                        "f1-score": 0.17424242424242425,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.3401360544217687,
                        "recall": 0.23809523809523808,
                        "f1-score": 0.25974025974025977,
                        "support": 21.0
                    }
                },
                "computers_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    }
                },
                "crime_and_law_accuse_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.2,
                        "f1-score": 0.33333333333333337,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.1,
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.05,
                        "f1-score": 0.08333333333333334,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.5,
                        "recall": 0.1,
                        "f1-score": 0.16666666666666669,
                        "support": 10.0
                    }
                },
                "culture_and_entertainment_1": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.5,
                        "f1-score": 0.5,
                        "support": 2.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.5,
                        "recall": 0.5,
                        "f1-score": 0.5,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 6.0
                    },
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.25,
                        "f1-score": 0.25,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 6.0
                    }
                },
                "internet_2": {
                    "AFTER": {
                        "precision": 0.6666666666666666,
                        "recall": 0.4,
                        "f1-score": 0.5,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 0.5,
                        "f1-score": 0.4,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.4,
                        "recall": 0.4,
                        "f1-score": 0.4000000000000001,
                        "support": 10.0
                    },
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.225,
                        "f1-score": 0.225,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.4666666666666666,
                        "recall": 0.4,
                        "f1-score": 0.41,
                        "support": 10.0
                    }
                },
                "culture_and_entertainment_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.375,
                        "recall": 0.5,
                        "f1-score": 0.42857142857142855,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.2,
                        "recall": 0.2,
                        "f1-score": 0.20000000000000004,
                        "support": 15.0
                    },
                    "macro avg": {
                        "precision": 0.09375,
                        "recall": 0.125,
                        "f1-score": 0.10714285714285714,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.15,
                        "recall": 0.2,
                        "f1-score": 0.1714285714285714,
                        "support": 15.0
                    }
                }
            },
            "refer": {
                "government_and_politics_riots_4": {
                    "AFTER": {
                        "precision": 0.1111111111111111,
                        "recall": 0.25,
                        "f1-score": 0.15384615384615383,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.25,
                        "recall": 0.08333333333333333,
                        "f1-score": 0.125,
                        "support": 12.0
                    },
                    "COEX": {
                        "precision": 0.5555555555555556,
                        "recall": 0.4166666666666667,
                        "f1-score": 0.4761904761904762,
                        "support": 12.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.25,
                    "macro avg": {
                        "precision": 0.22916666666666669,
                        "recall": 0.1875,
                        "f1-score": 0.1887591575091575,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.3611111111111111,
                        "recall": 0.25,
                        "f1-score": 0.2796310832025118,
                        "support": 28.0
                    }
                },
                "rail_transport_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "BEFORE": {
                        "precision": 0.9166666666666666,
                        "recall": 0.3235294117647059,
                        "f1-score": 0.4782608695652174,
                        "support": 34.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.3055555555555556,
                    "macro avg": {
                        "precision": 0.22916666666666666,
                        "recall": 0.08088235294117647,
                        "f1-score": 0.11956521739130435,
                        "support": 36.0
                    },
                    "weighted avg": {
                        "precision": 0.8657407407407407,
                        "recall": 0.3055555555555556,
                        "f1-score": 0.45169082125603865,
                        "support": 36.0
                    }
                },
                "politics_and_conflicts_policy_change_2": {
                    "AFTER": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.16666666666666666,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.16666666666666666,
                        "support": 6.0
                    },
                    "macro avg": {
                        "precision": 0.08333333333333333,
                        "recall": 0.08333333333333333,
                        "f1-score": 0.08333333333333333,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.16666666666666666,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.16666666666666666,
                        "support": 6.0
                    }
                },
                "politics_and_conflicts_drones_1": {
                    "AFTER": {
                        "precision": 0.75,
                        "recall": 0.2727272727272727,
                        "f1-score": 0.39999999999999997,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 8.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.14285714285714285,
                    "macro avg": {
                        "precision": 0.1875,
                        "recall": 0.06818181818181818,
                        "f1-score": 0.09999999999999999,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.39285714285714285,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.2095238095238095,
                        "support": 21.0
                    }
                },
                "disasters_and_accidents_road_crash_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.5,
                        "recall": 0.4,
                        "f1-score": 0.4444444444444445,
                        "support": 10.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.19047619047619047,
                    "macro avg": {
                        "precision": 0.125,
                        "recall": 0.1,
                        "f1-score": 0.11111111111111112,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.23809523809523808,
                        "recall": 0.19047619047619047,
                        "f1-score": 0.21164021164021166,
                        "support": 21.0
                    }
                },
                "crime_and_law_accuse_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.6666666666666666,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.4444444444444444,
                        "support": 6.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2,
                    "macro avg": {
                        "precision": 0.16666666666666666,
                        "recall": 0.08333333333333333,
                        "f1-score": 0.1111111111111111,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.4,
                        "recall": 0.2,
                        "f1-score": 0.26666666666666666,
                        "support": 10.0
                    }
                },
                "government_and_politics_protests_2": {
                    "AFTER": {
                        "precision": 0.16666666666666666,
                        "recall": 0.2,
                        "f1-score": 0.1818181818181818,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.1,
                        "f1-score": 0.16666666666666669,
                        "support": 20.0
                    },
                    "COEX": {
                        "precision": 0.18181818181818182,
                        "recall": 0.6666666666666666,
                        "f1-score": 0.28571428571428575,
                        "support": 3.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.17857142857142858,
                    "macro avg": {
                        "precision": 0.2121212121212121,
                        "recall": 0.24166666666666667,
                        "f1-score": 0.15854978354978355,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.4063852813852814,
                        "recall": 0.17857142857142858,
                        "f1-score": 0.1821273964131107,
                        "support": 28.0
                    }
                },
                "politics_and_conflicts_elections_2": {
                    "AFTER": {
                        "precision": 0.8,
                        "recall": 0.18181818181818182,
                        "f1-score": 0.2962962962962963,
                        "support": 22.0
                    },
                    "BEFORE": {
                        "precision": 0.36363636363636365,
                        "recall": 0.2857142857142857,
                        "f1-score": 0.32,
                        "support": 14.0
                    },
                    "COEX": {
                        "precision": 0.25,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.28571428571428575,
                        "support": 9.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.24444444444444444,
                    "macro avg": {
                        "precision": 0.3534090909090909,
                        "recall": 0.2002164502164502,
                        "f1-score": 0.22550264550264554,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.5542424242424242,
                        "recall": 0.24444444444444444,
                        "f1-score": 0.301554379776602,
                        "support": 45.0
                    }
                },
                "environment_2": {
                    "AFTER": {
                        "precision": 0.47058823529411764,
                        "recall": 0.38095238095238093,
                        "f1-score": 0.42105263157894735,
                        "support": 21.0
                    },
                    "BEFORE": {
                        "precision": 0.38461538461538464,
                        "recall": 0.21739130434782608,
                        "f1-score": 0.27777777777777773,
                        "support": 23.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.28888888888888886,
                    "macro avg": {
                        "precision": 0.21380090497737558,
                        "recall": 0.14958592132505175,
                        "f1-score": 0.17470760233918126,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.4161890397184515,
                        "recall": 0.28888888888888886,
                        "f1-score": 0.3384665367121507,
                        "support": 45.0
                    }
                },
                "weather_floods_3": {
                    "AFTER": {
                        "precision": 0.14285714285714285,
                        "recall": 0.25,
                        "f1-score": 0.18181818181818182,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 7.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.06666666666666667,
                    "macro avg": {
                        "precision": 0.03571428571428571,
                        "recall": 0.0625,
                        "f1-score": 0.045454545454545456,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.03809523809523809,
                        "recall": 0.06666666666666667,
                        "f1-score": 0.048484848484848485,
                        "support": 15.0
                    }
                },
                "sports_1": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 2.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.6666666666666666,
                        "recall": 0.6666666666666666,
                        "f1-score": 0.6666666666666666,
                        "support": 3.0
                    },
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.25,
                        "f1-score": 0.25,
                        "support": 3.0
                    },
                    "weighted avg": {
                        "precision": 0.6666666666666666,
                        "recall": 0.6666666666666666,
                        "f1-score": 0.6666666666666666,
                        "support": 3.0
                    }
                },
                "health_4": {
                    "AFTER": {
                        "precision": 0.25,
                        "recall": 0.1111111111111111,
                        "f1-score": 0.15384615384615383,
                        "support": 9.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.375,
                        "f1-score": 0.42857142857142855,
                        "support": 8.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.19047619047619047,
                    "macro avg": {
                        "precision": 0.1875,
                        "recall": 0.12152777777777778,
                        "f1-score": 0.1456043956043956,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.2976190476190476,
                        "recall": 0.19047619047619047,
                        "f1-score": 0.22919937205651492,
                        "support": 21.0
                    }
                },
                "weather_earthquakes_1": {
                    "AFTER": {
                        "precision": 0.1,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.125,
                        "support": 6.0
                    },
                    "BEFORE": {
                        "precision": 0.5833333333333334,
                        "recall": 0.21875,
                        "f1-score": 0.31818181818181823,
                        "support": 32.0
                    },
                    "COEX": {
                        "precision": 0.09090909090909091,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.1111111111111111,
                        "support": 7.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2,
                    "macro avg": {
                        "precision": 0.19356060606060607,
                        "recall": 0.13206845238095238,
                        "f1-score": 0.13857323232323232,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.44228956228956234,
                        "recall": 0.2,
                        "f1-score": 0.26021324354657693,
                        "support": 45.0
                    }
                },
                "space_4": {
                    "AFTER": {
                        "precision": 0.42857142857142855,
                        "recall": 0.2727272727272727,
                        "f1-score": 0.33333333333333326,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.5833333333333334,
                        "recall": 0.4666666666666667,
                        "f1-score": 0.5185185185185186,
                        "support": 15.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.35714285714285715,
                    "macro avg": {
                        "precision": 0.25297619047619047,
                        "recall": 0.18484848484848485,
                        "f1-score": 0.21296296296296297,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.48086734693877553,
                        "recall": 0.35714285714285715,
                        "f1-score": 0.4087301587301587,
                        "support": 28.0
                    }
                },
                "economy_and_business_strikes_2": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 1.0,
                        "f1-score": 0.6666666666666666,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.6666666666666666,
                        "recall": 0.5,
                        "f1-score": 0.5714285714285715,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.5,
                    "macro avg": {
                        "precision": 0.29166666666666663,
                        "recall": 0.375,
                        "f1-score": 0.30952380952380953,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.5277777777777778,
                        "recall": 0.5,
                        "f1-score": 0.4920634920634921,
                        "support": 6.0
                    }
                },
                "politics_and_conflicts_armed_conflict_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.09090909090909091,
                        "f1-score": 0.15384615384615385,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.06666666666666667,
                    "macro avg": {
                        "precision": 0.125,
                        "recall": 0.022727272727272728,
                        "f1-score": 0.038461538461538464,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.36666666666666664,
                        "recall": 0.06666666666666667,
                        "f1-score": 0.11282051282051284,
                        "support": 15.0
                    }
                },
                "infectious_disease_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    }
                },
                "health_1": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.4,
                        "support": 6.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.2,
                        "recall": 0.2,
                        "f1-score": 0.20000000000000004,
                        "support": 10.0
                    },
                    "macro avg": {
                        "precision": 0.125,
                        "recall": 0.08333333333333333,
                        "f1-score": 0.1,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.3,
                        "recall": 0.2,
                        "f1-score": 0.24000000000000005,
                        "support": 10.0
                    }
                },
                "disasters_and_accidents_shipwreck_2": {
                    "AFTER": {
                        "precision": 0.3333333333333333,
                        "recall": 0.18181818181818182,
                        "f1-score": 0.23529411764705885,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.25,
                        "recall": 0.1111111111111111,
                        "f1-score": 0.15384615384615383,
                        "support": 9.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.14285714285714285,
                    "macro avg": {
                        "precision": 0.14583333333333331,
                        "recall": 0.07323232323232323,
                        "f1-score": 0.09728506787330317,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.28174603174603174,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.18918336565395388,
                        "support": 21.0
                    }
                },
                "rail_transport_3": {
                    "AFTER": {
                        "precision": 0.375,
                        "recall": 0.6,
                        "f1-score": 0.4615384615384615,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.6666666666666666,
                        "recall": 0.2,
                        "f1-score": 0.30769230769230765,
                        "support": 10.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 15.0
                    },
                    "macro avg": {
                        "precision": 0.26041666666666663,
                        "recall": 0.2,
                        "f1-score": 0.1923076923076923,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.5694444444444444,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3589743589743589,
                        "support": 15.0
                    }
                },
                "weather_storms_1_extra": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    }
                },
                "health_1_extra": {
                    "AFTER": {
                        "precision": 0.3,
                        "recall": 0.25,
                        "f1-score": 0.2727272727272727,
                        "support": 12.0
                    },
                    "BEFORE": {
                        "precision": 0.6,
                        "recall": 0.21428571428571427,
                        "f1-score": 0.3157894736842105,
                        "support": 28.0
                    },
                    "COEX": {
                        "precision": 0.4,
                        "recall": 0.5333333333333333,
                        "f1-score": 0.4571428571428572,
                        "support": 15.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.3090909090909091,
                    "macro avg": {
                        "precision": 0.32499999999999996,
                        "recall": 0.2494047619047619,
                        "f1-score": 0.2614149008885851,
                        "support": 55.0
                    },
                    "weighted avg": {
                        "precision": 0.48,
                        "recall": 0.3090909090909091,
                        "f1-score": 0.3449450071459641,
                        "support": 55.0
                    }
                },
                "weather_floods_1": {
                    "AFTER": {
                        "precision": 0.058823529411764705,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.1,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.7142857142857143,
                        "recall": 0.4166666666666667,
                        "f1-score": 0.5263157894736842,
                        "support": 24.0
                    },
                    "COEX": {
                        "precision": 0.6666666666666666,
                        "recall": 0.35714285714285715,
                        "f1-score": 0.46511627906976744,
                        "support": 28.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.38181818181818183,
                    "macro avg": {
                        "precision": 0.3599439775910364,
                        "recall": 0.2767857142857143,
                        "f1-score": 0.2728580171358629,
                        "support": 55.0
                    },
                    "weighted avg": {
                        "precision": 0.6542908072319836,
                        "recall": 0.38181818181818183,
                        "f1-score": 0.4719060865694893,
                        "support": 55.0
                    }
                },
                "mining_4": {
                    "AFTER": {
                        "precision": 0.21428571428571427,
                        "recall": 0.2727272727272727,
                        "f1-score": 0.23999999999999996,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.6,
                        "recall": 0.12,
                        "f1-score": 0.19999999999999998,
                        "support": 25.0
                    },
                    "COEX": {
                        "precision": 0.1111111111111111,
                        "recall": 0.1111111111111111,
                        "f1-score": 0.1111111111111111,
                        "support": 9.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.15555555555555556,
                    "macro avg": {
                        "precision": 0.23134920634920636,
                        "recall": 0.12595959595959594,
                        "f1-score": 0.13777777777777778,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.40793650793650793,
                        "recall": 0.15555555555555556,
                        "f1-score": 0.192,
                        "support": 45.0
                    }
                },
                "disasters_and_accidents_volcanoes_4": {
                    "AFTER": {
                        "precision": 0.5555555555555556,
                        "recall": 0.25,
                        "f1-score": 0.3448275862068966,
                        "support": 20.0
                    },
                    "BEFORE": {
                        "precision": 0.25,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.18181818181818182,
                        "support": 14.0
                    },
                    "COEX": {
                        "precision": 0.1,
                        "recall": 0.5,
                        "f1-score": 0.16666666666666669,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2222222222222222,
                    "macro avg": {
                        "precision": 0.2263888888888889,
                        "recall": 0.2232142857142857,
                        "f1-score": 0.1733281086729363,
                        "support": 36.0
                    },
                    "weighted avg": {
                        "precision": 0.4114197530864197,
                        "recall": 0.2222222222222222,
                        "f1-score": 0.27153721119238367,
                        "support": 36.0
                    }
                },
                "politics_and_conflicts_elections_3": {
                    "AFTER": {
                        "precision": 0.3333333333333333,
                        "recall": 0.2,
                        "f1-score": 0.25,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.2,
                        "recall": 0.25,
                        "f1-score": 0.22222222222222224,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.5,
                        "recall": 0.5,
                        "f1-score": 0.5,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.3333333333333333,
                    "macro avg": {
                        "precision": 0.2583333333333333,
                        "recall": 0.2375,
                        "f1-score": 0.24305555555555555,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.36444444444444446,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3425925925925926,
                        "support": 15.0
                    }
                },
                "economy_and_business_strikes_3": {
                    "AFTER": {
                        "precision": 0.42857142857142855,
                        "recall": 0.3,
                        "f1-score": 0.3529411764705882,
                        "support": 10.0
                    },
                    "BEFORE": {
                        "precision": 0.42857142857142855,
                        "recall": 0.2727272727272727,
                        "f1-score": 0.33333333333333326,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.3333333333333333,
                        "recall": 0.42857142857142855,
                        "f1-score": 0.375,
                        "support": 7.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.32142857142857145,
                    "macro avg": {
                        "precision": 0.2976190476190476,
                        "recall": 0.25032467532467534,
                        "f1-score": 0.26531862745098034,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.4047619047619047,
                        "recall": 0.32142857142857145,
                        "f1-score": 0.35075280112044815,
                        "support": 28.0
                    }
                },
                "space_2": {
                    "AFTER": {
                        "precision": 0.7272727272727273,
                        "recall": 0.16,
                        "f1-score": 0.2622950819672131,
                        "support": 100.0
                    },
                    "BEFORE": {
                        "precision": 0.3684210526315789,
                        "recall": 0.13725490196078433,
                        "f1-score": 0.2,
                        "support": 51.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.1503267973856209,
                    "macro avg": {
                        "precision": 0.27392344497607657,
                        "recall": 0.07431372549019608,
                        "f1-score": 0.11557377049180327,
                        "support": 153.0
                    },
                    "weighted avg": {
                        "precision": 0.5981486693560997,
                        "recall": 0.1503267973856209,
                        "f1-score": 0.23810136076288438,
                        "support": 153.0
                    }
                },
                "politics_and_conflicts_resign_1": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.5,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 3.0
                    },
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.08333333333333333,
                        "f1-score": 0.125,
                        "support": 3.0
                    },
                    "weighted avg": {
                        "precision": 1.0,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.5,
                        "support": 3.0
                    }
                },
                "environment_4": {
                    "AFTER": {
                        "precision": 0.4,
                        "recall": 0.5,
                        "f1-score": 0.4444444444444445,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 0.4,
                        "f1-score": 0.3636363636363636,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.5,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.25,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.3333333333333333,
                    "macro avg": {
                        "precision": 0.30833333333333335,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.264520202020202,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.41777777777777775,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3397306397306397,
                        "support": 15.0
                    }
                },
                "space_1_extra": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.6,
                        "f1-score": 0.7499999999999999,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.5,
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.15,
                        "f1-score": 0.18749999999999997,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.8333333333333334,
                        "recall": 0.5,
                        "f1-score": 0.6249999999999999,
                        "support": 6.0
                    }
                },
                "health_3": {
                    "AFTER": {
                        "precision": 0.25,
                        "recall": 0.125,
                        "f1-score": 0.16666666666666666,
                        "support": 8.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.06666666666666667,
                    "macro avg": {
                        "precision": 0.0625,
                        "recall": 0.03125,
                        "f1-score": 0.041666666666666664,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.13333333333333333,
                        "recall": 0.06666666666666667,
                        "f1-score": 0.08888888888888888,
                        "support": 15.0
                    }
                },
                "environment_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.0,
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 15.0
                    }
                },
                "government_and_politics_protests_3": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.5,
                        "f1-score": 0.5,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.3333333333333333,
                    "macro avg": {
                        "precision": 0.125,
                        "recall": 0.125,
                        "f1-score": 0.125,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 6.0
                    }
                },
                "economy_and_business_financial_crisis_4": {
                    "AFTER": {
                        "precision": 0.3333333333333333,
                        "recall": 0.08333333333333333,
                        "f1-score": 0.13333333333333333,
                        "support": 12.0
                    },
                    "BEFORE": {
                        "precision": 0.2857142857142857,
                        "recall": 0.4,
                        "f1-score": 0.3333333333333333,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.25,
                        "recall": 0.5,
                        "f1-score": 0.3333333333333333,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.23809523809523808,
                    "macro avg": {
                        "precision": 0.21726190476190477,
                        "recall": 0.24583333333333335,
                        "f1-score": 0.2,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.30612244897959184,
                        "recall": 0.23809523809523808,
                        "f1-score": 0.21904761904761902,
                        "support": 21.0
                    }
                },
                "computers_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    }
                },
                "crime_and_law_accuse_4": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.2,
                        "f1-score": 0.28571428571428575,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.75,
                        "recall": 0.6,
                        "f1-score": 0.6666666666666665,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.4,
                    "macro avg": {
                        "precision": 0.3125,
                        "recall": 0.2,
                        "f1-score": 0.23809523809523808,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.625,
                        "recall": 0.4,
                        "f1-score": 0.4761904761904761,
                        "support": 10.0
                    }
                },
                "culture_and_entertainment_1": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.5,
                        "f1-score": 0.5,
                        "support": 2.0
                    },
                    "BEFORE": {
                        "precision": 0.6666666666666666,
                        "recall": 1.0,
                        "f1-score": 0.8,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 1.0,
                        "recall": 0.5,
                        "f1-score": 0.6666666666666666,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.6666666666666666,
                        "recall": 0.6666666666666666,
                        "f1-score": 0.6666666666666666,
                        "support": 6.0
                    },
                    "macro avg": {
                        "precision": 0.5416666666666666,
                        "recall": 0.5,
                        "f1-score": 0.4916666666666667,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.7222222222222222,
                        "recall": 0.6666666666666666,
                        "f1-score": 0.6555555555555556,
                        "support": 6.0
                    }
                },
                "internet_2": {
                    "AFTER": {
                        "precision": 0.3333333333333333,
                        "recall": 0.2,
                        "f1-score": 0.25,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 0.25,
                        "f1-score": 0.28571428571428575,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.2,
                        "recall": 0.2,
                        "f1-score": 0.20000000000000004,
                        "support": 10.0
                    },
                    "macro avg": {
                        "precision": 0.16666666666666666,
                        "recall": 0.1125,
                        "f1-score": 0.13392857142857145,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.3,
                        "recall": 0.2,
                        "f1-score": 0.23928571428571432,
                        "support": 10.0
                    }
                },
                "culture_and_entertainment_3": {
                    "AFTER": {
                        "precision": 0.2857142857142857,
                        "recall": 0.4,
                        "f1-score": 0.3333333333333333,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.5,
                        "f1-score": 0.6666666666666666,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.4,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3636363636363636,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.4,
                    "macro avg": {
                        "precision": 0.4214285714285714,
                        "recall": 0.30833333333333335,
                        "f1-score": 0.3409090909090909,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.521904761904762,
                        "recall": 0.4,
                        "f1-score": 0.4343434343434343,
                        "support": 15.0
                    }
                }
            },
            "refer_events": {
                "government_and_politics_riots_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.6666666666666666,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.4444444444444444,
                        "support": 12.0
                    },
                    "COEX": {
                        "precision": 0.5,
                        "recall": 0.25,
                        "f1-score": 0.3333333333333333,
                        "support": 12.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.25,
                    "macro avg": {
                        "precision": 0.29166666666666663,
                        "recall": 0.14583333333333331,
                        "f1-score": 0.19444444444444442,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.5,
                        "recall": 0.25,
                        "f1-score": 0.3333333333333333,
                        "support": 28.0
                    }
                },
                "rail_transport_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.4411764705882353,
                        "f1-score": 0.6122448979591837,
                        "support": 34.0
                    },
                    "COEX": {
                        "precision": 0.3333333333333333,
                        "recall": 1.0,
                        "f1-score": 0.5,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.4722222222222222,
                    "macro avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3602941176470588,
                        "f1-score": 0.2780612244897959,
                        "support": 36.0
                    },
                    "weighted avg": {
                        "precision": 0.9629629629629629,
                        "recall": 0.4722222222222222,
                        "f1-score": 0.6060090702947846,
                        "support": 36.0
                    }
                },
                "politics_and_conflicts_policy_change_2": {
                    "AFTER": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 0.5,
                        "f1-score": 0.4,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 6.0
                    },
                    "macro avg": {
                        "precision": 0.16666666666666666,
                        "recall": 0.20833333333333331,
                        "f1-score": 0.18333333333333335,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.27777777777777773,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3,
                        "support": 6.0
                    }
                },
                "politics_and_conflicts_drones_1": {
                    "AFTER": {
                        "precision": 0.375,
                        "recall": 0.2727272727272727,
                        "f1-score": 0.3157894736842105,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.25,
                        "recall": 0.25,
                        "f1-score": 0.25,
                        "support": 8.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.23809523809523808,
                    "macro avg": {
                        "precision": 0.15625,
                        "recall": 0.13068181818181818,
                        "f1-score": 0.14144736842105263,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.2916666666666667,
                        "recall": 0.23809523809523808,
                        "f1-score": 0.2606516290726817,
                        "support": 21.0
                    }
                },
                "disasters_and_accidents_road_crash_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "BEFORE": {
                        "precision": 0.7142857142857143,
                        "recall": 0.45454545454545453,
                        "f1-score": 0.5555555555555556,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.5,
                        "recall": 0.2,
                        "f1-score": 0.28571428571428575,
                        "support": 10.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.3333333333333333,
                    "macro avg": {
                        "precision": 0.3035714285714286,
                        "recall": 0.16363636363636364,
                        "f1-score": 0.21031746031746035,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.6122448979591837,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.4270597127739985,
                        "support": 21.0
                    }
                },
                "crime_and_law_accuse_3": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.5,
                        "f1-score": 0.5,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.5,
                        "f1-score": 0.6666666666666666,
                        "support": 6.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.5,
                        "recall": 0.5,
                        "f1-score": 0.5,
                        "support": 10.0
                    },
                    "macro avg": {
                        "precision": 0.375,
                        "recall": 0.25,
                        "f1-score": 0.29166666666666663,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.8,
                        "recall": 0.5,
                        "f1-score": 0.6,
                        "support": 10.0
                    }
                },
                "government_and_politics_protests_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.8,
                        "recall": 0.4,
                        "f1-score": 0.5333333333333333,
                        "support": 20.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2857142857142857,
                    "macro avg": {
                        "precision": 0.2,
                        "recall": 0.1,
                        "f1-score": 0.13333333333333333,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.5714285714285714,
                        "recall": 0.2857142857142857,
                        "f1-score": 0.38095238095238093,
                        "support": 28.0
                    }
                },
                "politics_and_conflicts_elections_2": {
                    "AFTER": {
                        "precision": 0.4,
                        "recall": 0.18181818181818182,
                        "f1-score": 0.25000000000000006,
                        "support": 22.0
                    },
                    "BEFORE": {
                        "precision": 0.38461538461538464,
                        "recall": 0.35714285714285715,
                        "f1-score": 0.3703703703703704,
                        "support": 14.0
                    },
                    "COEX": {
                        "precision": 0.21428571428571427,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.2608695652173913,
                        "support": 9.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.26666666666666666,
                    "macro avg": {
                        "precision": 0.24972527472527475,
                        "recall": 0.21807359307359309,
                        "f1-score": 0.22030998389694045,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.3580708180708181,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.28962247271426017,
                        "support": 45.0
                    }
                },
                "environment_2": {
                    "AFTER": {
                        "precision": 0.6666666666666666,
                        "recall": 0.47619047619047616,
                        "f1-score": 0.5555555555555556,
                        "support": 21.0
                    },
                    "BEFORE": {
                        "precision": 0.75,
                        "recall": 0.391304347826087,
                        "f1-score": 0.5142857142857143,
                        "support": 23.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.4222222222222222,
                    "macro avg": {
                        "precision": 0.35416666666666663,
                        "recall": 0.2168737060041408,
                        "f1-score": 0.2674603174603175,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.6944444444444444,
                        "recall": 0.4222222222222222,
                        "f1-score": 0.5221164021164022,
                        "support": 45.0
                    }
                },
                "weather_floods_3": {
                    "AFTER": {
                        "precision": 0.2,
                        "recall": 0.5,
                        "f1-score": 0.28571428571428575,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 7.0
                    },
                    "COEX": {
                        "precision": 0.25,
                        "recall": 0.25,
                        "f1-score": 0.25,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.2,
                        "recall": 0.2,
                        "f1-score": 0.20000000000000004,
                        "support": 15.0
                    },
                    "macro avg": {
                        "precision": 0.1125,
                        "recall": 0.1875,
                        "f1-score": 0.13392857142857145,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.12000000000000001,
                        "recall": 0.2,
                        "f1-score": 0.14285714285714288,
                        "support": 15.0
                    }
                },
                "sports_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 1.0,
                        "f1-score": 0.5,
                        "support": 1.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 3.0
                    },
                    "macro avg": {
                        "precision": 0.08333333333333333,
                        "recall": 0.25,
                        "f1-score": 0.125,
                        "support": 3.0
                    },
                    "weighted avg": {
                        "precision": 0.1111111111111111,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.16666666666666666,
                        "support": 3.0
                    }
                },
                "health_4": {
                    "AFTER": {
                        "precision": 0.2,
                        "recall": 0.1111111111111111,
                        "f1-score": 0.14285714285714285,
                        "support": 9.0
                    },
                    "BEFORE": {
                        "precision": 0.7142857142857143,
                        "recall": 0.625,
                        "f1-score": 0.6666666666666666,
                        "support": 8.0
                    },
                    "COEX": {
                        "precision": 0.1111111111111111,
                        "recall": 0.25,
                        "f1-score": 0.15384615384615383,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 21.0
                    },
                    "macro avg": {
                        "precision": 0.2563492063492064,
                        "recall": 0.2465277777777778,
                        "f1-score": 0.24084249084249085,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.37898715041572184,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3444967730682016,
                        "support": 21.0
                    }
                },
                "weather_earthquakes_1": {
                    "AFTER": {
                        "precision": 0.1111111111111111,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.13333333333333333,
                        "support": 6.0
                    },
                    "BEFORE": {
                        "precision": 0.7333333333333333,
                        "recall": 0.34375,
                        "f1-score": 0.4680851063829787,
                        "support": 32.0
                    },
                    "COEX": {
                        "precision": 0.05263157894736842,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.07692307692307693,
                        "support": 7.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.28888888888888886,
                    "macro avg": {
                        "precision": 0.22426900584795317,
                        "recall": 0.16331845238095238,
                        "f1-score": 0.16958537915984723,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.5444834307992202,
                        "recall": 0.28888888888888886,
                        "f1-score": 0.3626041098381524,
                        "support": 45.0
                    }
                },
                "space_4": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.2727272727272727,
                        "f1-score": 0.42857142857142855,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.2857142857142857,
                        "recall": 0.13333333333333333,
                        "f1-score": 0.18181818181818182,
                        "support": 15.0
                    },
                    "COEX": {
                        "precision": 0.2222222222222222,
                        "recall": 1.0,
                        "f1-score": 0.3636363636363636,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.25,
                    "macro avg": {
                        "precision": 0.376984126984127,
                        "recall": 0.3515151515151515,
                        "f1-score": 0.2435064935064935,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.5617913832199546,
                        "recall": 0.25,
                        "f1-score": 0.2917439703153989,
                        "support": 28.0
                    }
                },
                "economy_and_business_strikes_2": {
                    "AFTER": {
                        "precision": 0.2,
                        "recall": 1.0,
                        "f1-score": 0.33333333333333337,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.25,
                        "f1-score": 0.4,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 6.0
                    },
                    "macro avg": {
                        "precision": 0.3,
                        "recall": 0.3125,
                        "f1-score": 0.18333333333333335,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.7000000000000001,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.32222222222222224,
                        "support": 6.0
                    }
                },
                "politics_and_conflicts_armed_conflict_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.2727272727272727,
                        "f1-score": 0.42857142857142855,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.4,
                        "recall": 0.6666666666666666,
                        "f1-score": 0.5,
                        "support": 3.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 15.0
                    },
                    "macro avg": {
                        "precision": 0.35,
                        "recall": 0.23484848484848483,
                        "f1-score": 0.23214285714285715,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.8133333333333332,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.4142857142857143,
                        "support": 15.0
                    }
                },
                "infectious_disease_4": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.25,
                        "f1-score": 0.25,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    }
                },
                "health_1": {
                    "AFTER": {
                        "precision": 0.6666666666666666,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.4444444444444444,
                        "support": 6.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 3.0
                    },
                    "COEX": {
                        "precision": 0.3333333333333333,
                        "recall": 1.0,
                        "f1-score": 0.5,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.4,
                    "macro avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.41666666666666663,
                        "f1-score": 0.3194444444444444,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.5333333333333333,
                        "recall": 0.4,
                        "f1-score": 0.41666666666666663,
                        "support": 10.0
                    }
                },
                "disasters_and_accidents_shipwreck_2": {
                    "AFTER": {
                        "precision": 0.42857142857142855,
                        "recall": 0.2727272727272727,
                        "f1-score": 0.33333333333333326,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.4444444444444444,
                        "f1-score": 0.47058823529411764,
                        "support": 9.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 21.0
                    },
                    "macro avg": {
                        "precision": 0.23214285714285715,
                        "recall": 0.17929292929292928,
                        "f1-score": 0.20098039215686272,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.4387755102040817,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.37628384687208216,
                        "support": 21.0
                    }
                },
                "rail_transport_3": {
                    "AFTER": {
                        "precision": 0.3333333333333333,
                        "recall": 0.4,
                        "f1-score": 0.3636363636363636,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.2,
                        "f1-score": 0.28571428571428575,
                        "support": 10.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.26666666666666666,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.26666666666666666,
                        "support": 15.0
                    },
                    "macro avg": {
                        "precision": 0.20833333333333331,
                        "recall": 0.15000000000000002,
                        "f1-score": 0.16233766233766234,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.4444444444444444,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.31168831168831174,
                        "support": 15.0
                    }
                },
                "weather_storms_1_extra": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.25,
                        "f1-score": 0.25,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    }
                },
                "health_1_extra": {
                    "AFTER": {
                        "precision": 0.07142857142857142,
                        "recall": 0.08333333333333333,
                        "f1-score": 0.07692307692307691,
                        "support": 12.0
                    },
                    "BEFORE": {
                        "precision": 0.35,
                        "recall": 0.25,
                        "f1-score": 0.2916666666666667,
                        "support": 28.0
                    },
                    "COEX": {
                        "precision": 0.09090909090909091,
                        "recall": 0.06666666666666667,
                        "f1-score": 0.07692307692307691,
                        "support": 15.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.16363636363636364,
                    "macro avg": {
                        "precision": 0.12808441558441558,
                        "recall": 0.09999999999999999,
                        "f1-score": 0.11137820512820513,
                        "support": 55.0
                    },
                    "weighted avg": {
                        "precision": 0.21855962219598582,
                        "recall": 0.16363636363636364,
                        "f1-score": 0.18624708624708627,
                        "support": 55.0
                    }
                },
                "weather_floods_1": {
                    "AFTER": {
                        "precision": 0.16666666666666666,
                        "recall": 0.6666666666666666,
                        "f1-score": 0.26666666666666666,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.6666666666666666,
                        "recall": 0.25,
                        "f1-score": 0.36363636363636365,
                        "support": 24.0
                    },
                    "COEX": {
                        "precision": 0.7142857142857143,
                        "recall": 0.35714285714285715,
                        "f1-score": 0.4761904761904762,
                        "support": 28.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.32727272727272727,
                    "macro avg": {
                        "precision": 0.38690476190476186,
                        "recall": 0.31845238095238093,
                        "f1-score": 0.27662337662337666,
                        "support": 55.0
                    },
                    "weighted avg": {
                        "precision": 0.6636363636363637,
                        "recall": 0.32727272727272727,
                        "f1-score": 0.41564738292011016,
                        "support": 55.0
                    }
                },
                "mining_4": {
                    "AFTER": {
                        "precision": 0.25,
                        "recall": 0.2727272727272727,
                        "f1-score": 0.2608695652173913,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.5454545454545454,
                        "recall": 0.24,
                        "f1-score": 0.3333333333333333,
                        "support": 25.0
                    },
                    "COEX": {
                        "precision": 0.2727272727272727,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3,
                        "support": 9.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.26666666666666666,
                    "macro avg": {
                        "precision": 0.26704545454545453,
                        "recall": 0.2115151515151515,
                        "f1-score": 0.22355072463768116,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.4186868686868686,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.30895330112721414,
                        "support": 45.0
                    }
                },
                "disasters_and_accidents_volcanoes_4": {
                    "AFTER": {
                        "precision": 0.5294117647058824,
                        "recall": 0.45,
                        "f1-score": 0.48648648648648646,
                        "support": 20.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 0.21428571428571427,
                        "f1-score": 0.2608695652173913,
                        "support": 14.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.3333333333333333,
                    "macro avg": {
                        "precision": 0.21568627450980393,
                        "recall": 0.16607142857142856,
                        "f1-score": 0.18683901292596944,
                        "support": 36.0
                    },
                    "weighted avg": {
                        "precision": 0.42374727668845313,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.37171954563258913,
                        "support": 36.0
                    }
                },
                "politics_and_conflicts_elections_3": {
                    "AFTER": {
                        "precision": 0.2,
                        "recall": 0.2,
                        "f1-score": 0.20000000000000004,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.4444444444444444,
                        "recall": 0.6666666666666666,
                        "f1-score": 0.5333333333333333,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 15.0
                    },
                    "macro avg": {
                        "precision": 0.1611111111111111,
                        "recall": 0.21666666666666667,
                        "f1-score": 0.18333333333333335,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.24444444444444444,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.28,
                        "support": 15.0
                    }
                },
                "economy_and_business_strikes_3": {
                    "AFTER": {
                        "precision": 0.42857142857142855,
                        "recall": 0.3,
                        "f1-score": 0.3529411764705882,
                        "support": 10.0
                    },
                    "BEFORE": {
                        "precision": 0.4,
                        "recall": 0.18181818181818182,
                        "f1-score": 0.25000000000000006,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.35714285714285715,
                        "recall": 0.7142857142857143,
                        "f1-score": 0.4761904761904762,
                        "support": 7.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.35714285714285715,
                    "macro avg": {
                        "precision": 0.29642857142857143,
                        "recall": 0.29902597402597403,
                        "f1-score": 0.26978291316526615,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.39948979591836736,
                        "recall": 0.35714285714285715,
                        "f1-score": 0.343312324929972,
                        "support": 28.0
                    }
                },
                "space_2": {
                    "AFTER": {
                        "precision": 0.6216216216216216,
                        "recall": 0.23,
                        "f1-score": 0.33576642335766427,
                        "support": 100.0
                    },
                    "BEFORE": {
                        "precision": 0.2,
                        "recall": 0.13725490196078433,
                        "f1-score": 0.16279069767441862,
                        "support": 51.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.19607843137254902,
                    "macro avg": {
                        "precision": 0.20540540540540542,
                        "recall": 0.09181372549019609,
                        "f1-score": 0.12463928025802072,
                        "support": 153.0
                    },
                    "weighted avg": {
                        "precision": 0.4729553082494259,
                        "recall": 0.19607843137254902,
                        "f1-score": 0.27371874455661294,
                        "support": 153.0
                    }
                },
                "politics_and_conflicts_resign_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    }
                },
                "environment_4": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.5,
                        "f1-score": 0.5,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.5,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.25,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2,
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.1875,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.2,
                        "f1-score": 0.23333333333333334,
                        "support": 15.0
                    }
                },
                "space_1_extra": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.75,
                        "recall": 0.6,
                        "f1-score": 0.6666666666666665,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.5,
                        "recall": 0.5,
                        "f1-score": 0.5,
                        "support": 6.0
                    },
                    "macro avg": {
                        "precision": 0.1875,
                        "recall": 0.15,
                        "f1-score": 0.16666666666666663,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.625,
                        "recall": 0.5,
                        "f1-score": 0.5555555555555555,
                        "support": 6.0
                    }
                },
                "health_3": {
                    "AFTER": {
                        "precision": 0.2,
                        "recall": 0.125,
                        "f1-score": 0.15384615384615385,
                        "support": 8.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 6.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.2,
                        "recall": 0.2,
                        "f1-score": 0.20000000000000004,
                        "support": 15.0
                    },
                    "macro avg": {
                        "precision": 0.13333333333333333,
                        "recall": 0.11458333333333333,
                        "f1-score": 0.12179487179487179,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.24000000000000002,
                        "recall": 0.2,
                        "f1-score": 0.2153846153846154,
                        "support": 15.0
                    }
                },
                "environment_3": {
                    "AFTER": {
                        "precision": 0.8,
                        "recall": 0.36363636363636365,
                        "f1-score": 0.5000000000000001,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.2,
                        "recall": 0.5,
                        "f1-score": 0.28571428571428575,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.3333333333333333,
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.2159090909090909,
                        "f1-score": 0.19642857142857145,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.6133333333333334,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.4047619047619048,
                        "support": 15.0
                    }
                },
                "government_and_politics_protests_3": {
                    "AFTER": {
                        "precision": 0.75,
                        "recall": 0.75,
                        "f1-score": 0.75,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.5,
                        "recall": 0.5,
                        "f1-score": 0.5,
                        "support": 6.0
                    },
                    "macro avg": {
                        "precision": 0.1875,
                        "recall": 0.1875,
                        "f1-score": 0.1875,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.5,
                        "recall": 0.5,
                        "f1-score": 0.5,
                        "support": 6.0
                    }
                },
                "economy_and_business_financial_crisis_4": {
                    "AFTER": {
                        "precision": 0.8,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.47058823529411764,
                        "support": 12.0
                    },
                    "BEFORE": {
                        "precision": 0.1,
                        "recall": 0.2,
                        "f1-score": 0.13333333333333333,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.3333333333333333,
                        "recall": 0.5,
                        "f1-score": 0.4,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 21.0
                    },
                    "macro avg": {
                        "precision": 0.30833333333333335,
                        "recall": 0.2583333333333333,
                        "f1-score": 0.25098039215686274,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.5444444444444445,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.376844070961718,
                        "support": 21.0
                    }
                },
                "computers_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    }
                },
                "crime_and_law_accuse_4": {
                    "AFTER": {
                        "precision": 0.75,
                        "recall": 0.6,
                        "f1-score": 0.6666666666666665,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 0.2,
                        "f1-score": 0.25,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.4,
                        "recall": 0.4,
                        "f1-score": 0.4000000000000001,
                        "support": 10.0
                    },
                    "macro avg": {
                        "precision": 0.2708333333333333,
                        "recall": 0.2,
                        "f1-score": 0.22916666666666663,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.5416666666666666,
                        "recall": 0.4,
                        "f1-score": 0.4583333333333332,
                        "support": 10.0
                    }
                },
                "culture_and_entertainment_1": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.5,
                        "f1-score": 0.5,
                        "support": 2.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.5,
                        "f1-score": 0.5,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.5,
                        "recall": 0.5,
                        "f1-score": 0.5,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.5,
                        "recall": 0.5,
                        "f1-score": 0.5,
                        "support": 6.0
                    },
                    "macro avg": {
                        "precision": 0.375,
                        "recall": 0.375,
                        "f1-score": 0.375,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.5,
                        "recall": 0.5,
                        "f1-score": 0.5,
                        "support": 6.0
                    }
                },
                "internet_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 0.25,
                        "f1-score": 0.28571428571428575,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.1,
                        "recall": 0.1,
                        "f1-score": 0.10000000000000002,
                        "support": 10.0
                    },
                    "macro avg": {
                        "precision": 0.08333333333333333,
                        "recall": 0.0625,
                        "f1-score": 0.07142857142857144,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.13333333333333333,
                        "recall": 0.1,
                        "f1-score": 0.1142857142857143,
                        "support": 10.0
                    }
                },
                "culture_and_entertainment_3": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.2,
                        "f1-score": 0.28571428571428575,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 0.25,
                        "f1-score": 0.28571428571428575,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.4,
                        "recall": 0.6666666666666666,
                        "f1-score": 0.5,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.4,
                        "recall": 0.4,
                        "f1-score": 0.4000000000000001,
                        "support": 15.0
                    },
                    "macro avg": {
                        "precision": 0.30833333333333335,
                        "recall": 0.2791666666666667,
                        "f1-score": 0.2678571428571429,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.41555555555555557,
                        "recall": 0.4,
                        "f1-score": 0.3714285714285715,
                        "support": 15.0
                    }
                }
            },
            "hint": {
                "government_and_politics_riots_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.08333333333333333,
                        "f1-score": 0.14285714285714285,
                        "support": 12.0
                    },
                    "COEX": {
                        "precision": 0.5,
                        "recall": 0.25,
                        "f1-score": 0.3333333333333333,
                        "support": 12.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.14285714285714285,
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.08333333333333333,
                        "f1-score": 0.11904761904761904,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.42857142857142855,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.20408163265306123,
                        "support": 28.0
                    }
                },
                "rail_transport_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.38235294117647056,
                        "f1-score": 0.5531914893617021,
                        "support": 34.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.3611111111111111,
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.09558823529411764,
                        "f1-score": 0.13829787234042554,
                        "support": 36.0
                    },
                    "weighted avg": {
                        "precision": 0.9444444444444444,
                        "recall": 0.3611111111111111,
                        "f1-score": 0.5224586288416075,
                        "support": 36.0
                    }
                },
                "politics_and_conflicts_policy_change_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.0,
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    }
                },
                "politics_and_conflicts_drones_1": {
                    "AFTER": {
                        "precision": 0.6666666666666666,
                        "recall": 0.5454545454545454,
                        "f1-score": 0.6,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.25,
                        "f1-score": 0.3333333333333333,
                        "support": 8.0
                    },
                    "COEX": {
                        "precision": 0.14285714285714285,
                        "recall": 0.5,
                        "f1-score": 0.22222222222222224,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.42857142857142855,
                    "macro avg": {
                        "precision": 0.32738095238095233,
                        "recall": 0.32386363636363635,
                        "f1-score": 0.2888888888888889,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.5532879818594104,
                        "recall": 0.42857142857142855,
                        "f1-score": 0.4624338624338624,
                        "support": 21.0
                    }
                },
                "disasters_and_accidents_road_crash_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.5454545454545454,
                        "f1-score": 0.5217391304347826,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.5,
                        "recall": 0.1,
                        "f1-score": 0.16666666666666669,
                        "support": 10.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.3333333333333333,
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.16136363636363635,
                        "f1-score": 0.1721014492753623,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.5,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3526570048309179,
                        "support": 21.0
                    }
                },
                "crime_and_law_accuse_3": {
                    "AFTER": {
                        "precision": 0.3333333333333333,
                        "recall": 0.25,
                        "f1-score": 0.28571428571428575,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.25,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.2,
                        "support": 6.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.2,
                        "recall": 0.2,
                        "f1-score": 0.20000000000000004,
                        "support": 10.0
                    },
                    "macro avg": {
                        "precision": 0.14583333333333331,
                        "recall": 0.10416666666666666,
                        "f1-score": 0.12142857142857144,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.2833333333333333,
                        "recall": 0.2,
                        "f1-score": 0.23428571428571435,
                        "support": 10.0
                    }
                },
                "government_and_politics_protests_2": {
                    "AFTER": {
                        "precision": 0.2727272727272727,
                        "recall": 0.6,
                        "f1-score": 0.37499999999999994,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.6666666666666666,
                        "recall": 0.2,
                        "f1-score": 0.30769230769230765,
                        "support": 20.0
                    },
                    "COEX": {
                        "precision": 0.14285714285714285,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.2,
                        "support": 3.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2857142857142857,
                    "macro avg": {
                        "precision": 0.27056277056277056,
                        "recall": 0.2833333333333333,
                        "f1-score": 0.22067307692307692,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.5401978973407544,
                        "recall": 0.2857142857142857,
                        "f1-score": 0.3081730769230769,
                        "support": 28.0
                    }
                },
                "politics_and_conflicts_elections_2": {
                    "AFTER": {
                        "precision": 0.45454545454545453,
                        "recall": 0.22727272727272727,
                        "f1-score": 0.30303030303030304,
                        "support": 22.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 0.21428571428571427,
                        "f1-score": 0.2608695652173913,
                        "support": 14.0
                    },
                    "COEX": {
                        "precision": 0.375,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.35294117647058826,
                        "support": 9.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.24444444444444444,
                    "macro avg": {
                        "precision": 0.29071969696969696,
                        "recall": 0.1937229437229437,
                        "f1-score": 0.22921026117957066,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.40092592592592585,
                        "recall": 0.24444444444444444,
                        "f1-score": 0.2998958037321208,
                        "support": 45.0
                    }
                },
                "environment_2": {
                    "AFTER": {
                        "precision": 0.5625,
                        "recall": 0.42857142857142855,
                        "f1-score": 0.4864864864864864,
                        "support": 21.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.17391304347826086,
                        "f1-score": 0.25806451612903225,
                        "support": 23.0
                    },
                    "COEX": {
                        "precision": 0.125,
                        "recall": 1.0,
                        "f1-score": 0.2222222222222222,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.3111111111111111,
                    "macro avg": {
                        "precision": 0.296875,
                        "recall": 0.40062111801242234,
                        "f1-score": 0.24169330620943522,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.5208333333333334,
                        "recall": 0.3111111111111111,
                        "f1-score": 0.3638649402090261,
                        "support": 45.0
                    }
                },
                "weather_floods_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.22222222222222224,
                        "support": 7.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.06666666666666667,
                    "macro avg": {
                        "precision": 0.125,
                        "recall": 0.03571428571428571,
                        "f1-score": 0.05555555555555556,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.23333333333333334,
                        "recall": 0.06666666666666667,
                        "f1-score": 0.1037037037037037,
                        "support": 15.0
                    }
                },
                "sports_1": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.5,
                        "f1-score": 0.6666666666666666,
                        "support": 2.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.6666666666666666,
                        "recall": 0.6666666666666666,
                        "f1-score": 0.6666666666666666,
                        "support": 3.0
                    },
                    "macro avg": {
                        "precision": 0.5,
                        "recall": 0.375,
                        "f1-score": 0.41666666666666663,
                        "support": 3.0
                    },
                    "weighted avg": {
                        "precision": 1.0,
                        "recall": 0.6666666666666666,
                        "f1-score": 0.7777777777777777,
                        "support": 3.0
                    }
                },
                "health_4": {
                    "AFTER": {
                        "precision": 0.2,
                        "recall": 0.1111111111111111,
                        "f1-score": 0.14285714285714285,
                        "support": 9.0
                    },
                    "BEFORE": {
                        "precision": 0.2,
                        "recall": 0.125,
                        "f1-score": 0.15384615384615385,
                        "support": 8.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.09523809523809523,
                    "macro avg": {
                        "precision": 0.1,
                        "recall": 0.059027777777777776,
                        "f1-score": 0.07417582417582418,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.1619047619047619,
                        "recall": 0.09523809523809523,
                        "f1-score": 0.11983254840397697,
                        "support": 21.0
                    }
                },
                "weather_earthquakes_1": {
                    "AFTER": {
                        "precision": 0.2,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.25,
                        "support": 6.0
                    },
                    "BEFORE": {
                        "precision": 0.6363636363636364,
                        "recall": 0.21875,
                        "f1-score": 0.3255813953488372,
                        "support": 32.0
                    },
                    "COEX": {
                        "precision": 0.14285714285714285,
                        "recall": 0.42857142857142855,
                        "f1-score": 0.21428571428571427,
                        "support": 7.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.26666666666666666,
                    "macro avg": {
                        "precision": 0.2448051948051948,
                        "recall": 0.24516369047619047,
                        "f1-score": 0.19746677740863786,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.5014141414141414,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.29819121447028424,
                        "support": 45.0
                    }
                },
                "space_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.5555555555555556,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.4166666666666667,
                        "support": 15.0
                    },
                    "COEX": {
                        "precision": 0.2222222222222222,
                        "recall": 1.0,
                        "f1-score": 0.3636363636363636,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.25,
                    "macro avg": {
                        "precision": 0.19444444444444445,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.19507575757575757,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.31349206349206354,
                        "recall": 0.25,
                        "f1-score": 0.2491883116883117,
                        "support": 28.0
                    }
                },
                "economy_and_business_strikes_2": {
                    "AFTER": {
                        "precision": 0.3333333333333333,
                        "recall": 1.0,
                        "f1-score": 0.5,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.6666666666666666,
                        "recall": 0.5,
                        "f1-score": 0.5714285714285715,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.5,
                        "recall": 0.5,
                        "f1-score": 0.5,
                        "support": 6.0
                    },
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.375,
                        "f1-score": 0.2678571428571429,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.5,
                        "recall": 0.5,
                        "f1-score": 0.46428571428571436,
                        "support": 6.0
                    }
                },
                "politics_and_conflicts_armed_conflict_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.2727272727272727,
                        "f1-score": 0.42857142857142855,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.3333333333333333,
                        "recall": 0.6666666666666666,
                        "f1-score": 0.4444444444444444,
                        "support": 3.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.3333333333333333,
                    "macro avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.23484848484848483,
                        "f1-score": 0.21825396825396826,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.8,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.4031746031746032,
                        "support": 15.0
                    }
                },
                "infectious_disease_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    }
                },
                "health_1": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.2857142857142857,
                        "support": 6.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "COEX": {
                        "precision": 0.14285714285714285,
                        "recall": 1.0,
                        "f1-score": 0.25,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2,
                    "macro avg": {
                        "precision": 0.2857142857142857,
                        "recall": 0.2916666666666667,
                        "f1-score": 0.13392857142857142,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.6142857142857143,
                        "recall": 0.2,
                        "f1-score": 0.19642857142857142,
                        "support": 10.0
                    }
                },
                "disasters_and_accidents_shipwreck_2": {
                    "AFTER": {
                        "precision": 0.2,
                        "recall": 0.09090909090909091,
                        "f1-score": 0.12500000000000003,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.2222222222222222,
                        "f1-score": 0.30769230769230765,
                        "support": 9.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.14285714285714285,
                    "macro avg": {
                        "precision": 0.175,
                        "recall": 0.07828282828282829,
                        "f1-score": 0.10817307692307693,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.3190476190476191,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.19734432234432234,
                        "support": 21.0
                    }
                },
                "rail_transport_3": {
                    "AFTER": {
                        "precision": 0.3333333333333333,
                        "recall": 0.2,
                        "f1-score": 0.25,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.6666666666666666,
                        "recall": 0.2,
                        "f1-score": 0.30769230769230765,
                        "support": 10.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2,
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.1,
                        "f1-score": 0.13942307692307693,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.5555555555555555,
                        "recall": 0.2,
                        "f1-score": 0.28846153846153844,
                        "support": 15.0
                    }
                },
                "weather_storms_1_extra": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    }
                },
                "health_1_extra": {
                    "AFTER": {
                        "precision": 0.07142857142857142,
                        "recall": 0.08333333333333333,
                        "f1-score": 0.07692307692307691,
                        "support": 12.0
                    },
                    "BEFORE": {
                        "precision": 0.3,
                        "recall": 0.10714285714285714,
                        "f1-score": 0.15789473684210525,
                        "support": 28.0
                    },
                    "COEX": {
                        "precision": 0.4090909090909091,
                        "recall": 0.6,
                        "f1-score": 0.4864864864864865,
                        "support": 15.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.23636363636363636,
                    "macro avg": {
                        "precision": 0.19512987012987015,
                        "recall": 0.1976190476190476,
                        "f1-score": 0.18032607506291717,
                        "support": 55.0
                    },
                    "weighted avg": {
                        "precision": 0.2798819362455726,
                        "recall": 0.23636363636363636,
                        "f1-score": 0.22984412458096667,
                        "support": 55.0
                    }
                },
                "weather_floods_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.25,
                        "f1-score": 0.3333333333333333,
                        "support": 24.0
                    },
                    "COEX": {
                        "precision": 0.45,
                        "recall": 0.32142857142857145,
                        "f1-score": 0.375,
                        "support": 28.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2727272727272727,
                    "macro avg": {
                        "precision": 0.2375,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.17708333333333331,
                        "support": 55.0
                    },
                    "weighted avg": {
                        "precision": 0.4472727272727273,
                        "recall": 0.2727272727272727,
                        "f1-score": 0.33636363636363636,
                        "support": 55.0
                    }
                },
                "mining_4": {
                    "AFTER": {
                        "precision": 0.2222222222222222,
                        "recall": 0.18181818181818182,
                        "f1-score": 0.19999999999999998,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.4666666666666667,
                        "recall": 0.28,
                        "f1-score": 0.35000000000000003,
                        "support": 25.0
                    },
                    "COEX": {
                        "precision": 0.3333333333333333,
                        "recall": 0.4444444444444444,
                        "f1-score": 0.380952380952381,
                        "support": 9.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.28888888888888886,
                    "macro avg": {
                        "precision": 0.25555555555555554,
                        "recall": 0.22656565656565658,
                        "f1-score": 0.23273809523809524,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.3802469135802469,
                        "recall": 0.28888888888888886,
                        "f1-score": 0.3195238095238095,
                        "support": 45.0
                    }
                },
                "disasters_and_accidents_volcanoes_4": {
                    "AFTER": {
                        "precision": 0.2222222222222222,
                        "recall": 0.1,
                        "f1-score": 0.13793103448275865,
                        "support": 20.0
                    },
                    "BEFORE": {
                        "precision": 0.6666666666666666,
                        "recall": 0.2857142857142857,
                        "f1-score": 0.4,
                        "support": 14.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.16666666666666666,
                    "macro avg": {
                        "precision": 0.2222222222222222,
                        "recall": 0.09642857142857142,
                        "f1-score": 0.13448275862068967,
                        "support": 36.0
                    },
                    "weighted avg": {
                        "precision": 0.38271604938271603,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.23218390804597705,
                        "support": 36.0
                    }
                },
                "politics_and_conflicts_elections_3": {
                    "AFTER": {
                        "precision": 0.25,
                        "recall": 0.2,
                        "f1-score": 0.22222222222222224,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.5,
                        "f1-score": 0.6666666666666666,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.5,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.4,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.3333333333333333,
                    "macro avg": {
                        "precision": 0.4375,
                        "recall": 0.2583333333333333,
                        "f1-score": 0.3222222222222222,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.55,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.41185185185185186,
                        "support": 15.0
                    }
                },
                "economy_and_business_strikes_3": {
                    "AFTER": {
                        "precision": 0.2222222222222222,
                        "recall": 0.2,
                        "f1-score": 0.2105263157894737,
                        "support": 10.0
                    },
                    "BEFORE": {
                        "precision": 0.5714285714285714,
                        "recall": 0.36363636363636365,
                        "f1-score": 0.4444444444444444,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.5,
                        "recall": 0.42857142857142855,
                        "f1-score": 0.4615384615384615,
                        "support": 7.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.32142857142857145,
                    "macro avg": {
                        "precision": 0.3234126984126984,
                        "recall": 0.24805194805194808,
                        "f1-score": 0.2791273054430949,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.42885487528344673,
                        "recall": 0.32142857142857145,
                        "f1-score": 0.365175759912602,
                        "support": 28.0
                    }
                },
                "space_2": {
                    "AFTER": {
                        "precision": 0.5483870967741935,
                        "recall": 0.17,
                        "f1-score": 0.2595419847328244,
                        "support": 100.0
                    },
                    "BEFORE": {
                        "precision": 0.35714285714285715,
                        "recall": 0.19607843137254902,
                        "f1-score": 0.2531645569620253,
                        "support": 51.0
                    },
                    "COEX": {
                        "precision": 0.04,
                        "recall": 0.5,
                        "f1-score": 0.07407407407407407,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.1830065359477124,
                    "macro avg": {
                        "precision": 0.2363824884792627,
                        "recall": 0.21651960784313726,
                        "f1-score": 0.14669515394223095,
                        "support": 153.0
                    },
                    "weighted avg": {
                        "precision": 0.4779934339327129,
                        "recall": 0.1830065359477124,
                        "f1-score": 0.25499175834309723,
                        "support": 153.0
                    }
                },
                "politics_and_conflicts_resign_1": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.5,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 3.0
                    },
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.08333333333333333,
                        "f1-score": 0.125,
                        "support": 3.0
                    },
                    "weighted avg": {
                        "precision": 1.0,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.5,
                        "support": 3.0
                    }
                },
                "environment_4": {
                    "AFTER": {
                        "precision": 0.3333333333333333,
                        "recall": 0.5,
                        "f1-score": 0.4,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.6,
                        "recall": 0.6,
                        "f1-score": 0.6,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.3333333333333333,
                    "macro avg": {
                        "precision": 0.23333333333333334,
                        "recall": 0.275,
                        "f1-score": 0.25,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.28888888888888886,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.30666666666666664,
                        "support": 15.0
                    }
                },
                "space_1_extra": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.2,
                        "f1-score": 0.28571428571428575,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.16666666666666666,
                    "macro avg": {
                        "precision": 0.125,
                        "recall": 0.05,
                        "f1-score": 0.07142857142857144,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.4166666666666667,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.23809523809523814,
                        "support": 6.0
                    }
                },
                "health_3": {
                    "AFTER": {
                        "precision": 0.6,
                        "recall": 0.375,
                        "f1-score": 0.4615384615384615,
                        "support": 8.0
                    },
                    "BEFORE": {
                        "precision": 0.6,
                        "recall": 0.5,
                        "f1-score": 0.5454545454545454,
                        "support": 6.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.4,
                    "macro avg": {
                        "precision": 0.3,
                        "recall": 0.21875,
                        "f1-score": 0.2517482517482517,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.5599999999999999,
                        "recall": 0.4,
                        "f1-score": 0.4643356643356643,
                        "support": 15.0
                    }
                },
                "environment_3": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.2727272727272727,
                        "f1-score": 0.42857142857142855,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.2,
                        "recall": 0.5,
                        "f1-score": 0.28571428571428575,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.2,
                        "recall": 0.5,
                        "f1-score": 0.28571428571428575,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.3333333333333333,
                    "macro avg": {
                        "precision": 0.35,
                        "recall": 0.3181818181818182,
                        "f1-score": 0.25,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.7866666666666667,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3904761904761905,
                        "support": 15.0
                    }
                },
                "government_and_politics_protests_3": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.5,
                        "f1-score": 0.6666666666666666,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.25,
                        "recall": 1.0,
                        "f1-score": 0.4,
                        "support": 1.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.5,
                        "recall": 0.5,
                        "f1-score": 0.5,
                        "support": 6.0
                    },
                    "macro avg": {
                        "precision": 0.3125,
                        "recall": 0.375,
                        "f1-score": 0.26666666666666666,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.7083333333333334,
                        "recall": 0.5,
                        "f1-score": 0.5111111111111111,
                        "support": 6.0
                    }
                },
                "economy_and_business_financial_crisis_4": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.25,
                        "f1-score": 0.3333333333333333,
                        "support": 12.0
                    },
                    "BEFORE": {
                        "precision": 0.1111111111111111,
                        "recall": 0.2,
                        "f1-score": 0.14285714285714285,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.25,
                        "recall": 0.25,
                        "f1-score": 0.25,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.23809523809523808,
                    "macro avg": {
                        "precision": 0.2152777777777778,
                        "recall": 0.175,
                        "f1-score": 0.18154761904761904,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.35978835978835977,
                        "recall": 0.23809523809523808,
                        "f1-score": 0.272108843537415,
                        "support": 21.0
                    }
                },
                "computers_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    }
                },
                "crime_and_law_accuse_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.2,
                        "f1-score": 0.28571428571428575,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.1,
                    "macro avg": {
                        "precision": 0.125,
                        "recall": 0.05,
                        "f1-score": 0.07142857142857144,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.25,
                        "recall": 0.1,
                        "f1-score": 0.14285714285714288,
                        "support": 10.0
                    }
                },
                "culture_and_entertainment_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.5,
                        "recall": 0.5,
                        "f1-score": 0.5,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.16666666666666666,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.16666666666666666,
                        "support": 6.0
                    },
                    "macro avg": {
                        "precision": 0.125,
                        "recall": 0.125,
                        "f1-score": 0.125,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.16666666666666666,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.16666666666666666,
                        "support": 6.0
                    }
                },
                "internet_2": {
                    "AFTER": {
                        "precision": 0.3333333333333333,
                        "recall": 0.2,
                        "f1-score": 0.25,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 0.25,
                        "f1-score": 0.28571428571428575,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2,
                    "macro avg": {
                        "precision": 0.16666666666666666,
                        "recall": 0.1125,
                        "f1-score": 0.13392857142857145,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.3,
                        "recall": 0.2,
                        "f1-score": 0.23928571428571432,
                        "support": 10.0
                    }
                },
                "culture_and_entertainment_3": {
                    "AFTER": {
                        "precision": 0.3333333333333333,
                        "recall": 0.2,
                        "f1-score": 0.25,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.25,
                        "recall": 0.25,
                        "f1-score": 0.25,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.26666666666666666,
                    "macro avg": {
                        "precision": 0.22916666666666663,
                        "recall": 0.19583333333333333,
                        "f1-score": 0.20833333333333331,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.31111111111111106,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.2833333333333333,
                        "support": 15.0
                    }
                }
            },
            "pick": {
                "government_and_politics_riots_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.42857142857142855,
                        "recall": 0.25,
                        "f1-score": 0.3157894736842105,
                        "support": 12.0
                    },
                    "COEX": {
                        "precision": 0.8333333333333334,
                        "recall": 0.4166666666666667,
                        "f1-score": 0.5555555555555556,
                        "support": 12.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.2857142857142857,
                        "recall": 0.2857142857142857,
                        "f1-score": 0.2857142857142857,
                        "support": 28.0
                    },
                    "macro avg": {
                        "precision": 0.31547619047619047,
                        "recall": 0.16666666666666669,
                        "f1-score": 0.21783625730994152,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.5408163265306122,
                        "recall": 0.2857142857142857,
                        "f1-score": 0.3734335839598998,
                        "support": 28.0
                    }
                },
                "rail_transport_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "BEFORE": {
                        "precision": 0.8571428571428571,
                        "recall": 0.35294117647058826,
                        "f1-score": 0.5,
                        "support": 34.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.3333333333333333,
                    "macro avg": {
                        "precision": 0.21428571428571427,
                        "recall": 0.08823529411764706,
                        "f1-score": 0.125,
                        "support": 36.0
                    },
                    "weighted avg": {
                        "precision": 0.8095238095238095,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.4722222222222222,
                        "support": 36.0
                    }
                },
                "politics_and_conflicts_policy_change_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.3333333333333333,
                        "recall": 1.0,
                        "f1-score": 0.5,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.16666666666666666,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.16666666666666666,
                        "support": 6.0
                    },
                    "macro avg": {
                        "precision": 0.08333333333333333,
                        "recall": 0.25,
                        "f1-score": 0.125,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.05555555555555555,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.08333333333333333,
                        "support": 6.0
                    }
                },
                "politics_and_conflicts_drones_1": {
                    "AFTER": {
                        "precision": 0.6666666666666666,
                        "recall": 0.36363636363636365,
                        "f1-score": 0.4705882352941177,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.5714285714285714,
                        "recall": 0.5,
                        "f1-score": 0.5333333333333333,
                        "support": 8.0
                    },
                    "COEX": {
                        "precision": 0.25,
                        "recall": 1.0,
                        "f1-score": 0.4,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.47619047619047616,
                        "recall": 0.47619047619047616,
                        "f1-score": 0.47619047619047616,
                        "support": 21.0
                    },
                    "macro avg": {
                        "precision": 0.37202380952380953,
                        "recall": 0.46590909090909094,
                        "f1-score": 0.3509803921568627,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.590702947845805,
                        "recall": 0.47619047619047616,
                        "f1-score": 0.4877684407096172,
                        "support": 21.0
                    }
                },
                "disasters_and_accidents_road_crash_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.2727272727272727,
                        "f1-score": 0.3529411764705882,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.75,
                        "recall": 0.3,
                        "f1-score": 0.4285714285714285,
                        "support": 10.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.2857142857142857,
                        "recall": 0.2857142857142857,
                        "f1-score": 0.2857142857142857,
                        "support": 21.0
                    },
                    "macro avg": {
                        "precision": 0.3125,
                        "recall": 0.1431818181818182,
                        "f1-score": 0.19537815126050417,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.6190476190476191,
                        "recall": 0.2857142857142857,
                        "f1-score": 0.3889555822328931,
                        "support": 21.0
                    }
                },
                "crime_and_law_accuse_3": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.5,
                        "f1-score": 0.5,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.6,
                        "recall": 0.5,
                        "f1-score": 0.5454545454545454,
                        "support": 6.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.5,
                        "recall": 0.5,
                        "f1-score": 0.5,
                        "support": 10.0
                    },
                    "macro avg": {
                        "precision": 0.275,
                        "recall": 0.25,
                        "f1-score": 0.26136363636363635,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.5599999999999999,
                        "recall": 0.5,
                        "f1-score": 0.5272727272727272,
                        "support": 10.0
                    }
                },
                "government_and_politics_protests_2": {
                    "AFTER": {
                        "precision": 0.2727272727272727,
                        "recall": 0.6,
                        "f1-score": 0.37499999999999994,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.5555555555555556,
                        "recall": 0.25,
                        "f1-score": 0.3448275862068966,
                        "support": 20.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2857142857142857,
                    "macro avg": {
                        "precision": 0.20707070707070707,
                        "recall": 0.2125,
                        "f1-score": 0.17995689655172414,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.4455266955266955,
                        "recall": 0.2857142857142857,
                        "f1-score": 0.3132697044334975,
                        "support": 28.0
                    }
                },
                "politics_and_conflicts_elections_2": {
                    "AFTER": {
                        "precision": 0.631578947368421,
                        "recall": 0.5454545454545454,
                        "f1-score": 0.5853658536585366,
                        "support": 22.0
                    },
                    "BEFORE": {
                        "precision": 0.2857142857142857,
                        "recall": 0.2857142857142857,
                        "f1-score": 0.2857142857142857,
                        "support": 14.0
                    },
                    "COEX": {
                        "precision": 0.2,
                        "recall": 0.1111111111111111,
                        "f1-score": 0.14285714285714285,
                        "support": 9.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.37777777777777777,
                    "macro avg": {
                        "precision": 0.2793233082706767,
                        "recall": 0.23556998556998554,
                        "f1-score": 0.25348432055749126,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.43766081871345025,
                        "recall": 0.37777777777777777,
                        "f1-score": 0.4036391792489353,
                        "support": 45.0
                    }
                },
                "environment_2": {
                    "AFTER": {
                        "precision": 0.6666666666666666,
                        "recall": 0.38095238095238093,
                        "f1-score": 0.4848484848484849,
                        "support": 21.0
                    },
                    "BEFORE": {
                        "precision": 0.375,
                        "recall": 0.13043478260869565,
                        "f1-score": 0.19354838709677416,
                        "support": 23.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.24444444444444444,
                    "macro avg": {
                        "precision": 0.26041666666666663,
                        "recall": 0.12784679089026915,
                        "f1-score": 0.16959921798631478,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.5027777777777778,
                        "recall": 0.24444444444444444,
                        "f1-score": 0.325187357445422,
                        "support": 45.0
                    }
                },
                "weather_floods_3": {
                    "AFTER": {
                        "precision": 0.2727272727272727,
                        "recall": 0.75,
                        "f1-score": 0.39999999999999997,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.6666666666666666,
                        "recall": 0.2857142857142857,
                        "f1-score": 0.4,
                        "support": 7.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 15.0
                    },
                    "macro avg": {
                        "precision": 0.23484848484848483,
                        "recall": 0.2589285714285714,
                        "f1-score": 0.2,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.3838383838383838,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.29333333333333333,
                        "support": 15.0
                    }
                },
                "sports_1": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.5,
                        "f1-score": 0.6666666666666666,
                        "support": 2.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 3.0
                    },
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.125,
                        "f1-score": 0.16666666666666666,
                        "support": 3.0
                    },
                    "weighted avg": {
                        "precision": 0.6666666666666666,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.4444444444444444,
                        "support": 3.0
                    }
                },
                "health_4": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.4,
                        "support": 9.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 0.25,
                        "f1-score": 0.28571428571428575,
                        "support": 8.0
                    },
                    "COEX": {
                        "precision": 0.2222222222222222,
                        "recall": 0.5,
                        "f1-score": 0.30769230769230765,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 21.0
                    },
                    "macro avg": {
                        "precision": 0.26388888888888884,
                        "recall": 0.2708333333333333,
                        "f1-score": 0.24835164835164836,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.3835978835978836,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.33888016745159605,
                        "support": 21.0
                    }
                },
                "weather_earthquakes_1": {
                    "AFTER": {
                        "precision": 0.25,
                        "recall": 0.6666666666666666,
                        "f1-score": 0.36363636363636365,
                        "support": 6.0
                    },
                    "BEFORE": {
                        "precision": 0.7333333333333333,
                        "recall": 0.34375,
                        "f1-score": 0.4680851063829787,
                        "support": 32.0
                    },
                    "COEX": {
                        "precision": 0.07142857142857142,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.09523809523809523,
                        "support": 7.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.35555555555555557,
                        "recall": 0.35555555555555557,
                        "f1-score": 0.35555555555555557,
                        "support": 45.0
                    },
                    "macro avg": {
                        "precision": 0.2636904761904762,
                        "recall": 0.28831845238095233,
                        "f1-score": 0.23173989131435938,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.5659259259259259,
                        "recall": 0.35555555555555557,
                        "f1-score": 0.39616018339422593,
                        "support": 45.0
                    }
                },
                "space_4": {
                    "AFTER": {
                        "precision": 0.4,
                        "recall": 0.18181818181818182,
                        "f1-score": 0.25000000000000006,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.42857142857142855,
                        "recall": 0.2,
                        "f1-score": 0.27272727272727276,
                        "support": 15.0
                    },
                    "COEX": {
                        "precision": 0.07142857142857142,
                        "recall": 0.5,
                        "f1-score": 0.125,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.21428571428571427,
                    "macro avg": {
                        "precision": 0.22499999999999998,
                        "recall": 0.22045454545454546,
                        "f1-score": 0.1619318181818182,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.39183673469387753,
                        "recall": 0.21428571428571427,
                        "f1-score": 0.2532467532467533,
                        "support": 28.0
                    }
                },
                "economy_and_business_strikes_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.25,
                        "f1-score": 0.4,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.25,
                        "recall": 1.0,
                        "f1-score": 0.4,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 6.0
                    },
                    "macro avg": {
                        "precision": 0.3125,
                        "recall": 0.3125,
                        "f1-score": 0.2,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.7083333333333334,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 6.0
                    }
                },
                "politics_and_conflicts_armed_conflict_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.6666666666666666,
                        "recall": 0.36363636363636365,
                        "f1-score": 0.4705882352941177,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.14285714285714285,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.2,
                        "support": 3.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 15.0
                    },
                    "macro avg": {
                        "precision": 0.20238095238095238,
                        "recall": 0.17424242424242425,
                        "f1-score": 0.16764705882352943,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.5174603174603175,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3850980392156863,
                        "support": 15.0
                    }
                },
                "infectious_disease_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    }
                },
                "health_1": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.5,
                        "support": 6.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.4,
                        "support": 3.0
                    },
                    "COEX": {
                        "precision": 0.16666666666666666,
                        "recall": 1.0,
                        "f1-score": 0.2857142857142857,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.4,
                        "recall": 0.4,
                        "f1-score": 0.4000000000000001,
                        "support": 10.0
                    },
                    "macro avg": {
                        "precision": 0.4166666666666667,
                        "recall": 0.41666666666666663,
                        "f1-score": 0.29642857142857143,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.7666666666666667,
                        "recall": 0.4,
                        "f1-score": 0.44857142857142857,
                        "support": 10.0
                    }
                },
                "disasters_and_accidents_shipwreck_2": {
                    "AFTER": {
                        "precision": 0.6666666666666666,
                        "recall": 0.18181818181818182,
                        "f1-score": 0.28571428571428575,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.5555555555555556,
                        "f1-score": 0.5263157894736842,
                        "support": 9.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.3333333333333333,
                    "macro avg": {
                        "precision": 0.29166666666666663,
                        "recall": 0.18434343434343436,
                        "f1-score": 0.20300751879699247,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.5634920634920635,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3752237737200143,
                        "support": 21.0
                    }
                },
                "rail_transport_3": {
                    "AFTER": {
                        "precision": 0.4,
                        "recall": 0.4,
                        "f1-score": 0.4000000000000001,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.2,
                        "f1-score": 0.33333333333333337,
                        "support": 10.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.26666666666666666,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.26666666666666666,
                        "support": 15.0
                    },
                    "macro avg": {
                        "precision": 0.35,
                        "recall": 0.15000000000000002,
                        "f1-score": 0.18333333333333335,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.8,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.35555555555555557,
                        "support": 15.0
                    }
                },
                "weather_storms_1_extra": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.25,
                        "f1-score": 0.25,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    }
                },
                "health_1_extra": {
                    "AFTER": {
                        "precision": 0.2631578947368421,
                        "recall": 0.4166666666666667,
                        "f1-score": 0.3225806451612903,
                        "support": 12.0
                    },
                    "BEFORE": {
                        "precision": 0.5555555555555556,
                        "recall": 0.35714285714285715,
                        "f1-score": 0.43478260869565216,
                        "support": 28.0
                    },
                    "COEX": {
                        "precision": 0.2,
                        "recall": 0.2,
                        "f1-score": 0.20000000000000004,
                        "support": 15.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.32727272727272727,
                    "macro avg": {
                        "precision": 0.2546783625730994,
                        "recall": 0.24345238095238098,
                        "f1-score": 0.23934081346423564,
                        "support": 55.0
                    },
                    "weighted avg": {
                        "precision": 0.39479000531632114,
                        "recall": 0.32727272727272727,
                        "f1-score": 0.34627055973479537,
                        "support": 55.0
                    }
                },
                "weather_floods_1": {
                    "AFTER": {
                        "precision": 0.06896551724137931,
                        "recall": 0.6666666666666666,
                        "f1-score": 0.125,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.5454545454545454,
                        "recall": 0.25,
                        "f1-score": 0.34285714285714286,
                        "support": 24.0
                    },
                    "COEX": {
                        "precision": 0.4666666666666667,
                        "recall": 0.25,
                        "f1-score": 0.32558139534883723,
                        "support": 28.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.2727272727272727,
                        "recall": 0.2727272727272727,
                        "f1-score": 0.2727272727272727,
                        "support": 55.0
                    },
                    "macro avg": {
                        "precision": 0.27027168234064786,
                        "recall": 0.29166666666666663,
                        "f1-score": 0.19835963455149502,
                        "support": 55.0
                    },
                    "weighted avg": {
                        "precision": 0.47935404198727083,
                        "recall": 0.2727272727272727,
                        "f1-score": 0.32217909996979766,
                        "support": 55.0
                    }
                },
                "mining_4": {
                    "AFTER": {
                        "precision": 0.25,
                        "recall": 0.18181818181818182,
                        "f1-score": 0.2105263157894737,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.42857142857142855,
                        "recall": 0.12,
                        "f1-score": 0.1875,
                        "support": 25.0
                    },
                    "COEX": {
                        "precision": 0.16666666666666666,
                        "recall": 0.1111111111111111,
                        "f1-score": 0.13333333333333333,
                        "support": 9.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.13333333333333333,
                    "macro avg": {
                        "precision": 0.2113095238095238,
                        "recall": 0.10323232323232323,
                        "f1-score": 0.13283991228070174,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.3325396825396825,
                        "recall": 0.13333333333333333,
                        "f1-score": 0.1822953216374269,
                        "support": 45.0
                    }
                },
                "disasters_and_accidents_volcanoes_4": {
                    "AFTER": {
                        "precision": 0.7272727272727273,
                        "recall": 0.4,
                        "f1-score": 0.5161290322580645,
                        "support": 20.0
                    },
                    "BEFORE": {
                        "precision": 0.45454545454545453,
                        "recall": 0.35714285714285715,
                        "f1-score": 0.4,
                        "support": 14.0
                    },
                    "COEX": {
                        "precision": 0.14285714285714285,
                        "recall": 1.0,
                        "f1-score": 0.25,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.4166666666666667,
                        "recall": 0.4166666666666667,
                        "f1-score": 0.4166666666666667,
                        "support": 36.0
                    },
                    "macro avg": {
                        "precision": 0.33116883116883117,
                        "recall": 0.4392857142857143,
                        "f1-score": 0.2915322580645161,
                        "support": 36.0
                    },
                    "weighted avg": {
                        "precision": 0.5887445887445888,
                        "recall": 0.4166666666666667,
                        "f1-score": 0.4561827956989247,
                        "support": 36.0
                    }
                },
                "politics_and_conflicts_elections_3": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.6,
                        "f1-score": 0.5454545454545454,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.25,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.2,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.26666666666666666,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.26666666666666666,
                        "support": 15.0
                    },
                    "macro avg": {
                        "precision": 0.1875,
                        "recall": 0.19166666666666665,
                        "f1-score": 0.18636363636363634,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.26666666666666666,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.26181818181818184,
                        "support": 15.0
                    }
                },
                "economy_and_business_strikes_3": {
                    "AFTER": {
                        "precision": 0.625,
                        "recall": 0.5,
                        "f1-score": 0.5555555555555556,
                        "support": 10.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.45454545454545453,
                        "f1-score": 0.47619047619047616,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.2857142857142857,
                        "recall": 0.2857142857142857,
                        "f1-score": 0.2857142857142857,
                        "support": 7.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.42857142857142855,
                    "macro avg": {
                        "precision": 0.3526785714285714,
                        "recall": 0.31006493506493504,
                        "f1-score": 0.3293650793650793,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.49107142857142855,
                        "recall": 0.42857142857142855,
                        "f1-score": 0.45691609977324266,
                        "support": 28.0
                    }
                },
                "space_2": {
                    "AFTER": {
                        "precision": 0.7142857142857143,
                        "recall": 0.3,
                        "f1-score": 0.4225352112676056,
                        "support": 100.0
                    },
                    "BEFORE": {
                        "precision": 0.2903225806451613,
                        "recall": 0.17647058823529413,
                        "f1-score": 0.21951219512195125,
                        "support": 51.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2549019607843137,
                    "macro avg": {
                        "precision": 0.2511520737327189,
                        "recall": 0.11911764705882352,
                        "f1-score": 0.16051185159738923,
                        "support": 153.0
                    },
                    "weighted avg": {
                        "precision": 0.5636276015782657,
                        "recall": 0.2549019607843137,
                        "f1-score": 0.3493375364573861,
                        "support": 153.0
                    }
                },
                "politics_and_conflicts_resign_1": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.5,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 3.0
                    },
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.08333333333333333,
                        "f1-score": 0.125,
                        "support": 3.0
                    },
                    "weighted avg": {
                        "precision": 1.0,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.5,
                        "support": 3.0
                    }
                },
                "environment_4": {
                    "AFTER": {
                        "precision": 0.2,
                        "recall": 0.25,
                        "f1-score": 0.22222222222222224,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.25,
                        "recall": 0.2,
                        "f1-score": 0.22222222222222224,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.26666666666666666,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.26666666666666666,
                        "support": 15.0
                    },
                    "macro avg": {
                        "precision": 0.19583333333333333,
                        "recall": 0.19583333333333333,
                        "f1-score": 0.19444444444444445,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.26999999999999996,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.26666666666666666,
                        "support": 15.0
                    }
                },
                "space_1_extra": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.2,
                        "f1-score": 0.28571428571428575,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.16666666666666666,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.16666666666666666,
                        "support": 6.0
                    },
                    "macro avg": {
                        "precision": 0.125,
                        "recall": 0.05,
                        "f1-score": 0.07142857142857144,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.4166666666666667,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.23809523809523814,
                        "support": 6.0
                    }
                },
                "health_3": {
                    "AFTER": {
                        "precision": 0.3333333333333333,
                        "recall": 0.25,
                        "f1-score": 0.28571428571428575,
                        "support": 8.0
                    },
                    "BEFORE": {
                        "precision": 0.2857142857142857,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.30769230769230765,
                        "support": 6.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.26666666666666666,
                    "macro avg": {
                        "precision": 0.15476190476190477,
                        "recall": 0.14583333333333331,
                        "f1-score": 0.14835164835164835,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.292063492063492,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.2754578754578754,
                        "support": 15.0
                    }
                },
                "environment_3": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.36363636363636365,
                        "f1-score": 0.5333333333333333,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 0.5,
                        "f1-score": 0.4,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.2,
                        "recall": 0.5,
                        "f1-score": 0.28571428571428575,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.4,
                    "macro avg": {
                        "precision": 0.3833333333333333,
                        "recall": 0.34090909090909094,
                        "f1-score": 0.3047619047619048,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.8044444444444444,
                        "recall": 0.4,
                        "f1-score": 0.4825396825396825,
                        "support": 15.0
                    }
                },
                "government_and_politics_protests_3": {
                    "AFTER": {
                        "precision": 0.6666666666666666,
                        "recall": 0.5,
                        "f1-score": 0.5714285714285715,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "COEX": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.5,
                        "recall": 0.5,
                        "f1-score": 0.5,
                        "support": 6.0
                    },
                    "macro avg": {
                        "precision": 0.41666666666666663,
                        "recall": 0.375,
                        "f1-score": 0.3928571428571429,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.611111111111111,
                        "recall": 0.5,
                        "f1-score": 0.5476190476190477,
                        "support": 6.0
                    }
                },
                "economy_and_business_financial_crisis_4": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.4,
                        "support": 12.0
                    },
                    "BEFORE": {
                        "precision": 0.16666666666666666,
                        "recall": 0.2,
                        "f1-score": 0.1818181818181818,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.2857142857142857,
                        "recall": 0.5,
                        "f1-score": 0.36363636363636365,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 21.0
                    },
                    "macro avg": {
                        "precision": 0.23809523809523808,
                        "recall": 0.2583333333333333,
                        "f1-score": 0.23636363636363636,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.3798185941043084,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.34112554112554117,
                        "support": 21.0
                    }
                },
                "computers_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    }
                },
                "crime_and_law_accuse_4": {
                    "AFTER": {
                        "precision": 0.2,
                        "recall": 0.2,
                        "f1-score": 0.20000000000000004,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.1,
                        "recall": 0.1,
                        "f1-score": 0.10000000000000002,
                        "support": 10.0
                    },
                    "macro avg": {
                        "precision": 0.05,
                        "recall": 0.05,
                        "f1-score": 0.05000000000000001,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.1,
                        "recall": 0.1,
                        "f1-score": 0.10000000000000002,
                        "support": 10.0
                    }
                },
                "culture_and_entertainment_1": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.5,
                        "f1-score": 0.6666666666666666,
                        "support": 2.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.5,
                        "f1-score": 0.5,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.3333333333333333,
                        "recall": 0.5,
                        "f1-score": 0.4,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.5,
                        "recall": 0.5,
                        "f1-score": 0.5,
                        "support": 6.0
                    },
                    "macro avg": {
                        "precision": 0.4583333333333333,
                        "recall": 0.375,
                        "f1-score": 0.3916666666666666,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.611111111111111,
                        "recall": 0.5,
                        "f1-score": 0.5222222222222221,
                        "support": 6.0
                    }
                },
                "internet_2": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.6,
                        "f1-score": 0.7499999999999999,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.25,
                        "f1-score": 0.4,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.2,
                        "recall": 1.0,
                        "f1-score": 0.33333333333333337,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.5,
                    "macro avg": {
                        "precision": 0.55,
                        "recall": 0.4625,
                        "f1-score": 0.37083333333333335,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.9199999999999999,
                        "recall": 0.5,
                        "f1-score": 0.5683333333333332,
                        "support": 10.0
                    }
                },
                "culture_and_entertainment_3": {
                    "AFTER": {
                        "precision": 0.42857142857142855,
                        "recall": 0.6,
                        "f1-score": 0.5,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.5,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.4,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 15.0
                    },
                    "macro avg": {
                        "precision": 0.23214285714285715,
                        "recall": 0.23333333333333334,
                        "f1-score": 0.225,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.3428571428571428,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3266666666666667,
                        "support": 15.0
                    }
                }
            }
        }
    }
}

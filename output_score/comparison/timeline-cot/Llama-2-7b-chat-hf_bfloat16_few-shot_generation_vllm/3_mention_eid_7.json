{
    "args": {
        "batch_size": 8,
        "chunk_size": 4096,
        "dataset_name": "ctf-timeline-cot",
        "device": "cuda",
        "dirpath_log": "log",
        "dirpath_model": null,
        "dirpath_output": "output/comparison",
        "dirpath_output_score": "output_score/comparison",
        "filepath_test": "data/preprocessed/ctf-sample/test.json",
        "filepath_dev": "data/preprocessed/ctf-sample/dev.json",
        "inference_type": "few-shot",
        "local_rank": 0,
        "marker": "eid",
        "max_new_tokens": 512,
        "model_id": "meta-llama/Llama-2-7b-chat-hf",
        "num_demonstration": 3,
        "num_gpu": 1,
        "num_cpu": 4,
        "precision_type": "bfloat16",
        "representation": "mention",
        "seed": 7,
        "temperature": 0.0,
        "dirpath_model_cache": "/data/tir/projects/tir6/general/kimihiro/.cache/huggingface/transformers",
        "top_p": 1
    },
    "average": {
        "document-and-pair-wise-scores": {
            "range": {
                "min": 0.23681718934479892,
                "median": 0.31950180436777376,
                "max": 0.3775526439431248
            },
            "individual": {
                "simple": 0.23681718934479892,
                "list": 0.3775526439431248,
                "chronological": 0.31950180436777376,
                "you": 0.31806818007198945,
                "suppose": 0.35107507368356416
            }
        }
    },
    "individuals": {
        "document-and-pair-wise-scores": {
            "simple": {
                "government_and_politics_riots_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.16666666666666666,
                        "recall": 0.08333333333333333,
                        "f1-score": 0.1111111111111111,
                        "support": 12.0
                    },
                    "COEX": {
                        "precision": 0.4666666666666667,
                        "recall": 0.5833333333333334,
                        "f1-score": 0.5185185185185186,
                        "support": 12.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2857142857142857,
                    "macro avg": {
                        "precision": 0.15833333333333333,
                        "recall": 0.16666666666666669,
                        "f1-score": 0.15740740740740744,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.2714285714285714,
                        "recall": 0.2857142857142857,
                        "f1-score": 0.2698412698412699,
                        "support": 28.0
                    }
                },
                "rail_transport_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.23529411764705882,
                        "f1-score": 0.38095238095238093,
                        "support": 34.0
                    },
                    "COEX": {
                        "precision": 0.07142857142857142,
                        "recall": 1.0,
                        "f1-score": 0.13333333333333333,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.2777777777777778,
                        "recall": 0.2777777777777778,
                        "f1-score": 0.2777777777777778,
                        "support": 36.0
                    },
                    "macro avg": {
                        "precision": 0.26785714285714285,
                        "recall": 0.3088235294117647,
                        "f1-score": 0.12857142857142856,
                        "support": 36.0
                    },
                    "weighted avg": {
                        "precision": 0.9484126984126985,
                        "recall": 0.2777777777777778,
                        "f1-score": 0.36719576719576724,
                        "support": 36.0
                    }
                },
                "politics_and_conflicts_policy_change_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 1.0,
                        "f1-score": 0.5,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 6.0
                    },
                    "macro avg": {
                        "precision": 0.08333333333333333,
                        "recall": 0.25,
                        "f1-score": 0.125,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.1111111111111111,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.16666666666666666,
                        "support": 6.0
                    }
                },
                "politics_and_conflicts_drones_1": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.45454545454545453,
                        "f1-score": 0.625,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 8.0
                    },
                    "COEX": {
                        "precision": 0.06666666666666667,
                        "recall": 0.5,
                        "f1-score": 0.11764705882352941,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.2857142857142857,
                        "recall": 0.2857142857142857,
                        "f1-score": 0.2857142857142857,
                        "support": 21.0
                    },
                    "macro avg": {
                        "precision": 0.26666666666666666,
                        "recall": 0.23863636363636365,
                        "f1-score": 0.18566176470588236,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.5301587301587302,
                        "recall": 0.2857142857142857,
                        "f1-score": 0.3385854341736695,
                        "support": 21.0
                    }
                },
                "disasters_and_accidents_road_crash_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "BEFORE": {
                        "precision": 0.5333333333333333,
                        "recall": 0.7272727272727273,
                        "f1-score": 0.6153846153846153,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 10.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.38095238095238093,
                        "recall": 0.38095238095238093,
                        "f1-score": 0.38095238095238093,
                        "support": 21.0
                    },
                    "macro avg": {
                        "precision": 0.13333333333333333,
                        "recall": 0.18181818181818182,
                        "f1-score": 0.15384615384615383,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.27936507936507937,
                        "recall": 0.38095238095238093,
                        "f1-score": 0.3223443223443223,
                        "support": 21.0
                    }
                },
                "crime_and_law_accuse_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.25,
                        "support": 6.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.1,
                        "recall": 0.1,
                        "f1-score": 0.10000000000000002,
                        "support": 10.0
                    },
                    "macro avg": {
                        "precision": 0.125,
                        "recall": 0.041666666666666664,
                        "f1-score": 0.0625,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.3,
                        "recall": 0.1,
                        "f1-score": 0.15,
                        "support": 10.0
                    }
                },
                "government_and_politics_protests_2": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.2,
                        "f1-score": 0.33333333333333337,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.3,
                        "f1-score": 0.4615384615384615,
                        "support": 20.0
                    },
                    "COEX": {
                        "precision": 0.14285714285714285,
                        "recall": 1.0,
                        "f1-score": 0.25,
                        "support": 3.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.35714285714285715,
                        "recall": 0.35714285714285715,
                        "f1-score": 0.35714285714285715,
                        "support": 28.0
                    },
                    "macro avg": {
                        "precision": 0.5357142857142857,
                        "recall": 0.375,
                        "f1-score": 0.26121794871794873,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.9081632653061223,
                        "recall": 0.35714285714285715,
                        "f1-score": 0.4159798534798535,
                        "support": 28.0
                    }
                },
                "politics_and_conflicts_elections_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 22.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 14.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 9.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.0,
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 45.0
                    }
                },
                "environment_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 21.0
                    },
                    "BEFORE": {
                        "precision": 0.6388888888888888,
                        "recall": 1.0,
                        "f1-score": 0.7796610169491525,
                        "support": 23.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.5111111111111111,
                    "macro avg": {
                        "precision": 0.1597222222222222,
                        "recall": 0.25,
                        "f1-score": 0.19491525423728812,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.3265432098765432,
                        "recall": 0.5111111111111111,
                        "f1-score": 0.3984934086629001,
                        "support": 45.0
                    }
                },
                "weather_floods_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.6666666666666666,
                        "recall": 0.2857142857142857,
                        "f1-score": 0.4,
                        "support": 7.0
                    },
                    "COEX": {
                        "precision": 0.3333333333333333,
                        "recall": 0.25,
                        "f1-score": 0.28571428571428575,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2,
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.13392857142857142,
                        "f1-score": 0.17142857142857143,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.39999999999999997,
                        "recall": 0.2,
                        "f1-score": 0.26285714285714284,
                        "support": 15.0
                    }
                },
                "sports_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    }
                },
                "health_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 9.0
                    },
                    "BEFORE": {
                        "precision": 0.4666666666666667,
                        "recall": 0.875,
                        "f1-score": 0.608695652173913,
                        "support": 8.0
                    },
                    "COEX": {
                        "precision": 0.16666666666666666,
                        "recall": 0.25,
                        "f1-score": 0.2,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.38095238095238093,
                        "recall": 0.38095238095238093,
                        "f1-score": 0.38095238095238093,
                        "support": 21.0
                    },
                    "macro avg": {
                        "precision": 0.15833333333333333,
                        "recall": 0.28125,
                        "f1-score": 0.20217391304347826,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.20952380952380953,
                        "recall": 0.38095238095238093,
                        "f1-score": 0.26997929606625254,
                        "support": 21.0
                    }
                },
                "weather_earthquakes_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "BEFORE": {
                        "precision": 0.75,
                        "recall": 0.75,
                        "f1-score": 0.75,
                        "support": 32.0
                    },
                    "COEX": {
                        "precision": 0.5,
                        "recall": 0.2857142857142857,
                        "f1-score": 0.36363636363636365,
                        "support": 7.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.5777777777777777,
                    "macro avg": {
                        "precision": 0.3125,
                        "recall": 0.2589285714285714,
                        "f1-score": 0.27840909090909094,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.6111111111111112,
                        "recall": 0.5777777777777777,
                        "f1-score": 0.5898989898989899,
                        "support": 45.0
                    }
                },
                "space_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 15.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.0,
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 28.0
                    }
                },
                "economy_and_business_strikes_2": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.8,
                        "recall": 1.0,
                        "f1-score": 0.888888888888889,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.8333333333333334,
                        "recall": 0.8333333333333334,
                        "f1-score": 0.8333333333333334,
                        "support": 6.0
                    },
                    "macro avg": {
                        "precision": 0.45,
                        "recall": 0.5,
                        "f1-score": 0.4722222222222222,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.7000000000000001,
                        "recall": 0.8333333333333334,
                        "f1-score": 0.7592592592592592,
                        "support": 6.0
                    }
                },
                "politics_and_conflicts_armed_conflict_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.3,
                        "recall": 1.0,
                        "f1-score": 0.4615384615384615,
                        "support": 3.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.2,
                        "recall": 0.2,
                        "f1-score": 0.20000000000000004,
                        "support": 15.0
                    },
                    "macro avg": {
                        "precision": 0.075,
                        "recall": 0.25,
                        "f1-score": 0.11538461538461538,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.05999999999999999,
                        "recall": 0.2,
                        "f1-score": 0.0923076923076923,
                        "support": 15.0
                    }
                },
                "infectious_disease_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    }
                },
                "health_1": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.5,
                        "support": 6.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 0.6666666666666666,
                        "f1-score": 0.4444444444444444,
                        "support": 3.0
                    },
                    "COEX": {
                        "precision": 0.5,
                        "recall": 1.0,
                        "f1-score": 0.6666666666666666,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.5,
                        "recall": 0.5,
                        "f1-score": 0.5,
                        "support": 10.0
                    },
                    "macro avg": {
                        "precision": 0.4583333333333333,
                        "recall": 0.5,
                        "f1-score": 0.4027777777777778,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.75,
                        "recall": 0.5,
                        "f1-score": 0.5,
                        "support": 10.0
                    }
                },
                "disasters_and_accidents_shipwreck_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.6153846153846154,
                        "recall": 0.8888888888888888,
                        "f1-score": 0.7272727272727274,
                        "support": 9.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.38095238095238093,
                    "macro avg": {
                        "precision": 0.15384615384615385,
                        "recall": 0.2222222222222222,
                        "f1-score": 0.18181818181818185,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.26373626373626374,
                        "recall": 0.38095238095238093,
                        "f1-score": 0.31168831168831174,
                        "support": 21.0
                    }
                },
                "rail_transport_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.8,
                        "recall": 0.4,
                        "f1-score": 0.5333333333333333,
                        "support": 10.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.26666666666666666,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.26666666666666666,
                        "support": 15.0
                    },
                    "macro avg": {
                        "precision": 0.2,
                        "recall": 0.1,
                        "f1-score": 0.13333333333333333,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.5333333333333333,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.3555555555555555,
                        "support": 15.0
                    }
                },
                "weather_storms_1_extra": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    }
                },
                "health_1_extra": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.4166666666666667,
                        "f1-score": 0.5882352941176471,
                        "support": 12.0
                    },
                    "BEFORE": {
                        "precision": 0.7931034482758621,
                        "recall": 0.8214285714285714,
                        "f1-score": 0.8070175438596492,
                        "support": 28.0
                    },
                    "COEX": {
                        "precision": 0.47619047619047616,
                        "recall": 0.6666666666666666,
                        "f1-score": 0.5555555555555556,
                        "support": 15.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.6909090909090909,
                        "recall": 0.6909090909090909,
                        "f1-score": 0.6909090909090909,
                        "support": 55.0
                    },
                    "macro avg": {
                        "precision": 0.5673234811165846,
                        "recall": 0.47619047619047616,
                        "f1-score": 0.48770209838321293,
                        "support": 55.0
                    },
                    "weighted avg": {
                        "precision": 0.7518137035378415,
                        "recall": 0.6909090909090909,
                        "f1-score": 0.6907026925602777,
                        "support": 55.0
                    }
                },
                "weather_floods_1": {
                    "AFTER": {
                        "precision": 0.2,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.25,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.6216216216216216,
                        "recall": 0.9583333333333334,
                        "f1-score": 0.7540983606557377,
                        "support": 24.0
                    },
                    "COEX": {
                        "precision": 0.9230769230769231,
                        "recall": 0.42857142857142855,
                        "f1-score": 0.5853658536585366,
                        "support": 28.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.6545454545454545,
                        "recall": 0.6545454545454545,
                        "f1-score": 0.6545454545454545,
                        "support": 55.0
                    },
                    "macro avg": {
                        "precision": 0.4361746361746362,
                        "recall": 0.43005952380952384,
                        "f1-score": 0.3973660535785686,
                        "support": 55.0
                    },
                    "weighted avg": {
                        "precision": 0.7520922320922321,
                        "recall": 0.6545454545454545,
                        "f1-score": 0.6407019010577588,
                        "support": 55.0
                    }
                },
                "mining_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 25.0
                    },
                    "COEX": {
                        "precision": 0.25,
                        "recall": 1.0,
                        "f1-score": 0.4,
                        "support": 9.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.2,
                        "recall": 0.2,
                        "f1-score": 0.20000000000000004,
                        "support": 45.0
                    },
                    "macro avg": {
                        "precision": 0.0625,
                        "recall": 0.25,
                        "f1-score": 0.1,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.05,
                        "recall": 0.2,
                        "f1-score": 0.08,
                        "support": 45.0
                    }
                },
                "disasters_and_accidents_volcanoes_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 20.0
                    },
                    "BEFORE": {
                        "precision": 0.32,
                        "recall": 0.5714285714285714,
                        "f1-score": 0.41025641025641024,
                        "support": 14.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2222222222222222,
                    "macro avg": {
                        "precision": 0.08,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.10256410256410256,
                        "support": 36.0
                    },
                    "weighted avg": {
                        "precision": 0.12444444444444445,
                        "recall": 0.2222222222222222,
                        "f1-score": 0.15954415954415954,
                        "support": 36.0
                    }
                },
                "politics_and_conflicts_elections_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.3076923076923077,
                        "recall": 1.0,
                        "f1-score": 0.47058823529411764,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.5,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.25,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 15.0
                    },
                    "macro avg": {
                        "precision": 0.20192307692307693,
                        "recall": 0.2916666666666667,
                        "f1-score": 0.1801470588235294,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.28205128205128205,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.22549019607843138,
                        "support": 15.0
                    }
                },
                "economy_and_business_strikes_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 10.0
                    },
                    "BEFORE": {
                        "precision": 0.2777777777777778,
                        "recall": 0.45454545454545453,
                        "f1-score": 0.3448275862068966,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.4444444444444444,
                        "recall": 0.5714285714285714,
                        "f1-score": 0.5,
                        "support": 7.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.32142857142857145,
                        "recall": 0.32142857142857145,
                        "f1-score": 0.32142857142857145,
                        "support": 28.0
                    },
                    "macro avg": {
                        "precision": 0.18055555555555555,
                        "recall": 0.2564935064935065,
                        "f1-score": 0.21120689655172414,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.2202380952380952,
                        "recall": 0.32142857142857145,
                        "f1-score": 0.2604679802955665,
                        "support": 28.0
                    }
                },
                "space_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 100.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 51.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.0,
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 153.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 153.0
                    }
                },
                "politics_and_conflicts_resign_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    }
                },
                "environment_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.0,
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 15.0
                    }
                },
                "space_1_extra": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    }
                },
                "health_3": {
                    "AFTER": {
                        "precision": 0.8333333333333334,
                        "recall": 0.625,
                        "f1-score": 0.7142857142857143,
                        "support": 8.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.4,
                        "support": 6.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.4666666666666667,
                    "macro avg": {
                        "precision": 0.33333333333333337,
                        "recall": 0.23958333333333331,
                        "f1-score": 0.2785714285714286,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.6444444444444445,
                        "recall": 0.4666666666666667,
                        "f1-score": 0.540952380952381,
                        "support": 15.0
                    }
                },
                "environment_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.0,
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 15.0
                    }
                },
                "government_and_politics_protests_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 1.0,
                        "f1-score": 0.5,
                        "support": 1.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.16666666666666666,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.16666666666666666,
                        "support": 6.0
                    },
                    "macro avg": {
                        "precision": 0.08333333333333333,
                        "recall": 0.25,
                        "f1-score": 0.125,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.05555555555555555,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.08333333333333333,
                        "support": 6.0
                    }
                },
                "economy_and_business_financial_crisis_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 12.0
                    },
                    "BEFORE": {
                        "precision": 0.16666666666666666,
                        "recall": 0.6,
                        "f1-score": 0.2608695652173913,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.14285714285714285,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.14285714285714285,
                        "support": 21.0
                    },
                    "macro avg": {
                        "precision": 0.041666666666666664,
                        "recall": 0.15,
                        "f1-score": 0.06521739130434782,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.03968253968253968,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.062111801242236024,
                        "support": 21.0
                    }
                },
                "computers_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    }
                },
                "crime_and_law_accuse_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.8,
                        "f1-score": 0.888888888888889,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.4,
                        "recall": 0.4,
                        "f1-score": 0.4000000000000001,
                        "support": 10.0
                    },
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.2,
                        "f1-score": 0.22222222222222224,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.5,
                        "recall": 0.4,
                        "f1-score": 0.4444444444444445,
                        "support": 10.0
                    }
                },
                "culture_and_entertainment_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 1.0,
                        "f1-score": 0.5,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 6.0
                    },
                    "macro avg": {
                        "precision": 0.08333333333333333,
                        "recall": 0.25,
                        "f1-score": 0.125,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.1111111111111111,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.16666666666666666,
                        "support": 6.0
                    }
                },
                "internet_2": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.2,
                        "f1-score": 0.33333333333333337,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.5,
                        "f1-score": 0.6666666666666666,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.3,
                    "macro avg": {
                        "precision": 0.5,
                        "recall": 0.175,
                        "f1-score": 0.25,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.9,
                        "recall": 0.3,
                        "f1-score": 0.4333333333333334,
                        "support": 10.0
                    }
                },
                "culture_and_entertainment_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 1.0,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.2857142857142857,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.06666666666666667,
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.041666666666666664,
                        "f1-score": 0.07142857142857142,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.4,
                        "recall": 0.06666666666666667,
                        "f1-score": 0.11428571428571428,
                        "support": 15.0
                    }
                }
            },
            "list": {
                "government_and_politics_riots_4": {
                    "AFTER": {
                        "precision": 0.2,
                        "recall": 0.25,
                        "f1-score": 0.22222222222222224,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.25,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.28571428571428575,
                        "support": 12.0
                    },
                    "COEX": {
                        "precision": 0.14285714285714285,
                        "recall": 0.08333333333333333,
                        "f1-score": 0.10526315789473685,
                        "support": 12.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.21428571428571427,
                        "recall": 0.21428571428571427,
                        "f1-score": 0.21428571428571427,
                        "support": 28.0
                    },
                    "macro avg": {
                        "precision": 0.14821428571428572,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.15329991645781121,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.19693877551020408,
                        "recall": 0.21428571428571427,
                        "f1-score": 0.19930779329275575,
                        "support": 28.0
                    }
                },
                "rail_transport_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "BEFORE": {
                        "precision": 0.9444444444444444,
                        "recall": 1.0,
                        "f1-score": 0.9714285714285714,
                        "support": 34.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.9444444444444444,
                        "recall": 0.9444444444444444,
                        "f1-score": 0.9444444444444444,
                        "support": 36.0
                    },
                    "macro avg": {
                        "precision": 0.2361111111111111,
                        "recall": 0.25,
                        "f1-score": 0.24285714285714285,
                        "support": 36.0
                    },
                    "weighted avg": {
                        "precision": 0.8919753086419752,
                        "recall": 0.9444444444444444,
                        "f1-score": 0.9174603174603173,
                        "support": 36.0
                    }
                },
                "politics_and_conflicts_policy_change_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 1.0,
                        "f1-score": 0.5,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 6.0
                    },
                    "macro avg": {
                        "precision": 0.08333333333333333,
                        "recall": 0.25,
                        "f1-score": 0.125,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.1111111111111111,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.16666666666666666,
                        "support": 6.0
                    }
                },
                "politics_and_conflicts_drones_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.4117647058823529,
                        "recall": 0.875,
                        "f1-score": 0.56,
                        "support": 8.0
                    },
                    "COEX": {
                        "precision": 0.5,
                        "recall": 0.5,
                        "f1-score": 0.5,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.38095238095238093,
                        "recall": 0.38095238095238093,
                        "f1-score": 0.38095238095238093,
                        "support": 21.0
                    },
                    "macro avg": {
                        "precision": 0.22794117647058823,
                        "recall": 0.34375,
                        "f1-score": 0.265,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.20448179271708683,
                        "recall": 0.38095238095238093,
                        "f1-score": 0.260952380952381,
                        "support": 21.0
                    }
                },
                "disasters_and_accidents_road_crash_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "BEFORE": {
                        "precision": 0.5238095238095238,
                        "recall": 1.0,
                        "f1-score": 0.6875000000000001,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 10.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.5238095238095238,
                        "recall": 0.5238095238095238,
                        "f1-score": 0.5238095238095238,
                        "support": 21.0
                    },
                    "macro avg": {
                        "precision": 0.13095238095238096,
                        "recall": 0.25,
                        "f1-score": 0.17187500000000003,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.2743764172335601,
                        "recall": 0.5238095238095238,
                        "f1-score": 0.36011904761904767,
                        "support": 21.0
                    }
                },
                "crime_and_law_accuse_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.6,
                        "recall": 0.5,
                        "f1-score": 0.5454545454545454,
                        "support": 6.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.3,
                    "macro avg": {
                        "precision": 0.15,
                        "recall": 0.125,
                        "f1-score": 0.13636363636363635,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.36,
                        "recall": 0.3,
                        "f1-score": 0.32727272727272727,
                        "support": 10.0
                    }
                },
                "government_and_politics_protests_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.7142857142857143,
                        "recall": 1.0,
                        "f1-score": 0.8333333333333333,
                        "support": 20.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.7142857142857143,
                        "recall": 0.7142857142857143,
                        "f1-score": 0.7142857142857143,
                        "support": 28.0
                    },
                    "macro avg": {
                        "precision": 0.17857142857142858,
                        "recall": 0.25,
                        "f1-score": 0.20833333333333331,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.5102040816326531,
                        "recall": 0.7142857142857143,
                        "f1-score": 0.5952380952380951,
                        "support": 28.0
                    }
                },
                "politics_and_conflicts_elections_2": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.045454545454545456,
                        "f1-score": 0.08695652173913045,
                        "support": 22.0
                    },
                    "BEFORE": {
                        "precision": 0.3181818181818182,
                        "recall": 0.5,
                        "f1-score": 0.3888888888888889,
                        "support": 14.0
                    },
                    "COEX": {
                        "precision": 0.2,
                        "recall": 0.1111111111111111,
                        "f1-score": 0.14285714285714285,
                        "support": 9.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2,
                    "macro avg": {
                        "precision": 0.3795454545454545,
                        "recall": 0.16414141414141414,
                        "f1-score": 0.15467563837129056,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.6278787878787878,
                        "recall": 0.2,
                        "f1-score": 0.19207116018710224,
                        "support": 45.0
                    }
                },
                "environment_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 21.0
                    },
                    "BEFORE": {
                        "precision": 0.4166666666666667,
                        "recall": 0.6521739130434783,
                        "f1-score": 0.5084745762711865,
                        "support": 23.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.3333333333333333,
                    "macro avg": {
                        "precision": 0.10416666666666667,
                        "recall": 0.16304347826086957,
                        "f1-score": 0.12711864406779663,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.21296296296296297,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.25988700564971756,
                        "support": 45.0
                    }
                },
                "weather_floods_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.46153846153846156,
                        "recall": 0.8571428571428571,
                        "f1-score": 0.6,
                        "support": 7.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.4,
                        "recall": 0.4,
                        "f1-score": 0.4000000000000001,
                        "support": 15.0
                    },
                    "macro avg": {
                        "precision": 0.11538461538461539,
                        "recall": 0.21428571428571427,
                        "f1-score": 0.15,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.2153846153846154,
                        "recall": 0.4,
                        "f1-score": 0.28,
                        "support": 15.0
                    }
                },
                "sports_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 1.0,
                        "f1-score": 0.5,
                        "support": 1.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 3.0
                    },
                    "macro avg": {
                        "precision": 0.08333333333333333,
                        "recall": 0.25,
                        "f1-score": 0.125,
                        "support": 3.0
                    },
                    "weighted avg": {
                        "precision": 0.1111111111111111,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.16666666666666666,
                        "support": 3.0
                    }
                },
                "health_4": {
                    "AFTER": {
                        "precision": 0.75,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.46153846153846156,
                        "support": 9.0
                    },
                    "BEFORE": {
                        "precision": 0.5714285714285714,
                        "recall": 0.5,
                        "f1-score": 0.5333333333333333,
                        "support": 8.0
                    },
                    "COEX": {
                        "precision": 0.25,
                        "recall": 0.25,
                        "f1-score": 0.25,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.38095238095238093,
                    "macro avg": {
                        "precision": 0.39285714285714285,
                        "recall": 0.2708333333333333,
                        "f1-score": 0.3112179487179487,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.5867346938775511,
                        "recall": 0.38095238095238093,
                        "f1-score": 0.4485958485958486,
                        "support": 21.0
                    }
                },
                "weather_earthquakes_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "BEFORE": {
                        "precision": 0.6944444444444444,
                        "recall": 0.78125,
                        "f1-score": 0.7352941176470588,
                        "support": 32.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 7.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.5555555555555556,
                    "macro avg": {
                        "precision": 0.1736111111111111,
                        "recall": 0.1953125,
                        "f1-score": 0.1838235294117647,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.49382716049382713,
                        "recall": 0.5555555555555556,
                        "f1-score": 0.522875816993464,
                        "support": 45.0
                    }
                },
                "space_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 15.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.0,
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 28.0
                    }
                },
                "economy_and_business_strikes_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.6666666666666666,
                        "recall": 1.0,
                        "f1-score": 0.8,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.6666666666666666,
                        "recall": 0.6666666666666666,
                        "f1-score": 0.6666666666666666,
                        "support": 6.0
                    },
                    "macro avg": {
                        "precision": 0.16666666666666666,
                        "recall": 0.25,
                        "f1-score": 0.2,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.4444444444444444,
                        "recall": 0.6666666666666666,
                        "f1-score": 0.5333333333333333,
                        "support": 6.0
                    }
                },
                "politics_and_conflicts_armed_conflict_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.6666666666666666,
                        "recall": 0.36363636363636365,
                        "f1-score": 0.4705882352941177,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.25,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.28571428571428575,
                        "support": 3.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 15.0
                    },
                    "macro avg": {
                        "precision": 0.22916666666666666,
                        "recall": 0.17424242424242425,
                        "f1-score": 0.18907563025210086,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.5388888888888889,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.40224089635854343,
                        "support": 15.0
                    }
                },
                "infectious_disease_4": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.25,
                        "f1-score": 0.25,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    }
                },
                "health_1": {
                    "AFTER": {
                        "precision": 0.75,
                        "recall": 0.5,
                        "f1-score": 0.6,
                        "support": 6.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 1.0,
                        "f1-score": 0.6666666666666666,
                        "support": 3.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.6,
                        "recall": 0.6,
                        "f1-score": 0.6,
                        "support": 10.0
                    },
                    "macro avg": {
                        "precision": 0.3125,
                        "recall": 0.375,
                        "f1-score": 0.31666666666666665,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.6,
                        "recall": 0.6,
                        "f1-score": 0.5599999999999999,
                        "support": 10.0
                    }
                },
                "disasters_and_accidents_shipwreck_2": {
                    "AFTER": {
                        "precision": 0.6,
                        "recall": 0.5454545454545454,
                        "f1-score": 0.5714285714285713,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.4,
                        "recall": 0.2222222222222222,
                        "f1-score": 0.2857142857142857,
                        "support": 9.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.38095238095238093,
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.1919191919191919,
                        "f1-score": 0.21428571428571425,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.48571428571428565,
                        "recall": 0.38095238095238093,
                        "f1-score": 0.42176870748299305,
                        "support": 21.0
                    }
                },
                "rail_transport_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.6666666666666666,
                        "recall": 0.4,
                        "f1-score": 0.5,
                        "support": 10.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.26666666666666666,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.26666666666666666,
                        "support": 15.0
                    },
                    "macro avg": {
                        "precision": 0.16666666666666666,
                        "recall": 0.1,
                        "f1-score": 0.125,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.4444444444444444,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.3333333333333333,
                        "support": 15.0
                    }
                },
                "weather_storms_1_extra": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.25,
                        "f1-score": 0.25,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    }
                },
                "health_1_extra": {
                    "AFTER": {
                        "precision": 0.875,
                        "recall": 0.5833333333333334,
                        "f1-score": 0.7000000000000001,
                        "support": 12.0
                    },
                    "BEFORE": {
                        "precision": 0.6222222222222222,
                        "recall": 1.0,
                        "f1-score": 0.7671232876712328,
                        "support": 28.0
                    },
                    "COEX": {
                        "precision": 1.0,
                        "recall": 0.13333333333333333,
                        "f1-score": 0.23529411764705882,
                        "support": 15.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.6727272727272727,
                        "recall": 0.6727272727272727,
                        "f1-score": 0.6727272727272727,
                        "support": 55.0
                    },
                    "macro avg": {
                        "precision": 0.6243055555555556,
                        "recall": 0.4291666666666667,
                        "f1-score": 0.42560435132957297,
                        "support": 55.0
                    },
                    "weighted avg": {
                        "precision": 0.7804040404040404,
                        "recall": 0.6727272727272727,
                        "f1-score": 0.6074338876272801,
                        "support": 55.0
                    }
                },
                "weather_floods_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.5277777777777778,
                        "recall": 0.7916666666666666,
                        "f1-score": 0.6333333333333333,
                        "support": 24.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 28.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.34545454545454546,
                    "macro avg": {
                        "precision": 0.13194444444444445,
                        "recall": 0.19791666666666666,
                        "f1-score": 0.15833333333333333,
                        "support": 55.0
                    },
                    "weighted avg": {
                        "precision": 0.23030303030303031,
                        "recall": 0.34545454545454546,
                        "f1-score": 0.27636363636363637,
                        "support": 55.0
                    }
                },
                "mining_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.5714285714285714,
                        "recall": 0.96,
                        "f1-score": 0.7164179104477612,
                        "support": 25.0
                    },
                    "COEX": {
                        "precision": 0.3333333333333333,
                        "recall": 0.1111111111111111,
                        "f1-score": 0.16666666666666666,
                        "support": 9.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.5555555555555556,
                        "recall": 0.5555555555555556,
                        "f1-score": 0.5555555555555556,
                        "support": 45.0
                    },
                    "macro avg": {
                        "precision": 0.22619047619047616,
                        "recall": 0.2677777777777778,
                        "f1-score": 0.22077114427860695,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.3841269841269841,
                        "recall": 0.5555555555555556,
                        "f1-score": 0.4313432835820895,
                        "support": 45.0
                    }
                },
                "disasters_and_accidents_volcanoes_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 20.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 1.0,
                        "f1-score": 0.6666666666666666,
                        "support": 14.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.3888888888888889,
                    "macro avg": {
                        "precision": 0.125,
                        "recall": 0.25,
                        "f1-score": 0.16666666666666666,
                        "support": 36.0
                    },
                    "weighted avg": {
                        "precision": 0.19444444444444445,
                        "recall": 0.3888888888888889,
                        "f1-score": 0.25925925925925924,
                        "support": 36.0
                    }
                },
                "politics_and_conflicts_elections_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.26666666666666666,
                        "recall": 1.0,
                        "f1-score": 0.4210526315789474,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.26666666666666666,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.26666666666666666,
                        "support": 15.0
                    },
                    "macro avg": {
                        "precision": 0.06666666666666667,
                        "recall": 0.25,
                        "f1-score": 0.10526315789473685,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.07111111111111111,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.11228070175438597,
                        "support": 15.0
                    }
                },
                "economy_and_business_strikes_3": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.5,
                        "f1-score": 0.6666666666666666,
                        "support": 10.0
                    },
                    "BEFORE": {
                        "precision": 0.47619047619047616,
                        "recall": 0.9090909090909091,
                        "f1-score": 0.6249999999999999,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.5,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.22222222222222224,
                        "support": 7.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.5714285714285714,
                        "recall": 0.5714285714285714,
                        "f1-score": 0.5714285714285714,
                        "support": 28.0
                    },
                    "macro avg": {
                        "precision": 0.49404761904761907,
                        "recall": 0.387987012987013,
                        "f1-score": 0.3784722222222222,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.6692176870748299,
                        "recall": 0.5714285714285714,
                        "f1-score": 0.5391865079365078,
                        "support": 28.0
                    }
                },
                "space_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 100.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 51.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.0,
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 153.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 153.0
                    }
                },
                "politics_and_conflicts_resign_1": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.6666666666666666,
                        "f1-score": 0.8,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.6666666666666666,
                        "recall": 0.6666666666666666,
                        "f1-score": 0.6666666666666666,
                        "support": 3.0
                    },
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.2,
                        "support": 3.0
                    },
                    "weighted avg": {
                        "precision": 1.0,
                        "recall": 0.6666666666666666,
                        "f1-score": 0.8000000000000002,
                        "support": 3.0
                    }
                },
                "environment_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 1.0,
                        "f1-score": 0.5,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 15.0
                    },
                    "macro avg": {
                        "precision": 0.08333333333333333,
                        "recall": 0.25,
                        "f1-score": 0.125,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.1111111111111111,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.16666666666666666,
                        "support": 15.0
                    }
                },
                "space_1_extra": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.8333333333333334,
                        "recall": 1.0,
                        "f1-score": 0.9090909090909091,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.8333333333333334,
                        "recall": 0.8333333333333334,
                        "f1-score": 0.8333333333333334,
                        "support": 6.0
                    },
                    "macro avg": {
                        "precision": 0.20833333333333334,
                        "recall": 0.25,
                        "f1-score": 0.22727272727272727,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.6944444444444445,
                        "recall": 0.8333333333333334,
                        "f1-score": 0.7575757575757575,
                        "support": 6.0
                    }
                },
                "health_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 8.0
                    },
                    "BEFORE": {
                        "precision": 0.4,
                        "recall": 1.0,
                        "f1-score": 0.5714285714285715,
                        "support": 6.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.4,
                        "recall": 0.4,
                        "f1-score": 0.4000000000000001,
                        "support": 15.0
                    },
                    "macro avg": {
                        "precision": 0.1,
                        "recall": 0.25,
                        "f1-score": 0.14285714285714288,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.16000000000000003,
                        "recall": 0.4,
                        "f1-score": 0.2285714285714286,
                        "support": 15.0
                    }
                },
                "environment_3": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.5454545454545454,
                        "f1-score": 0.7058823529411764,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.2222222222222222,
                        "recall": 1.0,
                        "f1-score": 0.3636363636363636,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.5333333333333333,
                        "recall": 0.5333333333333333,
                        "f1-score": 0.5333333333333333,
                        "support": 15.0
                    },
                    "macro avg": {
                        "precision": 0.3055555555555556,
                        "recall": 0.38636363636363635,
                        "f1-score": 0.267379679144385,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.762962962962963,
                        "recall": 0.5333333333333333,
                        "f1-score": 0.5661319073083778,
                        "support": 15.0
                    }
                },
                "government_and_politics_protests_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.2,
                        "recall": 1.0,
                        "f1-score": 0.33333333333333337,
                        "support": 1.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.16666666666666666,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.16666666666666666,
                        "support": 6.0
                    },
                    "macro avg": {
                        "precision": 0.05,
                        "recall": 0.25,
                        "f1-score": 0.08333333333333334,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.03333333333333333,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.05555555555555556,
                        "support": 6.0
                    }
                },
                "economy_and_business_financial_crisis_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 12.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.0,
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 21.0
                    }
                },
                "computers_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    }
                },
                "crime_and_law_accuse_4": {
                    "AFTER": {
                        "precision": 0.75,
                        "recall": 0.6,
                        "f1-score": 0.6666666666666665,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.6,
                        "f1-score": 0.7499999999999999,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.6,
                        "recall": 0.6,
                        "f1-score": 0.6,
                        "support": 10.0
                    },
                    "macro avg": {
                        "precision": 0.4375,
                        "recall": 0.3,
                        "f1-score": 0.35416666666666663,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.875,
                        "recall": 0.6,
                        "f1-score": 0.7083333333333333,
                        "support": 10.0
                    }
                },
                "culture_and_entertainment_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 1.0,
                        "f1-score": 0.5,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 6.0
                    },
                    "macro avg": {
                        "precision": 0.08333333333333333,
                        "recall": 0.25,
                        "f1-score": 0.125,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.1111111111111111,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.16666666666666666,
                        "support": 6.0
                    }
                },
                "internet_2": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.2,
                        "f1-score": 0.33333333333333337,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.5,
                        "f1-score": 0.5,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.3,
                    "macro avg": {
                        "precision": 0.375,
                        "recall": 0.175,
                        "f1-score": 0.20833333333333334,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.7,
                        "recall": 0.3,
                        "f1-score": 0.3666666666666667,
                        "support": 10.0
                    }
                },
                "culture_and_entertainment_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.26666666666666666,
                        "recall": 1.0,
                        "f1-score": 0.4210526315789474,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.26666666666666666,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.26666666666666666,
                        "support": 15.0
                    },
                    "macro avg": {
                        "precision": 0.06666666666666667,
                        "recall": 0.25,
                        "f1-score": 0.10526315789473685,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.07111111111111111,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.11228070175438597,
                        "support": 15.0
                    }
                }
            },
            "chronological": {
                "government_and_politics_riots_4": {
                    "AFTER": {
                        "precision": 0.75,
                        "recall": 0.75,
                        "f1-score": 0.75,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.5555555555555556,
                        "recall": 0.4166666666666667,
                        "f1-score": 0.4761904761904762,
                        "support": 12.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 12.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2857142857142857,
                    "macro avg": {
                        "precision": 0.3263888888888889,
                        "recall": 0.2916666666666667,
                        "f1-score": 0.30654761904761907,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.3452380952380953,
                        "recall": 0.2857142857142857,
                        "f1-score": 0.3112244897959184,
                        "support": 28.0
                    }
                },
                "rail_transport_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "BEFORE": {
                        "precision": 0.9696969696969697,
                        "recall": 0.9411764705882353,
                        "f1-score": 0.955223880597015,
                        "support": 34.0
                    },
                    "COEX": {
                        "precision": 0.3333333333333333,
                        "recall": 0.5,
                        "f1-score": 0.4,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.9166666666666666,
                        "recall": 0.9166666666666666,
                        "f1-score": 0.9166666666666666,
                        "support": 36.0
                    },
                    "macro avg": {
                        "precision": 0.32575757575757575,
                        "recall": 0.3602941176470588,
                        "f1-score": 0.33880597014925373,
                        "support": 36.0
                    },
                    "weighted avg": {
                        "precision": 0.9343434343434343,
                        "recall": 0.9166666666666666,
                        "f1-score": 0.9243781094527362,
                        "support": 36.0
                    }
                },
                "politics_and_conflicts_policy_change_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 1.0,
                        "f1-score": 0.5,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 6.0
                    },
                    "macro avg": {
                        "precision": 0.08333333333333333,
                        "recall": 0.25,
                        "f1-score": 0.125,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.1111111111111111,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.16666666666666666,
                        "support": 6.0
                    }
                },
                "politics_and_conflicts_drones_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 8.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.0,
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 21.0
                    }
                },
                "disasters_and_accidents_road_crash_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "BEFORE": {
                        "precision": 0.5238095238095238,
                        "recall": 1.0,
                        "f1-score": 0.6875000000000001,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 10.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.5238095238095238,
                        "recall": 0.5238095238095238,
                        "f1-score": 0.5238095238095238,
                        "support": 21.0
                    },
                    "macro avg": {
                        "precision": 0.13095238095238096,
                        "recall": 0.25,
                        "f1-score": 0.17187500000000003,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.2743764172335601,
                        "recall": 0.5238095238095238,
                        "f1-score": 0.36011904761904767,
                        "support": 21.0
                    }
                },
                "crime_and_law_accuse_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.625,
                        "recall": 0.8333333333333334,
                        "f1-score": 0.7142857142857143,
                        "support": 6.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.5,
                        "recall": 0.5,
                        "f1-score": 0.5,
                        "support": 10.0
                    },
                    "macro avg": {
                        "precision": 0.15625,
                        "recall": 0.20833333333333334,
                        "f1-score": 0.17857142857142858,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.375,
                        "recall": 0.5,
                        "f1-score": 0.42857142857142855,
                        "support": 10.0
                    }
                },
                "government_and_politics_protests_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.7142857142857143,
                        "recall": 1.0,
                        "f1-score": 0.8333333333333333,
                        "support": 20.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.7142857142857143,
                        "recall": 0.7142857142857143,
                        "f1-score": 0.7142857142857143,
                        "support": 28.0
                    },
                    "macro avg": {
                        "precision": 0.17857142857142858,
                        "recall": 0.25,
                        "f1-score": 0.20833333333333331,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.5102040816326531,
                        "recall": 0.7142857142857143,
                        "f1-score": 0.5952380952380951,
                        "support": 28.0
                    }
                },
                "politics_and_conflicts_elections_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 22.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 14.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 9.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.0,
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 45.0
                    }
                },
                "environment_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 21.0
                    },
                    "BEFORE": {
                        "precision": 0.6111111111111112,
                        "recall": 0.9565217391304348,
                        "f1-score": 0.7457627118644068,
                        "support": 23.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.4888888888888889,
                    "macro avg": {
                        "precision": 0.1527777777777778,
                        "recall": 0.2391304347826087,
                        "f1-score": 0.1864406779661017,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.3123456790123457,
                        "recall": 0.4888888888888889,
                        "f1-score": 0.38116760828625235,
                        "support": 45.0
                    }
                },
                "weather_floods_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.45454545454545453,
                        "recall": 0.7142857142857143,
                        "f1-score": 0.5555555555555556,
                        "support": 7.0
                    },
                    "COEX": {
                        "precision": 0.5,
                        "recall": 0.5,
                        "f1-score": 0.5,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.4666666666666667,
                        "recall": 0.4666666666666667,
                        "f1-score": 0.4666666666666667,
                        "support": 15.0
                    },
                    "macro avg": {
                        "precision": 0.23863636363636365,
                        "recall": 0.3035714285714286,
                        "f1-score": 0.2638888888888889,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.34545454545454546,
                        "recall": 0.4666666666666667,
                        "f1-score": 0.3925925925925926,
                        "support": 15.0
                    }
                },
                "sports_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 1.0,
                        "f1-score": 0.5,
                        "support": 1.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 3.0
                    },
                    "macro avg": {
                        "precision": 0.08333333333333333,
                        "recall": 0.25,
                        "f1-score": 0.125,
                        "support": 3.0
                    },
                    "weighted avg": {
                        "precision": 0.1111111111111111,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.16666666666666666,
                        "support": 3.0
                    }
                },
                "health_4": {
                    "AFTER": {
                        "precision": 0.75,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.46153846153846156,
                        "support": 9.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.375,
                        "f1-score": 0.42857142857142855,
                        "support": 8.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2857142857142857,
                    "macro avg": {
                        "precision": 0.3125,
                        "recall": 0.17708333333333331,
                        "f1-score": 0.22252747252747251,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.5119047619047619,
                        "recall": 0.2857142857142857,
                        "f1-score": 0.36106750392464676,
                        "support": 21.0
                    }
                },
                "weather_earthquakes_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "BEFORE": {
                        "precision": 0.6944444444444444,
                        "recall": 0.78125,
                        "f1-score": 0.7352941176470588,
                        "support": 32.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 7.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.5555555555555556,
                    "macro avg": {
                        "precision": 0.1736111111111111,
                        "recall": 0.1953125,
                        "f1-score": 0.1838235294117647,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.49382716049382713,
                        "recall": 0.5555555555555556,
                        "f1-score": 0.522875816993464,
                        "support": 45.0
                    }
                },
                "space_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 15.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.0,
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 28.0
                    }
                },
                "economy_and_business_strikes_2": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.8,
                        "recall": 1.0,
                        "f1-score": 0.888888888888889,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.8333333333333334,
                        "recall": 0.8333333333333334,
                        "f1-score": 0.8333333333333334,
                        "support": 6.0
                    },
                    "macro avg": {
                        "precision": 0.45,
                        "recall": 0.5,
                        "f1-score": 0.4722222222222222,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.7000000000000001,
                        "recall": 0.8333333333333334,
                        "f1-score": 0.7592592592592592,
                        "support": 6.0
                    }
                },
                "politics_and_conflicts_armed_conflict_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.75,
                        "recall": 0.8181818181818182,
                        "f1-score": 0.7826086956521738,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.6,
                        "recall": 0.6,
                        "f1-score": 0.6,
                        "support": 15.0
                    },
                    "macro avg": {
                        "precision": 0.1875,
                        "recall": 0.20454545454545456,
                        "f1-score": 0.19565217391304346,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.55,
                        "recall": 0.6,
                        "f1-score": 0.5739130434782608,
                        "support": 15.0
                    }
                },
                "infectious_disease_4": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.25,
                        "f1-score": 0.25,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    }
                },
                "health_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "BEFORE": {
                        "precision": 0.3,
                        "recall": 1.0,
                        "f1-score": 0.4615384615384615,
                        "support": 3.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.3,
                        "recall": 0.3,
                        "f1-score": 0.3,
                        "support": 10.0
                    },
                    "macro avg": {
                        "precision": 0.075,
                        "recall": 0.25,
                        "f1-score": 0.11538461538461538,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.09,
                        "recall": 0.3,
                        "f1-score": 0.13846153846153847,
                        "support": 10.0
                    }
                },
                "disasters_and_accidents_shipwreck_2": {
                    "AFTER": {
                        "precision": 0.6666666666666666,
                        "recall": 0.18181818181818182,
                        "f1-score": 0.28571428571428575,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 0.4444444444444444,
                        "f1-score": 0.380952380952381,
                        "support": 9.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2857142857142857,
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.15656565656565657,
                        "f1-score": 0.16666666666666669,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.492063492063492,
                        "recall": 0.2857142857142857,
                        "f1-score": 0.3129251700680272,
                        "support": 21.0
                    }
                },
                "rail_transport_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.6666666666666666,
                        "recall": 0.4,
                        "f1-score": 0.5,
                        "support": 10.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.26666666666666666,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.26666666666666666,
                        "support": 15.0
                    },
                    "macro avg": {
                        "precision": 0.16666666666666666,
                        "recall": 0.1,
                        "f1-score": 0.125,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.4444444444444444,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.3333333333333333,
                        "support": 15.0
                    }
                },
                "weather_storms_1_extra": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    }
                },
                "health_1_extra": {
                    "AFTER": {
                        "precision": 0.875,
                        "recall": 0.5833333333333334,
                        "f1-score": 0.7000000000000001,
                        "support": 12.0
                    },
                    "BEFORE": {
                        "precision": 0.6428571428571429,
                        "recall": 0.9642857142857143,
                        "f1-score": 0.7714285714285715,
                        "support": 28.0
                    },
                    "COEX": {
                        "precision": 0.6,
                        "recall": 0.2,
                        "f1-score": 0.3,
                        "support": 15.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.6727272727272727,
                        "recall": 0.6727272727272727,
                        "f1-score": 0.6727272727272727,
                        "support": 55.0
                    },
                    "macro avg": {
                        "precision": 0.5294642857142857,
                        "recall": 0.4369047619047619,
                        "f1-score": 0.4428571428571429,
                        "support": 55.0
                    },
                    "weighted avg": {
                        "precision": 0.6818181818181818,
                        "recall": 0.6727272727272727,
                        "f1-score": 0.6272727272727273,
                        "support": 55.0
                    }
                },
                "weather_floods_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.5277777777777778,
                        "recall": 0.7916666666666666,
                        "f1-score": 0.6333333333333333,
                        "support": 24.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 28.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.34545454545454546,
                    "macro avg": {
                        "precision": 0.13194444444444445,
                        "recall": 0.19791666666666666,
                        "f1-score": 0.15833333333333333,
                        "support": 55.0
                    },
                    "weighted avg": {
                        "precision": 0.23030303030303031,
                        "recall": 0.34545454545454546,
                        "f1-score": 0.27636363636363637,
                        "support": 55.0
                    }
                },
                "mining_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.7272727272727273,
                        "recall": 0.96,
                        "f1-score": 0.8275862068965517,
                        "support": 25.0
                    },
                    "COEX": {
                        "precision": 0.3333333333333333,
                        "recall": 0.1111111111111111,
                        "f1-score": 0.16666666666666666,
                        "support": 9.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.5555555555555556,
                    "macro avg": {
                        "precision": 0.26515151515151514,
                        "recall": 0.2677777777777778,
                        "f1-score": 0.24856321839080459,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.47070707070707074,
                        "recall": 0.5555555555555556,
                        "f1-score": 0.49310344827586206,
                        "support": 45.0
                    }
                },
                "disasters_and_accidents_volcanoes_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 20.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 1.0,
                        "f1-score": 0.6666666666666666,
                        "support": 14.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.3888888888888889,
                    "macro avg": {
                        "precision": 0.125,
                        "recall": 0.25,
                        "f1-score": 0.16666666666666666,
                        "support": 36.0
                    },
                    "weighted avg": {
                        "precision": 0.19444444444444445,
                        "recall": 0.3888888888888889,
                        "f1-score": 0.25925925925925924,
                        "support": 36.0
                    }
                },
                "politics_and_conflicts_elections_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.26666666666666666,
                        "recall": 1.0,
                        "f1-score": 0.4210526315789474,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.26666666666666666,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.26666666666666666,
                        "support": 15.0
                    },
                    "macro avg": {
                        "precision": 0.06666666666666667,
                        "recall": 0.25,
                        "f1-score": 0.10526315789473685,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.07111111111111111,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.11228070175438597,
                        "support": 15.0
                    }
                },
                "economy_and_business_strikes_3": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.4,
                        "f1-score": 0.5714285714285715,
                        "support": 10.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 0.6363636363636364,
                        "f1-score": 0.56,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.3333333333333333,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.2,
                        "support": 7.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.42857142857142855,
                    "macro avg": {
                        "precision": 0.4583333333333333,
                        "recall": 0.2948051948051948,
                        "f1-score": 0.3328571428571429,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.6369047619047619,
                        "recall": 0.42857142857142855,
                        "f1-score": 0.4740816326530613,
                        "support": 28.0
                    }
                },
                "space_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 100.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 51.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.0,
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 153.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 153.0
                    }
                },
                "politics_and_conflicts_resign_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    }
                },
                "environment_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 1.0,
                        "f1-score": 0.6666666666666666,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.3333333333333333,
                    "macro avg": {
                        "precision": 0.125,
                        "recall": 0.25,
                        "f1-score": 0.16666666666666666,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.16666666666666666,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.2222222222222222,
                        "support": 15.0
                    }
                },
                "space_1_extra": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.8333333333333334,
                        "recall": 1.0,
                        "f1-score": 0.9090909090909091,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.8333333333333334,
                        "recall": 0.8333333333333334,
                        "f1-score": 0.8333333333333334,
                        "support": 6.0
                    },
                    "macro avg": {
                        "precision": 0.20833333333333334,
                        "recall": 0.25,
                        "f1-score": 0.22727272727272727,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.6944444444444445,
                        "recall": 0.8333333333333334,
                        "f1-score": 0.7575757575757575,
                        "support": 6.0
                    }
                },
                "health_3": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.375,
                        "f1-score": 0.5454545454545454,
                        "support": 8.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 1.0,
                        "f1-score": 0.6666666666666666,
                        "support": 6.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.6,
                        "recall": 0.6,
                        "f1-score": 0.6,
                        "support": 15.0
                    },
                    "macro avg": {
                        "precision": 0.375,
                        "recall": 0.34375,
                        "f1-score": 0.303030303030303,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.7333333333333333,
                        "recall": 0.6,
                        "f1-score": 0.5575757575757575,
                        "support": 15.0
                    }
                },
                "environment_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.0,
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 15.0
                    }
                },
                "government_and_politics_protests_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.2,
                        "recall": 1.0,
                        "f1-score": 0.33333333333333337,
                        "support": 1.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.16666666666666666,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.16666666666666666,
                        "support": 6.0
                    },
                    "macro avg": {
                        "precision": 0.05,
                        "recall": 0.25,
                        "f1-score": 0.08333333333333334,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.03333333333333333,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.05555555555555556,
                        "support": 6.0
                    }
                },
                "economy_and_business_financial_crisis_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 12.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.0,
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 21.0
                    }
                },
                "computers_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    }
                },
                "crime_and_law_accuse_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.16666666666666666,
                        "recall": 0.2,
                        "f1-score": 0.1818181818181818,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.1,
                        "recall": 0.1,
                        "f1-score": 0.10000000000000002,
                        "support": 10.0
                    },
                    "macro avg": {
                        "precision": 0.041666666666666664,
                        "recall": 0.05,
                        "f1-score": 0.04545454545454545,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.08333333333333333,
                        "recall": 0.1,
                        "f1-score": 0.0909090909090909,
                        "support": 10.0
                    }
                },
                "culture_and_entertainment_1": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 2.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 1.0,
                        "f1-score": 0.6666666666666666,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.6666666666666666,
                        "recall": 0.6666666666666666,
                        "f1-score": 0.6666666666666666,
                        "support": 6.0
                    },
                    "macro avg": {
                        "precision": 0.375,
                        "recall": 0.5,
                        "f1-score": 0.41666666666666663,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.5,
                        "recall": 0.6666666666666666,
                        "f1-score": 0.5555555555555555,
                        "support": 6.0
                    }
                },
                "internet_2": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.2,
                        "f1-score": 0.33333333333333337,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.5714285714285714,
                        "recall": 1.0,
                        "f1-score": 0.7272727272727273,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.5,
                        "recall": 0.5,
                        "f1-score": 0.5,
                        "support": 10.0
                    },
                    "macro avg": {
                        "precision": 0.39285714285714285,
                        "recall": 0.3,
                        "f1-score": 0.26515151515151514,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.7285714285714285,
                        "recall": 0.5,
                        "f1-score": 0.45757575757575764,
                        "support": 10.0
                    }
                },
                "culture_and_entertainment_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.26666666666666666,
                        "recall": 1.0,
                        "f1-score": 0.4210526315789474,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.26666666666666666,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.26666666666666666,
                        "support": 15.0
                    },
                    "macro avg": {
                        "precision": 0.06666666666666667,
                        "recall": 0.25,
                        "f1-score": 0.10526315789473685,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.07111111111111111,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.11228070175438597,
                        "support": 15.0
                    }
                }
            },
            "you": {
                "government_and_politics_riots_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.5294117647058824,
                        "recall": 0.75,
                        "f1-score": 0.6206896551724139,
                        "support": 12.0
                    },
                    "COEX": {
                        "precision": 0.5,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.25,
                        "support": 12.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.39285714285714285,
                    "macro avg": {
                        "precision": 0.25735294117647056,
                        "recall": 0.22916666666666666,
                        "f1-score": 0.21767241379310348,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.44117647058823534,
                        "recall": 0.39285714285714285,
                        "f1-score": 0.373152709359606,
                        "support": 28.0
                    }
                },
                "rail_transport_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "BEFORE": {
                        "precision": 0.9393939393939394,
                        "recall": 0.9117647058823529,
                        "f1-score": 0.9253731343283583,
                        "support": 34.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.8611111111111112,
                        "recall": 0.8611111111111112,
                        "f1-score": 0.8611111111111112,
                        "support": 36.0
                    },
                    "macro avg": {
                        "precision": 0.23484848484848486,
                        "recall": 0.22794117647058823,
                        "f1-score": 0.23134328358208958,
                        "support": 36.0
                    },
                    "weighted avg": {
                        "precision": 0.8872053872053872,
                        "recall": 0.8611111111111112,
                        "f1-score": 0.8739635157545607,
                        "support": 36.0
                    }
                },
                "politics_and_conflicts_policy_change_2": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.6666666666666666,
                        "f1-score": 0.8,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.5,
                        "f1-score": 0.6666666666666666,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.5,
                    "macro avg": {
                        "precision": 0.5,
                        "recall": 0.29166666666666663,
                        "f1-score": 0.3666666666666667,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.8333333333333334,
                        "recall": 0.5,
                        "f1-score": 0.6222222222222222,
                        "support": 6.0
                    }
                },
                "politics_and_conflicts_drones_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 0.75,
                        "f1-score": 0.46153846153846156,
                        "support": 8.0
                    },
                    "COEX": {
                        "precision": 0.3333333333333333,
                        "recall": 0.5,
                        "f1-score": 0.4,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 21.0
                    },
                    "macro avg": {
                        "precision": 0.16666666666666666,
                        "recall": 0.3125,
                        "f1-score": 0.2153846153846154,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.15873015873015872,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.2139194139194139,
                        "support": 21.0
                    }
                },
                "disasters_and_accidents_road_crash_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "BEFORE": {
                        "precision": 0.5238095238095238,
                        "recall": 1.0,
                        "f1-score": 0.6875000000000001,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 10.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.5238095238095238,
                        "recall": 0.5238095238095238,
                        "f1-score": 0.5238095238095238,
                        "support": 21.0
                    },
                    "macro avg": {
                        "precision": 0.13095238095238096,
                        "recall": 0.25,
                        "f1-score": 0.17187500000000003,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.2743764172335601,
                        "recall": 0.5238095238095238,
                        "f1-score": 0.36011904761904767,
                        "support": 21.0
                    }
                },
                "crime_and_law_accuse_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.5,
                        "support": 6.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2,
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.08333333333333333,
                        "f1-score": 0.125,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.6,
                        "recall": 0.2,
                        "f1-score": 0.3,
                        "support": 10.0
                    }
                },
                "government_and_politics_protests_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.7142857142857143,
                        "recall": 1.0,
                        "f1-score": 0.8333333333333333,
                        "support": 20.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.7142857142857143,
                        "recall": 0.7142857142857143,
                        "f1-score": 0.7142857142857143,
                        "support": 28.0
                    },
                    "macro avg": {
                        "precision": 0.17857142857142858,
                        "recall": 0.25,
                        "f1-score": 0.20833333333333331,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.5102040816326531,
                        "recall": 0.7142857142857143,
                        "f1-score": 0.5952380952380951,
                        "support": 28.0
                    }
                },
                "politics_and_conflicts_elections_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 22.0
                    },
                    "BEFORE": {
                        "precision": 0.358974358974359,
                        "recall": 1.0,
                        "f1-score": 0.5283018867924528,
                        "support": 14.0
                    },
                    "COEX": {
                        "precision": 0.16666666666666666,
                        "recall": 0.1111111111111111,
                        "f1-score": 0.13333333333333333,
                        "support": 9.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 45.0
                    },
                    "macro avg": {
                        "precision": 0.13141025641025642,
                        "recall": 0.2777777777777778,
                        "f1-score": 0.16540880503144653,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.145014245014245,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.19102725366876308,
                        "support": 45.0
                    }
                },
                "environment_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 21.0
                    },
                    "BEFORE": {
                        "precision": 0.6111111111111112,
                        "recall": 0.9565217391304348,
                        "f1-score": 0.7457627118644068,
                        "support": 23.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.4888888888888889,
                    "macro avg": {
                        "precision": 0.1527777777777778,
                        "recall": 0.2391304347826087,
                        "f1-score": 0.1864406779661017,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.3123456790123457,
                        "recall": 0.4888888888888889,
                        "f1-score": 0.38116760828625235,
                        "support": 45.0
                    }
                },
                "weather_floods_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.46153846153846156,
                        "recall": 0.8571428571428571,
                        "f1-score": 0.6,
                        "support": 7.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.4,
                        "recall": 0.4,
                        "f1-score": 0.4000000000000001,
                        "support": 15.0
                    },
                    "macro avg": {
                        "precision": 0.11538461538461539,
                        "recall": 0.21428571428571427,
                        "f1-score": 0.15,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.2153846153846154,
                        "recall": 0.4,
                        "f1-score": 0.28,
                        "support": 15.0
                    }
                },
                "sports_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 1.0,
                        "f1-score": 0.5,
                        "support": 1.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 3.0
                    },
                    "macro avg": {
                        "precision": 0.08333333333333333,
                        "recall": 0.25,
                        "f1-score": 0.125,
                        "support": 3.0
                    },
                    "weighted avg": {
                        "precision": 0.1111111111111111,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.16666666666666666,
                        "support": 3.0
                    }
                },
                "health_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 9.0
                    },
                    "BEFORE": {
                        "precision": 0.5333333333333333,
                        "recall": 1.0,
                        "f1-score": 0.6956521739130436,
                        "support": 8.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.38095238095238093,
                    "macro avg": {
                        "precision": 0.13333333333333333,
                        "recall": 0.25,
                        "f1-score": 0.1739130434782609,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.20317460317460317,
                        "recall": 0.38095238095238093,
                        "f1-score": 0.2650103519668737,
                        "support": 21.0
                    }
                },
                "weather_earthquakes_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "BEFORE": {
                        "precision": 0.75,
                        "recall": 0.65625,
                        "f1-score": 0.7,
                        "support": 32.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 7.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.4666666666666667,
                    "macro avg": {
                        "precision": 0.1875,
                        "recall": 0.1640625,
                        "f1-score": 0.175,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.5333333333333333,
                        "recall": 0.4666666666666667,
                        "f1-score": 0.49777777777777776,
                        "support": 45.0
                    }
                },
                "space_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 15.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.0,
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 28.0
                    }
                },
                "economy_and_business_strikes_2": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.8,
                        "recall": 1.0,
                        "f1-score": 0.888888888888889,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.8333333333333334,
                        "recall": 0.8333333333333334,
                        "f1-score": 0.8333333333333334,
                        "support": 6.0
                    },
                    "macro avg": {
                        "precision": 0.45,
                        "recall": 0.5,
                        "f1-score": 0.4722222222222222,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.7000000000000001,
                        "recall": 0.8333333333333334,
                        "f1-score": 0.7592592592592592,
                        "support": 6.0
                    }
                },
                "politics_and_conflicts_armed_conflict_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.8461538461538461,
                        "recall": 1.0,
                        "f1-score": 0.9166666666666666,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.5,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.4,
                        "support": 3.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.8,
                        "recall": 0.8,
                        "f1-score": 0.8000000000000002,
                        "support": 15.0
                    },
                    "macro avg": {
                        "precision": 0.33653846153846156,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.32916666666666666,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.7205128205128205,
                        "recall": 0.8,
                        "f1-score": 0.7522222222222221,
                        "support": 15.0
                    }
                },
                "infectious_disease_4": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.25,
                        "f1-score": 0.25,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    }
                },
                "health_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "BEFORE": {
                        "precision": 0.3,
                        "recall": 1.0,
                        "f1-score": 0.4615384615384615,
                        "support": 3.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.3,
                        "recall": 0.3,
                        "f1-score": 0.3,
                        "support": 10.0
                    },
                    "macro avg": {
                        "precision": 0.075,
                        "recall": 0.25,
                        "f1-score": 0.11538461538461538,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.09,
                        "recall": 0.3,
                        "f1-score": 0.13846153846153847,
                        "support": 10.0
                    }
                },
                "disasters_and_accidents_shipwreck_2": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.2727272727272727,
                        "f1-score": 0.42857142857142855,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.4,
                        "recall": 0.4444444444444444,
                        "f1-score": 0.4210526315789474,
                        "support": 9.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.3333333333333333,
                    "macro avg": {
                        "precision": 0.35,
                        "recall": 0.17929292929292928,
                        "f1-score": 0.212406015037594,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.6952380952380952,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.40494092373791624,
                        "support": 21.0
                    }
                },
                "rail_transport_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.6666666666666666,
                        "recall": 0.4,
                        "f1-score": 0.5,
                        "support": 10.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.26666666666666666,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.26666666666666666,
                        "support": 15.0
                    },
                    "macro avg": {
                        "precision": 0.16666666666666666,
                        "recall": 0.1,
                        "f1-score": 0.125,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.4444444444444444,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.3333333333333333,
                        "support": 15.0
                    }
                },
                "weather_storms_1_extra": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    }
                },
                "health_1_extra": {
                    "AFTER": {
                        "precision": 0.875,
                        "recall": 0.5833333333333334,
                        "f1-score": 0.7000000000000001,
                        "support": 12.0
                    },
                    "BEFORE": {
                        "precision": 0.6222222222222222,
                        "recall": 1.0,
                        "f1-score": 0.7671232876712328,
                        "support": 28.0
                    },
                    "COEX": {
                        "precision": 1.0,
                        "recall": 0.13333333333333333,
                        "f1-score": 0.23529411764705882,
                        "support": 15.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.6727272727272727,
                        "recall": 0.6727272727272727,
                        "f1-score": 0.6727272727272727,
                        "support": 55.0
                    },
                    "macro avg": {
                        "precision": 0.6243055555555556,
                        "recall": 0.4291666666666667,
                        "f1-score": 0.42560435132957297,
                        "support": 55.0
                    },
                    "weighted avg": {
                        "precision": 0.7804040404040404,
                        "recall": 0.6727272727272727,
                        "f1-score": 0.6074338876272801,
                        "support": 55.0
                    }
                },
                "weather_floods_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.5714285714285714,
                        "recall": 0.6666666666666666,
                        "f1-score": 0.6153846153846153,
                        "support": 24.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 28.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2909090909090909,
                    "macro avg": {
                        "precision": 0.14285714285714285,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.15384615384615383,
                        "support": 55.0
                    },
                    "weighted avg": {
                        "precision": 0.24935064935064935,
                        "recall": 0.2909090909090909,
                        "f1-score": 0.2685314685314685,
                        "support": 55.0
                    }
                },
                "mining_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.5555555555555556,
                        "recall": 1.0,
                        "f1-score": 0.7142857142857143,
                        "support": 25.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 9.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.5555555555555556,
                        "recall": 0.5555555555555556,
                        "f1-score": 0.5555555555555556,
                        "support": 45.0
                    },
                    "macro avg": {
                        "precision": 0.1388888888888889,
                        "recall": 0.25,
                        "f1-score": 0.17857142857142858,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.30864197530864196,
                        "recall": 0.5555555555555556,
                        "f1-score": 0.39682539682539686,
                        "support": 45.0
                    }
                },
                "disasters_and_accidents_volcanoes_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 20.0
                    },
                    "BEFORE": {
                        "precision": 0.3888888888888889,
                        "recall": 1.0,
                        "f1-score": 0.56,
                        "support": 14.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.3888888888888889,
                        "recall": 0.3888888888888889,
                        "f1-score": 0.3888888888888889,
                        "support": 36.0
                    },
                    "macro avg": {
                        "precision": 0.09722222222222222,
                        "recall": 0.25,
                        "f1-score": 0.14,
                        "support": 36.0
                    },
                    "weighted avg": {
                        "precision": 0.15123456790123457,
                        "recall": 0.3888888888888889,
                        "f1-score": 0.2177777777777778,
                        "support": 36.0
                    }
                },
                "politics_and_conflicts_elections_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.26666666666666666,
                        "recall": 1.0,
                        "f1-score": 0.4210526315789474,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.26666666666666666,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.26666666666666666,
                        "support": 15.0
                    },
                    "macro avg": {
                        "precision": 0.06666666666666667,
                        "recall": 0.25,
                        "f1-score": 0.10526315789473685,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.07111111111111111,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.11228070175438597,
                        "support": 15.0
                    }
                },
                "economy_and_business_strikes_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 10.0
                    },
                    "BEFORE": {
                        "precision": 0.39285714285714285,
                        "recall": 1.0,
                        "f1-score": 0.5641025641025641,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 7.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.39285714285714285,
                        "recall": 0.39285714285714285,
                        "f1-score": 0.39285714285714285,
                        "support": 28.0
                    },
                    "macro avg": {
                        "precision": 0.09821428571428571,
                        "recall": 0.25,
                        "f1-score": 0.14102564102564102,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.15433673469387754,
                        "recall": 0.39285714285714285,
                        "f1-score": 0.22161172161172163,
                        "support": 28.0
                    }
                },
                "space_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 100.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 51.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.0,
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 153.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 153.0
                    }
                },
                "politics_and_conflicts_resign_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    }
                },
                "environment_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 1.0,
                        "f1-score": 0.5,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 15.0
                    },
                    "macro avg": {
                        "precision": 0.08333333333333333,
                        "recall": 0.25,
                        "f1-score": 0.125,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.1111111111111111,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.16666666666666666,
                        "support": 15.0
                    }
                },
                "space_1_extra": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.8333333333333334,
                        "recall": 1.0,
                        "f1-score": 0.9090909090909091,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.8333333333333334,
                        "recall": 0.8333333333333334,
                        "f1-score": 0.8333333333333334,
                        "support": 6.0
                    },
                    "macro avg": {
                        "precision": 0.20833333333333334,
                        "recall": 0.25,
                        "f1-score": 0.22727272727272727,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.6944444444444445,
                        "recall": 0.8333333333333334,
                        "f1-score": 0.7575757575757575,
                        "support": 6.0
                    }
                },
                "health_3": {
                    "AFTER": {
                        "precision": 0.6666666666666666,
                        "recall": 0.25,
                        "f1-score": 0.36363636363636365,
                        "support": 8.0
                    },
                    "BEFORE": {
                        "precision": 0.7142857142857143,
                        "recall": 0.8333333333333334,
                        "f1-score": 0.7692307692307692,
                        "support": 6.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.4666666666666667,
                    "macro avg": {
                        "precision": 0.34523809523809523,
                        "recall": 0.27083333333333337,
                        "f1-score": 0.28321678321678323,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.6412698412698412,
                        "recall": 0.4666666666666667,
                        "f1-score": 0.5016317016317016,
                        "support": 15.0
                    }
                },
                "environment_3": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.18181818181818182,
                        "f1-score": 0.3076923076923077,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.25,
                        "recall": 1.0,
                        "f1-score": 0.4,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.26666666666666666,
                    "macro avg": {
                        "precision": 0.3125,
                        "recall": 0.29545454545454547,
                        "f1-score": 0.17692307692307693,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.7666666666666667,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.278974358974359,
                        "support": 15.0
                    }
                },
                "government_and_politics_protests_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.2,
                        "recall": 1.0,
                        "f1-score": 0.33333333333333337,
                        "support": 1.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.16666666666666666,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.16666666666666666,
                        "support": 6.0
                    },
                    "macro avg": {
                        "precision": 0.05,
                        "recall": 0.25,
                        "f1-score": 0.08333333333333334,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.03333333333333333,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.05555555555555556,
                        "support": 6.0
                    }
                },
                "economy_and_business_financial_crisis_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 12.0
                    },
                    "BEFORE": {
                        "precision": 0.15789473684210525,
                        "recall": 0.6,
                        "f1-score": 0.25,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.14285714285714285,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.14285714285714285,
                        "support": 21.0
                    },
                    "macro avg": {
                        "precision": 0.039473684210526314,
                        "recall": 0.15,
                        "f1-score": 0.0625,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.03759398496240601,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.05952380952380952,
                        "support": 21.0
                    }
                },
                "computers_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    }
                },
                "crime_and_law_accuse_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 10.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 10.0
                    }
                },
                "culture_and_entertainment_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.0,
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    }
                },
                "internet_2": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.2,
                        "f1-score": 0.33333333333333337,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.5714285714285714,
                        "recall": 1.0,
                        "f1-score": 0.7272727272727273,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.5,
                        "recall": 0.5,
                        "f1-score": 0.5,
                        "support": 10.0
                    },
                    "macro avg": {
                        "precision": 0.39285714285714285,
                        "recall": 0.3,
                        "f1-score": 0.26515151515151514,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.7285714285714285,
                        "recall": 0.5,
                        "f1-score": 0.45757575757575764,
                        "support": 10.0
                    }
                },
                "culture_and_entertainment_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.26666666666666666,
                        "recall": 1.0,
                        "f1-score": 0.4210526315789474,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.26666666666666666,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.26666666666666666,
                        "support": 15.0
                    },
                    "macro avg": {
                        "precision": 0.06666666666666667,
                        "recall": 0.25,
                        "f1-score": 0.10526315789473685,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.07111111111111111,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.11228070175438597,
                        "support": 15.0
                    }
                }
            },
            "suppose": {
                "government_and_politics_riots_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.34782608695652173,
                        "recall": 0.6666666666666666,
                        "f1-score": 0.4571428571428571,
                        "support": 12.0
                    },
                    "COEX": {
                        "precision": 0.2,
                        "recall": 0.08333333333333333,
                        "f1-score": 0.11764705882352941,
                        "support": 12.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.32142857142857145,
                        "recall": 0.32142857142857145,
                        "f1-score": 0.32142857142857145,
                        "support": 28.0
                    },
                    "macro avg": {
                        "precision": 0.13695652173913042,
                        "recall": 0.1875,
                        "f1-score": 0.14369747899159663,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.23478260869565218,
                        "recall": 0.32142857142857145,
                        "f1-score": 0.24633853541416562,
                        "support": 28.0
                    }
                },
                "rail_transport_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "BEFORE": {
                        "precision": 0.9354838709677419,
                        "recall": 0.8529411764705882,
                        "f1-score": 0.8923076923076922,
                        "support": 34.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.8055555555555556,
                        "recall": 0.8055555555555556,
                        "f1-score": 0.8055555555555556,
                        "support": 36.0
                    },
                    "macro avg": {
                        "precision": 0.23387096774193547,
                        "recall": 0.21323529411764705,
                        "f1-score": 0.22307692307692306,
                        "support": 36.0
                    },
                    "weighted avg": {
                        "precision": 0.8835125448028673,
                        "recall": 0.8055555555555556,
                        "f1-score": 0.8427350427350427,
                        "support": 36.0
                    }
                },
                "politics_and_conflicts_policy_change_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 1.0,
                        "f1-score": 0.5,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 6.0
                    },
                    "macro avg": {
                        "precision": 0.08333333333333333,
                        "recall": 0.25,
                        "f1-score": 0.125,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.1111111111111111,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.16666666666666666,
                        "support": 6.0
                    }
                },
                "politics_and_conflicts_drones_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.29411764705882354,
                        "recall": 0.625,
                        "f1-score": 0.4,
                        "support": 8.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.23809523809523808,
                        "recall": 0.23809523809523808,
                        "f1-score": 0.23809523809523808,
                        "support": 21.0
                    },
                    "macro avg": {
                        "precision": 0.07352941176470588,
                        "recall": 0.15625,
                        "f1-score": 0.1,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.11204481792717087,
                        "recall": 0.23809523809523808,
                        "f1-score": 0.1523809523809524,
                        "support": 21.0
                    }
                },
                "disasters_and_accidents_road_crash_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "BEFORE": {
                        "precision": 0.5238095238095238,
                        "recall": 1.0,
                        "f1-score": 0.6875000000000001,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 10.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.5238095238095238,
                        "recall": 0.5238095238095238,
                        "f1-score": 0.5238095238095238,
                        "support": 21.0
                    },
                    "macro avg": {
                        "precision": 0.13095238095238096,
                        "recall": 0.25,
                        "f1-score": 0.17187500000000003,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.2743764172335601,
                        "recall": 0.5238095238095238,
                        "f1-score": 0.36011904761904767,
                        "support": 21.0
                    }
                },
                "crime_and_law_accuse_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 1.0,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.5,
                        "support": 6.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2,
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.08333333333333333,
                        "f1-score": 0.125,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.6,
                        "recall": 0.2,
                        "f1-score": 0.3,
                        "support": 10.0
                    }
                },
                "government_and_politics_protests_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.7142857142857143,
                        "recall": 1.0,
                        "f1-score": 0.8333333333333333,
                        "support": 20.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 3.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.7142857142857143,
                        "recall": 0.7142857142857143,
                        "f1-score": 0.7142857142857143,
                        "support": 28.0
                    },
                    "macro avg": {
                        "precision": 0.17857142857142858,
                        "recall": 0.25,
                        "f1-score": 0.20833333333333331,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.5102040816326531,
                        "recall": 0.7142857142857143,
                        "f1-score": 0.5952380952380951,
                        "support": 28.0
                    }
                },
                "politics_and_conflicts_elections_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 22.0
                    },
                    "BEFORE": {
                        "precision": 0.3157894736842105,
                        "recall": 0.42857142857142855,
                        "f1-score": 0.36363636363636365,
                        "support": 14.0
                    },
                    "COEX": {
                        "precision": 0.15384615384615385,
                        "recall": 0.2222222222222222,
                        "f1-score": 0.18181818181818185,
                        "support": 9.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.17777777777777778,
                    "macro avg": {
                        "precision": 0.11740890688259109,
                        "recall": 0.16269841269841268,
                        "f1-score": 0.13636363636363638,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.1290148448043185,
                        "recall": 0.17777777777777778,
                        "f1-score": 0.14949494949494951,
                        "support": 45.0
                    }
                },
                "environment_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 21.0
                    },
                    "BEFORE": {
                        "precision": 0.6388888888888888,
                        "recall": 1.0,
                        "f1-score": 0.7796610169491525,
                        "support": 23.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.5111111111111111,
                    "macro avg": {
                        "precision": 0.1597222222222222,
                        "recall": 0.25,
                        "f1-score": 0.19491525423728812,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.3265432098765432,
                        "recall": 0.5111111111111111,
                        "f1-score": 0.3984934086629001,
                        "support": 45.0
                    }
                },
                "weather_floods_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.45454545454545453,
                        "recall": 0.7142857142857143,
                        "f1-score": 0.5555555555555556,
                        "support": 7.0
                    },
                    "COEX": {
                        "precision": 0.5,
                        "recall": 0.5,
                        "f1-score": 0.5,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.4666666666666667,
                        "recall": 0.4666666666666667,
                        "f1-score": 0.4666666666666667,
                        "support": 15.0
                    },
                    "macro avg": {
                        "precision": 0.23863636363636365,
                        "recall": 0.3035714285714286,
                        "f1-score": 0.2638888888888889,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.34545454545454546,
                        "recall": 0.4666666666666667,
                        "f1-score": 0.3925925925925926,
                        "support": 15.0
                    }
                },
                "sports_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 1.0,
                        "f1-score": 0.5,
                        "support": 1.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 3.0
                    },
                    "macro avg": {
                        "precision": 0.08333333333333333,
                        "recall": 0.25,
                        "f1-score": 0.125,
                        "support": 3.0
                    },
                    "weighted avg": {
                        "precision": 0.1111111111111111,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.16666666666666666,
                        "support": 3.0
                    }
                },
                "health_4": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.2222222222222222,
                        "f1-score": 0.3636363636363636,
                        "support": 9.0
                    },
                    "BEFORE": {
                        "precision": 0.4444444444444444,
                        "recall": 1.0,
                        "f1-score": 0.6153846153846153,
                        "support": 8.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.47619047619047616,
                        "recall": 0.47619047619047616,
                        "f1-score": 0.47619047619047616,
                        "support": 21.0
                    },
                    "macro avg": {
                        "precision": 0.3611111111111111,
                        "recall": 0.3055555555555556,
                        "f1-score": 0.24475524475524474,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.5978835978835979,
                        "recall": 0.47619047619047616,
                        "f1-score": 0.3902763902763902,
                        "support": 21.0
                    }
                },
                "weather_earthquakes_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "BEFORE": {
                        "precision": 0.75,
                        "recall": 0.65625,
                        "f1-score": 0.7,
                        "support": 32.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 7.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.4666666666666667,
                    "macro avg": {
                        "precision": 0.1875,
                        "recall": 0.1640625,
                        "f1-score": 0.175,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.5333333333333333,
                        "recall": 0.4666666666666667,
                        "f1-score": 0.49777777777777776,
                        "support": 45.0
                    }
                },
                "space_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 15.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.0,
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 28.0
                    }
                },
                "economy_and_business_strikes_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.6666666666666666,
                        "recall": 1.0,
                        "f1-score": 0.8,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.6666666666666666,
                        "recall": 0.6666666666666666,
                        "f1-score": 0.6666666666666666,
                        "support": 6.0
                    },
                    "macro avg": {
                        "precision": 0.16666666666666666,
                        "recall": 0.25,
                        "f1-score": 0.2,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.4444444444444444,
                        "recall": 0.6666666666666666,
                        "f1-score": 0.5333333333333333,
                        "support": 6.0
                    }
                },
                "politics_and_conflicts_armed_conflict_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.7272727272727273,
                        "recall": 0.7272727272727273,
                        "f1-score": 0.7272727272727273,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.25,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.28571428571428575,
                        "support": 3.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.6,
                        "recall": 0.6,
                        "f1-score": 0.6,
                        "support": 15.0
                    },
                    "macro avg": {
                        "precision": 0.24431818181818182,
                        "recall": 0.26515151515151514,
                        "f1-score": 0.2532467532467533,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.5833333333333334,
                        "recall": 0.6,
                        "f1-score": 0.5904761904761905,
                        "support": 15.0
                    }
                },
                "infectious_disease_4": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.25,
                        "f1-score": 0.25,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    }
                },
                "health_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "BEFORE": {
                        "precision": 0.3,
                        "recall": 1.0,
                        "f1-score": 0.4615384615384615,
                        "support": 3.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.3,
                        "recall": 0.3,
                        "f1-score": 0.3,
                        "support": 10.0
                    },
                    "macro avg": {
                        "precision": 0.075,
                        "recall": 0.25,
                        "f1-score": 0.11538461538461538,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.09,
                        "recall": 0.3,
                        "f1-score": 0.13846153846153847,
                        "support": 10.0
                    }
                },
                "disasters_and_accidents_shipwreck_2": {
                    "AFTER": {
                        "precision": 0.5,
                        "recall": 0.09090909090909091,
                        "f1-score": 0.15384615384615385,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.4166666666666667,
                        "recall": 0.5555555555555556,
                        "f1-score": 0.4761904761904762,
                        "support": 9.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.2857142857142857,
                    "macro avg": {
                        "precision": 0.22916666666666669,
                        "recall": 0.16161616161616163,
                        "f1-score": 0.1575091575091575,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.44047619047619047,
                        "recall": 0.2857142857142857,
                        "f1-score": 0.2846677132391418,
                        "support": 21.0
                    }
                },
                "rail_transport_3": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.4,
                        "f1-score": 0.5714285714285715,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.7692307692307693,
                        "recall": 1.0,
                        "f1-score": 0.8695652173913044,
                        "support": 10.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.8,
                        "recall": 0.8,
                        "f1-score": 0.8000000000000002,
                        "support": 15.0
                    },
                    "macro avg": {
                        "precision": 0.4423076923076923,
                        "recall": 0.35,
                        "f1-score": 0.36024844720496896,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.8461538461538463,
                        "recall": 0.8,
                        "f1-score": 0.7701863354037268,
                        "support": 15.0
                    }
                },
                "weather_storms_1_extra": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.25,
                        "f1-score": 0.25,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 1.0,
                        "recall": 1.0,
                        "f1-score": 1.0,
                        "support": 1.0
                    }
                },
                "health_1_extra": {
                    "AFTER": {
                        "precision": 0.8571428571428571,
                        "recall": 0.5,
                        "f1-score": 0.631578947368421,
                        "support": 12.0
                    },
                    "BEFORE": {
                        "precision": 0.6363636363636364,
                        "recall": 1.0,
                        "f1-score": 0.7777777777777778,
                        "support": 28.0
                    },
                    "COEX": {
                        "precision": 0.75,
                        "recall": 0.2,
                        "f1-score": 0.31578947368421056,
                        "support": 15.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.6727272727272727,
                        "recall": 0.6727272727272727,
                        "f1-score": 0.6727272727272727,
                        "support": 55.0
                    },
                    "macro avg": {
                        "precision": 0.5608766233766234,
                        "recall": 0.425,
                        "f1-score": 0.4312865497076024,
                        "support": 55.0
                    },
                    "weighted avg": {
                        "precision": 0.7155253837072019,
                        "recall": 0.6727272727272727,
                        "f1-score": 0.6198830409356726,
                        "support": 55.0
                    }
                },
                "weather_floods_1": {
                    "AFTER": {
                        "precision": 0.125,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.18181818181818182,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.43243243243243246,
                        "recall": 0.6666666666666666,
                        "f1-score": 0.5245901639344263,
                        "support": 24.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 28.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.3090909090909091,
                    "macro avg": {
                        "precision": 0.13935810810810811,
                        "recall": 0.25,
                        "f1-score": 0.176602086438152,
                        "support": 55.0
                    },
                    "weighted avg": {
                        "precision": 0.19551597051597053,
                        "recall": 0.3090909090909091,
                        "f1-score": 0.23882942690692316,
                        "support": 55.0
                    }
                },
                "mining_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.5555555555555556,
                        "recall": 1.0,
                        "f1-score": 0.7142857142857143,
                        "support": 25.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 9.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.5555555555555556,
                        "recall": 0.5555555555555556,
                        "f1-score": 0.5555555555555556,
                        "support": 45.0
                    },
                    "macro avg": {
                        "precision": 0.1388888888888889,
                        "recall": 0.25,
                        "f1-score": 0.17857142857142858,
                        "support": 45.0
                    },
                    "weighted avg": {
                        "precision": 0.30864197530864196,
                        "recall": 0.5555555555555556,
                        "f1-score": 0.39682539682539686,
                        "support": 45.0
                    }
                },
                "disasters_and_accidents_volcanoes_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 20.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 1.0,
                        "f1-score": 0.6666666666666666,
                        "support": 14.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.3888888888888889,
                    "macro avg": {
                        "precision": 0.125,
                        "recall": 0.25,
                        "f1-score": 0.16666666666666666,
                        "support": 36.0
                    },
                    "weighted avg": {
                        "precision": 0.19444444444444445,
                        "recall": 0.3888888888888889,
                        "f1-score": 0.25925925925925924,
                        "support": 36.0
                    }
                },
                "politics_and_conflicts_elections_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.0,
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 15.0
                    }
                },
                "economy_and_business_strikes_3": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.4,
                        "f1-score": 0.5714285714285715,
                        "support": 10.0
                    },
                    "BEFORE": {
                        "precision": 0.5384615384615384,
                        "recall": 0.6363636363636364,
                        "f1-score": 0.5833333333333334,
                        "support": 11.0
                    },
                    "COEX": {
                        "precision": 0.25,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.18181818181818182,
                        "support": 7.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.42857142857142855,
                    "macro avg": {
                        "precision": 0.4471153846153846,
                        "recall": 0.2948051948051948,
                        "f1-score": 0.3341450216450217,
                        "support": 28.0
                    },
                    "weighted avg": {
                        "precision": 0.6311813186813187,
                        "recall": 0.42857142857142855,
                        "f1-score": 0.47870284477427344,
                        "support": 28.0
                    }
                },
                "space_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 100.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 51.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.0,
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 153.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 153.0
                    }
                },
                "politics_and_conflicts_resign_1": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.5,
                        "support": 3.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 3.0
                    },
                    "macro avg": {
                        "precision": 0.25,
                        "recall": 0.08333333333333333,
                        "f1-score": 0.125,
                        "support": 3.0
                    },
                    "weighted avg": {
                        "precision": 1.0,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.5,
                        "support": 3.0
                    }
                },
                "environment_4": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.25,
                        "f1-score": 0.4,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 0.6,
                        "f1-score": 0.42857142857142855,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.26666666666666666,
                    "macro avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.2125,
                        "f1-score": 0.20714285714285713,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.3777777777777777,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.24952380952380954,
                        "support": 15.0
                    }
                },
                "space_1_extra": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.8333333333333334,
                        "recall": 1.0,
                        "f1-score": 0.9090909090909091,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.8333333333333334,
                        "recall": 0.8333333333333334,
                        "f1-score": 0.8333333333333334,
                        "support": 6.0
                    },
                    "macro avg": {
                        "precision": 0.20833333333333334,
                        "recall": 0.25,
                        "f1-score": 0.22727272727272727,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.6944444444444445,
                        "recall": 0.8333333333333334,
                        "f1-score": 0.7575757575757575,
                        "support": 6.0
                    }
                },
                "health_3": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.375,
                        "f1-score": 0.5454545454545454,
                        "support": 8.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 1.0,
                        "f1-score": 0.6666666666666666,
                        "support": 6.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.6,
                        "recall": 0.6,
                        "f1-score": 0.6,
                        "support": 15.0
                    },
                    "macro avg": {
                        "precision": 0.375,
                        "recall": 0.34375,
                        "f1-score": 0.303030303030303,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.7333333333333333,
                        "recall": 0.6,
                        "f1-score": 0.5575757575757575,
                        "support": 15.0
                    }
                },
                "environment_3": {
                    "AFTER": {
                        "precision": 1.0,
                        "recall": 0.18181818181818182,
                        "f1-score": 0.3076923076923077,
                        "support": 11.0
                    },
                    "BEFORE": {
                        "precision": 0.25,
                        "recall": 1.0,
                        "f1-score": 0.4,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.26666666666666666,
                    "macro avg": {
                        "precision": 0.3125,
                        "recall": 0.29545454545454547,
                        "f1-score": 0.17692307692307693,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.7666666666666667,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.278974358974359,
                        "support": 15.0
                    }
                },
                "government_and_politics_protests_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "BEFORE": {
                        "precision": 0.2,
                        "recall": 1.0,
                        "f1-score": 0.33333333333333337,
                        "support": 1.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.16666666666666666,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.16666666666666666,
                        "support": 6.0
                    },
                    "macro avg": {
                        "precision": 0.05,
                        "recall": 0.25,
                        "f1-score": 0.08333333333333334,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.03333333333333333,
                        "recall": 0.16666666666666666,
                        "f1-score": 0.05555555555555556,
                        "support": 6.0
                    }
                },
                "economy_and_business_financial_crisis_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 12.0
                    },
                    "BEFORE": {
                        "precision": 0.16666666666666666,
                        "recall": 0.6,
                        "f1-score": 0.2608695652173913,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.14285714285714285,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.14285714285714285,
                        "support": 21.0
                    },
                    "macro avg": {
                        "precision": 0.041666666666666664,
                        "recall": 0.15,
                        "f1-score": 0.06521739130434782,
                        "support": 21.0
                    },
                    "weighted avg": {
                        "precision": 0.03968253968253968,
                        "recall": 0.14285714285714285,
                        "f1-score": 0.062111801242236024,
                        "support": 21.0
                    }
                },
                "computers_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    }
                },
                "crime_and_law_accuse_4": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.5,
                        "recall": 1.0,
                        "f1-score": 0.6666666666666666,
                        "support": 5.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.5,
                        "recall": 0.5,
                        "f1-score": 0.5,
                        "support": 10.0
                    },
                    "macro avg": {
                        "precision": 0.125,
                        "recall": 0.25,
                        "f1-score": 0.16666666666666666,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.25,
                        "recall": 0.5,
                        "f1-score": 0.3333333333333333,
                        "support": 10.0
                    }
                },
                "culture_and_entertainment_1": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "BEFORE": {
                        "precision": 0.3333333333333333,
                        "recall": 1.0,
                        "f1-score": 0.5,
                        "support": 2.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 2.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.3333333333333333,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.3333333333333333,
                        "support": 6.0
                    },
                    "macro avg": {
                        "precision": 0.08333333333333333,
                        "recall": 0.25,
                        "f1-score": 0.125,
                        "support": 6.0
                    },
                    "weighted avg": {
                        "precision": 0.1111111111111111,
                        "recall": 0.3333333333333333,
                        "f1-score": 0.16666666666666666,
                        "support": 6.0
                    }
                },
                "internet_2": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 1.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "accuracy": 0.0,
                    "macro avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 10.0
                    },
                    "weighted avg": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 10.0
                    }
                },
                "culture_and_entertainment_3": {
                    "AFTER": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 5.0
                    },
                    "BEFORE": {
                        "precision": 0.26666666666666666,
                        "recall": 1.0,
                        "f1-score": 0.4210526315789474,
                        "support": 4.0
                    },
                    "COEX": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 6.0
                    },
                    "null": {
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1-score": 0.0,
                        "support": 0.0
                    },
                    "micro avg": {
                        "precision": 0.26666666666666666,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.26666666666666666,
                        "support": 15.0
                    },
                    "macro avg": {
                        "precision": 0.06666666666666667,
                        "recall": 0.25,
                        "f1-score": 0.10526315789473685,
                        "support": 15.0
                    },
                    "weighted avg": {
                        "precision": 0.07111111111111111,
                        "recall": 0.26666666666666666,
                        "f1-score": 0.11228070175438597,
                        "support": 15.0
                    }
                }
            }
        }
    }
}

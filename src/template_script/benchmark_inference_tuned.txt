#!/usr/bin/bash

export CUDA_VISIBLE_DEVICES=0

if [ -n "$MAMBA_EXE" ]; then
  CONDA=micromamba
  eval "$(micromamba shell hook -s bash)"
else
  CONDA=conda
  eval "$(conda shell.bash hook)"
fi

$CONDA activate llm

dirpath_output=./output/benchmark/
dirpath_output_score=./output_score/benchmark/
dirpath_log=./log
filepath_test={filepath_data_test}

dataset_name={dataset_name}
inference_type={inference_type}
seeds=( 7 )

batch_size=8
model_id={model_id}
precision_type={precision_type}
num_gpu=1

max_new_tokens=64
num_demonstration=0
temperature=0

dirpath_model={dirpath_model}
peft_model_path={peft_model_path}

for seed in "${seeds[@]}"; do
    python src/{code}.py \
        --batch_size $batch_size \
        --dataset_name $dataset_name \
        --dirpath_log $dirpath_log \
        --dirpath_model $dirpath_model \
        --dirpath_output $dirpath_output \
        --dirpath_output_score $dirpath_output_score \
        --filepath_test $filepath_test \
        --inference_type $inference_type \
        --model_id $model_id \
        --num_gpu $num_gpu \
        --precision_type $precision_type \
        --peft_model_path $peft_model_path \
        --max_new_tokens $max_new_tokens \
        --num_demonstration $num_demonstration \
        --temperature $temperature \
        --seed "$seed"
done

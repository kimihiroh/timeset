{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f897701b-222c-4eb3-93ca-017524385ee5",
   "metadata": {},
   "source": [
    "# Check FT/PEFT results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e42d36-c753-4089-979f-b8c0cdd7abd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e9ca3e-b3e5-4ba7-a831-524e41bc48bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\"temporal-nli\", \"torque\", \"tddiscourse\", \"matres\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d17bb28-c18c-46f4-8210-65cc496c688f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in datasets:\n",
    "    print(f\"<{dataset}>\")\n",
    "    for filepath in Path(f\"../output_score/benchmark/{dataset}/\").glob(\"*_ft_*/*.json\"):\n",
    "        with open(filepath, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "        print(f\"  {data['args']['model_id']}\")\n",
    "        if dataset == \"temporal-nli\":\n",
    "            score = data['individuals']['example-wise-scores']['0']['macro avg']['f1-score']\n",
    "            print(f\"    {metric}: {score:.3f}\")\n",
    "        elif dataset == 'matres':\n",
    "            score = data['individuals']['example-wise-scores']['0']['micro avg']['f1-score']\n",
    "            print(f\"    {metric}: {score:.3f}\")\n",
    "        else:\n",
    "            for metric, scores in data['average'].items():\n",
    "                print(f\"    {metric}: {scores['median']:.3f}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5ff0e9-62c5-473c-a260-f6c4caa67013",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in datasets:\n",
    "    print(f\"<{dataset}>\")\n",
    "    for filepath in Path(f\"../output_score/benchmark/{dataset}/\").glob(\"*_peft_*/*.json\"):\n",
    "        with open(filepath, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "        print(f\"  {data['args']['model_id']}\")\n",
    "        \n",
    "        if dataset == \"temporal-nli\":\n",
    "            score = data['individuals']['example-wise-scores']['0']['macro avg']['f1-score']\n",
    "            print(f\"    {metric}: {score:.3f}\")\n",
    "        elif dataset == 'matres':\n",
    "            score = data['individuals']['example-wise-scores']['0']['micro avg']['f1-score']\n",
    "            print(f\"    {metric}: {score:.3f}\")\n",
    "        else:\n",
    "            for metric, scores in data['average'].items():\n",
    "                print(f\"    {metric}: {scores['median']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f67b63-7c6c-4553-a429-bb3df1ae8c2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff053aa1-8c61-4533-85fd-7060dee212f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c68766-7daa-4e97-b852-6618bcd8e518",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04b3b7f-b6e9-4c61-b288-8c50b05cfd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dirpath = Path(\"#TODO: dir\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d709c71a-4ce3-4ce9-bbcc-2c511bb61325",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\"matres\", \"torque\", \"tddiscourse\", \"temporal-nli\"]\n",
    "best = defaultdict(lambda: defaultdict(lambda: defaultdict(float)))\n",
    "count_log = defaultdict(lambda: defaultdict(int))\n",
    "for dataset in datasets:\n",
    "    \n",
    "    dirpath_dataset = dirpath / dataset\n",
    "    for dirpath_model in dirpath_dataset.glob('*'):\n",
    "        \n",
    "        for filepath_log in dirpath_model.glob('*.log'):\n",
    "            with open(filepath_log, \"r\") as f:\n",
    "                log = json.load(f)\n",
    "            if log[\"best\"]:\n",
    "                score = log[\"best\"][\"score\"]\n",
    "            else:\n",
    "                score = .0\n",
    "            count_log[dataset][dirpath_model.name] += 1\n",
    "            if best[dataset][dirpath_model.name][\"score\"] < score:\n",
    "                best[dataset][dirpath_model.name][\"score\"] = score\n",
    "                best[dataset][dirpath_model.name][\"path\"] = filepath_log.parent / filepath_log.stem\n",
    "\n",
    "for dataset, values in best.items():\n",
    "    print(f\"\\n[{dataset}]\")\n",
    "    for model, _values in values.items():\n",
    "        path_name = _values['path'].name if _values['path'] else \"None\"\n",
    "        print(f\"  {model:55}: {_values['score']:.3f}, ({count_log[dataset][model]}), {path_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3852dd5-eed8-4670-9c3a-23ef18f93d8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7836172b-8bbc-4e73-9bee-563fc836bb40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f830de7-ccce-4454-843e-8fbea2891eae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc6e853-8ec9-410c-abd6-820c2f9306c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\"temporal-nli\", \"matres\", \"tddiscourse\", \"torque\"]\n",
    "model_ids = [\"Llama-2-7b-hf\", \"Llama-2-7b-chat-hf\", \"Llama-2-13b-hf\", \"Llama-2-70b-hf\", \"flan-t5-xl\", \"flan-t5-xxl\", \"t5-3b\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b4571e-c3be-41c5-a800-883180b2b073",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "dirpath = Path(\"../output_score/benchmark/\")\n",
    "scores = defaultdict(lambda: defaultdict(list))\n",
    "for dataset in datasets:\n",
    "    print(dataset)\n",
    "    for model_id in model_ids:\n",
    "        print(f\"  {model_id}\")\n",
    "        for filepath in dirpath.glob(f\"{dataset}/*{model_id}*few-shot*/*.json\"):\n",
    "            \n",
    "            with open(filepath, \"r\") as f:\n",
    "                data = json.load(f)\n",
    "            \n",
    "            if dataset == \"temporal-nli\":\n",
    "                _max = statistics.median(\n",
    "                    [x['macro avg']['f1-score'] for x in data['individuals']['example-wise-scores'].values()]\n",
    "                )\n",
    "                scores[dataset][model_id].append(_max)\n",
    "            elif dataset == 'matres':\n",
    "                # for k, x in data['individuals']['example-wise-scores'].items():\n",
    "                #     if 'micro avg' not in x:\n",
    "                #         print(filepath)\n",
    "                #         print(k)\n",
    "                #         print(x)\n",
    "                _max = statistics.median(\n",
    "                    [x['micro avg']['f1-score'] if 'micro avg' in x else x['accuracy'] for x in data['individuals']['example-wise-scores'].values()]\n",
    "                )\n",
    "                scores[dataset][model_id].append(_max)\n",
    "            else:\n",
    "                if dataset == \"torque\":\n",
    "                    _max = data['average']['exact-match-relaxed']['median']\n",
    "                else:\n",
    "                    _max = data['average']['example-wise-scores']['median']\n",
    "                scores[dataset][model_id].append(_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f1ad0e-4f59-4cda-a33c-040bec217082",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset, _scores in scores.items():\n",
    "    print(f\"{dataset}\")\n",
    "    for model, __scores in _scores.items():\n",
    "        print(f\"  {model}: {max(__scores):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a849e141-89cc-45ae-b5be-dce64dcb32e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "timeset",
   "language": "python",
   "name": "timeset"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
